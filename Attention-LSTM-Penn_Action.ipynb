{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acba090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa13c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf0822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeab214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a504b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn='D:/Penn_Action/*/'\n",
    "tr= glob(trn)\n",
    "\n",
    "len(tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ff3ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Penn_Action\\\\baseball_pitch\\\\0001\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0002\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0003\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0004\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0005\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0006\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0007\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0008\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0009\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0011\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0012\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0013\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0014\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0015\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0016\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0017\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0018\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0019\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0020\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0021\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0022\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0023\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0024\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0025\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0026\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0027\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0028\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0029\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0030\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0031\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0032\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0033\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0034\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0035\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0036\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0037\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0038\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0039\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0040\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0041\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0042\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0043\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0044\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0045\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0046\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0047\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0048\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0049\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0050\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0051\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0052\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0053\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0054\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0055\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0056\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0057\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0058\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0059\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0060\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0061\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0062\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0063\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0064\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0065\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0066\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0067\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0068\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0069\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0070\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0071\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0072\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0073\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0074\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0075\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0076\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0077\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0078\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0079\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0080\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0081\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0082\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0083\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0084\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0085\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0086\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0087\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0088\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0089\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0090\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0091\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0092\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0093\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0094\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0095\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0096\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0097\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0098\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0099\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0100\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0101\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0102\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0103\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0104\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0105\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0106\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0107\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0108\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0109\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0110\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0111\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0112\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0113\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0114\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0115\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0116\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0117\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0118\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0119\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0120\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0121\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0122\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0123\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0124\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0125\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0126\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0127\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0128\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0129\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0130\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0131\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0132\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0133\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0134\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0135\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0136\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0137\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0138\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0139\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0140\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0141\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0142\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0143\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0144\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0145\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0146\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0147\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0148\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0149\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0150\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0151\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0152\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0153\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0154\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0155\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0156\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0157\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0158\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0159\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0160\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0161\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0162\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0163\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0164\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0165\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0166\\\\',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0167\\\\']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = glob(tr[0]+'/*/')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb9999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "test_y = []\n",
    "\n",
    "y = 0\n",
    "for i in tr:\n",
    "    \n",
    "    #print(i)\n",
    "    x = glob(i+'/*/')\n",
    "    \n",
    "    #shuffle(x)\n",
    "    t,v = train_test_split( x , test_size=0.2, random_state=42)\n",
    "    vv, tt = train_test_split( v , test_size=0.5, random_state=42)\n",
    "    \n",
    "    for j in t:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "        \n",
    "        train.append(j)\n",
    "        train_y.append(y)\n",
    "    \n",
    "    for j in vv:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        val.append(j)\n",
    "        val_y.append(y)\n",
    "        \n",
    "    for j in tt:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        test.append(j)\n",
    "        test_y.append(y)\n",
    "        \n",
    "    y = y+1\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tra_y =  np.array(to_categorical(train_y))\n",
    "va_y  =  np.array(to_categorical(val_y))\n",
    "te_y  =  np.array(to_categorical(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5cbea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, tra_y) = shuffle(train, tra_y)\n",
    "(val, va_y) = shuffle(val, va_y)\n",
    "(test, te_y) = shuffle(test, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0b6466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bf33ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000001.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000002.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000003.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000004.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000005.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000006.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000007.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000008.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000009.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000010.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000011.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000012.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000013.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000014.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000015.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000016.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000017.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000018.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000019.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000020.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000021.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000022.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000023.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000024.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000025.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000026.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000027.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000028.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000029.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000030.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000031.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000032.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000033.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000034.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000035.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000036.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000037.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000038.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000039.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000040.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000041.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000042.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000043.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000044.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000045.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000046.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000047.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000048.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000049.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000050.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000051.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000052.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000053.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000054.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000055.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000056.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000057.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000058.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000059.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000060.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000061.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000062.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000063.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000064.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000065.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000066.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000067.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000068.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000069.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000070.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000071.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000072.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000073.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000074.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000075.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000076.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000077.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000078.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000079.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000080.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000081.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000082.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000083.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000084.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000085.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000086.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000087.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000088.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000089.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000090.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000091.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000092.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000093.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000094.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000095.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000096.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000097.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000098.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000099.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000100.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000101.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000102.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000103.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000104.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000105.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000106.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000107.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000108.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000109.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000110.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\000111.jpg',\n",
       " 'E:/Penn_Action\\\\baseball_pitch\\\\0010\\\\PaxHeaders.46615']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = glob(val[5]+'/*')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb778605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b3703c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    higher = len(x)\n",
    "    import more_itertools as mit\n",
    "    \n",
    "    y = mit.random_combination(range(0, higher), r=15)\n",
    "\n",
    "    for i in y:\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((50, 50))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(50,50,3))\n",
    "        \n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d63babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def get_tex(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    higher = len(x)\n",
    "    import more_itertools as mit\n",
    "    \n",
    "    y = mit.random_combination(range(0, higher), r=15)\n",
    "\n",
    "    for i in y:\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((50, 50))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(50,50,3))\n",
    "        \n",
    "    y = mit.random_combination(range(0, 2), r=1)\n",
    "    \n",
    "    if (y == 0):\n",
    "        gen = ImageDataGenerator()\n",
    "        imgdat = []    \n",
    "        for i in range(0,len(imgdata)):\n",
    "            imgdat.append ( gen.apply_transform(imgdata[i], {'ty':100, 'theta':10}) )\n",
    "            \n",
    "    imgdat = imgdata\n",
    "    idata = np.array(imgdat)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3c98322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_tex(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4331b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , batch_size) :\n",
    "    self.filename = filename\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6bc375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(train, tra_y, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(val, va_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbe2817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = My_Test_Generator(test, batch_size).__getitem__(7)\n",
    "arr = np.array(My_Test_Generator(test, batch_size).__getitem__(0))\n",
    "for i in range(1,(len(x))):\n",
    "    x = My_Test_Generator(test, batch_size).__getitem__(i)\n",
    "    arr = np.concatenate((arr,x),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fdbdc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2727, 5893, 6243, 6705, 6836, 7698, 9264, 9331, 9652, 9751)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import more_itertools as mit\n",
    "y = mit.random_combination(range(1000, 10000), r=10)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a8275bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = My_Test_Generator(test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef19bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a8e6e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 15, 50, 50, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3e51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9c51980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10, 60, 60, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c6d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d262b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c2759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "56c507ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3499, 6, 28, 28, 3)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52b5cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"organmnist3d\"\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = ( 6, 28, 28, 3 )\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 60\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (4, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ae32102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88acaa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf0e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c674b1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6123, 2)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31947b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fc77872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "inputs = layers.Input(shape= (6,28,28,3) )\n",
    "\n",
    "x = (TimeDistributed( Flatten() )) (inputs)\n",
    "y = TimeDistributed(layers.Dense(units=256, activation=\"tanh\")) (x)\n",
    "\n",
    "z = LSTM(128,return_sequences=True,dropout=0.1) (y)\n",
    "\n",
    "encoded_patches = (PatchEncoder(6, 128 )) (z)\n",
    "\n",
    "for _ in range(2):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=2, key_dim=128, dropout=0.1 )  (x1, x1)\n",
    "\n",
    "        \n",
    "    x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(LSTM(128,return_sequences=False,dropout=0.2) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = LSTM(100,return_sequences=False,dropout=0.2)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=2, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f07b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ce1b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50e37073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(8, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                (layers.Conv2D(16, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                (layers.Conv2D(32, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim),\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26057200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 15, 50, 50,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder (PatchEncoder)    (None, 15, 32)       22928       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 15, 32)       64          patch_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 15, 32)       8416        layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 15, 32)       8320        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 15, 32)       0           multi_head_attention[0][0]       \n",
      "                                                                 patch_encoder[0][0]              \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 15, 32)       64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 15, 32)       1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 15, 32)       0           sequential_1[0][0]               \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 15, 32)       64          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 15, 32)       8416        layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 15, 32)       8320        layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 32)       0           multi_head_attention_1[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 15, 32)       64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 15, 32)       1056        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 15, 32)       0           sequential_2[0][0]               \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 15, 32)       64          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 15)           495         global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 59,327\n",
      "Trainable params: 59,327\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "inputs = layers.Input(shape= (15,50,50,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(15, 32 )) (inputs)\n",
    "\n",
    "for _ in range(2):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=2, key_dim=32, dropout=0.2 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.2)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=15, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8262812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.0000001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2676f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chsha\\AppData\\Local\\Temp/ipykernel_15552/3135080164.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "58/58 [==============================] - 525s 9s/step - loss: 0.2004 - accuracy: 0.9326 - val_loss: 4.9774 - val_accuracy: 0.3906\n",
      "Epoch 2/2\n",
      "58/58 [==============================] - 508s 9s/step - loss: 0.1316 - accuracy: 0.9542 - val_loss: 4.7092 - val_accuracy: 0.3991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e65409d60>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 2,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef7bac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chsha\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
      "C:\\Users\\chsha\\AppData\\Local\\Temp/ipykernel_2348/1543328956.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(My_Test_Generator(test, batch_size), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b4d89f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "p = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c36be08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 32\n  y sizes: 200\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2348/1530380399.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlossAndMetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlossAndMetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1464\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m         \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1466\u001b[1;33m         data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1467\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1647\u001b[0m           label, \", \".join(str(i.shape[0]) for i in tf.nest.flatten(single_data)))\n\u001b[0;32m   1648\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1649\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 32\n  y sizes: 200\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "lossAndMetrics = model.evaluate(arr[:200], te_y[:])\n",
    "lossAndMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d68227f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chsha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:217: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test, p)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bb2f5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.160373687744141, 0.36000001430511475]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9acfadae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08dc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847db778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0cf3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split( train_df,YY_Train , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4cc7dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
    "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
    "    # Preprocess images\n",
    "    frames = tf.image.convert_image_dtype(\n",
    "        frames[\n",
    "            ..., tf.newaxis\n",
    "        ],  # The new axis is to help for further processing with Conv3D layers\n",
    "        tf.float32,\n",
    "    )\n",
    "    # Parse label\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return frames, label\n",
    "\n",
    "\n",
    "def prepare_dataloader(\n",
    "    videos: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    loader_type: str = \"train\",\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "):\n",
    "    \"\"\"Utility function to prepare the dataloader.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
    "\n",
    "    if loader_type == \"train\":\n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
    "\n",
    "    dataloader = (\n",
    "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "trainloader = prepare_dataloader(X_train , y_train , \"train\")\n",
    "validloader = prepare_dataloader(X_val, y_val, \"valid\")\n",
    "testloader = prepare_dataloader(test_df,YY_Test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0523831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f4f081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "\n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e6b82757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_vivit_classifier(\n",
    "    tubelet_embedder,\n",
    "    positional_encoder,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    transformer_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embed_dim=PROJECTION_DIM,\n",
    "    layer_norm_eps=LAYER_NORM_EPS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = tubelet_embedder(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization and MHSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
    "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
    "            ]\n",
    "        )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "28803bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 6, 28, 28, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tubelet_embedding_11 (TubeletEm (None, 9, 128)       98432       input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoder_11 (Position (None, 9, 128)       1152        tubelet_embedding_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_95 (LayerNo (None, 9, 128)       256         positional_encoder_11[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_38 (MultiH (None, 9, 128)       66048       layer_normalization_95[0][0]     \n",
      "                                                                 layer_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 9, 128)       0           multi_head_attention_38[0][0]    \n",
      "                                                                 positional_encoder_11[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_96 (LayerNo (None, 9, 128)       256         add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_38 (Sequential)      (None, 9, 128)       131712      layer_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 9, 128)       0           sequential_38[0][0]              \n",
      "                                                                 add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_97 (LayerNo (None, 9, 128)       256         add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_39 (MultiH (None, 9, 128)       66048       layer_normalization_97[0][0]     \n",
      "                                                                 layer_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 9, 128)       0           multi_head_attention_39[0][0]    \n",
      "                                                                 add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_98 (LayerNo (None, 9, 128)       256         add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_39 (Sequential)      (None, 9, 128)       131712      layer_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 9, 128)       0           sequential_39[0][0]              \n",
      "                                                                 add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_99 (LayerNo (None, 9, 128)       256         add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           layer_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 2)            258         global_average_pooling1d_11[0][0]\n",
      "==================================================================================================\n",
      "Total params: 496,642\n",
      "Trainable params: 496,642\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (4, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2\n",
    "# TRAINING\n",
    "EPOCHS = 100\n",
    "\n",
    "md = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
    "    )\n",
    "\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf326e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60360ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6aa5b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 21s 100ms/step - loss: 0.4438 - accuracy: 0.8424 - top-5-accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.8206 - val_top-5-accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.3220 - accuracy: 0.8571 - top-5-accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.8679 - val_top-5-accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.2685 - accuracy: 0.8812 - top-5-accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.8874 - val_top-5-accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.1945 - accuracy: 0.9147 - top-5-accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9119 - val_top-5-accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.1727 - accuracy: 0.9265 - top-5-accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9086 - val_top-5-accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.1640 - accuracy: 0.9294 - top-5-accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9135 - val_top-5-accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.1650 - accuracy: 0.9318 - top-5-accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9054 - val_top-5-accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.1682 - accuracy: 0.9326 - top-5-accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9201 - val_top-5-accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.1533 - accuracy: 0.9347 - top-5-accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9086 - val_top-5-accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.1515 - accuracy: 0.9392 - top-5-accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.1439 - accuracy: 0.9400 - top-5-accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9038 - val_top-5-accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.1444 - accuracy: 0.9457 - top-5-accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.1286 - accuracy: 0.9502 - top-5-accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9103 - val_top-5-accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.1529 - accuracy: 0.9400 - top-5-accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9217 - val_top-5-accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.1377 - accuracy: 0.9469 - top-5-accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9217 - val_top-5-accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.1164 - accuracy: 0.9543 - top-5-accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9315 - val_top-5-accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.1148 - accuracy: 0.9575 - top-5-accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.1081 - accuracy: 0.9543 - top-5-accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.1072 - accuracy: 0.9555 - top-5-accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9331 - val_top-5-accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.0989 - accuracy: 0.9637 - top-5-accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9282 - val_top-5-accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0997 - accuracy: 0.9608 - top-5-accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.1015 - accuracy: 0.9563 - top-5-accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9364 - val_top-5-accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 7s 87ms/step - loss: 0.0888 - accuracy: 0.9633 - top-5-accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 0.0983 - accuracy: 0.9620 - top-5-accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9429 - val_top-5-accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 0.0908 - accuracy: 0.9592 - top-5-accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9347 - val_top-5-accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 7s 84ms/step - loss: 0.0856 - accuracy: 0.9669 - top-5-accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000 \n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.1158 - accuracy: 0.9563 - top-5-accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9315 - val_top-5-accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0791 - accuracy: 0.9653 - top-5-accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9201 - val_top-5-accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0864 - accuracy: 0.9641 - top-5-accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9315 - val_top-5-accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 8s 101ms/step - loss: 0.0829 - accuracy: 0.9653 - top-5-accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9299 - val_top-5-accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.0760 - accuracy: 0.9694 - top-5-accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0746 - accuracy: 0.9698 - top-5-accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0709 - accuracy: 0.9743 - top-5-accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9299 - val_top-5-accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.0623 - accuracy: 0.9780 - top-5-accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9233 - val_top-5-accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 7s 87ms/step - loss: 0.0710 - accuracy: 0.9673 - top-5-accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9184 - val_top-5-accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0865 - accuracy: 0.9628 - top-5-accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9054 - val_top-5-accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0697 - accuracy: 0.9726 - top-5-accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9217 - val_top-5-accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.0651 - accuracy: 0.9718 - top-5-accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9299 - val_top-5-accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 0.0517 - accuracy: 0.9812 - top-5-accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9282 - val_top-5-accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 0.0587 - accuracy: 0.9767 - top-5-accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0625 - accuracy: 0.9743 - top-5-accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9168 - val_top-5-accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0583 - accuracy: 0.9771 - top-5-accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0524 - accuracy: 0.9808 - top-5-accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9217 - val_top-5-accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 0.0595 - accuracy: 0.9780 - top-5-accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0425 - accuracy: 0.9845 - top-5-accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9233 - val_top-5-accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0394 - accuracy: 0.9841 - top-5-accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9282 - val_top-5-accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0437 - accuracy: 0.9820 - top-5-accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9233 - val_top-5-accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0421 - accuracy: 0.9812 - top-5-accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9152 - val_top-5-accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.0599 - accuracy: 0.9763 - top-5-accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9282 - val_top-5-accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.0353 - accuracy: 0.9873 - top-5-accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0357 - accuracy: 0.9861 - top-5-accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9217 - val_top-5-accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 0.0357 - accuracy: 0.9878 - top-5-accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9233 - val_top-5-accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.0395 - accuracy: 0.9824 - top-5-accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0337 - accuracy: 0.9873 - top-5-accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.9135 - val_top-5-accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.0495 - accuracy: 0.9808 - top-5-accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 0.0615 - accuracy: 0.9751 - top-5-accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.9266 - val_top-5-accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0297 - accuracy: 0.9906 - top-5-accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 0.9331 - val_top-5-accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.0341 - accuracy: 0.9886 - top-5-accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9315 - val_top-5-accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0308 - accuracy: 0.9906 - top-5-accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9233 - val_top-5-accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.0349 - accuracy: 0.9878 - top-5-accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9282 - val_top-5-accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.0236 - accuracy: 0.9898 - top-5-accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.9315 - val_top-5-accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.0308 - accuracy: 0.9886 - top-5-accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9168 - val_top-5-accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0491 - accuracy: 0.9829 - top-5-accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9217 - val_top-5-accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 0.0249 - accuracy: 0.9914 - top-5-accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9103 - val_top-5-accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 8s 98ms/step - loss: 0.0383 - accuracy: 0.9849 - top-5-accuracy: 1.0000 - val_loss: 0.5387 - val_accuracy: 0.9005 - val_top-5-accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.0476 - accuracy: 0.9833 - top-5-accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9184 - val_top-5-accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.0276 - accuracy: 0.9865 - top-5-accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 0.8940 - val_top-5-accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0324 - accuracy: 0.9873 - top-5-accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9331 - val_top-5-accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.0207 - accuracy: 0.9910 - top-5-accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9152 - val_top-5-accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.0320 - accuracy: 0.9886 - top-5-accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.9135 - val_top-5-accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0308 - accuracy: 0.9878 - top-5-accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9054 - val_top-5-accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0241 - accuracy: 0.9914 - top-5-accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9233 - val_top-5-accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0267 - accuracy: 0.9914 - top-5-accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.9201 - val_top-5-accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0273 - accuracy: 0.9910 - top-5-accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.9038 - val_top-5-accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.0259 - accuracy: 0.9910 - top-5-accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9315 - val_top-5-accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.0241 - accuracy: 0.9894 - top-5-accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9201 - val_top-5-accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0202 - accuracy: 0.9939 - top-5-accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9217 - val_top-5-accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0246 - accuracy: 0.9922 - top-5-accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.8956 - val_top-5-accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0440 - accuracy: 0.9849 - top-5-accuracy: 1.0000 - val_loss: 0.5318 - val_accuracy: 0.9054 - val_top-5-accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0208 - accuracy: 0.9910 - top-5-accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.9038 - val_top-5-accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0191 - accuracy: 0.9918 - top-5-accuracy: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.8989 - val_top-5-accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 7s 91ms/step - loss: 0.0277 - accuracy: 0.9910 - top-5-accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9103 - val_top-5-accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 8s 100ms/step - loss: 0.0269 - accuracy: 0.9898 - top-5-accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9217 - val_top-5-accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.0168 - accuracy: 0.9935 - top-5-accuracy: 1.0000 - val_loss: 0.5888 - val_accuracy: 0.9054 - val_top-5-accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 7s 96ms/step - loss: 0.0504 - accuracy: 0.9820 - top-5-accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.9152 - val_top-5-accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.0142 - accuracy: 0.9967 - top-5-accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.0139 - accuracy: 0.9951 - top-5-accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9347 - val_top-5-accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0079 - accuracy: 0.9976 - top-5-accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.9331 - val_top-5-accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 0.0117 - accuracy: 0.9951 - top-5-accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.9331 - val_top-5-accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 0.0184 - accuracy: 0.9927 - top-5-accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.0294 - accuracy: 0.9873 - top-5-accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.9168 - val_top-5-accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.0299 - accuracy: 0.9898 - top-5-accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.9315 - val_top-5-accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0106 - accuracy: 0.9967 - top-5-accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9282 - val_top-5-accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 8s 99ms/step - loss: 0.0080 - accuracy: 0.9976 - top-5-accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9315 - val_top-5-accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 0.0100 - accuracy: 0.9971 - top-5-accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9086 - val_top-5-accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0189 - accuracy: 0.9931 - top-5-accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9250 - val_top-5-accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0087 - accuracy: 0.9959 - top-5-accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9282 - val_top-5-accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 0.0153 - accuracy: 0.9935 - top-5-accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9299 - val_top-5-accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0172 - accuracy: 0.9943 - top-5-accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.9070 - val_top-5-accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.0271 - accuracy: 0.9906 - top-5-accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9299 - val_top-5-accuracy: 1.0000\n",
      "41/41 [==============================] - 2s 28ms/step - loss: 0.0922 - accuracy: 0.9809 - top-5-accuracy: 1.0000\n",
      "Test accuracy: 98.09%\n",
      "Test top 5 accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_experiment():\n",
    "    # Initialize model\n",
    "    model = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
    "    )\n",
    "\n",
    "    # Compile the model with the optimizer, loss function\n",
    "    # and the metrics.\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Train the model.\n",
    "    _ = model.fit(trainloader, epochs=EPOCHS, validation_data=validloader)\n",
    "\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4c6df61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1105,   21],\n",
       "       [   4,  180]], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY_Test = YY_Test\n",
    "pred = model.predict(test_df)\n",
    "p = np.round(pred)\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = YY_Test\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f7d70cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935064935064935"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "b = 1 - ( (a[1][0]/a[1][1] + a[0][1]/a[0][0])/2  )\n",
    "r = 1 - (  a[1][1]  / (a[1][1] + a[0][1])  )\n",
    "print(f,b,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a3620fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398567119155354"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d38f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f75542c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "199466a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train_df[19]\n",
    "y = train_df[3]\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "im1 = np.arange(100).reshape((10, 10))\n",
    "im2 = im1.T\n",
    "im3 = np.flipud(im1)\n",
    "im4 = np.fliplr(im2)\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, [x[0], x[1], x[2], x[3],y[0], y[1], y[2], y[3]]):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3eb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257102bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "027188ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, ZeroPadding3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea8a42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 10, 43, 40, 2)     164       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 10, 21, 20, 2)     0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 10, 21, 20, 4)     220       \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 5, 10, 10, 4)      0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 5, 10, 10, 8)      872       \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 2, 5, 5, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 2, 5, 5, 16)       3472      \n",
      "_________________________________________________________________\n",
      "poodfl3 (MaxPooling3D)       (None, 1, 2, 2, 16)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 51)                5151      \n",
      "=================================================================\n",
      "Total params: 16,379\n",
      "Trainable params: 16,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(2, (3, 3, 3), activation=\"relu\",name=\"conv1\",   input_shape=(10,43,40,3), strides=(1, 1, 1), padding=\"same\"))  \n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\"))\n",
    "model.add(Conv3D(4, (3, 3, 3), activation=\"relu\",name=\"conv2\", strides=(1, 1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\"))\n",
    "model.add(Conv3D(8, (3, 3, 3), activation=\"relu\",name=\"conv3a\", strides=(1, 1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\"))\n",
    "model.add(Conv3D(16, (3, 3, 3), activation=\"relu\",name=\"conv4a\", strides=(1, 1, 1), padding=\"same\")) \n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"poodfl3\", padding=\"valid\"))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "                     \n",
    "    # FC layers group\n",
    "model.add(Dense(100, activation='relu', name='fc6'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(51, activation='softmax', name='fc8'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1b41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chsha\\AppData\\Local\\Temp/ipykernel_19652/2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "122/122 [==============================] - 580s 5s/step - loss: 3.9375 - accuracy: 0.0643 - val_loss: 3.9140 - val_accuracy: 0.0883\n",
      "Epoch 2/100\n",
      "101/122 [=======================>......] - ETA: 1:23 - loss: 3.9179 - accuracy: 0.0597"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac55aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test\n",
    "pred = model.predict(test_df)\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5845ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "b = 1 - ( (a[1][0]/a[1][1] + a[0][1]/a[0][0])/2  )\n",
    "r = 1 - (  a[1][1]  / (a[1][1] + a[0][1])  )\n",
    "print(f,b,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3fe9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fd8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f6883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c412a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b058ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43530db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99db6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b30013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf04e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7ac18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196759ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5bfae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4f0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250da400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
