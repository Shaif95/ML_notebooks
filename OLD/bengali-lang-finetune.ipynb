{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":85416,"databundleVersionId":9690815,"sourceType":"competition"},{"sourceId":11371,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":5171,"modelId":3533},{"sourceId":27825,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":22009,"modelId":3533}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U keras-nlp tensorflow datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T06:03:39.698925Z","iopub.execute_input":"2025-01-14T06:03:39.699471Z","iopub.status.idle":"2025-01-14T06:05:01.194035Z","shell.execute_reply.started":"2025-01-14T06:03:39.699435Z","shell.execute_reply":"2025-01-14T06:05:01.192956Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-nlp in /opt/conda/lib/python3.10/site-packages (0.15.1)\nCollecting keras-nlp\n  Downloading keras_nlp-0.18.1-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nCollecting tensorflow\n  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nCollecting datasets\n  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\nCollecting keras-hub==0.18.1 (from keras-nlp)\n  Downloading keras_hub-0.18.1-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (21.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (2024.5.15)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (13.7.1)\nRequirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (0.3.1)\nRequirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras-hub==0.18.1->keras-nlp) (2.16.1)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nCollecting tensorboard<2.19,>=2.18 (from tensorflow)\n  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting keras>=3.5.0 (from tensorflow)\n  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nCollecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.11.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-hub==0.18.1->keras-nlp) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.18.1->keras-nlp) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-hub==0.18.1->keras-nlp) (2.18.0)\nCollecting tensorflow\n  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.3.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.18.1->keras-nlp) (0.1.2)\nDownloading keras_nlp-0.18.1-py3-none-any.whl (2.0 kB)\nDownloading keras_hub-0.18.1-py3-none-any.whl (691 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.2/691.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras, tensorflow, datasets, keras-hub, keras-nlp\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.16.1\n    Uninstalling tensorflow-2.16.1:\n      Successfully uninstalled tensorflow-2.16.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.0.1\n    Uninstalling datasets-3.0.1:\n      Successfully uninstalled datasets-3.0.1\n  Attempting uninstall: keras-nlp\n    Found existing installation: keras-nlp 0.15.1\n    Uninstalling keras-nlp-0.15.1:\n      Successfully uninstalled keras-nlp-0.15.1\nSuccessfully installed datasets-3.2.0 keras-3.8.0 keras-hub-0.18.1 keras-nlp-0.18.1 tensorflow-2.16.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install transformers datasets tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T06:05:01.196085Z","iopub.execute_input":"2025-01-14T06:05:01.196369Z","iopub.status.idle":"2025-01-14T06:05:09.441461Z","shell.execute_reply.started":"2025-01-14T06:05:01.196341Z","shell.execute_reply":"2025-01-14T06:05:09.440399Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.2.0)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install keras_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T06:05:09.442708Z","iopub.execute_input":"2025-01-14T06:05:09.442996Z","iopub.status.idle":"2025-01-14T06:05:17.417174Z","shell.execute_reply.started":"2025-01-14T06:05:09.442968Z","shell.execute_reply":"2025-01-14T06:05:17.416069Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras_hub in /opt/conda/lib/python3.10/site-packages (0.18.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras_hub) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras_hub) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras_hub) (21.3)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras_hub) (2024.5.15)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras_hub) (13.7.1)\nRequirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras_hub) (0.3.1)\nRequirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras_hub) (2.16.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras_hub) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kagglehub->keras_hub) (4.66.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras_hub) (3.1.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras_hub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras_hub) (2.18.0)\nRequirement already satisfied: tensorflow<2.17,>=2.16.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text->keras_hub) (2.16.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras_hub) (0.1.2)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (3.8.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (0.37.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->kagglehub->keras_hub) (2024.8.30)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (0.43.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (0.11.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (3.0.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_hub) (2.1.5)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Wikipedia Bengali Sentence Scraper**\nThis Python script scrapes **Bengali sentences** from 6 main Wikipedia pages and **10 random linked pages** from each, resulting in a total of **66 pages**. The script uses `requests` to fetch the page content, `BeautifulSoup` to parse the HTML, and `re` to ensure sentences contain Bengali characters.\n\n### **Code Explanation:**\n\n1. **Function `extract_sentences_from_url(url)`**:\n   - Takes a Wikipedia URL as input and extracts Bengali sentences.\n   - Sentences are split using the Bengali full stop (`।`).\n   - Ensures the sentences contain Bengali characters (Unicode `\\u0980-\\u09FF`).\n   \n2. **Main URL List**:\n   - Contains 6 main Wikipedia pages related to notable Bengali figures and topics.\n   \n3. **Loop Through Pages**:\n   - For each main page, sentences are extracted.\n   - Finds all Wikipedia links (`/wiki/`) on the page.\n   - 10 random links are selected from each page.\n   - Sentences from the linked pages are also extracted.\n   \n4. **Final Output**:\n   - The `random_bengali_sentences` list contains all the scraped Bengali sentences.\n   - Prints the first 5 Bengali sentences for verification.\n","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport random\nimport re\n\n# Function to extract Bengali sentences from a Wikipedia page\ndef extract_sentences_from_url(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    paragraphs = soup.find_all(\"p\")\n    bengali_sentences = []\n    \n    for para in paragraphs:\n        text = para.get_text(strip=True)\n        sentences = text.split('।')  # Split using Bengali full stop\n        for sentence in sentences:\n            sentence = sentence.strip()\n            if re.search(r'[\\u0980-\\u09FF]', sentence):  # Ensure it's a Bengali sentence\n                bengali_sentences.append(sentence + '।')  # Add Bengali full stop\n    return bengali_sentences\n\n# Main Wikipedia page URLs\nmain_urls = [\n    \"https://bn.wikipedia.org/wiki/%E0%A6%B0%E0%A6%AC%E0%A7%80%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A7%8D%E0%A6%B0%E0%A6%A8%E0%A6%BE%E0%A6%A5_%E0%A6%A0%E0%A6%BE%E0%A6%95%E0%A7%81%E0%A6%B0\",\n    \"https://bn.wikipedia.org/wiki/%E0%A6%B8%E0%A7%81%E0%A6%AD%E0%A6%BE%E0%A6%B7%E0%A6%9A%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A7%8D%E0%A6%B0_%E0%A6%AC%E0%A6%B8%E0%A7%81\",\n    \"https://bn.wikipedia.org/wiki/%E0%A6%85%E0%A6%AE%E0%A6%B0%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%AF_%E0%A6%B8%E0%A7%87%E0%A6%A8\",\n    \"https://bn.wikipedia.org/wiki/%E0%A6%B6%E0%A7%87%E0%A6%96_%E0%A6%AE%E0%A7%81%E0%A6%9C%E0%A6%BF%E0%A6%AC%E0%A7%81%E0%A6%B0_%E0%A6%B0%E0%A6%B9%E0%A6%AE%E0%A6%BE%E0%A6%A8\",\n    \"https://bn.wikipedia.org/wiki/%E0%A6%B8%E0%A6%A4%E0%A7%8D%E0%A6%AF%E0%A6%9C%E0%A6%BF%E0%A7%8E_%E0%A6%B0%E0%A6%BE%E0%A6%AF%E0%A6%BC\",\n    \"https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%BE%E0%A6%82%E0%A6%B2%E0%A6%BE%E0%A6%A6%E0%A7%87%E0%A6%B6%E0%A7%87_%E0%A6%A8%E0%A6%BE%E0%A6%B0%E0%A7%80\"\n]\n\n# Final list to store all Bengali sentences\nall_sentences = []\n\n# Iterate over each main page\nfor main_url in main_urls:\n    # Extract sentences from the main page\n    main_page_sentences = extract_sentences_from_url(main_url)\n    all_sentences.extend(main_page_sentences)\n\n    # Get 10 random links from each main page\n    response = requests.get(main_url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    links = soup.find_all(\"a\", href=True)\n    wiki_links = [\"https://bn.wikipedia.org\" + link[\"href\"] for link in links if link[\"href\"].startswith(\"/wiki/\")]\n    random_links = random.sample(wiki_links, 10)  # Select 10 random links\n\n    # Extract sentences from each linked page\n    for link in random_links:\n        linked_page_sentences = extract_sentences_from_url(link)\n        all_sentences.extend(linked_page_sentences)\n\n# Store the first 5 Bengali sentences for display\nrandom_bengali_sentences = all_sentences\n\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T06:14:18.115944Z","iopub.execute_input":"2025-01-14T06:14:18.116248Z","iopub.status.idle":"2025-01-14T06:15:20.088073Z","shell.execute_reply.started":"2025-01-14T06:14:18.116220Z","shell.execute_reply":"2025-01-14T06:15:20.087211Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"len(all_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T06:15:20.089537Z","iopub.execute_input":"2025-01-14T06:15:20.089911Z","iopub.status.idle":"2025-01-14T06:15:20.095991Z","shell.execute_reply.started":"2025-01-14T06:15:20.089873Z","shell.execute_reply":"2025-01-14T06:15:20.095233Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"7321"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# **Display Sample Bengali Sentences**\nThis section takes a subset of the extracted Bengali sentences and displays them for verification.\n- We select the **first 3 Bengali sentences** from the `all_sentences` list.\n- The sentences are then printed with their index to provide a sample overview.\n","metadata":{}},{"cell_type":"code","source":"# Store the first 5 Bengali sentences for display\nrrandom_bengali_sentences = all_sentences[:3]\n\n# Output the Bengali sentences\nfor idx, sentence in enumerate(rrandom_bengali_sentences):\n    print(f\"Sentence {idx + 1}: {sentence}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T06:15:20.111966Z","iopub.execute_input":"2025-01-14T06:15:20.112191Z","iopub.status.idle":"2025-01-14T06:15:20.119956Z","shell.execute_reply.started":"2025-01-14T06:15:20.112155Z","shell.execute_reply":"2025-01-14T06:15:20.119143Z"}},"outputs":[{"name":"stdout","text":"Sentence 1: এটি এই পাতার একটি পরীক্ষিত সংস্করণ।\nSentence 2: রবীন্দ্রনাথ ঠাকুরএফআরএএস(৭ মে ১৮৬১ – ৭ আগস্ট ১৯৪১; ২৫ বৈশাখ ১২৬৮ – ২২ শ্রাবণ ১৩৪৮ বঙ্গাব্দ)[১]ছিলেন একাধারেবাঙালিকবি,ঔপন্যাসিক, সংগীতস্রষ্টা,নাট্যকার, চিত্রকর,ছোটগল্পকার, প্রাবন্ধিক,অভিনেতা, কণ্ঠশিল্পী ওদার্শনিক।\nSentence 3: [২]তাকেবাংলা ভাষারসর্বশ্রেষ্ঠ সাহিত্যিক মনে করা হয়।\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# **Prepare Dataset for Fine-Tuning**\nThis section prepares the dataset in a **prompt-response format** for fine-tuning a conversational AI model:\n- Each Bengali sentence is formatted as:\n  - **Prompt:** Simulates the user’s message.\n  - **Target:** Simulates the model’s expected response.\n- The format includes special tokens like `<start_of_turn>` and `<end_of_turn>` to indicate the boundaries of turns.\n- The dataset contains tuples of `(prompt, target)`.\n- Finally, the first 2 examples from the dataset are printed for inspection.\n","metadata":{}},{"cell_type":"code","source":"# Prepare the dataset for fine-tuning\ndataset = []\n\nfor sentence in random_bengali_sentences:\n    # Create the prompt and target\n    prompt = f\"<start_of_turn>user\\n{sentence}<end_of_turn>\\n<start_of_turn>model\\n\"\n    target = f\"{sentence}<end_of_turn>\"\n    dataset.append((prompt, target))\n\n# Print the prepared data\nfor idx, (prompt, target) in enumerate(dataset[:2]):\n    print(f\"Example {idx+1}:\")\n    print(\"Prompt:\")\n    print(prompt)\n    print(\"Target:\")\n    print(target)\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T06:15:37.073021Z","iopub.execute_input":"2025-01-14T06:15:37.073680Z","iopub.status.idle":"2025-01-14T06:15:37.086208Z","shell.execute_reply.started":"2025-01-14T06:15:37.073640Z","shell.execute_reply":"2025-01-14T06:15:37.085292Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Example 1:\nPrompt:\n<start_of_turn>user\nএটি এই পাতার একটি পরীক্ষিত সংস্করণ।<end_of_turn>\n<start_of_turn>model\n\nTarget:\nএটি এই পাতার একটি পরীক্ষিত সংস্করণ।<end_of_turn>\n\nExample 2:\nPrompt:\n<start_of_turn>user\nরবীন্দ্রনাথ ঠাকুরএফআরএএস(৭ মে ১৮৬১ – ৭ আগস্ট ১৯৪১; ২৫ বৈশাখ ১২৬৮ – ২২ শ্রাবণ ১৩৪৮ বঙ্গাব্দ)[১]ছিলেন একাধারেবাঙালিকবি,ঔপন্যাসিক, সংগীতস্রষ্টা,নাট্যকার, চিত্রকর,ছোটগল্পকার, প্রাবন্ধিক,অভিনেতা, কণ্ঠশিল্পী ওদার্শনিক।<end_of_turn>\n<start_of_turn>model\n\nTarget:\nরবীন্দ্রনাথ ঠাকুরএফআরএএস(৭ মে ১৮৬১ – ৭ আগস্ট ১৯৪১; ২৫ বৈশাখ ১২৬৮ – ২২ শ্রাবণ ১৩৪৮ বঙ্গাব্দ)[১]ছিলেন একাধারেবাঙালিকবি,ঔপন্যাসিক, সংগীতস্রষ্টা,নাট্যকার, চিত্রকর,ছোটগল্পকার, প্রাবন্ধিক,অভিনেতা, কণ্ঠশিল্পী ওদার্শনিক।<end_of_turn>\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# **Model Setup and Configuration**\nThis section sets up the deep learning environment and loads the pre-trained **Gemma Causal Language Model** using Keras Hub.\n- **Backend Selection:** Choose between `JAX` and `TensorFlow` for computation.\n- **Precision Setting:** Use `bfloat16` precision to reduce memory usage.\n- **Model Preprocessing and Loading:**\n  - Load the preprocessor and model with the `gemma_1.1_instruct_2b_en` preset.\n  - The model expects sequences of length `256`.\n- **LoRA (Low-Rank Adaptation):**\n  - Enable LoRA with `rank=4` to make the model more memory efficient during fine-tuning.\n- **Model Summary:** Display the model's architecture for verification.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\n\n# Set the backend to JAX or TensorFlow\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # Change to \"tensorflow\" if preferred\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # Suppress TensorFlow logging\n\nimport keras\nimport keras_hub\n\n# Set precision to bfloat16 to reduce memory usage\nkeras.config.set_dtype_policy(\"bfloat16\")\n\n# Load the preprocessor and model\npreprocessor = keras_hub.models.GemmaCausalLMPreprocessor.from_preset(\n    \"gemma_1.1_instruct_2b_en\", sequence_length=256\n)\ngemma_lm = keras_hub.models.GemmaCausalLM.from_preset(\n    \"gemma_1.1_instruct_2b_en\", preprocessor=preprocessor\n)\n\n# Enable LoRA with a rank of 4\ngemma_lm.backbone.enable_lora(rank=4)\n\n# Print the model summary to verify\ngemma_lm.summary()\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T06:15:46.514445Z","iopub.execute_input":"2025-01-14T06:15:46.515039Z","iopub.status.idle":"2025-01-14T06:16:50.706797Z","shell.execute_reply.started":"2025-01-14T06:15:46.515006Z","shell.execute_reply":"2025-01-14T06:16:50.705948Z"},"trusted":true},"outputs":[{"name":"stderr","text":"normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (4.67 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (4.67 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (2.60 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (2.60 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (4.67 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (4.67 GB)\n</pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# **Prepare Dataset for Training and Fine-Tuning the Model**\nThis section prepares the dataset for training using TensorFlow and fine-tunes the pre-trained **Gemma Causal Language Model**:\n- **Data Generator Function:** Yields each `(prompt + target)` pair as combined text for training.\n- **TensorFlow Dataset Creation:** Converts the generator output into a `tf.data.Dataset` object and batches the dataset.\n- **Model Compilation:**\n  - Uses `SGD` (Stochastic Gradient Descent) as the optimizer with a small learning rate (`1e-4`).\n  - Loss function: `SparseCategoricalCrossentropy` (used for classification tasks).\n  - Metric: `SparseCategoricalAccuracy` to track model performance during training.\n- **Fine-Tuning:** The model is fine-tuned for **1 epoch** on the provided dataset.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Prepare the dataset for training\ndef data_generator():\n    for prompt, target in dataset:\n        combined_text = prompt + target\n        yield combined_text\n\n# Create a tf.data.Dataset\ntrain_ds = tf.data.Dataset.from_generator(\n    data_generator,\n    output_types=tf.string,\n    output_shapes=()\n)\n\ntrain_ds = train_ds.batch(1)\n\n# Compile the model\noptimizer = keras.optimizers.SGD(learning_rate=1e-4)\ngemma_lm.compile(\n    optimizer=optimizer,\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Fine-tune the model\ngemma_lm.fit(train_ds, epochs=1)\n","metadata":{"execution":{"iopub.status.busy":"2025-01-14T06:17:10.517001Z","iopub.execute_input":"2025-01-14T06:17:10.517643Z"},"trusted":true},"outputs":[{"name":"stdout","text":"     99/Unknown \u001b[1m428s\u001b[0m 4s/step - loss: 1.9641 - sparse_categorical_accuracy: 0.2573 - weighted_sparse_categorical_accuracy: 0.5798","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# **Model Inference with Multiple Types of Questions**\nThis section demonstrates how to generate responses for various types of Bengali questions:\n1. **Philosophical Question:** Asks about the meaning of life.\n2. **Historical Question:** Inquires about a historical figure or event.\n3. **Scientific Question:** Asks about a scientific concept.\n4. **Google-related Question:** Asks a general question referencing \"Google\".\n5. **Translation Request:** Asks the model to translate a sentence.\n- Each input is formatted and passed to the model, and the generated responses are displayed.\n","metadata":{}},{"cell_type":"code","source":"# Assuming the model is fine-tuned on a larger dataset\n\n# List of different types of Bengali questions\nquestions = {\n    \"Philosophical Question\": \"জীবনের অর্থ কি?\",  # \"What is the meaning of life?\"\n    \"Historical Question\": \"বঙ্গবন্ধু শেখ মুজিবুর রহমান কে ছিলেন?\",  # \"Who was Bangabandhu Sheikh Mujibur Rahman?\"\n    \"Scientific Question\": \"আলো কি কণিকা না তরঙ্গ?\",  # \"Is light a particle or a wave?\"\n    \"Google-related Question\": \"গুগল কবে প্রতিষ্ঠিত হয়েছিল?\",  # \"When was Google founded?\"\n    \"Translation Request\": \"Translate to English: আমি তোমাকে ভালোবাসি।\"  # Asking for translation of \"I love you.\"\n}\n\n# Generate and print responses for each type of question\nfor question_type, question_text in questions.items():\n    # Format the input for the conversational model\n    formatted_input = f\"<start_of_turn>user\\n{question_text}<end_of_turn>\\n<start_of_turn>model\\n\"\n    \n    # Generate the response using the fine-tuned model\n    output = gemma_lm.generate(formatted_input, max_length=256)  # Generate a response with a maximum length of 256 tokens\n    generated_response = output.replace(formatted_input, \"\").strip()  # Clean the response by removing the formatted input\n    \n    # Print the question type, input, and generated output\n    print(f\"\\n--- {question_type} ---\")\n    print(\"Custom Input:\")\n    print(question_text)\n    print(\"\\nGenerated Output:\")\n    print(generated_response)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}