{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ae3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acbbce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn='D:/Penn_Action/*/'\n",
    "tr= glob(trn)\n",
    "\n",
    "len(tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3b2ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "test_y = []\n",
    "\n",
    "y = 0\n",
    "for i in tr:\n",
    "    \n",
    "    #print(i)\n",
    "    x = glob(i+'/*/')\n",
    "    \n",
    "    #shuffle(x)\n",
    "    t,tt = train_test_split( x , test_size=0.1, random_state=42)\n",
    "    t, vv = train_test_split( t , test_size=0.1, random_state=42)\n",
    "    \n",
    "    for j in t:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "        \n",
    "        train.append(j)\n",
    "        train_y.append(y)\n",
    "    \n",
    "    for j in vv:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        val.append(j)\n",
    "        val_y.append(y)\n",
    "        \n",
    "    for j in tt:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        test.append(j)\n",
    "        test_y.append(y)\n",
    "        \n",
    "    y = y+1\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tra_y =  np.array(to_categorical(train_y))\n",
    "va_y  =  np.array(to_categorical(val_y))\n",
    "te_y  =  np.array(to_categorical(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e3bfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, tra_y) = shuffle(train, tra_y)\n",
    "(val, va_y) = shuffle(val, va_y)\n",
    "(test, te_y) = shuffle(test, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39c12008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the resized images array: (239, 10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# Initialize a numpy array to store the resized images\n",
    "resized_images = np.zeros((len(test), 10, 64, 64, 3), dtype=np.uint8)\n",
    "\n",
    "# Loop through each folder in the \"test\" array\n",
    "for i, folder in enumerate(test):\n",
    "\n",
    "    # Loop through the first 10 images in the current folder\n",
    "    for j, filename in enumerate(os.listdir(folder)[:10]):\n",
    "\n",
    "        # Load the image and resize it to 64x64 pixels\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "\n",
    "        # Store the resized image in the numpy array\n",
    "        resized_images[i, j] = img\n",
    "\n",
    "X_test = resized_images\n",
    "print(\"Shape of the resized images array:\", np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f94c382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "764a45fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    higher = len(x)\n",
    "    import more_itertools as mit\n",
    "    \n",
    "    y = mit.random_combination(range(0, higher), r=10)\n",
    "\n",
    "    for i in y:\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((64, 64))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(64,64,3))\n",
    "        \n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09b055ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "995461c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(train, tra_y, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(val, va_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cb5d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , batch_size) :\n",
    "    self.filename = filename\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faa3e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = my_training_batch_generator.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe4941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859263e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7f2b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_7 (TimeDis  (None, 10, 62, 62, 32)   896       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 10, 31, 31, 32)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 10, 29, 29, 64)   18496     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 10, 14, 14, 64)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 10, 12, 12, 128)  73856     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 10, 6, 6, 128)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_13 (TimeDi  (None, 10, 4608)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 25)                463400    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 557,038\n",
      "Trainable params: 557,038\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "num_frames = 10\n",
    "frame_height = 64\n",
    "frame_width = 64\n",
    "num_channels = 3\n",
    "num_classes = 15  # Change this to the number of classes in your dataset\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CNN\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(num_frames, frame_height, frame_width, num_channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(25))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "161da374",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1a3cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_4068\\1675710652.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 30,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_4068\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "59/59 [==============================] - 104s 2s/step - loss: 2.6161 - accuracy: 0.1242 - val_loss: 2.5594 - val_accuracy: 0.1682\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 90s 2s/step - loss: 2.3596 - accuracy: 0.2148 - val_loss: 2.3306 - val_accuracy: 0.2430\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 89s 2s/step - loss: 2.1458 - accuracy: 0.3038 - val_loss: 2.2042 - val_accuracy: 0.2617\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 88s 1s/step - loss: 1.9733 - accuracy: 0.3737 - val_loss: 1.9606 - val_accuracy: 0.3832\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 88s 1s/step - loss: 1.7683 - accuracy: 0.4350 - val_loss: 1.8846 - val_accuracy: 0.4112\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 87s 1s/step - loss: 1.5436 - accuracy: 0.5096 - val_loss: 1.7927 - val_accuracy: 0.4393\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 85s 1s/step - loss: 1.4046 - accuracy: 0.5741 - val_loss: 1.8585 - val_accuracy: 0.4486\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 89s 2s/step - loss: 1.2377 - accuracy: 0.6370 - val_loss: 1.6668 - val_accuracy: 0.4439\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 100s 2s/step - loss: 1.0757 - accuracy: 0.6807 - val_loss: 1.5895 - val_accuracy: 0.4907\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.8975 - accuracy: 0.7633 - val_loss: 1.6789 - val_accuracy: 0.4720\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.7548 - accuracy: 0.8145 - val_loss: 1.5274 - val_accuracy: 0.4813\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.6474 - accuracy: 0.8433 - val_loss: 1.6077 - val_accuracy: 0.4907\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.5587 - accuracy: 0.8715 - val_loss: 1.5813 - val_accuracy: 0.4766\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 94s 2s/step - loss: 0.4649 - accuracy: 0.9120 - val_loss: 1.5323 - val_accuracy: 0.5374\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 93s 2s/step - loss: 0.3757 - accuracy: 0.9366 - val_loss: 1.6372 - val_accuracy: 0.4813\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 272s 5s/step - loss: 0.3026 - accuracy: 0.9568 - val_loss: 1.6117 - val_accuracy: 0.5140\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 333s 6s/step - loss: 0.2543 - accuracy: 0.9701 - val_loss: 1.6643 - val_accuracy: 0.5187\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 264s 4s/step - loss: 0.2283 - accuracy: 0.9744 - val_loss: 1.5059 - val_accuracy: 0.5701\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 275s 5s/step - loss: 0.1773 - accuracy: 0.9824 - val_loss: 1.5589 - val_accuracy: 0.5607\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 284s 5s/step - loss: 0.1498 - accuracy: 0.9851 - val_loss: 1.5658 - val_accuracy: 0.5374\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.1364 - accuracy: 0.9851 - val_loss: 1.6006 - val_accuracy: 0.5327\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.1951 - accuracy: 0.9632 - val_loss: 1.6452 - val_accuracy: 0.5327\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.1349 - accuracy: 0.9840 - val_loss: 1.6753 - val_accuracy: 0.5280\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.1118 - accuracy: 0.9893 - val_loss: 1.6367 - val_accuracy: 0.5514\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0861 - accuracy: 0.9925 - val_loss: 1.6215 - val_accuracy: 0.5701\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0758 - accuracy: 0.9920 - val_loss: 1.6729 - val_accuracy: 0.5234\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0706 - accuracy: 0.9936 - val_loss: 1.6931 - val_accuracy: 0.5421\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 253s 4s/step - loss: 0.0576 - accuracy: 0.9947 - val_loss: 1.6643 - val_accuracy: 0.5327\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0516 - accuracy: 0.9963 - val_loss: 1.7807 - val_accuracy: 0.5093\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0468 - accuracy: 0.9957 - val_loss: 1.6936 - val_accuracy: 0.5514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2240af743a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 30,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07fcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c64b2eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26359832635983266"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "p = np.argmax(predictions, axis=1)\n",
    "yy = np.argmax(te_y, axis=1)\n",
    "score = accuracy_score(yy, p)\n",
    "                            \n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd108b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b3b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d2f2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super(PatchEncoder, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(2, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\": self.projection_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3f731ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 10, 64, 64,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " patch_encoder_2 (PatchEncoder)  (None, 10, 32)      61912       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 10, 32)      64          ['patch_encoder_2[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 10, 32)      25184       ['layer_normalization_13[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 10, 32)       0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'patch_encoder_2[0][0]']        \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 10, 32)      64          ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_11 (Sequential)     (None, 10, 32)       1056        ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 10, 32)       0           ['sequential_11[0][0]',          \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 10, 32)      64          ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 10, 32)      25184       ['layer_normalization_15[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 10, 32)       0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 10, 32)      64          ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)     (None, 10, 32)       1056        ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 10, 32)       0           ['sequential_12[0][0]',          \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 10, 32)      64          ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 10, 32)      25184       ['layer_normalization_17[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 10, 32)       0           ['multi_head_attention_8[0][0]', \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 10, 32)      64          ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)     (None, 10, 32)       1056        ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 10, 32)       0           ['sequential_13[0][0]',          \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 10, 32)      64          ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 10, 32)      25184       ['layer_normalization_19[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 10, 32)       0           ['multi_head_attention_9[0][0]', \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 10, 32)      64          ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 10, 32)       1056        ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 10, 32)       0           ['sequential_14[0][0]',          \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 10, 32)      64          ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 10, 32)      25184       ['layer_normalization_21[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 10, 32)       0           ['multi_head_attention_10[0][0]',\n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 10, 32)      64          ['add_20[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)     (None, 10, 32)       1056        ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 10, 32)       0           ['sequential_15[0][0]',          \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 10, 32)      64          ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 10, 32)      25184       ['layer_normalization_23[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 10, 32)       0           ['multi_head_attention_11[0][0]',\n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 10, 32)      64          ['add_22[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_16 (Sequential)     (None, 10, 32)       1056        ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 10, 32)       0           ['sequential_16[0][0]',          \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 10, 32)      64          ['add_23[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 32)          0           ['layer_normalization_25[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 15)           495         ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 220,679\n",
      "Trainable params: 220,679\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (10,64,64,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(10, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output= layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "outputs = layers.Dense(units=15, activation=\"softmax\") ( representation)\n",
    "\n",
    "model1 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18646585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_4068\\3920478310.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model1.fit_generator(generator=my_training_batch_generator, epochs = 60,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_4068\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "59/59 [==============================] - 96s 2s/step - loss: 0.1055 - accuracy: 0.9696 - val_loss: 5.1788 - val_accuracy: 0.2243\n",
      "Epoch 2/60\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.0969 - accuracy: 0.9696 - val_loss: 4.9431 - val_accuracy: 0.2523\n",
      "Epoch 3/60\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0670 - accuracy: 0.9792 - val_loss: 5.2636 - val_accuracy: 0.2570\n",
      "Epoch 4/60\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.0728 - accuracy: 0.9760 - val_loss: 5.1069 - val_accuracy: 0.2664\n",
      "Epoch 5/60\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0834 - accuracy: 0.9728 - val_loss: 5.1353 - val_accuracy: 0.2710\n",
      "Epoch 6/60\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.0713 - accuracy: 0.9787 - val_loss: 5.2660 - val_accuracy: 0.2430\n",
      "Epoch 7/60\n",
      "59/59 [==============================] - 90s 2s/step - loss: 0.0653 - accuracy: 0.9845 - val_loss: 5.2239 - val_accuracy: 0.2664\n",
      "Epoch 8/60\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0790 - accuracy: 0.9755 - val_loss: 5.2192 - val_accuracy: 0.2710\n",
      "Epoch 9/60\n",
      "59/59 [==============================] - 87s 1s/step - loss: 0.0595 - accuracy: 0.9840 - val_loss: 5.5010 - val_accuracy: 0.2664\n",
      "Epoch 10/60\n",
      "59/59 [==============================] - 95s 2s/step - loss: 0.0787 - accuracy: 0.9776 - val_loss: 5.3785 - val_accuracy: 0.2757\n",
      "Epoch 11/60\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0549 - accuracy: 0.9851 - val_loss: 5.5098 - val_accuracy: 0.2757\n",
      "Epoch 12/60\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.0483 - accuracy: 0.9829 - val_loss: 5.6250 - val_accuracy: 0.2336\n",
      "Epoch 13/60\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.0487 - accuracy: 0.9840 - val_loss: 5.7181 - val_accuracy: 0.2477\n",
      "Epoch 14/60\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.0677 - accuracy: 0.9771 - val_loss: 5.6790 - val_accuracy: 0.2477\n",
      "Epoch 15/60\n",
      "59/59 [==============================] - 84s 1s/step - loss: 0.0669 - accuracy: 0.9787 - val_loss: 5.4252 - val_accuracy: 0.2570\n",
      "Epoch 16/60\n",
      "59/59 [==============================] - 88s 1s/step - loss: 0.0467 - accuracy: 0.9851 - val_loss: 5.7839 - val_accuracy: 0.2523\n",
      "Epoch 17/60\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0674 - accuracy: 0.9787 - val_loss: 5.9374 - val_accuracy: 0.2570\n",
      "Epoch 18/60\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0478 - accuracy: 0.9899 - val_loss: 5.8017 - val_accuracy: 0.2897\n",
      "Epoch 19/60\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0825 - accuracy: 0.9755 - val_loss: 5.7407 - val_accuracy: 0.2477\n",
      "Epoch 20/60\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0605 - accuracy: 0.9808 - val_loss: 5.8401 - val_accuracy: 0.2664\n",
      "Epoch 21/60\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0529 - accuracy: 0.9845 - val_loss: 5.8524 - val_accuracy: 0.2710\n",
      "Epoch 22/60\n",
      "59/59 [==============================] - 225s 4s/step - loss: 0.0331 - accuracy: 0.9904 - val_loss: 5.9156 - val_accuracy: 0.2617\n",
      "Epoch 23/60\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 5.8887 - val_accuracy: 0.2523\n",
      "Epoch 24/60\n",
      "59/59 [==============================] - 261s 4s/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 5.9633 - val_accuracy: 0.2336\n",
      "Epoch 25/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0591 - accuracy: 0.9808 - val_loss: 6.3304 - val_accuracy: 0.2290\n",
      "Epoch 26/60\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0616 - accuracy: 0.9792 - val_loss: 6.1392 - val_accuracy: 0.2570\n",
      "Epoch 27/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0908 - accuracy: 0.9760 - val_loss: 6.1174 - val_accuracy: 0.2570\n",
      "Epoch 28/60\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0744 - accuracy: 0.9776 - val_loss: 6.0664 - val_accuracy: 0.2383\n",
      "Epoch 29/60\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0675 - accuracy: 0.9819 - val_loss: 6.0266 - val_accuracy: 0.2383\n",
      "Epoch 30/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0325 - accuracy: 0.9904 - val_loss: 5.9912 - val_accuracy: 0.2523\n",
      "Epoch 31/60\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0364 - accuracy: 0.9899 - val_loss: 6.1237 - val_accuracy: 0.2430\n",
      "Epoch 32/60\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 6.3023 - val_accuracy: 0.2383\n",
      "Epoch 33/60\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 6.1405 - val_accuracy: 0.2383\n",
      "Epoch 34/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0386 - accuracy: 0.9888 - val_loss: 6.0331 - val_accuracy: 0.2617\n",
      "Epoch 35/60\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 6.0578 - val_accuracy: 0.2664\n",
      "Epoch 36/60\n",
      "59/59 [==============================] - 262s 4s/step - loss: 0.0352 - accuracy: 0.9867 - val_loss: 6.0853 - val_accuracy: 0.2570\n",
      "Epoch 37/60\n",
      "59/59 [==============================] - 256s 4s/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 6.2083 - val_accuracy: 0.2710\n",
      "Epoch 38/60\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0309 - accuracy: 0.9931 - val_loss: 6.2079 - val_accuracy: 0.2617\n",
      "Epoch 39/60\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 6.2131 - val_accuracy: 0.2804\n",
      "Epoch 40/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0466 - accuracy: 0.9872 - val_loss: 6.2731 - val_accuracy: 0.2523\n",
      "Epoch 41/60\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 6.0060 - val_accuracy: 0.2664\n",
      "Epoch 42/60\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0299 - accuracy: 0.9931 - val_loss: 6.3048 - val_accuracy: 0.2804\n",
      "Epoch 43/60\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 6.1754 - val_accuracy: 0.2523\n",
      "Epoch 44/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0309 - accuracy: 0.9931 - val_loss: 6.2569 - val_accuracy: 0.2290\n",
      "Epoch 45/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 6.0944 - val_accuracy: 0.2430\n",
      "Epoch 46/60\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0611 - accuracy: 0.9803 - val_loss: 6.2731 - val_accuracy: 0.2336\n",
      "Epoch 47/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0968 - accuracy: 0.9733 - val_loss: 6.2710 - val_accuracy: 0.2383\n",
      "Epoch 48/60\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 6.1069 - val_accuracy: 0.2570\n",
      "Epoch 49/60\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0722 - accuracy: 0.9797 - val_loss: 6.0888 - val_accuracy: 0.2243\n",
      "Epoch 50/60\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0420 - accuracy: 0.9888 - val_loss: 6.1204 - val_accuracy: 0.2243\n",
      "Epoch 51/60\n",
      "59/59 [==============================] - 258s 4s/step - loss: 0.0359 - accuracy: 0.9877 - val_loss: 6.0645 - val_accuracy: 0.2804\n",
      "Epoch 52/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0484 - accuracy: 0.9861 - val_loss: 6.2781 - val_accuracy: 0.2430\n",
      "Epoch 53/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 6.1011 - val_accuracy: 0.2617\n",
      "Epoch 54/60\n",
      "59/59 [==============================] - 255s 4s/step - loss: 0.0286 - accuracy: 0.9936 - val_loss: 6.0859 - val_accuracy: 0.2570\n",
      "Epoch 55/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 5.9613 - val_accuracy: 0.2617\n",
      "Epoch 56/60\n",
      "59/59 [==============================] - 260s 4s/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 6.3273 - val_accuracy: 0.2430\n",
      "Epoch 57/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0160 - accuracy: 0.9931 - val_loss: 6.5056 - val_accuracy: 0.2196\n",
      "Epoch 58/60\n",
      "59/59 [==============================] - 283s 5s/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 6.1371 - val_accuracy: 0.2710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/60\n",
      "59/59 [==============================] - 259s 4s/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 6.1597 - val_accuracy: 0.2617\n",
      "Epoch 60/60\n",
      "59/59 [==============================] - 257s 4s/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 6.5147 - val_accuracy: 0.2570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224d17b9e50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics='accuracy')\n",
    "model1.fit_generator(generator=my_training_batch_generator, epochs = 60,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da7dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11c50b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13389121338912133"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model1.predict(X_test)\n",
    "p = np.argmax(predictions, axis=1)\n",
    "yy = np.argmax(te_y, axis=1)\n",
    "score = accuracy_score(yy, p)\n",
    "                            \n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e8907a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927bff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243626d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889fc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
