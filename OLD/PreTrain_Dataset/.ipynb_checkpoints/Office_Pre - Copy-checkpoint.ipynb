{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764360c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6be7053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4357, 32, 32, 3)\n",
      "Y shape: (4357, 65)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r'F:\\OfficeHomeDataset_10072016\\OfficeHomeDataset_10072016\\Real World'\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create a dictionary to map folder names to unique labels\n",
    "folder_to_label = {}\n",
    "\n",
    "# Loop through subdirectories (classes) and assign unique labels\n",
    "for index, class_folder in enumerate(os.listdir(directory_path)):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "\n",
    "    # Store the mapping of folder name to unique label\n",
    "    folder_to_label[class_folder] = index\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        try:\n",
    "            if image_file.endswith('.jpg'):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "                # Load image, convert to RGB and resize\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                img = img.resize((32, 32))\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Append image and label to lists\n",
    "                X.append(img_array)\n",
    "                Y.append(index)  # Use the unique label for this folder\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image file {image_file}: {e}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "\n",
    "# Encode labels using one-hot encoding\n",
    "Y = to_categorical(Y, num_classes=65)  # 65 different folders\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'Y shape: {Y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156b83fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (43, 32, 32, 3)\n",
      "Y_train shape: (43, 65)\n",
      "X_test shape: (4314, 32, 32, 3)\n",
      "Y_test shape: (4314, 65)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.99, random_state=42)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'Y_test shape: {Y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0512bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ca7ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4439, 32, 32, 3)\n",
      "Y shape: (4439, 65)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r'F:\\OfficeHomeDataset_10072016\\OfficeHomeDataset_10072016\\Product'\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create a dictionary to map folder names to unique labels\n",
    "folder_to_label = {}\n",
    "\n",
    "# Loop through subdirectories (classes) and assign unique labels\n",
    "for index, class_folder in enumerate(os.listdir(directory_path)):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "\n",
    "    # Store the mapping of folder name to unique label\n",
    "    folder_to_label[class_folder] = index\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        try:\n",
    "            if image_file.endswith('.jpg'):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "                # Load image, convert to RGB and resize\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                img = img.resize((32, 32))\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Append image and label to lists\n",
    "                X.append(img_array)\n",
    "                Y.append(index)  # Use the unique label for this folder\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image file {image_file}: {e}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "\n",
    "# Encode labels using one-hot encoding\n",
    "Y = to_categorical(Y, num_classes=65)  # 65 different folders\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'Y shape: {Y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccb3a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4394, 32, 32, 3)\n",
      "Y_train shape: (4394, 65)\n",
      "X_test shape: (45, 32, 32, 3)\n",
      "Y_test shape: (45, 65)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.01, random_state=42)\n",
    "\n",
    "print(f'X_train shape: {x_train.shape}')\n",
    "print(f'Y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {x_test.shape}')\n",
    "print(f'Y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba298e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc1fea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "110/110 [==============================] - 14s 62ms/step - loss: 4.6590 - accuracy: 0.1323 - val_loss: 114.0415 - val_accuracy: 0.0239\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 4.0134 - accuracy: 0.2339 - val_loss: 585.2821 - val_accuracy: 0.0694\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 3.8036 - accuracy: 0.2637 - val_loss: 419.0599 - val_accuracy: 0.0330\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 4.5434 - accuracy: 0.1246 - val_loss: 746.6944 - val_accuracy: 0.0102\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 4.4923 - accuracy: 0.1104 - val_loss: 14.4301 - val_accuracy: 0.0296\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 4.6730 - accuracy: 0.0802 - val_loss: 14.0491 - val_accuracy: 0.0353\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 4.5319 - accuracy: 0.0959 - val_loss: 1005.0612 - val_accuracy: 0.0319\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 4.2456 - accuracy: 0.1183 - val_loss: 14.5387 - val_accuracy: 0.0774\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 4.6069 - accuracy: 0.0910 - val_loss: 8.5390 - val_accuracy: 0.0193\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 4.3415 - accuracy: 0.0714 - val_loss: 347.5167 - val_accuracy: 0.0330\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 4.2993 - accuracy: 0.1027 - val_loss: 168.7667 - val_accuracy: 0.0410\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 3.9904 - accuracy: 0.1371 - val_loss: 18.8640 - val_accuracy: 0.0967\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 3.8998 - accuracy: 0.1548 - val_loss: 26.9807 - val_accuracy: 0.0796\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 3.5419 - accuracy: 0.1758 - val_loss: 29.0464 - val_accuracy: 0.1650\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 3.4828 - accuracy: 0.2037 - val_loss: 5.6320 - val_accuracy: 0.1547\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 3.5406 - accuracy: 0.2043 - val_loss: 313.1946 - val_accuracy: 0.0910\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 3.4376 - accuracy: 0.2427 - val_loss: 10.2983 - val_accuracy: 0.2036\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 3.0973 - accuracy: 0.2751 - val_loss: 4.7136 - val_accuracy: 0.2116\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 2.9380 - accuracy: 0.3135 - val_loss: 3.0535 - val_accuracy: 0.2605\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 5s 50ms/step - loss: 2.8784 - accuracy: 0.3411 - val_loss: 8.3479 - val_accuracy: 0.2491\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 3.4892 - accuracy: 0.2324 - val_loss: 6.0894 - val_accuracy: 0.0273\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 3.6173 - accuracy: 0.2085 - val_loss: 3.5703 - val_accuracy: 0.1342\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 3.2677 - accuracy: 0.2518 - val_loss: 3.7263 - val_accuracy: 0.2059\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 3.0452 - accuracy: 0.2853 - val_loss: 25.0486 - val_accuracy: 0.1024\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 2.8449 - accuracy: 0.3024 - val_loss: 5.4391 - val_accuracy: 0.2503\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 2.6178 - accuracy: 0.3414 - val_loss: 3.4864 - val_accuracy: 0.3049\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.4080 - accuracy: 0.3758 - val_loss: 3.2212 - val_accuracy: 0.2355\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.3710 - accuracy: 0.4131 - val_loss: 2.9071 - val_accuracy: 0.3322\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 5s 50ms/step - loss: 2.1485 - accuracy: 0.4560 - val_loss: 3.0077 - val_accuracy: 0.3424\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 2.2742 - accuracy: 0.4515 - val_loss: 4.3924 - val_accuracy: 0.1729\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 2.5144 - accuracy: 0.4302 - val_loss: 2.8540 - val_accuracy: 0.3322\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 2.1218 - accuracy: 0.5047 - val_loss: 4.1055 - val_accuracy: 0.3424\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 1.9784 - accuracy: 0.5349 - val_loss: 3.2044 - val_accuracy: 0.2685\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 1.9719 - accuracy: 0.5260 - val_loss: 12.2810 - val_accuracy: 0.3515\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 1.7615 - accuracy: 0.5804 - val_loss: 3.4723 - val_accuracy: 0.4016\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 5s 50ms/step - loss: 1.6287 - accuracy: 0.6236 - val_loss: 14.5956 - val_accuracy: 0.2844\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 1.7705 - accuracy: 0.5616 - val_loss: 3.3047 - val_accuracy: 0.2514\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 2.0318 - accuracy: 0.5203 - val_loss: 10.0590 - val_accuracy: 0.2890\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 1.6386 - accuracy: 0.6011 - val_loss: 3.2937 - val_accuracy: 0.3072\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 1.2160 - accuracy: 0.6825 - val_loss: 3.4019 - val_accuracy: 0.4255\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 1.2035 - accuracy: 0.7061 - val_loss: 4.6259 - val_accuracy: 0.3038\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 1.3137 - accuracy: 0.6899 - val_loss: 5.9384 - val_accuracy: 0.3823\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 1.0306 - accuracy: 0.7585 - val_loss: 3.2929 - val_accuracy: 0.4334\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 1.0778 - accuracy: 0.7582 - val_loss: 5.2294 - val_accuracy: 0.1570\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 1.5391 - accuracy: 0.6327 - val_loss: 51.6537 - val_accuracy: 0.0876\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 1.4454 - accuracy: 0.6367 - val_loss: 4.8862 - val_accuracy: 0.2127\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 1.1156 - accuracy: 0.7303 - val_loss: 6.1784 - val_accuracy: 0.3936\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 5s 50ms/step - loss: 0.9012 - accuracy: 0.7801 - val_loss: 3.1842 - val_accuracy: 0.4357\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 0.9103 - accuracy: 0.7855 - val_loss: 48.9534 - val_accuracy: 0.3356\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 0.7805 - accuracy: 0.8276 - val_loss: 5.0207 - val_accuracy: 0.4073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc3f40c250>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"C:\\Users\\shaif\\Downloads\\office_real_32_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    \n",
    "num_classes = 65  # Update with the actual number of classes in your target data\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "new_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model with early stopping\n",
    "new_model.fit(x_train, y_train,validation_split = 0.2, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a0281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "589a9abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 5s 25ms/step\n",
      "Accuracy: 0.09457579972183588\n",
      "F1 Score (Micro): 0.09457579972183588\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = new_model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6d446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1ae12b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "110/110 [==============================] - 13s 57ms/step - loss: 5.2053 - accuracy: 0.0697 - val_loss: 4.2893 - val_accuracy: 0.0171\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 4.2350 - accuracy: 0.1448 - val_loss: 4.1992 - val_accuracy: 0.0614\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 4.2979 - accuracy: 0.2026 - val_loss: 10.5808 - val_accuracy: 0.0546\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 4.3175 - accuracy: 0.1832 - val_loss: 4.6092 - val_accuracy: 0.0944\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 3.6431 - accuracy: 0.2615 - val_loss: 8.1855 - val_accuracy: 0.2036\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 3.9190 - accuracy: 0.2373 - val_loss: 16.3712 - val_accuracy: 0.0250\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 3.8260 - accuracy: 0.2051 - val_loss: 4.9348 - val_accuracy: 0.1035\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 3.9417 - accuracy: 0.2026 - val_loss: 46.3667 - val_accuracy: 0.0444\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 3.6995 - accuracy: 0.2313 - val_loss: 21.3237 - val_accuracy: 0.1126\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 3.4431 - accuracy: 0.2754 - val_loss: 3.6674 - val_accuracy: 0.1866\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 3.1844 - accuracy: 0.3135 - val_loss: 3.5025 - val_accuracy: 0.2025\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 3.0253 - accuracy: 0.3218 - val_loss: 3.4818 - val_accuracy: 0.2162\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 2.8308 - accuracy: 0.3852 - val_loss: 3.2416 - val_accuracy: 0.2355\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 2.8721 - accuracy: 0.4017 - val_loss: 3.7046 - val_accuracy: 0.2230\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 2.4622 - accuracy: 0.4600 - val_loss: 7.4643 - val_accuracy: 0.2787\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 2.3049 - accuracy: 0.4876 - val_loss: 4.0563 - val_accuracy: 0.2799\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 6s 52ms/step - loss: 3.0074 - accuracy: 0.3559 - val_loss: 4.4277 - val_accuracy: 0.1411\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 2.5411 - accuracy: 0.4367 - val_loss: 3.3132 - val_accuracy: 0.2639\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 2.2877 - accuracy: 0.4794 - val_loss: 6.2439 - val_accuracy: 0.1058\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 2.0923 - accuracy: 0.5272 - val_loss: 3.1441 - val_accuracy: 0.3322\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 2.2537 - accuracy: 0.4962 - val_loss: 6.6090 - val_accuracy: 0.1854\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 2.1057 - accuracy: 0.5269 - val_loss: 11.5276 - val_accuracy: 0.0637\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 3.4022 - accuracy: 0.2552 - val_loss: 1218.9354 - val_accuracy: 0.0228\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 2.8785 - accuracy: 0.3422 - val_loss: 591.7113 - val_accuracy: 0.0580\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 2.5126 - accuracy: 0.4523 - val_loss: 11.2885 - val_accuracy: 0.2480\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 2.0532 - accuracy: 0.5440 - val_loss: 4.3483 - val_accuracy: 0.3754\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 1.7742 - accuracy: 0.5952 - val_loss: 36.6914 - val_accuracy: 0.0648\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 2.0097 - accuracy: 0.5366 - val_loss: 6.6946 - val_accuracy: 0.2514\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 5s 50ms/step - loss: 1.6097 - accuracy: 0.6179 - val_loss: 5.4216 - val_accuracy: 0.3299\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 1.9060 - accuracy: 0.5545 - val_loss: 30.6240 - val_accuracy: 0.1763\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 1.7224 - accuracy: 0.6071 - val_loss: 5.4868 - val_accuracy: 0.3379\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 1.4019 - accuracy: 0.6882 - val_loss: 4.0029 - val_accuracy: 0.4084\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 1.2454 - accuracy: 0.7331 - val_loss: 4.4963 - val_accuracy: 0.4209\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 5s 49ms/step - loss: 1.0297 - accuracy: 0.7781 - val_loss: 27.3982 - val_accuracy: 0.2025\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 6s 50ms/step - loss: 1.1121 - accuracy: 0.7516 - val_loss: 8.1407 - val_accuracy: 0.4050\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 1.5767 - accuracy: 0.6344 - val_loss: 5.3610 - val_accuracy: 0.2423\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 1.3751 - accuracy: 0.6632 - val_loss: 5.4783 - val_accuracy: 0.4061\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 5s 48ms/step - loss: 1.2372 - accuracy: 0.7175 - val_loss: 68.5834 - val_accuracy: 0.0819\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 1.4180 - accuracy: 0.6984 - val_loss: 37.7328 - val_accuracy: 0.2582\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.9776 - accuracy: 0.7935 - val_loss: 3.3823 - val_accuracy: 0.4073\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.9067 - accuracy: 0.8065 - val_loss: 3.2431 - val_accuracy: 0.4084\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 5s 46ms/step - loss: 0.7643 - accuracy: 0.8450 - val_loss: 10.6967 - val_accuracy: 0.3709\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.8176 - accuracy: 0.8495 - val_loss: 3.2118 - val_accuracy: 0.4357\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.8426 - accuracy: 0.8381 - val_loss: 893.2125 - val_accuracy: 0.2207\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.8741 - accuracy: 0.8151 - val_loss: 31.9552 - val_accuracy: 0.3220\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.8655 - accuracy: 0.8421 - val_loss: 22.9442 - val_accuracy: 0.3015\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.8070 - accuracy: 0.8370 - val_loss: 5.6286 - val_accuracy: 0.4505\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.6090 - accuracy: 0.8828 - val_loss: 3.5321 - val_accuracy: 0.4505\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.6612 - accuracy: 0.8791 - val_loss: 3.8558 - val_accuracy: 0.3276\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.6710 - accuracy: 0.8697 - val_loss: 16.0526 - val_accuracy: 0.3788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc3f2810d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(65, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb070f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a42a3c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 3s 15ms/step\n",
      "Accuracy: 0.09040333796940195\n",
      "F1 Score (Micro): 0.09040333796940195\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b56a807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f91bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fef83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58adffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a6a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5221c9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
