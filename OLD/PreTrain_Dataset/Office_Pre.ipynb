{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ae513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92815a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4357, 32, 32, 3)\n",
      "Y shape: (4357, 65)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r'F:\\OfficeHomeDataset_10072016\\OfficeHomeDataset_10072016\\Real World'\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Create a dictionary to map folder names to unique labels\n",
    "folder_to_label = {}\n",
    "\n",
    "# Loop through subdirectories (classes) and assign unique labels\n",
    "for index, class_folder in enumerate(os.listdir(directory_path)):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "\n",
    "    # Store the mapping of folder name to unique label\n",
    "    folder_to_label[class_folder] = index\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        try:\n",
    "            if image_file.endswith('.jpg'):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "                # Load image, convert to RGB and resize\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                img = img.resize((32, 32))\n",
    "                img_array = np.array(img)\n",
    "\n",
    "                # Append image and label to lists\n",
    "                X.append(img_array)\n",
    "                Y.append(index)  # Use the unique label for this folder\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image file {image_file}: {e}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "\n",
    "# Encode labels using one-hot encoding\n",
    "Y = to_categorical(Y, num_classes=65)  # 65 different folders\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'Y shape: {Y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0806e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3485, 32, 32, 3)\n",
      "Y_train shape: (3485, 65)\n",
      "X_test shape: (872, 32, 32, 3)\n",
      "Y_test shape: (872, 65)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'Y_test shape: {Y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a47a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b3be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5414924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 [==============================] - 13s 77ms/step - loss: 5.1287 - accuracy: 0.0603 - val_loss: 179.0523 - val_accuracy: 0.0129\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 4s 44ms/step - loss: 4.8280 - accuracy: 0.0714 - val_loss: 308.3452 - val_accuracy: 0.0287\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 4.6448 - accuracy: 0.0757 - val_loss: 6.7680 - val_accuracy: 0.0760\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 4.4730 - accuracy: 0.0922 - val_loss: 12.0361 - val_accuracy: 0.0746\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 4.4156 - accuracy: 0.1119 - val_loss: 1771.8322 - val_accuracy: 0.0445\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 4.6779 - accuracy: 0.0717 - val_loss: 26.5750 - val_accuracy: 0.0631\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 4.6362 - accuracy: 0.0671 - val_loss: 6.3638 - val_accuracy: 0.0789\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 4s 47ms/step - loss: 4.5185 - accuracy: 0.0793 - val_loss: 12.8565 - val_accuracy: 0.0488\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 4.2923 - accuracy: 0.0933 - val_loss: 21.0726 - val_accuracy: 0.0574\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 4.1842 - accuracy: 0.1119 - val_loss: 4.3710 - val_accuracy: 0.0775\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 4s 48ms/step - loss: 4.1652 - accuracy: 0.1191 - val_loss: 16.6402 - val_accuracy: 0.0775\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 4s 46ms/step - loss: 4.0891 - accuracy: 0.1155 - val_loss: 6.4536 - val_accuracy: 0.1105\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 5s 53ms/step - loss: 3.9387 - accuracy: 0.1564 - val_loss: 11.1573 - val_accuracy: 0.1062\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 3.9122 - accuracy: 0.1467 - val_loss: 14.4891 - val_accuracy: 0.1119\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 3.8683 - accuracy: 0.1539 - val_loss: 6.4966 - val_accuracy: 0.1234\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 3.6647 - accuracy: 0.1700 - val_loss: 4.0521 - val_accuracy: 0.1291\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 3.7456 - accuracy: 0.1862 - val_loss: 3.7435 - val_accuracy: 0.1263\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 3.6009 - accuracy: 0.2131 - val_loss: 3.7798 - val_accuracy: 0.1105\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 3.5067 - accuracy: 0.2091 - val_loss: 4.1465 - val_accuracy: 0.0947\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 3.9953 - accuracy: 0.1862 - val_loss: 15.8767 - val_accuracy: 0.1105\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 3.8566 - accuracy: 0.1912 - val_loss: 108.3464 - val_accuracy: 0.0890\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 3.7474 - accuracy: 0.1905 - val_loss: 51.5521 - val_accuracy: 0.0976\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 4.0535 - accuracy: 0.1707 - val_loss: 4.1915 - val_accuracy: 0.1033\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 4.2306 - accuracy: 0.1273 - val_loss: 91.2743 - val_accuracy: 0.0803\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 3.8742 - accuracy: 0.1707 - val_loss: 9.6844 - val_accuracy: 0.1320\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 3.4816 - accuracy: 0.2080 - val_loss: 4.4904 - val_accuracy: 0.1564\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 3.2406 - accuracy: 0.2679 - val_loss: 3.6045 - val_accuracy: 0.1664\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 3.5170 - accuracy: 0.2030 - val_loss: 175.0276 - val_accuracy: 0.0918\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 3.3561 - accuracy: 0.2385 - val_loss: 17.8313 - val_accuracy: 0.1133\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 3.0679 - accuracy: 0.2902 - val_loss: 3.7858 - val_accuracy: 0.1722\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 3.1190 - accuracy: 0.2687 - val_loss: 4.5310 - val_accuracy: 0.1047\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 3.1899 - accuracy: 0.2514 - val_loss: 5.8581 - val_accuracy: 0.1506\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 3.0020 - accuracy: 0.2808 - val_loss: 3.7946 - val_accuracy: 0.1564\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 3.3754 - accuracy: 0.2324 - val_loss: 13.8271 - val_accuracy: 0.1162\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 3.0678 - accuracy: 0.2866 - val_loss: 5.2939 - val_accuracy: 0.1506\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 2.7628 - accuracy: 0.3397 - val_loss: 8.4078 - val_accuracy: 0.1392\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 2.4962 - accuracy: 0.3963 - val_loss: 6.6456 - val_accuracy: 0.1521\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 4s 45ms/step - loss: 2.3168 - accuracy: 0.4301 - val_loss: 4.4214 - val_accuracy: 0.1779\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 4s 46ms/step - loss: 2.0521 - accuracy: 0.5032 - val_loss: 4.0369 - val_accuracy: 0.1765\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 2.0527 - accuracy: 0.5104 - val_loss: 5.6043 - val_accuracy: 0.1621\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 5s 52ms/step - loss: 1.8381 - accuracy: 0.5592 - val_loss: 4.4144 - val_accuracy: 0.1607\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 3.0194 - accuracy: 0.2902 - val_loss: 5.2789 - val_accuracy: 0.1033\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 5s 53ms/step - loss: 2.9353 - accuracy: 0.2877 - val_loss: 4.7240 - val_accuracy: 0.1119\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 2.9198 - accuracy: 0.3056 - val_loss: 4.7014 - val_accuracy: 0.1119\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 3.1283 - accuracy: 0.2615 - val_loss: 5.4906 - val_accuracy: 0.1004\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 5s 53ms/step - loss: 2.9002 - accuracy: 0.2956 - val_loss: 16.8653 - val_accuracy: 0.0818\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 2.3906 - accuracy: 0.4157 - val_loss: 4.4814 - val_accuracy: 0.1679\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.9162 - accuracy: 0.5434 - val_loss: 4.9067 - val_accuracy: 0.1750\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 1.6320 - accuracy: 0.5943 - val_loss: 5.1061 - val_accuracy: 0.1750\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.7831 - accuracy: 0.5642 - val_loss: 7.0312 - val_accuracy: 0.1607\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 1.2922 - accuracy: 0.6822 - val_loss: 4.6251 - val_accuracy: 0.1765\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 1.1508 - accuracy: 0.7374 - val_loss: 4.7880 - val_accuracy: 0.1779\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.9889 - accuracy: 0.7909 - val_loss: 4.7028 - val_accuracy: 0.2037\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 5s 52ms/step - loss: 1.0534 - accuracy: 0.7407 - val_loss: 6.0372 - val_accuracy: 0.1750\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 0.9408 - accuracy: 0.7830 - val_loss: 5.3207 - val_accuracy: 0.1908\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.9305 - accuracy: 0.7999 - val_loss: 6.0450 - val_accuracy: 0.1894\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 0.7872 - accuracy: 0.8275 - val_loss: 5.7227 - val_accuracy: 0.1793\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 5s 52ms/step - loss: 0.6603 - accuracy: 0.8529 - val_loss: 5.2812 - val_accuracy: 0.1923\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 0.5904 - accuracy: 0.8956 - val_loss: 5.7067 - val_accuracy: 0.1894\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 5s 52ms/step - loss: 0.5546 - accuracy: 0.8809 - val_loss: 5.9244 - val_accuracy: 0.1908\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 0.6485 - accuracy: 0.8655 - val_loss: 5.5823 - val_accuracy: 0.1937\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 0.6199 - accuracy: 0.8766 - val_loss: 6.3373 - val_accuracy: 0.2080\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 0.5095 - accuracy: 0.9039 - val_loss: 5.9989 - val_accuracy: 0.1980\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 5s 53ms/step - loss: 0.5146 - accuracy: 0.9017 - val_loss: 5.9329 - val_accuracy: 0.1994\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 4s 51ms/step - loss: 0.5578 - accuracy: 0.9071 - val_loss: 6.7955 - val_accuracy: 0.1908\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 4s 48ms/step - loss: 0.3390 - accuracy: 0.9297 - val_loss: 6.1701 - val_accuracy: 0.1851\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 0.4774 - accuracy: 0.9017 - val_loss: 6.1277 - val_accuracy: 0.1836\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 0.3810 - accuracy: 0.9243 - val_loss: 7.3975 - val_accuracy: 0.1593\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 5s 53ms/step - loss: 0.4420 - accuracy: 0.9053 - val_loss: 6.1094 - val_accuracy: 0.1937\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 4s 48ms/step - loss: 0.3193 - accuracy: 0.9473 - val_loss: 7.1082 - val_accuracy: 0.1406\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 2.2412 - accuracy: 0.4835 - val_loss: 6.3881 - val_accuracy: 0.1564\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 5s 53ms/step - loss: 0.7495 - accuracy: 0.8268 - val_loss: 5.8004 - val_accuracy: 0.2023\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.9781 - accuracy: 0.7464 - val_loss: 6.5175 - val_accuracy: 0.1879\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 0.5433 - accuracy: 0.8777 - val_loss: 5.7958 - val_accuracy: 0.2080\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 0.3748 - accuracy: 0.9250 - val_loss: 5.8204 - val_accuracy: 0.2023\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 0.3828 - accuracy: 0.9218 - val_loss: 6.0288 - val_accuracy: 0.1980\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 0.3212 - accuracy: 0.9419 - val_loss: 6.0421 - val_accuracy: 0.2080\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 0.2760 - accuracy: 0.9455 - val_loss: 6.2789 - val_accuracy: 0.1851\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.2614 - accuracy: 0.9494 - val_loss: 6.7691 - val_accuracy: 0.1865\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.3015 - accuracy: 0.9451 - val_loss: 6.6536 - val_accuracy: 0.2009\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 0.2474 - accuracy: 0.9516 - val_loss: 6.4404 - val_accuracy: 0.1808\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 0.2556 - accuracy: 0.9430 - val_loss: 6.7205 - val_accuracy: 0.1980\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 0.2936 - accuracy: 0.9397 - val_loss: 6.4767 - val_accuracy: 0.1937\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 0.6480 - accuracy: 0.8443 - val_loss: 7.2460 - val_accuracy: 0.1750\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 0.4065 - accuracy: 0.9060 - val_loss: 7.0050 - val_accuracy: 0.1679\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.2874 - accuracy: 0.9437 - val_loss: 6.8532 - val_accuracy: 0.1865\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 0.2397 - accuracy: 0.9480 - val_loss: 7.1626 - val_accuracy: 0.1865\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 5s 52ms/step - loss: 0.1851 - accuracy: 0.9627 - val_loss: 6.5467 - val_accuracy: 0.2052\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.2025 - accuracy: 0.9605 - val_loss: 6.5414 - val_accuracy: 0.2095\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 5s 52ms/step - loss: 1.0135 - accuracy: 0.7507 - val_loss: 6.8891 - val_accuracy: 0.1865\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 0.3565 - accuracy: 0.9089 - val_loss: 6.7359 - val_accuracy: 0.2152\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 0.2468 - accuracy: 0.9544 - val_loss: 6.5235 - val_accuracy: 0.2037\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 0.1645 - accuracy: 0.9634 - val_loss: 6.5670 - val_accuracy: 0.1937\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 0.1937 - accuracy: 0.9598 - val_loss: 6.7562 - val_accuracy: 0.1994\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 0.2879 - accuracy: 0.9354 - val_loss: 6.9696 - val_accuracy: 0.1851\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 5s 53ms/step - loss: 0.1833 - accuracy: 0.9591 - val_loss: 7.1676 - val_accuracy: 0.1937\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 0.2667 - accuracy: 0.9469 - val_loss: 6.6255 - val_accuracy: 0.1664\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4543 - accuracy: 0.6324 - val_loss: 6.3913 - val_accuracy: 0.1865\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 0.4046 - accuracy: 0.8989 - val_loss: 6.2548 - val_accuracy: 0.1980\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 6s 72ms/step - loss: 0.1978 - accuracy: 0.9552 - val_loss: 6.1894 - val_accuracy: 0.2052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19439162760>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"C:\\Users\\shaif\\Downloads\\office_real_32_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    \n",
    "num_classes = 65  # Update with the actual number of classes in your target data\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model with early stopping\n",
    "new_model.fit(X_train, Y_train,validation_split = 0.2, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205e0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2191621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 30ms/step\n",
      "Accuracy: 0.2121559633027523\n",
      "F1 Score (Micro): 0.2121559633027523\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = new_model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84781411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "186a10ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 12s 67ms/step - loss: 4.7903 - accuracy: 0.0714 - val_loss: 8.1750 - val_accuracy: 0.0531\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 4.2607 - accuracy: 0.0994 - val_loss: 16.2618 - val_accuracy: 0.0187\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 4.5316 - accuracy: 0.0775 - val_loss: 17.3926 - val_accuracy: 0.0344\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 4.4399 - accuracy: 0.0864 - val_loss: 8.6135 - val_accuracy: 0.0588\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 4.4135 - accuracy: 0.0907 - val_loss: 4.8565 - val_accuracy: 0.0617\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 4.0357 - accuracy: 0.1123 - val_loss: 4.2735 - val_accuracy: 0.0732\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 4.0548 - accuracy: 0.1374 - val_loss: 9.9162 - val_accuracy: 0.0961\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 3.9153 - accuracy: 0.1485 - val_loss: 5.2574 - val_accuracy: 0.0717\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 4.2535 - accuracy: 0.1184 - val_loss: 5.3980 - val_accuracy: 0.0545\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 4.1362 - accuracy: 0.1327 - val_loss: 5.1097 - val_accuracy: 0.0861\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 4.1749 - accuracy: 0.1410 - val_loss: 5.0618 - val_accuracy: 0.1047\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 4.2596 - accuracy: 0.1420 - val_loss: 1040.6515 - val_accuracy: 0.0172\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 4.6869 - accuracy: 0.0703 - val_loss: 23.8839 - val_accuracy: 0.0201\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 4.3991 - accuracy: 0.0951 - val_loss: 19.9790 - val_accuracy: 0.0531\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 4.1520 - accuracy: 0.1327 - val_loss: 6.6328 - val_accuracy: 0.0689\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 6s 72ms/step - loss: 4.0243 - accuracy: 0.1370 - val_loss: 9.5871 - val_accuracy: 0.0660\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 4.2515 - accuracy: 0.1331 - val_loss: 4.1541 - val_accuracy: 0.0789\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 6s 72ms/step - loss: 4.2361 - accuracy: 0.1356 - val_loss: 4.4220 - val_accuracy: 0.0775\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 6s 73ms/step - loss: 3.8963 - accuracy: 0.1467 - val_loss: 4.0144 - val_accuracy: 0.1119\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 3.8206 - accuracy: 0.1481 - val_loss: 5.4318 - val_accuracy: 0.0918\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 3.7035 - accuracy: 0.1819 - val_loss: 29.6705 - val_accuracy: 0.0588\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 3.7567 - accuracy: 0.1761 - val_loss: 4.2185 - val_accuracy: 0.0646\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 3.4887 - accuracy: 0.2001 - val_loss: 4.7429 - val_accuracy: 0.1621\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 3.3199 - accuracy: 0.2202 - val_loss: 4.7108 - val_accuracy: 0.0904\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 4s 51ms/step - loss: 3.4690 - accuracy: 0.2267 - val_loss: 4.6101 - val_accuracy: 0.0918\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 3.3002 - accuracy: 0.2428 - val_loss: 4.1302 - val_accuracy: 0.1377\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 3.1722 - accuracy: 0.2726 - val_loss: 6.1982 - val_accuracy: 0.1377\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 3.0986 - accuracy: 0.2776 - val_loss: 4.8155 - val_accuracy: 0.0703\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 3.5187 - accuracy: 0.2281 - val_loss: 6.1677 - val_accuracy: 0.0933\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 3.4614 - accuracy: 0.2482 - val_loss: 13.5468 - val_accuracy: 0.1176\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 4s 51ms/step - loss: 3.4208 - accuracy: 0.2568 - val_loss: 45.1165 - val_accuracy: 0.0990\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 3.1030 - accuracy: 0.2945 - val_loss: 6.0626 - val_accuracy: 0.0703\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 3.1495 - accuracy: 0.2618 - val_loss: 4.2960 - val_accuracy: 0.1363\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 2.7127 - accuracy: 0.3390 - val_loss: 5.5989 - val_accuracy: 0.1148\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 2.5045 - accuracy: 0.3863 - val_loss: 6.9929 - val_accuracy: 0.1463\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 2.2807 - accuracy: 0.4322 - val_loss: 4.6440 - val_accuracy: 0.1980\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 2.2547 - accuracy: 0.4426 - val_loss: 3.8764 - val_accuracy: 0.1693\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 2.2826 - accuracy: 0.4480 - val_loss: 6.1742 - val_accuracy: 0.0818\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 2.4356 - accuracy: 0.4060 - val_loss: 7.2841 - val_accuracy: 0.1521\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 6s 72ms/step - loss: 2.1870 - accuracy: 0.4831 - val_loss: 6.4973 - val_accuracy: 0.0904\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 2.3052 - accuracy: 0.4240 - val_loss: 5.4299 - val_accuracy: 0.1636\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.8772 - accuracy: 0.5524 - val_loss: 4.8352 - val_accuracy: 0.1392\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 1.7488 - accuracy: 0.5836 - val_loss: 4.9286 - val_accuracy: 0.1320\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 1.7719 - accuracy: 0.5771 - val_loss: 5.3213 - val_accuracy: 0.0990\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 3.0055 - accuracy: 0.3221 - val_loss: 6.5768 - val_accuracy: 0.0918\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 2.1636 - accuracy: 0.4523 - val_loss: 4.3398 - val_accuracy: 0.2109\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5859 - accuracy: 0.5911 - val_loss: 6.9524 - val_accuracy: 0.1578\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 1.7490 - accuracy: 0.5635 - val_loss: 5.2008 - val_accuracy: 0.1463\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.2734 - accuracy: 0.6897 - val_loss: 4.5250 - val_accuracy: 0.2023\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 1.0411 - accuracy: 0.7346 - val_loss: 4.4845 - val_accuracy: 0.2310\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 0.9168 - accuracy: 0.7773 - val_loss: 4.7312 - val_accuracy: 0.2109\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 1.0720 - accuracy: 0.7285 - val_loss: 6.8569 - val_accuracy: 0.1779\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.8797 - accuracy: 0.7794 - val_loss: 4.6396 - val_accuracy: 0.2095\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 0.7551 - accuracy: 0.8167 - val_loss: 5.3183 - val_accuracy: 0.1894\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.7750 - accuracy: 0.8271 - val_loss: 5.2556 - val_accuracy: 0.1908\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.6805 - accuracy: 0.8354 - val_loss: 5.2809 - val_accuracy: 0.2009\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 0.5934 - accuracy: 0.8626 - val_loss: 6.1413 - val_accuracy: 0.1521\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 6s 71ms/step - loss: 3.3191 - accuracy: 0.2493 - val_loss: 6.0890 - val_accuracy: 0.0717\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 6s 73ms/step - loss: 2.1240 - accuracy: 0.4297 - val_loss: 4.7091 - val_accuracy: 0.1750\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 6s 70ms/step - loss: 1.4768 - accuracy: 0.6148 - val_loss: 4.9022 - val_accuracy: 0.1750\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 6s 73ms/step - loss: 1.1855 - accuracy: 0.7048 - val_loss: 5.1160 - val_accuracy: 0.2138\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 7s 76ms/step - loss: 0.9104 - accuracy: 0.7669 - val_loss: 4.8529 - val_accuracy: 0.2080\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 6s 73ms/step - loss: 0.7236 - accuracy: 0.8189 - val_loss: 5.2127 - val_accuracy: 0.2152\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 0.6247 - accuracy: 0.8418 - val_loss: 5.2941 - val_accuracy: 0.2080\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 0.9617 - accuracy: 0.7446 - val_loss: 5.3735 - val_accuracy: 0.2066\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 0.5950 - accuracy: 0.8454 - val_loss: 5.4304 - val_accuracy: 0.1994\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 0.8734 - accuracy: 0.7568 - val_loss: 5.2059 - val_accuracy: 0.2037\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 0.5544 - accuracy: 0.8580 - val_loss: 5.1719 - val_accuracy: 0.2152\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 0.4433 - accuracy: 0.8874 - val_loss: 5.3803 - val_accuracy: 0.2166\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.3212 - accuracy: 0.9186 - val_loss: 5.3657 - val_accuracy: 0.2353\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.3389 - accuracy: 0.9189 - val_loss: 5.5276 - val_accuracy: 0.2195\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 6s 63ms/step - loss: 0.4540 - accuracy: 0.8989 - val_loss: 5.6273 - val_accuracy: 0.2195\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 5s 52ms/step - loss: 0.2936 - accuracy: 0.9290 - val_loss: 5.3764 - val_accuracy: 0.2253\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 4s 51ms/step - loss: 0.5348 - accuracy: 0.8572 - val_loss: 5.8740 - val_accuracy: 0.1937\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 0.5489 - accuracy: 0.8465 - val_loss: 6.2268 - val_accuracy: 0.2095\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.3360 - accuracy: 0.9161 - val_loss: 5.5996 - val_accuracy: 0.2683\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 0.2970 - accuracy: 0.9286 - val_loss: 5.6435 - val_accuracy: 0.2367\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 0.2644 - accuracy: 0.9290 - val_loss: 5.7979 - val_accuracy: 0.2339\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 0.2111 - accuracy: 0.9469 - val_loss: 5.7573 - val_accuracy: 0.2410\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.2680 - accuracy: 0.9304 - val_loss: 6.0985 - val_accuracy: 0.2382\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 0.1971 - accuracy: 0.9476 - val_loss: 6.0034 - val_accuracy: 0.2324\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.1527 - accuracy: 0.9623 - val_loss: 5.8922 - val_accuracy: 0.2339\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 0.1576 - accuracy: 0.9602 - val_loss: 5.7966 - val_accuracy: 0.2367\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 0.2624 - accuracy: 0.9311 - val_loss: 6.1191 - val_accuracy: 0.2267\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 6s 73ms/step - loss: 0.2169 - accuracy: 0.9394 - val_loss: 5.8266 - val_accuracy: 0.2267\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 6s 72ms/step - loss: 0.3068 - accuracy: 0.9204 - val_loss: 6.0465 - val_accuracy: 0.2453\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 6s 72ms/step - loss: 0.3380 - accuracy: 0.9118 - val_loss: 5.7942 - val_accuracy: 0.2539\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 0.2121 - accuracy: 0.9476 - val_loss: 6.1659 - val_accuracy: 0.2324\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 5s 61ms/step - loss: 0.4639 - accuracy: 0.8727 - val_loss: 6.0502 - val_accuracy: 0.1894\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 0.2686 - accuracy: 0.9286 - val_loss: 6.0552 - val_accuracy: 0.2209\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.2039 - accuracy: 0.9491 - val_loss: 6.1397 - val_accuracy: 0.2339\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 0.1984 - accuracy: 0.9537 - val_loss: 5.9562 - val_accuracy: 0.2296\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 0.1600 - accuracy: 0.9623 - val_loss: 6.2545 - val_accuracy: 0.2195\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 0.1742 - accuracy: 0.9487 - val_loss: 6.1640 - val_accuracy: 0.2324\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.1648 - accuracy: 0.9537 - val_loss: 6.3503 - val_accuracy: 0.2253\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.1766 - accuracy: 0.9580 - val_loss: 6.5921 - val_accuracy: 0.2181\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 5s 60ms/step - loss: 0.1467 - accuracy: 0.9609 - val_loss: 6.3588 - val_accuracy: 0.2310\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 5s 62ms/step - loss: 0.9930 - accuracy: 0.7421 - val_loss: 8.0008 - val_accuracy: 0.2152\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 0.3390 - accuracy: 0.9125 - val_loss: 6.3645 - val_accuracy: 0.2209\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 0.2291 - accuracy: 0.9351 - val_loss: 7.2254 - val_accuracy: 0.1980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19443f99550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(65, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f09a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1fb53b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 30ms/step\n",
      "Accuracy: 0.21330275229357798\n",
      "F1 Score (Micro): 0.21330275229357798\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb0131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d1706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd74c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e387f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81271cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468bc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c2543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
