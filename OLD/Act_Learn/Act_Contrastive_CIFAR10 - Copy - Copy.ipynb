{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4316b827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaif\\.conda\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 512\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "hidden_units = 512\n",
    "projection_units = 256\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e5cfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8628ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7088558",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "#train_labels = to_categorical(train_labels)\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255 \n",
    "\n",
    "x_train, x_unlab, y_train, y_unlab = train_test_split( train_images, train_labels , test_size=0.5, random_state=42 )\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( x_train,y_train , test_size=0.2, random_state=40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db0b606f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37093df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.02),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728bd488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, None, None, 3)     7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "def create_encoder():\n",
    "    resnet = tf.keras.applications.ResNet50V2( include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\" )\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = resnet(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79f4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbbad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e9383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e54f9228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a73fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "\n",
    "        logits = tf.divide( tf.matmul(  \n",
    "            feature_vectors_normalized, tf.transpose(feature_vectors_normalized)),self.temperature,)\n",
    "        \n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a97bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar-encoder_with_projection-head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             23564807  \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,089,351\n",
      "Trainable params: 24,043,904\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7568\\3577858032.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mencoder_with_projection_head\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m history = encoder_with_projection_head.fit(\n\u001b[0m\u001b[0;32m     12\u001b[0m     x=X_train, y=Y_train, batch_size=batch_size, epochs=2)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    961\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 785\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    786\u001b[0m             *args, **kwds))\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2522\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2523\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2524\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m             \u001b[1;31m# Only get placeholders for arguments, not captures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2759\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplaceholder_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"args\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2760\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2762\u001b[0m           \u001b[0mgraph_capture_container\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_capture_func_lib\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2668\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   2671\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2672\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1286\u001b[0m         if x is not None)\n\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m     \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[0;32m    417\u001b[0m       \u001b[0mcontrol_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMUST_RUN_ORDER_INSENSITIVE_STATEFUL_OPS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;31m# This will add it to self._independent_ops, but also mark it with an\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;31m# attribute.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mtype\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2581\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2582\u001b[0m     \u001b[1;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2583\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2585\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "history = encoder_with_projection_head.fit(\n",
    "    x=X_train, y=Y_train, batch_size=batch_size, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "42b74c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "157/157 [==============================] - 13s 47ms/step - loss: nan - sparse_categorical_accuracy: 0.1015\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 10s 62ms/step - loss: nan - sparse_categorical_accuracy: 0.1015\n",
      "157/157 [==============================] - 4s 21ms/step - loss: nan - sparse_categorical_accuracy: 0.1044\n",
      "Test accuracy: 10.44%\n"
     ]
    }
   ],
   "source": [
    "classifier = create_classifier(encoder, trainable=False) \n",
    "\n",
    "history = classifier.fit(x=X_train, y=Y_train, batch_size=batch_size, epochs=num_epochs) \n",
    "\n",
    "accuracy = classifier.evaluate(X_test, Y_test)[1] \n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b5efe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for merging new history objects with older ones\n",
    "def append_history(losses, val_losses, accuracy, val_accuracy, history):\n",
    "    losses = losses + history.history[\"loss\"]\n",
    "    val_losses = val_losses + history.history[\"val_loss\"]\n",
    "    accuracy = accuracy + history.history[\"accuracy\"]\n",
    "    val_accuracy = val_accuracy + history.history[\"val_accuracy\"]\n",
    "    return losses, val_losses, accuracy, val_accuracy\n",
    "\n",
    "\n",
    "# Plotter function\n",
    "def plot_history(losses, val_losses, accuracies, val_accuracies):\n",
    "    plt.plot(losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.legend([\"train_loss\", \"val_loss\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(accuracies)\n",
    "    plt.plot(val_accuracies)\n",
    "    plt.legend([\"train_accuracy\", \"val_accuracy\"])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170d608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def resmodel():\n",
    "    \n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3),))\n",
    "    model.add(layers.Conv2D(64, (3, 3),))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3),))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Flatten()) \n",
    "    model.add(layers.Dense(32))\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "149d9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def create_model(X,Y,X_test, Y_test,num_epochs):\n",
    "    \n",
    "    data_augmentation.layers[0].adapt(X)\n",
    "    \n",
    "    encoder = create_encoder()\n",
    "\n",
    "    encoder_with_projection_head = add_projection_head(encoder)\n",
    "    \n",
    "    encoder_with_projection_head.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                                     loss=SupervisedContrastiveLoss(temperature),)\n",
    "    \n",
    "    \n",
    "    history = encoder_with_projection_head.fit(x=X, y=Y, batch_size=256, epochs=num_epochs)\n",
    "    \n",
    "    \n",
    "    classifier = create_classifier(encoder, trainable=False) \n",
    "\n",
    "    history = classifier.fit(x=X, y=Y, batch_size=batch_size, epochs=num_epochs) \n",
    "\n",
    "    accuracy = classifier.evaluate(X_test, Y_test)[1] \n",
    "    \n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    #model.summary()\n",
    "    return encoder,classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9537820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.concatenate((X_train, x_unlab))\n",
    "X_all = arr\n",
    "arr = np.concatenate((Y_train, y_unlab))\n",
    "Y_all = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bcdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks=[keras.callbacks.EarlyStopping(patience=4, verbose=1), ],\n",
    "\n",
    "def train_full_model(X_train, X_test, Y_train, Y_test,num):\n",
    "    \n",
    "    X_train, Y_train = shuffle(X_train, Y_train)\n",
    "    \n",
    "    encoder,classifier = create_model(X_train,Y_train,X_test, Y_test,num)\n",
    "\n",
    "    accuracy = classifier.evaluate(X_test, Y_test)[1] \n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\") \n",
    "    \n",
    "    \n",
    "    return encoder,classifier\n",
    "\n",
    "\n",
    "encoder,classifier = train_full_model(X_all, X_test, Y_all, Y_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9dd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder,classifier = train_full_model(X_train, X_test, Y_train, Y_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37c43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d502ccbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3603ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "313/313 [==============================] - 883s 3s/step - loss: 4.0011\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 883s 3s/step - loss: 3.8776\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 896s 3s/step - loss: 3.8134\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 904s 3s/step - loss: 3.7631\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 920s 3s/step - loss: 3.7228\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "313/313 [==============================] - 87s 260ms/step - loss: 2.2893 - sparse_categorical_accuracy: 0.2341\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 88s 280ms/step - loss: 1.9369 - sparse_categorical_accuracy: 0.2792\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 84s 269ms/step - loss: 1.8383 - sparse_categorical_accuracy: 0.2986\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 86s 275ms/step - loss: 1.8147 - sparse_categorical_accuracy: 0.3096\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 86s 276ms/step - loss: 1.7801 - sparse_categorical_accuracy: 0.3192\n",
      "157/157 [==============================] - 17s 100ms/step - loss: 1.7134 - sparse_categorical_accuracy: 0.3596\n",
      "Acc Test : \n",
      "\n",
      "\n",
      "0.3596000075340271\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "720\n",
      "\n",
      "\n",
      "Chosen in each iter : \n",
      "3210\n",
      "\n",
      "\n",
      "391/391 [==============================] - 73s 183ms/step\n",
      "782/782 [==============================] - 80s 100ms/step\n",
      "(2803,)\n",
      "(360,)\n",
      "(360,)\n",
      "(360,)\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.6515 - sparse_categorical_accuracy: 0.3735\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.3735283613204956\n",
      "Now2\n",
      "(20360, 1)\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1273/1273 [==============================] - 121s 95ms/step - loss: 1.7704 - sparse_categorical_accuracy: 0.3288\n",
      "Epoch 2/5\n",
      "1273/1273 [==============================] - 118s 93ms/step - loss: 1.7393 - sparse_categorical_accuracy: 0.3382\n",
      "Epoch 3/5\n",
      "1273/1273 [==============================] - 118s 93ms/step - loss: 1.7250 - sparse_categorical_accuracy: 0.3442\n",
      "Epoch 4/5\n",
      "1273/1273 [==============================] - 119s 93ms/step - loss: 1.7121 - sparse_categorical_accuracy: 0.3490\n",
      "Epoch 5/5\n",
      "1273/1273 [==============================] - 114s 90ms/step - loss: 1.7090 - sparse_categorical_accuracy: 0.3438\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "720\n",
      "\n",
      "\n",
      "Chosen in each iter : \n",
      "3210\n",
      "\n",
      "\n",
      "347/347 [==============================] - 63s 181ms/step\n",
      "694/694 [==============================] - 69s 99ms/step\n",
      "694/694 [==============================] - 70s 102ms/step\n",
      "(2877,)\n",
      "(360,)\n",
      "(360,)\n",
      "(360,)\n",
      "90/90 [==============================] - 9s 101ms/step - loss: 1.6091 - sparse_categorical_accuracy: 0.3810\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.380952388048172\n",
      "Now2\n",
      "(20720, 1)\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1295/1295 [==============================] - 120s 93ms/step - loss: 1.7074 - sparse_categorical_accuracy: 0.3516\n",
      "Epoch 2/5\n",
      "1295/1295 [==============================] - 120s 93ms/step - loss: 1.7002 - sparse_categorical_accuracy: 0.3542\n",
      "Epoch 3/5\n",
      "1295/1295 [==============================] - 122s 94ms/step - loss: 1.6898 - sparse_categorical_accuracy: 0.3586\n",
      "Epoch 4/5\n",
      "1295/1295 [==============================] - 122s 94ms/step - loss: 1.6889 - sparse_categorical_accuracy: 0.3613\n",
      "Epoch 5/5\n",
      "1295/1295 [==============================] - 118s 91ms/step - loss: 1.6835 - sparse_categorical_accuracy: 0.3623\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "720\n",
      "\n",
      "\n",
      "Chosen in each iter : \n",
      "3210\n",
      "\n",
      "\n",
      "297/297 [==============================] - 54s 182ms/step\n",
      "594/594 [==============================] - 58s 98ms/step\n",
      "594/594 [==============================] - 62s 104ms/step\n",
      "(2788,)\n",
      "(360,)\n",
      "(360,)\n",
      "(360,)\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 1.5353 - sparse_categorical_accuracy: 0.4071\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.4071018695831299\n",
      "Now2\n",
      "(21080, 1)\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1318/1318 [==============================] - 123s 94ms/step - loss: 1.6820 - sparse_categorical_accuracy: 0.3599\n",
      "Epoch 2/5\n",
      "1318/1318 [==============================] - 125s 95ms/step - loss: 1.6826 - sparse_categorical_accuracy: 0.3656\n",
      "Epoch 3/5\n",
      "1318/1318 [==============================] - 123s 93ms/step - loss: 1.6734 - sparse_categorical_accuracy: 0.3674\n",
      "Epoch 4/5\n",
      "1318/1318 [==============================] - 125s 95ms/step - loss: 1.6777 - sparse_categorical_accuracy: 0.3627\n",
      "Epoch 5/5\n",
      "1318/1318 [==============================] - 121s 92ms/step - loss: 1.6706 - sparse_categorical_accuracy: 0.3679\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "720\n",
      "\n",
      "\n",
      "Chosen in each iter : \n",
      "3210\n",
      "\n",
      "\n",
      "249/249 [==============================] - 45s 181ms/step\n",
      "497/497 [==============================] - 49s 98ms/step\n",
      "497/497 [==============================] - 51s 103ms/step\n",
      "(3093,)\n",
      "(360,)\n",
      "(360,)\n",
      "(360,)\n",
      "97/97 [==============================] - 10s 106ms/step - loss: 1.5896 - sparse_categorical_accuracy: 0.3957\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.3957323133945465\n",
      "Now2\n",
      "(21440, 1)\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1340/1340 [==============================] - 125s 93ms/step - loss: 1.6781 - sparse_categorical_accuracy: 0.3644\n",
      "Epoch 2/5\n",
      "1340/1340 [==============================] - 125s 94ms/step - loss: 1.6781 - sparse_categorical_accuracy: 0.3659\n",
      "Epoch 3/5\n",
      "1340/1340 [==============================] - 126s 94ms/step - loss: 1.6686 - sparse_categorical_accuracy: 0.3630\n",
      "Epoch 4/5\n",
      "1340/1340 [==============================] - 125s 93ms/step - loss: 1.6638 - sparse_categorical_accuracy: 0.3744\n",
      "Epoch 5/5\n",
      "1340/1340 [==============================] - 126s 94ms/step - loss: 1.6691 - sparse_categorical_accuracy: 0.3669\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "720\n",
      "\n",
      "\n",
      "Chosen in each iter : \n",
      "3210\n",
      "\n",
      "\n",
      "196/196 [==============================] - 36s 181ms/step\n",
      "391/391 [==============================] - 38s 97ms/step\n",
      "391/391 [==============================] - 39s 101ms/step\n",
      "(2965,)\n",
      "(360,)\n",
      "(360,)\n",
      "(360,)\n",
      "93/93 [==============================] - 9s 102ms/step - loss: 1.6335 - sparse_categorical_accuracy: 0.3963\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.3962900638580322\n",
      "Now2\n",
      "(21800, 1)\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 128s 94ms/step - loss: 1.6686 - sparse_categorical_accuracy: 0.3695\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 130s 95ms/step - loss: 1.6706 - sparse_categorical_accuracy: 0.3679\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 127s 93ms/step - loss: 1.6636 - sparse_categorical_accuracy: 0.3724\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 129s 95ms/step - loss: 1.6572 - sparse_categorical_accuracy: 0.3690\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 126s 93ms/step - loss: 1.6679 - sparse_categorical_accuracy: 0.3717\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "720\n",
      "\n",
      "\n",
      "Chosen in each iter : \n",
      "3210\n",
      "\n",
      "\n",
      "146/146 [==============================] - 26s 181ms/step\n",
      "291/291 [==============================] - 29s 98ms/step\n",
      "291/291 [==============================] - 30s 104ms/step\n",
      "(2996,)\n",
      "(360,)\n",
      "(360,)\n",
      "(360,)\n",
      "94/94 [==============================] - 10s 107ms/step - loss: 1.7096 - sparse_categorical_accuracy: 0.3728\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.37283045053482056\n",
      "Now2\n",
      "(22160, 1)\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1385/1385 [==============================] - 129s 93ms/step - loss: 1.6593 - sparse_categorical_accuracy: 0.3675\n",
      "Epoch 2/5\n",
      "1385/1385 [==============================] - 131s 95ms/step - loss: 1.6682 - sparse_categorical_accuracy: 0.3716\n",
      "Epoch 3/5\n",
      "1385/1385 [==============================] - 131s 95ms/step - loss: 1.6535 - sparse_categorical_accuracy: 0.3784\n",
      "Epoch 4/5\n",
      "1385/1385 [==============================] - 131s 95ms/step - loss: 1.6577 - sparse_categorical_accuracy: 0.3769\n",
      "Epoch 5/5\n",
      "1385/1385 [==============================] - 131s 95ms/step - loss: 1.6574 - sparse_categorical_accuracy: 0.3729\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "720\n",
      "\n",
      "\n",
      "Chosen in each iter : \n",
      "3210\n",
      "\n",
      "\n",
      "95/95 [==============================] - 17s 179ms/step\n",
      "189/189 [==============================] - 19s 99ms/step\n",
      "189/189 [==============================] - 18s 97ms/step\n",
      "(3059,)\n",
      "(360,)\n",
      "(360,)\n",
      "(360,)\n",
      "96/96 [==============================] - 9s 98ms/step - loss: 1.7599 - sparse_categorical_accuracy: 0.3406\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.34063419699668884\n",
      "Now2\n",
      "(22520, 1)\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "1408/1408 [==============================] - 132s 94ms/step - loss: 1.6537 - sparse_categorical_accuracy: 0.3780\n",
      "Epoch 2/5\n",
      "1408/1408 [==============================] - 131s 93ms/step - loss: 1.6597 - sparse_categorical_accuracy: 0.3762\n",
      "Epoch 3/5\n",
      "1408/1408 [==============================] - 131s 93ms/step - loss: 1.6595 - sparse_categorical_accuracy: 0.3757\n",
      "Epoch 4/5\n",
      "1408/1408 [==============================] - 130s 92ms/step - loss: 1.6530 - sparse_categorical_accuracy: 0.3750\n",
      "Epoch 5/5\n",
      "1408/1408 [==============================] - 130s 92ms/step - loss: 1.6476 - sparse_categorical_accuracy: 0.3768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_active_learning_models(encoder,classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations,num_epochs=1):\n",
    "\n",
    "\n",
    "\n",
    "    accuracy = classifier.evaluate(X_test, Y_test, batch_size=32)[1]\n",
    "    \n",
    "    \n",
    "    print(\"Acc Test : \")\n",
    "    print(\"\\n\")\n",
    "    print(accuracy)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    entropy = []\n",
    "    l = len(y_unlab)\n",
    "    d = int ( np.round ( l/num_iterations ) )\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        l = len(y_unlab)\n",
    "        \n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        \n",
    "        print(\"Iteration : \")\n",
    "        \n",
    "        print(iteration+1)\n",
    "        \n",
    "        print(\"\\n\\n\\n\\n\\n\")\n",
    "        nn_clusters = 10\n",
    "        num_points_per_class = int ( np.round (d/10)   )\n",
    "        \n",
    "        budget =  int ( np.round (d/100)   )\n",
    "        num_points_per_class = num_points_per_class - (budget)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"Annotated in each iter : \")\n",
    "        print(budget*20)\n",
    "        print(\"\\n\")\n",
    "        print(\"Chosen in each iter : \")\n",
    "        print(num_points_per_class*10)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        x_ulb = encoder.predict(x_unlab, batch_size=64)\n",
    "        kmeans = KMeans(n_clusters=nn_clusters, init='k-means++', n_init=10).fit(x_ulb)\n",
    "\n",
    "        closest_points_indices = []\n",
    "        annotate_indices = []\n",
    "        \n",
    "        for i in range(10):\n",
    "            \n",
    "            cluster_center = kmeans.cluster_centers_[i]\n",
    "            \n",
    "            cluster_indices = np.where(kmeans.labels_ == i)[0]\n",
    "            \n",
    "            distances = np.linalg.norm(x_ulb[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "            closest_indices = cluster_indices[np.argsort(distances)[:num_points_per_class]]\n",
    "            \n",
    "            #annotate = cluster_indices[np.argsort(distances,-1)[:budget]] \n",
    "            \n",
    "            closest_points_indices.extend(closest_indices)\n",
    "            \n",
    "            #annotate_indices.extend(annotate)\n",
    "\n",
    "        chosen_indices = closest_points_indices\n",
    "    \n",
    "        rnd = chosen_indices\n",
    "        \n",
    "        if (iteration == 0):\n",
    "            xx_ulb = classifier.predict(x_unlab, batch_size=32)\n",
    "            argmax_indices = np.argmax(xx_ulb, axis=1)\n",
    "            entropy = x_ulb[np.arange(len(xx_ulb)), argmax_indices]\n",
    "            most_uncertain_idx = np.argsort(entropy)[-(budget*10):]\n",
    "            \n",
    "        else :\n",
    "            xx_ulb = cls0.predict(x_unlab, batch_size=32)\n",
    "            argmax_indices = np.argmax(xx_ulb, axis=1)\n",
    "            entropy = x_ulb[np.arange(len(xx_ulb)), argmax_indices]\n",
    "            \n",
    "            xx_ulb = cls1.predict(x_unlab, batch_size=32)\n",
    "            argmax_indices = np.argmax(xx_ulb, axis=1)\n",
    "            entropy_new = x_ulb[np.arange(len(xx_ulb)), argmax_indices]\n",
    "            \n",
    "            most_uncertain_idx = np.argsort(np.abs(entropy_new - entropy))[::-1][:(budget*10)]\n",
    "            \n",
    "        annotate_indices.extend(most_uncertain_idx)\n",
    "        annt = annotate_indices\n",
    "        \n",
    "        print(np.shape(rnd))\n",
    "        print(np.shape(annotate_indices))\n",
    "        print(np.shape(most_uncertain_idx))\n",
    "        print(np.shape(annt))\n",
    "        \n",
    "        all = list(range(1, l))\n",
    "        main_list = list(set(all) - set(rnd) - set(annt))\n",
    "        new_lab = x_unlab[rnd]\n",
    "        new_annt = x_unlab[annt]\n",
    "        arr = np.concatenate((X_train,new_annt))\n",
    "        X_train = arr\n",
    "\n",
    "        \n",
    "        accuracy = classifier.evaluate(new_lab, y_unlab[rnd], batch_size=32)[1]\n",
    "        print(\"Acc : \")\n",
    "        print(\"\\n\")\n",
    "        print(accuracy)\n",
    "        \n",
    "        annt_y = y_unlab[annt]\n",
    "        \n",
    "        \n",
    "        arr = np.concatenate((Y_train, annt_y))\n",
    "        Y_train = arr\n",
    "        \n",
    "        \n",
    "        x_unlab = x_unlab[main_list]\n",
    "\n",
    "        y_unlab = y_unlab[main_list]\n",
    "        \n",
    "        #history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=batch_size, epochs=5)\n",
    "        \n",
    "        print(\"Now2\")\n",
    "        print(np.shape(Y_train))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        cls0=classifier\n",
    "        cls1=classifier\n",
    "        history = classifier.fit(x=X_train, y=Y_train, batch_size=16, epochs=5) \n",
    "        cls1=classifier\n",
    "   \n",
    "    \n",
    "    return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "#train_labels = to_categorical(train_labels)\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255 \n",
    "\n",
    "x_train, x_unlab, y_train, y_unlab = train_test_split( train_images, train_labels , test_size=0.5, random_state=42 )\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( x_train,y_train , test_size=0.2, random_state=40 )\n",
    "\n",
    "data_augmentation.layers[0].adapt(X_train)\n",
    "encoder = create_encoder()\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                        loss=SupervisedContrastiveLoss(temperature))\n",
    "    \n",
    "history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=64, epochs=5)\n",
    "classifier = create_classifier(encoder, trainable=False) \n",
    "history = classifier.fit(x=X_train, y=Y_train, batch_size=64, epochs=5) \n",
    "\n",
    "encoder, classifier,X_train,Y_train,x_unlab,y_unlab = train_active_learning_models(encoder, classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecd0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c9710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(final_encoder, final_classifier, X_test, Y_test):\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Test set evaluation: \", model.evaluate( X_test, Y_test , verbose=0, return_dict=True), )\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f086bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f59626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_active_learning_models(encoder,classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations,num_epochs=1):\n",
    "   \n",
    "    \n",
    "    entropy = []\n",
    "    l = len(y_unlab)\n",
    "    d = int ( np.round ( l/num_iterations ) )\n",
    "    #x = int(np.round( l/d ))\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        l = len(y_unlab)\n",
    "        \n",
    "        print(\"\\n\\n\\n\\n\")\n",
    "        \n",
    "        print(\"Iteration : \")\n",
    "        \n",
    "        print(iteration+1)\n",
    "        \n",
    "        print(\"\\n\\n\\n\\n\\n\")\n",
    "        \n",
    "        nn_clusters = 10\n",
    "        num_points_per_class = int ( np.round (d/10)   )\n",
    "        \n",
    "        budget =  int(num_points_per_class /10 )\n",
    "        num_points_per_class = num_points_per_class - budget\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"Annotated in each iter : \")\n",
    "        print(budget*10)\n",
    "        print(\"\\n\")\n",
    "        print(\"Chosen in each iter : \")\n",
    "        print(num_points_per_class*10)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        budget = budget/2\n",
    "  \n",
    "        try :\n",
    "            x_ulb = encoder.predict(x_unlab, batch_size=batch_size)\n",
    "        except:\n",
    "            return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "        \n",
    "        if (iteration == 0):\n",
    "            argmax_indices = np.argmax(x_ulb, axis=1)\n",
    "            entropy = x_ulb[np.arange(len(x_ulb)), argmax_indices]\n",
    "            most_uncertain_idx = np.argsort(entropy)[-budget:]\n",
    "            \n",
    "        else :\n",
    "            argmax_indices = np.argmax(x_ulb, axis=1)\n",
    "            entropy_new = x_ulb[np.arange(len(x_ulb)), argmax_indices]\n",
    "            most_uncertain_idx = np.argsort(np.abs(entropy_new - entropy))[::-1][:budget]\n",
    "            entropy = entropy_new\n",
    "        \n",
    "        for i in range(10):\n",
    "            \n",
    "            cluster_center = kmeans.cluster_centers_[i]\n",
    "            \n",
    "            cluster_indices = np.where(kmeans.labels_ == i)[0]\n",
    "            \n",
    "            distances = np.linalg.norm(x_ulb[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "            #closest_indices = cluster_indices[np.argsort(distances)[:num_points_per_class]]\n",
    "            \n",
    "            annotate = cluster_indices[np.argsort(distances,-1)[:budget]] \n",
    "            \n",
    "            #closest_points_indices.extend(closest_indices)\n",
    "            \n",
    "            annotate_indices.extend(annotate)\n",
    "        \n",
    "        print(np.shape(x_ulb))\n",
    "\n",
    "        annotate_indices.extend(most_uncertain_idx)\n",
    "        \n",
    "    \n",
    "        print(np.shape(annotate_indices))\n",
    "        \n",
    "        annt = annotate_indices\n",
    "        \n",
    "        \n",
    "        all = list(range(1, l))\n",
    "        main_list = list(set(all) - set(annt))\n",
    "        \n",
    "        #add those index to from unlablled set to training set\n",
    "        #new_lab = x_unlab[rnd]\n",
    "        new_annt = x_unlab[annt]\n",
    "        arr = np.concatenate((X_train,new_annt))\n",
    "        X_train = arr\n",
    "\n",
    "        \n",
    "        try :\n",
    "            accuracy = classifier.evaluate(new_lab, y_unlab[rnd], batch_size=8)[1]\n",
    "        except:\n",
    "            return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "        \n",
    "        print(\"Acc : \")\n",
    "        print(\"\\n\")\n",
    "        print(accuracy)\n",
    "        \n",
    "        annt_y = y_unlab[annt]\n",
    "        print(\"This\")\n",
    "        print(np.shape(Y_train))\n",
    "        print(\"Now\")\n",
    "        #print(np.shape(new_y))\n",
    "        \n",
    "        #new_yy = np.argmax(new_y, axis=1)\n",
    "        \n",
    "        #new_yy = new_yy.reshape(len(new_y),1)\n",
    "        \n",
    "        \n",
    "        arr = np.concatenate((Y_train, annt_y))\n",
    "        Y_train = arr\n",
    "        \n",
    "        \n",
    "        #create the new unlabelled set\n",
    "        x_unlab = x_unlab[main_list]\n",
    "\n",
    "        #create the new unlabelled label set\n",
    "        y_unlab = y_unlab[main_list]\n",
    "        \n",
    "        \n",
    "        #try :\n",
    "            #history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=batch_size, epochs=5)\n",
    "        #except :\n",
    "            #return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "        \n",
    "        print(\"Now2\")\n",
    "        print(np.shape(Y_train))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        try :\n",
    "            history = classifier.fit(x=X_train, y=Y_train, batch_size=4, epochs=1) \n",
    "        except:\n",
    "            return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "        \n",
    "        #test on data\n",
    "    \n",
    "    #accuracy = classifier.evaluate(X_test, Y_test, batch_size=4)[1]\n",
    "   \n",
    "    \n",
    "    return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "\n",
    "\n",
    "encoder, classifier,X_train,Y_train,x_unlab,y_unlab = train_active_learning_models(encoder, classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7cc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce050fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e06e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fef761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe097e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c607e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ebeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200acef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c572288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db3896e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc8782e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b52b9631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21d9bcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e4973cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0f1d50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8],\n",
       "       [7],\n",
       "       [8],\n",
       "       ...,\n",
       "       [3],\n",
       "       [1],\n",
       "       [3]], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6c0521d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =np.argmax(Y_train)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "930a11af",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5784\\240059899.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c0914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9925aa47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "276f19e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e458d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "414cabed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.20110315, 3.28177562, 4.28466595, 3.05597306, 3.33640414,\n",
       "       3.98344707, 3.98666134, 4.06497428, 4.61018985, 3.41586384,\n",
       "       3.54981722, 2.33302412, 4.17731431, 3.57913508, 3.18228556,\n",
       "       3.16413198, 3.4941552 , 3.27640799, 3.24224851, 3.39185237,\n",
       "       3.48132308, 3.75702406, 4.00681291, 4.2488176 , 3.35583782,\n",
       "       3.56878115, 3.42452029, 2.61749758, 3.90703722, 4.2038775 ,\n",
       "       3.1870036 , 3.83536252, 3.79608028, 4.51522581, 2.59527454,\n",
       "       3.84691179, 2.88297182, 3.52732167, 2.96102925, 2.91282736,\n",
       "       4.15999665, 3.5694131 , 4.14234101, 3.18152454, 3.96936405,\n",
       "       3.16415649, 1.97201757, 2.94901682, 2.76512967, 3.55981656,\n",
       "       3.66758179, 3.68152961, 3.10485252, 4.46079242, 3.82450346,\n",
       "       3.19445297, 3.66166685, 3.86158568, 3.00918278, 3.70965738,\n",
       "       3.98134712, 3.18750898, 4.04726307, 3.63988304, 2.82992511,\n",
       "       4.16999716, 3.90547543, 3.96388523, 3.89829874, 2.95138845,\n",
       "       3.50773932, 3.75178351, 3.43119484, 3.6526706 , 4.17225859,\n",
       "       3.89054326, 3.54273941, 3.30663502, 3.78305522, 4.05477031,\n",
       "       4.17099904, 3.48666447, 3.80506138, 3.9878952 , 2.96183557,\n",
       "       3.9693975 , 3.98904895, 4.23369898, 4.0319976 , 3.57621579,\n",
       "       3.21858544, 3.775138  , 2.93769652, 3.71047999, 3.38943265,\n",
       "       3.06666888, 3.44867473, 3.91236451, 3.90685529, 2.66336563,\n",
       "       3.97238137, 4.13013287, 3.77677078, 3.66780693, 3.97490223,\n",
       "       3.75442132, 3.23571423, 3.82205868, 3.90976623, 3.02624137,\n",
       "       3.58152941, 3.02555525, 3.309159  , 3.59004026, 3.36589188,\n",
       "       2.9814233 , 3.54222197, 3.50980924, 3.94343211, 3.21528132,\n",
       "       4.05593245, 3.06273173, 4.10275642, 3.93960989, 4.12109515,\n",
       "       4.07544278, 4.37653037, 3.15560633, 2.81228865, 3.91413805,\n",
       "       3.05114   , 3.74329031, 4.27226746, 3.20897465, 3.15163035,\n",
       "       4.37402352, 3.46617281, 3.23783171, 4.15762121, 3.86840621,\n",
       "       3.63871981, 3.54226529, 2.67817055, 3.27856018, 2.77895095,\n",
       "       4.09941026, 3.28430839, 4.10361714, 3.20128995, 3.2958743 ,\n",
       "       3.26752403, 3.84112248, 4.2100667 , 3.98880306, 4.24573126,\n",
       "       4.10588555, 3.7483696 , 3.41648901, 3.96364222, 3.26234577,\n",
       "       3.99301481, 4.1176671 , 3.88096038, 4.35275712, 3.41070178,\n",
       "       3.36604811, 1.87487286, 3.41360141, 4.53284701, 3.73999453,\n",
       "       3.82025807, 4.57310383, 3.14800636, 3.02479989, 4.86004774,\n",
       "       3.38945459, 3.62997535, 2.87543719, 3.88280979, 3.41427115,\n",
       "       3.45416762, 3.61648715, 3.77020556, 3.8361806 , 3.65894986,\n",
       "       3.85640771, 4.44274916, 2.98393124, 4.07934246, 3.81760707,\n",
       "       4.0093267 , 2.8540359 , 3.52176779, 4.10236545, 3.38369407,\n",
       "       2.99520753, 3.73158778, 4.37109329, 3.61008679, 4.09883067,\n",
       "       3.07853725, 3.79031243, 3.73961444, 3.70268167, 2.91555746,\n",
       "       3.19240857, 2.36107514, 4.06721548, 3.77268521, 3.71589213,\n",
       "       3.55216906, 4.21967861, 3.37955275, 3.39082823, 2.96950106,\n",
       "       2.7668516 , 3.33037107, 3.39158452, 4.18496709, 3.31020721,\n",
       "       3.49837857, 3.4157106 , 3.44344037, 4.21222802, 4.26521268,\n",
       "       3.89962948, 4.40012905, 4.01327981, 2.80667818, 2.95563636,\n",
       "       4.38343759, 4.36005375, 3.02991912, 3.5806933 , 4.00672615,\n",
       "       3.39722341, 4.15800636, 2.94486384, 3.64691062, 2.97506236,\n",
       "       2.76112932, 3.73016645, 4.73331715, 4.59531502, 3.46112498,\n",
       "       3.23926644, 2.02770163, 4.37121838, 3.49158462, 3.98698729,\n",
       "       3.24713652, 3.75294614, 4.06548057, 3.69226634, 3.23055354,\n",
       "       4.04349131, 4.09960088, 3.9553108 , 3.69201232, 3.68147358,\n",
       "       3.91616057, 3.60126524, 4.12736048, 3.95451734, 3.34592074,\n",
       "       2.53183781, 3.56520218, 4.31140506, 4.16561041, 3.70337498,\n",
       "       3.28165032, 3.55314873, 3.03557243, 4.39432606, 3.95800254,\n",
       "       4.02635521, 3.63190966, 4.06171965, 3.26142383, 4.79602791,\n",
       "       3.0966188 , 3.22922204, 4.68982139, 3.92143197, 3.28227007,\n",
       "       3.64008784, 4.32928711, 3.81188946, 3.46447651, 3.05451862,\n",
       "       3.72957445, 4.19190658, 2.97678801, 3.30814537, 3.58021271,\n",
       "       4.4199317 , 4.00297005, 3.91926378, 4.54444138, 3.91440178,\n",
       "       3.97747045, 3.05390996, 4.0847411 , 3.21152302, 2.6734532 ,\n",
       "       3.88585618, 4.43386043, 4.39356865, 3.75917427, 3.51728412,\n",
       "       4.36666827, 3.95462968, 3.15750178, 3.71698004, 3.68968515,\n",
       "       3.77147034, 3.21429638, 3.8142321 , 3.5923573 , 2.99965889,\n",
       "       2.8448129 , 3.86577733, 3.56703405, 2.92198751, 3.65784863,\n",
       "       3.89354389, 3.53982409, 3.7298472 , 3.78596449, 3.67637594,\n",
       "       3.60216928, 3.92846053, 4.33017753, 3.92526055, 3.82621825,\n",
       "       3.13202927, 3.60579539, 2.67795246, 2.57453357, 3.97666848,\n",
       "       3.38078144, 3.38106777, 4.12148536, 3.375378  , 3.75538438,\n",
       "       3.94042979, 3.82590113, 1.97385082, 3.50702295, 4.46235996,\n",
       "       3.69488603, 3.89940907, 3.42635875, 3.91493056, 3.55175518,\n",
       "       3.94382656, 3.42635225, 3.98503496, 3.85532737, 3.50642588,\n",
       "       3.7499201 , 4.34573959, 4.62255669, 4.24611034, 3.54506122,\n",
       "       3.59931484, 4.31449327, 3.48708265, 3.53790253, 4.87020265,\n",
       "       4.07952782, 3.06354802, 3.88168081, 3.5118395 , 4.17472101,\n",
       "       2.47019602, 3.74541354, 3.96285858, 3.41892691, 3.80210021,\n",
       "       3.84702336, 3.42650031, 4.63904091, 3.51197428, 2.93091734,\n",
       "       3.44253643, 4.05325448, 3.48400884, 4.21227797, 3.67453692,\n",
       "       4.45812271, 3.91702186, 4.44668079, 4.40086535, 3.78520241,\n",
       "       3.87429962, 3.51583551, 3.8259161 , 3.71330691, 2.84906479,\n",
       "       4.37125132, 3.75508349, 2.80942007, 2.67390699, 3.45247019,\n",
       "       2.65223547, 4.06123954, 3.22258674, 3.58408882, 3.76041717,\n",
       "       3.48533017, 4.26374952, 4.3133991 , 3.75456369, 3.46414979,\n",
       "       2.6648523 , 3.60382265, 3.79677922, 2.98354424, 3.08125836,\n",
       "       4.22391347, 3.38841614, 4.3356461 , 4.14400027, 3.110347  ,\n",
       "       3.78151386, 3.75289636, 4.00393413, 3.84726237, 4.28611128,\n",
       "       3.56785636, 3.50642746, 4.12630928, 3.74352391, 4.46555327,\n",
       "       3.69177944, 3.1674667 , 2.99091466, 4.28602452, 4.06480461,\n",
       "       3.73708937, 4.38782683, 3.35162868, 3.23917045, 3.70591703,\n",
       "       2.67608153, 3.97729729, 3.47305282, 3.96980434, 4.29601023,\n",
       "       2.75641914, 3.72677632, 4.15242563, 3.57580811, 3.78314464,\n",
       "       3.65170455, 3.56487138, 2.66410221, 3.85830082, 3.55996839,\n",
       "       4.08393125, 4.58529018, 3.91845616, 3.46138092, 3.74975729,\n",
       "       3.8283195 , 3.54169568, 4.21497141, 3.63183132, 3.24555928,\n",
       "       3.7094842 , 4.45628738, 3.38347168, 3.19389378, 3.78427338,\n",
       "       3.35174434, 4.17525301, 3.42765056, 3.10234348, 3.51319352,\n",
       "       3.72735403, 3.87820019, 3.74478321, 3.44416467, 3.26061828,\n",
       "       3.73419456, 3.75199292, 3.62139024, 3.55001266, 3.12609371,\n",
       "       4.33118155, 3.06431458, 3.05134134, 3.22966038, 3.12231749,\n",
       "       3.61770913, 3.41239316, 3.86946212, 3.90195342, 3.2932887 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy = []\n",
    "x_ulb = np.random.rand(500, 10)\n",
    "d = 50\n",
    "entropy = -np.sum(x_ulb * np.log2(x_ulb), axis=1)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d04764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98585580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba139580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ff09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
