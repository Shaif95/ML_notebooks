{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "7GPGQ-m2APJD",
    "outputId": "efd142a2-6bea-4596-c180-30caac27a179"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yH47C7lKASRU"
   },
   "outputs": [],
   "source": [
    "#!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BR1vlIt8ASXS"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bQai29TrASbv"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "trn1='D:/Inv_Data_Imbalance/data/invasive-aquatic-species-data/invasive/*/'\n",
    "trn2='D:/Inv_Data_Imbalance/data/invasive-aquatic-species-data/noninvasive/*/'\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dcvkYlBqASfP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3700"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = glob(tr1[9]+'/*')\n",
    "len(tr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1= shuffle(tr1)\n",
    "tr2= shuffle(tr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2960.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_index_inv = np.round( len(tr1)* .8  )\n",
    "tran_index_noninv = np.round( len(tr2)* .8  )\n",
    "tran_index_noninv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "2U0aIHXvASoQ",
    "outputId": "87e0486a-6205-49e9-f8b9-e83b31a536c5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "model = load_model('encoder80.h5')\n",
    "encoder = Model(inputs=model.input, outputs=model.get_layer('encoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.6086711e-03, -9.3669966e-02, -9.6447907e-02, -8.6818703e-02,\n",
       "        7.7567406e-02,  1.9020731e-02,  4.0794928e-02,  6.2635168e-05,\n",
       "       -4.6611305e-02, -4.7604204e-04, -7.5581715e-02,  5.7421941e-02,\n",
       "        6.9124638e-03, -4.2364165e-02, -1.6146716e-01, -1.9400319e-01,\n",
       "        1.2882081e-01,  9.8593816e-02,  6.6207349e-02, -6.4897155e-03,\n",
       "        2.8586350e-02,  1.3940273e-02, -9.0845659e-02, -4.1631501e-02,\n",
       "        2.3579005e-02,  5.7420217e-02, -1.0428248e-01, -2.1749079e-02,\n",
       "        2.9841663e-02, -4.4662822e-02, -1.2994805e-01,  2.6749004e-02,\n",
       "       -3.5418514e-03, -3.8465835e-02,  3.9044306e-02,  4.4700086e-02,\n",
       "        1.5987540e-03, -6.3281797e-02, -1.3490459e-01, -3.5610344e-02,\n",
       "       -1.8756554e-01, -7.6036854e-03,  5.1221952e-02, -9.9714920e-02,\n",
       "       -7.2538897e-02,  3.8552828e-02,  4.0632445e-02, -6.4132117e-02,\n",
       "        2.6336871e-02,  2.7594235e-02, -5.8440180e-03, -4.5225449e-02,\n",
       "        7.1946792e-02,  3.1144006e-02,  3.8435992e-02,  2.1447694e-01,\n",
       "       -9.9337166e-03, -2.2197476e-02, -5.3333312e-02,  5.6252237e-02,\n",
       "        4.8188303e-02, -7.7645527e-03,  3.9521690e-02,  5.7656873e-02,\n",
       "       -3.3247778e-03, -1.7369078e-01, -1.7619535e-02,  5.6882720e-02,\n",
       "       -3.8226496e-03, -5.6549676e-02,  7.9616476e-03, -3.4645118e-02,\n",
       "        4.6961490e-02, -2.3319505e-02, -5.1524714e-02, -5.7104319e-02,\n",
       "        5.8609247e-02, -5.9659816e-03, -5.0348405e-02, -1.5067080e-02,\n",
       "       -1.2069237e-03,  3.1861193e-03, -2.6226711e-02, -6.5688804e-02,\n",
       "       -3.8370695e-02, -1.3973409e-01, -4.7306549e-02, -8.8146076e-02,\n",
       "       -1.1932755e-02,  9.4762489e-02, -1.1219578e-02,  2.7028169e-02,\n",
       "        6.7412388e-03, -5.1192649e-02, -6.4007759e-02, -1.7195415e-02,\n",
       "       -7.4592352e-02, -4.8696566e-03, -1.8162748e-02, -2.1842916e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[:(int) (tran_index_inv)]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[:(int) (tran_index_noninv)]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[:(int) (tran_index_inv)])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,len(a)):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr2[:(int) (tran_index_noninv)])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,len(a)):\n",
    "        data.append(a[k])        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((40, 40))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(40,40,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),40,40,3))\n",
    "\n",
    "encoded = encoder.predict(X_train)\n",
    "\n",
    "encoded[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3499, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "train_df= []\n",
    "for i in range(0, len(breath)):\n",
    "    \n",
    "    y = end+breath[i]\n",
    "    en_sum = [sum(x) for x in zip(*encoded[end:y])]\n",
    "    res = [(x/breath[i]) for x in (en_sum)]\n",
    "    train_df.append(res)\n",
    "    #print(en_sum)\n",
    "    #print(res)\n",
    "    end = end + breath[i]\n",
    "        \n",
    "Y_train =(label)\n",
    "train_df = np.array(train_df)\n",
    "train_df,Y_train = shuffle(train_df,Y_train)\n",
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3499, 48)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.6086711e-03, -9.3669966e-02, -9.6447907e-02, -8.6818703e-02,\n",
       "        7.7567406e-02,  1.9020731e-02,  4.0794928e-02,  6.2635168e-05,\n",
       "       -4.6611305e-02, -4.7604204e-04, -7.5581715e-02,  5.7421941e-02,\n",
       "        6.9124638e-03, -4.2364165e-02, -1.6146716e-01, -1.9400319e-01,\n",
       "        1.2882081e-01,  9.8593816e-02,  6.6207349e-02, -6.4897155e-03,\n",
       "        2.8586350e-02,  1.3940273e-02, -9.0845659e-02, -4.1631501e-02,\n",
       "        2.3579005e-02,  5.7420217e-02, -1.0428248e-01, -2.1749079e-02,\n",
       "        2.9841663e-02, -4.4662822e-02, -1.2994805e-01,  2.6749004e-02,\n",
       "       -3.5418514e-03, -3.8465835e-02,  3.9044306e-02,  4.4700086e-02,\n",
       "        1.5987540e-03, -6.3281797e-02, -1.3490459e-01, -3.5610344e-02,\n",
       "       -1.8756554e-01, -7.6036854e-03,  5.1221952e-02, -9.9714920e-02,\n",
       "       -7.2538897e-02,  3.8552828e-02,  4.0632445e-02, -6.4132117e-02,\n",
       "        2.6336871e-02,  2.7594235e-02, -5.8440180e-03, -4.5225449e-02,\n",
       "        7.1946792e-02,  3.1144006e-02,  3.8435992e-02,  2.1447694e-01,\n",
       "       -9.9337166e-03, -2.2197476e-02, -5.3333312e-02,  5.6252237e-02,\n",
       "        4.8188303e-02, -7.7645527e-03,  3.9521690e-02,  5.7656873e-02,\n",
       "       -3.3247778e-03, -1.7369078e-01, -1.7619535e-02,  5.6882720e-02,\n",
       "       -3.8226496e-03, -5.6549676e-02,  7.9616476e-03, -3.4645118e-02,\n",
       "        4.6961490e-02, -2.3319505e-02, -5.1524714e-02, -5.7104319e-02,\n",
       "        5.8609247e-02, -5.9659816e-03, -5.0348405e-02, -1.5067080e-02,\n",
       "       -1.2069237e-03,  3.1861193e-03, -2.6226711e-02, -6.5688804e-02,\n",
       "       -3.8370695e-02, -1.3973409e-01, -4.7306549e-02, -8.8146076e-02,\n",
       "       -1.1932755e-02,  9.4762489e-02, -1.1219578e-02,  2.7028169e-02,\n",
       "        6.7412388e-03, -5.1192649e-02, -6.4007759e-02, -1.7195415e-02,\n",
       "       -7.4592352e-02, -4.8696566e-03, -1.8162748e-02, -2.1842916e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[(int) (tran_index_inv) + 1 :]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[ (int)(tran_index_noninv) + 1:]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[(int) (tran_index_inv) + 1 :])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,len(a)):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr2[ (int)(tran_index_noninv) + 1:])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,len(a)):\n",
    "        data.append(a[k])        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((40, 40))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(40,40,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),40,40,3))\n",
    "\n",
    "encoded = encoder.predict(X_test)\n",
    "\n",
    "encoded[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22531, 64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "test_df= []\n",
    "for i in range(0, len(breath[:850])):\n",
    "    \n",
    "    y = end+breath[i]\n",
    "    en_sum = [sum(x) for x in zip(*encoded[end:y])]\n",
    "    #len()\n",
    "    res = [(x/breath[i]) for x in (en_sum)]\n",
    "    test_df.append(res)\n",
    "    #print(en_sum)\n",
    "    #print(res)\n",
    "    end = end + breath[i]\n",
    "        \n",
    "Y_test = (label)\n",
    "test_df = np.array(test_df)\n",
    "test_df,Y_test = shuffle(test_df,Y_test[:850])\n",
    "np.shape(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(30, activation=\"relu\", input_shape=(50,)))\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(2, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "77/77 [==============================] - 4s 20ms/step - loss: 0.0530 - get_f1: 0.9793 - val_loss: 0.0858 - val_get_f1: 0.9697\n",
      "Epoch 2/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0499 - get_f1: 0.9797 - val_loss: 0.0872 - val_get_f1: 0.9669\n",
      "Epoch 3/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0503 - get_f1: 0.9793 - val_loss: 0.0854 - val_get_f1: 0.9688\n",
      "Epoch 4/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0487 - get_f1: 0.9806 - val_loss: 0.0870 - val_get_f1: 0.9688\n",
      "Epoch 5/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0470 - get_f1: 0.9825 - val_loss: 0.0869 - val_get_f1: 0.9706\n",
      "Epoch 6/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0476 - get_f1: 0.9810 - val_loss: 0.0859 - val_get_f1: 0.9678\n",
      "Epoch 7/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0456 - get_f1: 0.9830 - val_loss: 0.0866 - val_get_f1: 0.9659\n",
      "Epoch 8/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0463 - get_f1: 0.9798 - val_loss: 0.0850 - val_get_f1: 0.9659\n",
      "Epoch 9/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0443 - get_f1: 0.9818 - val_loss: 0.0847 - val_get_f1: 0.9678\n",
      "Epoch 10/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0447 - get_f1: 0.9831 - val_loss: 0.0927 - val_get_f1: 0.9669\n",
      "Epoch 11/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0433 - get_f1: 0.9830 - val_loss: 0.0843 - val_get_f1: 0.9697\n",
      "Epoch 12/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0418 - get_f1: 0.9842 - val_loss: 0.0883 - val_get_f1: 0.9669\n",
      "Epoch 13/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0420 - get_f1: 0.9825 - val_loss: 0.0841 - val_get_f1: 0.9716\n",
      "Epoch 14/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0429 - get_f1: 0.9821 - val_loss: 0.0867 - val_get_f1: 0.9688\n",
      "Epoch 15/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0416 - get_f1: 0.9842 - val_loss: 0.0861 - val_get_f1: 0.9697\n",
      "Epoch 16/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0397 - get_f1: 0.9850 - val_loss: 0.0873 - val_get_f1: 0.9678\n",
      "Epoch 17/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0390 - get_f1: 0.9842 - val_loss: 0.0871 - val_get_f1: 0.9688\n",
      "Epoch 18/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0392 - get_f1: 0.9850 - val_loss: 0.0861 - val_get_f1: 0.9725\n",
      "Epoch 19/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0375 - get_f1: 0.9854 - val_loss: 0.0854 - val_get_f1: 0.9716\n",
      "Epoch 20/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0368 - get_f1: 0.9842 - val_loss: 0.0852 - val_get_f1: 0.9735\n",
      "Epoch 21/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0367 - get_f1: 0.9838 - val_loss: 0.0855 - val_get_f1: 0.9725\n",
      "Epoch 22/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0354 - get_f1: 0.9867 - val_loss: 0.0945 - val_get_f1: 0.9640\n",
      "Epoch 23/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0392 - get_f1: 0.9842 - val_loss: 0.0873 - val_get_f1: 0.9716\n",
      "Epoch 24/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0358 - get_f1: 0.9846 - val_loss: 0.0892 - val_get_f1: 0.9716\n",
      "Epoch 25/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0343 - get_f1: 0.9878 - val_loss: 0.0862 - val_get_f1: 0.9725\n",
      "Epoch 26/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0335 - get_f1: 0.9866 - val_loss: 0.0897 - val_get_f1: 0.9697\n",
      "Epoch 27/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0337 - get_f1: 0.9862 - val_loss: 0.0890 - val_get_f1: 0.9725\n",
      "Epoch 28/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0353 - get_f1: 0.9858 - val_loss: 0.0881 - val_get_f1: 0.9725\n",
      "Epoch 29/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0337 - get_f1: 0.9870 - val_loss: 0.0921 - val_get_f1: 0.9678\n",
      "Epoch 30/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0322 - get_f1: 0.9850 - val_loss: 0.0887 - val_get_f1: 0.9725\n",
      "Epoch 31/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0313 - get_f1: 0.9878 - val_loss: 0.0903 - val_get_f1: 0.9725\n",
      "Epoch 32/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0303 - get_f1: 0.9878 - val_loss: 0.0895 - val_get_f1: 0.9735\n",
      "Epoch 33/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0302 - get_f1: 0.9879 - val_loss: 0.0885 - val_get_f1: 0.9735\n",
      "Epoch 34/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0312 - get_f1: 0.9866 - val_loss: 0.0883 - val_get_f1: 0.9735\n",
      "Epoch 35/300\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.0302 - get_f1: 0.9871 - val_loss: 0.0937 - val_get_f1: 0.9697\n",
      "Epoch 36/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0296 - get_f1: 0.9875 - val_loss: 0.0906 - val_get_f1: 0.9716\n",
      "Epoch 37/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0299 - get_f1: 0.9878 - val_loss: 0.0915 - val_get_f1: 0.9716\n",
      "Epoch 38/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0293 - get_f1: 0.9878 - val_loss: 0.0929 - val_get_f1: 0.9735\n",
      "Epoch 39/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0286 - get_f1: 0.9882 - val_loss: 0.0923 - val_get_f1: 0.9735\n",
      "Epoch 40/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0275 - get_f1: 0.9894 - val_loss: 0.0917 - val_get_f1: 0.9706\n",
      "Epoch 41/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0273 - get_f1: 0.9887 - val_loss: 0.0933 - val_get_f1: 0.9725\n",
      "Epoch 42/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0271 - get_f1: 0.9899 - val_loss: 0.0936 - val_get_f1: 0.9706\n",
      "Epoch 43/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0264 - get_f1: 0.9878 - val_loss: 0.0931 - val_get_f1: 0.9735 - loss: 0.0263 - get_f1: 0.\n",
      "Epoch 44/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0253 - get_f1: 0.9919 - val_loss: 0.0943 - val_get_f1: 0.9735\n",
      "Epoch 45/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0258 - get_f1: 0.9894 - val_loss: 0.0950 - val_get_f1: 0.9716\n",
      "Epoch 46/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0251 - get_f1: 0.9919 - val_loss: 0.1028 - val_get_f1: 0.9659\n",
      "Epoch 47/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0245 - get_f1: 0.9915 - val_loss: 0.0950 - val_get_f1: 0.9725\n",
      "Epoch 48/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0241 - get_f1: 0.9907 - val_loss: 0.0982 - val_get_f1: 0.9716\n",
      "Epoch 49/300\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.0239 - get_f1: 0.9923 - val_loss: 0.0969 - val_get_f1: 0.9706\n",
      "Epoch 50/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0232 - get_f1: 0.9923 - val_loss: 0.0972 - val_get_f1: 0.9725\n",
      "Epoch 51/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0227 - get_f1: 0.9931 - val_loss: 0.0982 - val_get_f1: 0.9716\n",
      "Epoch 52/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0227 - get_f1: 0.9907 - val_loss: 0.1053 - val_get_f1: 0.9650\n",
      "Epoch 53/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0221 - get_f1: 0.9919 - val_loss: 0.1013 - val_get_f1: 0.9716\n",
      "Epoch 54/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0217 - get_f1: 0.9935 - val_loss: 0.0999 - val_get_f1: 0.9735\n",
      "Epoch 55/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0221 - get_f1: 0.9935 - val_loss: 0.0965 - val_get_f1: 0.9735\n",
      "Epoch 56/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0215 - get_f1: 0.9919 - val_loss: 0.1036 - val_get_f1: 0.9706\n",
      "Epoch 57/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0204 - get_f1: 0.9935 - val_loss: 0.0993 - val_get_f1: 0.9754\n",
      "Epoch 58/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0213 - get_f1: 0.9923 - val_loss: 0.1017 - val_get_f1: 0.9716\n",
      "Epoch 59/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0200 - get_f1: 0.9931 - val_loss: 0.1089 - val_get_f1: 0.9659\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0223 - get_f1: 0.9927 - val_loss: 0.1015 - val_get_f1: 0.9735\n",
      "Epoch 61/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0198 - get_f1: 0.9927 - val_loss: 0.1004 - val_get_f1: 0.9735\n",
      "Epoch 62/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0209 - get_f1: 0.9935 - val_loss: 0.1072 - val_get_f1: 0.9678\n",
      "Epoch 63/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0183 - get_f1: 0.9940 - val_loss: 0.1067 - val_get_f1: 0.9697\n",
      "Epoch 64/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0192 - get_f1: 0.9951 - val_loss: 0.1101 - val_get_f1: 0.9688\n",
      "Epoch 65/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0189 - get_f1: 0.9939 - val_loss: 0.1089 - val_get_f1: 0.9697\n",
      "Epoch 66/300\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.0186 - get_f1: 0.9931 - val_loss: 0.1056 - val_get_f1: 0.9725\n",
      "Epoch 67/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0171 - get_f1: 0.9951 - val_loss: 0.1070 - val_get_f1: 0.9716\n",
      "Epoch 68/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0213 - get_f1: 0.9919 - val_loss: 0.1121 - val_get_f1: 0.9669\n",
      "Epoch 69/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0166 - get_f1: 0.9955 - val_loss: 0.1080 - val_get_f1: 0.9754\n",
      "Epoch 70/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0172 - get_f1: 0.9939 - val_loss: 0.1100 - val_get_f1: 0.9744\n",
      "Epoch 71/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0169 - get_f1: 0.9939 - val_loss: 0.1125 - val_get_f1: 0.9688\n",
      "Epoch 72/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0177 - get_f1: 0.9943 - val_loss: 0.1057 - val_get_f1: 0.9744\n",
      "Epoch 73/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0155 - get_f1: 0.9947 - val_loss: 0.1118 - val_get_f1: 0.9706\n",
      "Epoch 74/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0167 - get_f1: 0.9951 - val_loss: 0.1123 - val_get_f1: 0.9697\n",
      "Epoch 75/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0163 - get_f1: 0.9959 - val_loss: 0.1124 - val_get_f1: 0.9744\n",
      "Epoch 76/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0194 - get_f1: 0.9923 - val_loss: 0.1104 - val_get_f1: 0.9754\n",
      "Epoch 77/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0152 - get_f1: 0.9959 - val_loss: 0.1134 - val_get_f1: 0.9725\n",
      "Epoch 78/300\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.0150 - get_f1: 0.9959 - val_loss: 0.1166 - val_get_f1: 0.9688\n",
      "Epoch 79/300\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.0139 - get_f1: 0.9959 - val_loss: 0.1116 - val_get_f1: 0.9754loss: 0.0137 - get_f1\n",
      "Epoch 80/300\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 0.0159 - get_f1: 0.9952 - val_loss: 0.1140 - val_get_f1: 0.9744\n",
      "Epoch 81/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0137 - get_f1: 0.9963 - val_loss: 0.1235 - val_get_f1: 0.9697\n",
      "Epoch 82/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0180 - get_f1: 0.9931 - val_loss: 0.1157 - val_get_f1: 0.9754\n",
      "Epoch 83/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0129 - get_f1: 0.9968 - val_loss: 0.1197 - val_get_f1: 0.9716\n",
      "Epoch 84/300\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.0139 - get_f1: 0.9955 - val_loss: 0.1212 - val_get_f1: 0.9725\n",
      "Epoch 85/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0131 - get_f1: 0.9968 - val_loss: 0.1172 - val_get_f1: 0.9697\n",
      "Epoch 86/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0127 - get_f1: 0.9963 - val_loss: 0.1196 - val_get_f1: 0.9706\n",
      "Epoch 87/300\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.0126 - get_f1: 0.9959 - val_loss: 0.1235 - val_get_f1: 0.9716\n",
      "Epoch 88/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0122 - get_f1: 0.9972 - val_loss: 0.1211 - val_get_f1: 0.9725\n",
      "Epoch 89/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0127 - get_f1: 0.9956 - val_loss: 0.1237 - val_get_f1: 0.9716\n",
      "Epoch 90/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0132 - get_f1: 0.9955 - val_loss: 0.1237 - val_get_f1: 0.9725\n",
      "Epoch 91/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0122 - get_f1: 0.9980 - val_loss: 0.1228 - val_get_f1: 0.9725\n",
      "Epoch 92/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0141 - get_f1: 0.9959 - val_loss: 0.1216 - val_get_f1: 0.9725\n",
      "Epoch 93/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0113 - get_f1: 0.9972 - val_loss: 0.1226 - val_get_f1: 0.9735\n",
      "Epoch 94/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0115 - get_f1: 0.9976 - val_loss: 0.1261 - val_get_f1: 0.9697\n",
      "Epoch 95/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0118 - get_f1: 0.9963 - val_loss: 0.1267 - val_get_f1: 0.9697\n",
      "Epoch 96/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0119 - get_f1: 0.9963 - val_loss: 0.1362 - val_get_f1: 0.9669\n",
      "Epoch 97/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0128 - get_f1: 0.9963 - val_loss: 0.1259 - val_get_f1: 0.9716\n",
      "Epoch 98/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0118 - get_f1: 0.9968 - val_loss: 0.1272 - val_get_f1: 0.9706\n",
      "Epoch 99/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0101 - get_f1: 0.9972 - val_loss: 0.1298 - val_get_f1: 0.9754\n",
      "Epoch 100/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0094 - get_f1: 0.9968 - val_loss: 0.1337 - val_get_f1: 0.9706\n",
      "Epoch 101/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0109 - get_f1: 0.9968 - val_loss: 0.1332 - val_get_f1: 0.9725\n",
      "Epoch 102/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0104 - get_f1: 0.9976 - val_loss: 0.1326 - val_get_f1: 0.9725\n",
      "Epoch 103/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0094 - get_f1: 0.9972 - val_loss: 0.1328 - val_get_f1: 0.9688\n",
      "Epoch 104/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0116 - get_f1: 0.9959 - val_loss: 0.1319 - val_get_f1: 0.9716\n",
      "Epoch 105/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0104 - get_f1: 0.9968 - val_loss: 0.1379 - val_get_f1: 0.9669\n",
      "Epoch 106/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0100 - get_f1: 0.9968 - val_loss: 0.1311 - val_get_f1: 0.9754\n",
      "Epoch 107/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0096 - get_f1: 0.9976 - val_loss: 0.1314 - val_get_f1: 0.9735\n",
      "Epoch 108/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0087 - get_f1: 0.9976 - val_loss: 0.1352 - val_get_f1: 0.9688\n",
      "Epoch 109/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0079 - get_f1: 0.9984 - val_loss: 0.1427 - val_get_f1: 0.9706\n",
      "Epoch 110/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0087 - get_f1: 0.9976 - val_loss: 0.1383 - val_get_f1: 0.9706\n",
      "Epoch 111/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0092 - get_f1: 0.9976 - val_loss: 0.1353 - val_get_f1: 0.9706\n",
      "Epoch 112/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0086 - get_f1: 0.9980 - val_loss: 0.1387 - val_get_f1: 0.9725\n",
      "Epoch 113/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0102 - get_f1: 0.9968 - val_loss: 0.1538 - val_get_f1: 0.9716\n",
      "Epoch 114/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0114 - get_f1: 0.9960 - val_loss: 0.1398 - val_get_f1: 0.9716\n",
      "Epoch 115/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0117 - get_f1: 0.9951 - val_loss: 0.1351 - val_get_f1: 0.9725\n",
      "Epoch 116/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0073 - get_f1: 0.9980 - val_loss: 0.1356 - val_get_f1: 0.9725\n",
      "Epoch 117/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0073 - get_f1: 0.9980 - val_loss: 0.1410 - val_get_f1: 0.9735\n",
      "Epoch 118/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0083 - get_f1: 0.9976 - val_loss: 0.1391 - val_get_f1: 0.9763\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0076 - get_f1: 0.9984 - val_loss: 0.1428 - val_get_f1: 0.9744\n",
      "Epoch 120/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0073 - get_f1: 0.9992 - val_loss: 0.1449 - val_get_f1: 0.9688\n",
      "Epoch 121/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0078 - get_f1: 0.9980 - val_loss: 0.1424 - val_get_f1: 0.9725\n",
      "Epoch 122/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0072 - get_f1: 0.9980 - val_loss: 0.1418 - val_get_f1: 0.9773\n",
      "Epoch 123/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0072 - get_f1: 0.9980 - val_loss: 0.1413 - val_get_f1: 0.9688\n",
      "Epoch 124/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0078 - get_f1: 0.9980 - val_loss: 0.1430 - val_get_f1: 0.9754\n",
      "Epoch 125/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0062 - get_f1: 0.9988 - val_loss: 0.1518 - val_get_f1: 0.9735\n",
      "Epoch 126/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0069 - get_f1: 0.9984 - val_loss: 0.1464 - val_get_f1: 0.9763\n",
      "Epoch 127/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0072 - get_f1: 0.9984 - val_loss: 0.1428 - val_get_f1: 0.9716\n",
      "Epoch 128/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0064 - get_f1: 0.9980 - val_loss: 0.1493 - val_get_f1: 0.9773\n",
      "Epoch 129/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0052 - get_f1: 0.9988 - val_loss: 0.1512 - val_get_f1: 0.9744\n",
      "Epoch 130/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0055 - get_f1: 0.9996 - val_loss: 0.1573 - val_get_f1: 0.9725\n",
      "Epoch 131/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0054 - get_f1: 0.9988 - val_loss: 0.1493 - val_get_f1: 0.9716\n",
      "Epoch 132/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0053 - get_f1: 0.9988 - val_loss: 0.1496 - val_get_f1: 0.9725\n",
      "Epoch 133/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0060 - get_f1: 0.9992 - val_loss: 0.1512 - val_get_f1: 0.9716\n",
      "Epoch 134/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0061 - get_f1: 0.9980 - val_loss: 0.1590 - val_get_f1: 0.9706\n",
      "Epoch 135/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0057 - get_f1: 0.9988 - val_loss: 0.1552 - val_get_f1: 0.9716\n",
      "Epoch 136/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0061 - get_f1: 0.9992 - val_loss: 0.1572 - val_get_f1: 0.9763\n",
      "Epoch 137/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0056 - get_f1: 0.9984 - val_loss: 0.1584 - val_get_f1: 0.9697\n",
      "Epoch 138/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0058 - get_f1: 0.9984 - val_loss: 0.1583 - val_get_f1: 0.9735\n",
      "Epoch 139/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0055 - get_f1: 0.9992 - val_loss: 0.1626 - val_get_f1: 0.9716\n",
      "Epoch 140/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0048 - get_f1: 0.9988 - val_loss: 0.1645 - val_get_f1: 0.9754\n",
      "Epoch 141/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0047 - get_f1: 0.9992 - val_loss: 0.1632 - val_get_f1: 0.9744\n",
      "Epoch 142/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0044 - get_f1: 0.9996 - val_loss: 0.1614 - val_get_f1: 0.9754\n",
      "Epoch 143/300\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.0037 - get_f1: 0.9992 - val_loss: 0.1704 - val_get_f1: 0.9725\n",
      "Epoch 144/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0049 - get_f1: 0.9984 - val_loss: 0.1604 - val_get_f1: 0.9754\n",
      "Epoch 145/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0041 - get_f1: 0.9996 - val_loss: 0.1735 - val_get_f1: 0.9716\n",
      "Epoch 146/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0041 - get_f1: 0.9996 - val_loss: 0.1746 - val_get_f1: 0.9735\n",
      "Epoch 147/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0039 - get_f1: 0.9996 - val_loss: 0.1654 - val_get_f1: 0.9735\n",
      "Epoch 148/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0035 - get_f1: 0.9996 - val_loss: 0.1673 - val_get_f1: 0.9744\n",
      "Epoch 149/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0035 - get_f1: 0.9992 - val_loss: 0.1795 - val_get_f1: 0.9744\n",
      "Epoch 150/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0037 - get_f1: 0.9988 - val_loss: 0.1701 - val_get_f1: 0.9744\n",
      "Epoch 151/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0055 - get_f1: 0.9976 - val_loss: 0.1734 - val_get_f1: 0.9735\n",
      "Epoch 152/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0033 - get_f1: 0.9996 - val_loss: 0.1744 - val_get_f1: 0.9725\n",
      "Epoch 153/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0029 - get_f1: 0.9996 - val_loss: 0.1822 - val_get_f1: 0.9744\n",
      "Epoch 154/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0032 - get_f1: 0.9996 - val_loss: 0.1779 - val_get_f1: 0.9744\n",
      "Epoch 155/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0031 - get_f1: 1.0000 - val_loss: 0.1775 - val_get_f1: 0.9735\n",
      "Epoch 156/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0033 - get_f1: 0.9996 - val_loss: 0.1832 - val_get_f1: 0.9716\n",
      "Epoch 157/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0034 - get_f1: 0.9996 - val_loss: 0.1783 - val_get_f1: 0.9735\n",
      "Epoch 158/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0038 - get_f1: 0.9988 - val_loss: 0.1844 - val_get_f1: 0.9754\n",
      "Epoch 159/300\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.0026 - get_f1: 0.9996 - val_loss: 0.1795 - val_get_f1: 0.9735\n",
      "Epoch 160/300\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.0028 - get_f1: 0.9996 - val_loss: 0.1830 - val_get_f1: 0.9744\n",
      "Epoch 161/300\n",
      "63/77 [=======================>......] - ETA: 0s - loss: 0.0033 - get_f1: 0.9990"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=([get_f1]))\n",
    "\n",
    "model.fit(selected_features_train, Y_train, epochs=300, batch_size=32, validation_split = .3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "t0WupP5MASsp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[711,   7],\n",
       "       [  5, 127]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y_test\n",
    "pred = model.predict(selected_features_test)\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 30)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(selected_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(selected_features_test)\n",
    "np.shape(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfeature.utility import construct_W\n",
    "kwargs_W = {\"metric\":\"euclidean\",\"neighbor_mode\":\"knn\",\"weight_mode\":\"heat_kernel\",\"k\":5,'t':1}\n",
    "W = construct_W.construct_W(X_train, **kwargs_W)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CJm3BoDAASxQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 84, 26,  5, 28, 93, 20, 45, 87, 73, 65, 68, 97, 24, 25, 71, 16,\n",
       "       86, 42, 41, 59, 37, 99, 18, 57, 47, 51, 35, 82,  0, 53, 33, 50, 31,\n",
       "        8, 94, 74, 30, 10, 36, 23, 34,  1,  6, 90,  9, 14, 81, 58, 11, 22,\n",
       "       48, 88, 79, 55, 89, 46, 85, 70, 12, 17, 39, 80, 83, 62, 96, 56, 67,\n",
       "       69, 27, 66, 91, 15, 60, 43, 92,  3,  2, 98, 77, 63, 49, 52, 75,  7,\n",
       "       19, 13, 38, 72, 54, 21, 76, 95, 61, 29,  4, 32, 40, 78, 44])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skfeature.function.similarity_based import fisher_score\n",
    "score = fisher_score.fisher_score(train_df, Y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64 84 26  5 28 93 20 45 87 73 65 68 97 24 25 71 16 86 42 41 59 37 99 18\n",
      " 57 47 51 35 82  0 53 33 50 31  8 94 74 30 10 36 23 34  1  6 90  9 14 81\n",
      " 58 11 22 48 88 79 55 89 46 85 70 12 17 39 80 83 62 96 56 67 69 27 66 91\n",
      " 15 60 43 92  3  2 98 77 63 49 52 75  7 19 13 38 72 54 21 76 95 61 29  4\n",
      " 32 40 78 44]\n"
     ]
    }
   ],
   "source": [
    "idx = fisher_score.fisher_score(train_df, Y_train, mode='rank') #returns rank directly instead of fisher score. so no need for feature_ranking\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fea = 50\n",
    "selected_features_train = train_df[:, idx[0:num_fea]]\n",
    "selected_features_test = test_df[:, idx[0:num_fea]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Xep7twf9AS1a"
   },
   "outputs": [],
   "source": [
    "selected_features_train = np.array(selected_features_train.astype('float32'))\n",
    "selected_features_test = np.array(selected_features_test.astype('float32'))\n",
    "Y_test = to_categorical(Y_test)\n",
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "fKdVerU-AS5M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00371764,  0.00498228,  0.05336196, -0.01909056, -0.00454004,\n",
       "        0.01734734, -0.00291995, -0.09460013,  0.01814024, -0.00771649,\n",
       "       -0.02187526, -0.03938345, -0.00258373, -0.00736343,  0.0619969 ,\n",
       "        0.00981687, -0.02070476,  0.02501709,  0.01276932,  0.01795072,\n",
       "        0.02019595,  0.01036787,  0.01084555, -0.02179153, -0.01408069,\n",
       "        0.0213378 ,  0.00896297,  0.02400279,  0.05476911,  0.03921095],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "6Y3b2HL3AS82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = to_categorical(Y_test)\n",
    "np.shape(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w22uJ1CfATAZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "waqiqSpwATEK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqYBK9ztATHs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vjWMpOJEATMC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9315706>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QFBnxXTGATPc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9315706080411963"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15968,   776],\n",
       "       [  606,  2846]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Kq72WMRIATTb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344424638542286"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Bg4buVwsATXc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829075064369182"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.1974423e-14>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "inv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
