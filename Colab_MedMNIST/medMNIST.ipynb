{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuAIDLLtksw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2f267a-9b19-42c1-e0b9-9b506016a898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40 kB 35.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 51 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 61 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 71 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 81 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 87 kB 3.3 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qq medmnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-self-attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFfWB-v7OD6G",
        "outputId": "feb96603-c06a-4453-c13c-db0e02927928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-self-attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.21.6)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=0d396652546ebf45a4a3080ba39d3ad1e1494157aafc5314f3f93459966f32e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-multi-head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxN3zg0zjSCw",
        "outputId": "d1ac003b-82a4-448f-8158-62211737c5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-multi-head\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head) (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention==0.51.0->keras-multi-head) (1.21.6)\n",
            "Building wheels for collected packages: keras-multi-head\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=6b507a6e4dcd78e7cbec03668a766b9dc25868e3395bcfdc710f8bd5f576f8eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/aa/3c/9d15d24005179dae08ff291ce99c754b296347817d076fd9fb\n",
            "Successfully built keras-multi-head\n",
            "Installing collected packages: keras-multi-head\n",
            "Successfully installed keras-multi-head-0.29.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ZYZQ1rOunH81",
        "outputId": "5351d0e3-3010-42ef-e3ab-4b24316c8d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Collecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires keras<2.9,>=2.8.0rc0, but you have keras 2.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import imageio\n",
        "import medmnist\n",
        "import ipywidgets\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "import collections\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import keras\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import keras\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import keras\n",
        "import json\n",
        "import tensorflow as tf \n",
        "from keras.layers import Input\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import tensorflow.keras as keras"
      ],
      "metadata": {
        "id": "-c6sYy6zk-5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_NAME = \"organmnist3d\"\n",
        "BATCH_SIZE = 32\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "INPUT_SHAPE = (28, 28, 28, 1)\n",
        "NUM_CLASSES = 11\n",
        "\n",
        "# OPTIMIZER\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "# TRAINING\n",
        "EPOCHS = 60\n",
        "\n",
        "# TUBELET EMBEDDING\n",
        "PATCH_SIZE = (8, 8, 8)\n",
        "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
        "\n",
        "# ViViT ARCHITECTURE\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 128\n",
        "NUM_HEADS = 1\n",
        "NUM_LAYERS = 1"
      ],
      "metadata": {
        "id": "5FIQKenIk-6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_prepare_dataset(data_info: dict):\n",
        "\n",
        "    data_path = keras.utils.get_file(origin=data_info[\"url\"], md5_hash=data_info[\"MD5\"])\n",
        "\n",
        "    with np.load(data_path) as data:\n",
        "        # Get videos\n",
        "        train_videos = data[\"train_images\"]\n",
        "        valid_videos = data[\"val_images\"]\n",
        "        test_videos = data[\"test_images\"]\n",
        "\n",
        "        # Get labels\n",
        "        train_labels = data[\"train_labels\"].flatten()\n",
        "        valid_labels = data[\"val_labels\"].flatten()\n",
        "        test_labels = data[\"test_labels\"].flatten()\n",
        "\n",
        "    return (\n",
        "        (train_videos, train_labels),\n",
        "        (valid_videos, valid_labels),\n",
        "        (test_videos, test_labels),\n",
        "    )\n",
        "\n",
        "\n",
        "# Get the metadata of the dataset\n",
        "info = medmnist.INFO[DATASET_NAME]\n",
        "\n",
        "# Get the dataset\n",
        "prepared_dataset = download_and_prepare_dataset(info)\n",
        "(train_videos, train_labels) = prepared_dataset[0]\n",
        "(valid_videos, valid_labels) = prepared_dataset[1]\n",
        "(test_videos, test_labels) = prepared_dataset[2]"
      ],
      "metadata": {
        "id": "KtF54ixMk--j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
        "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
        "    # Preprocess images\n",
        "    frames = tf.image.convert_image_dtype(\n",
        "        frames[\n",
        "            ..., tf.newaxis\n",
        "        ],  # The new axis is to help for further processing with Conv3D layers\n",
        "        tf.float32,\n",
        "    )\n",
        "    # Parse label\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    return frames, label\n",
        "\n",
        "\n",
        "def prepare_dataloader(\n",
        "    videos: np.ndarray,\n",
        "    labels: np.ndarray,\n",
        "    loader_type: str = \"train\",\n",
        "    batch_size: int = BATCH_SIZE,\n",
        "):\n",
        "    \"\"\"Utility function to prepare the dataloader.\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
        "\n",
        "    if loader_type == \"train\":\n",
        "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
        "\n",
        "    dataloader = (\n",
        "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "trainloader = prepare_dataloader(train_videos, train_labels, \"train\")\n",
        "validloader = prepare_dataloader(valid_videos, valid_labels, \"valid\")\n",
        "testloader = prepare_dataloader(test_videos, test_labels, \"test\")"
      ],
      "metadata": {
        "id": "34o25m_bk-_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TubeletEmbedding(layers.Layer):\n",
        "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.projection = layers.Conv3D(\n",
        "            filters=embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            strides=patch_size,\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
        "\n",
        "    def call(self, videos):\n",
        "        projected_patches = self.projection(videos)\n",
        "        flattened_patches = self.flatten(projected_patches)\n",
        "        return flattened_patches"
      ],
      "metadata": {
        "id": "UQMwQq9Mk_Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, num_tokens, _ = input_shape\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_tokens, output_dim=self.embed_dim\n",
        "        )\n",
        "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
        "\n",
        "    def call(self, encoded_tokens):\n",
        "        # Encode the positions and add it to the encoded tokens\n",
        "        encoded_positions = self.position_embedding(self.positions)\n",
        "        encoded_tokens = encoded_tokens + encoded_positions\n",
        "        return encoded_tokens"
      ],
      "metadata": {
        "id": "Ju3sa39Ek_Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_vivit_classifier(\n",
        "    tubelet_embedder,\n",
        "    positional_encoder,\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    transformer_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    embed_dim=PROJECTION_DIM,\n",
        "    layer_norm_eps=LAYER_NORM_EPS,\n",
        "    num_classes=NUM_CLASSES,\n",
        "):\n",
        "    # Get the input layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    patches = tubelet_embedder(inputs)\n",
        "    # Encode patches.\n",
        "    encoded_patches = positional_encoder(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization and MHSA\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
        "        )(x1, x1)\n",
        "\n",
        "        # Skip connection\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        # Layer Normalization and MLP\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
        "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
        "            ]\n",
        "        )(x3)\n",
        "\n",
        "        # Skip connection\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Layer normalization and Global average pooling.\n",
        "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
        "    representation = layers.GlobalAvgPool1D()(representation)\n",
        "\n",
        "    # Classify outputs.\n",
        "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
        "\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "DJCPHMC9k_Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# TUBELET EMBEDDING\n",
        "PATCH_SIZE = (8, 8, 8)\n",
        "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
        "\n",
        "NUM_HEADS = 1\n",
        "NUM_LAYERS = 1\n",
        "\n",
        "md = create_vivit_classifier(\n",
        "        tubelet_embedder=TubeletEmbedding(\n",
        "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
        "        ),\n",
        "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
        "        transformer_layers=NUM_LAYERS,\n",
        "        num_heads=NUM_HEADS,\n",
        "        embed_dim=PROJECTION_DIM\n",
        "\n",
        "    )\n",
        "\n",
        "md.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvFDTZEmk_Jq",
        "outputId": "d68bf515-5e97-4080-c441-eacfd8d6cf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 28, 28, 28,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " tubelet_embedding_3 (TubeletEm  (None, 27, 128)     65664       ['input_4[0][0]']                \n",
            " bedding)                                                                                         \n",
            "                                                                                                  \n",
            " positional_encoder_3 (Position  (None, 27, 128)     3456        ['tubelet_embedding_3[0][0]']    \n",
            " alEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 27, 128)     256         ['positional_encoder_3[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 27, 128)     66048       ['layer_normalization_9[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 27, 128)      0           ['multi_head_attention_3[0][0]', \n",
            "                                                                  'positional_encoder_3[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 27, 128)     256         ['add_6[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 27, 128)      131712      ['layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 27, 128)      0           ['sequential[0][0]',             \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 27, 128)     256         ['add_7[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling1d_3 (Gl  (None, 128)         0           ['layer_normalization_11[0][0]'] \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 11)           1419        ['global_average_pooling1d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 269,067\n",
            "Trainable params: 269,067\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "EPOCHS = 20\n",
        "\n",
        "def run_experiment():\n",
        "    # Initialize model\n",
        "    model = create_vivit_classifier(\n",
        "        tubelet_embedder=TubeletEmbedding(\n",
        "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
        "        ),\n",
        "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
        "    )\n",
        "\n",
        "    # Compile the model with the optimizer, loss function\n",
        "    # and the metrics.\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Train the model.\n",
        "    _ = model.fit(trainloader, epochs=EPOCHS, validation_data=validloader)\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = run_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QWsQOqok_N7",
        "outputId": "657dedb4-6e18-4ea5-f7dc-df8fa495eccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 4s 82ms/step - loss: 2.4231 - accuracy: 0.1286 - top-5-accuracy: 0.5689 - val_loss: 2.3345 - val_accuracy: 0.1801 - val_top-5-accuracy: 0.5652\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 2s 73ms/step - loss: 2.2553 - accuracy: 0.1728 - top-5-accuracy: 0.6358 - val_loss: 2.2011 - val_accuracy: 0.1553 - val_top-5-accuracy: 0.5839\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 2s 72ms/step - loss: 2.1255 - accuracy: 0.1924 - top-5-accuracy: 0.7119 - val_loss: 1.9649 - val_accuracy: 0.2919 - val_top-5-accuracy: 0.7888\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 2s 71ms/step - loss: 1.9307 - accuracy: 0.2767 - top-5-accuracy: 0.7932 - val_loss: 1.6671 - val_accuracy: 0.3789 - val_top-5-accuracy: 0.8075\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 2s 71ms/step - loss: 1.7259 - accuracy: 0.3611 - top-5-accuracy: 0.8323 - val_loss: 1.5659 - val_accuracy: 0.3665 - val_top-5-accuracy: 0.8696\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 2s 71ms/step - loss: 1.5958 - accuracy: 0.3776 - top-5-accuracy: 0.9002 - val_loss: 1.3374 - val_accuracy: 0.4596 - val_top-5-accuracy: 0.9441\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 2s 71ms/step - loss: 1.5924 - accuracy: 0.4053 - top-5-accuracy: 0.8807 - val_loss: 1.2524 - val_accuracy: 0.5776 - val_top-5-accuracy: 0.9565\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 2s 70ms/step - loss: 1.4257 - accuracy: 0.4506 - top-5-accuracy: 0.9239 - val_loss: 1.2311 - val_accuracy: 0.5155 - val_top-5-accuracy: 0.9379\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 2s 70ms/step - loss: 1.4414 - accuracy: 0.4403 - top-5-accuracy: 0.9177 - val_loss: 1.1487 - val_accuracy: 0.5963 - val_top-5-accuracy: 0.9752\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 2s 70ms/step - loss: 1.3461 - accuracy: 0.4753 - top-5-accuracy: 0.9342 - val_loss: 0.9980 - val_accuracy: 0.6211 - val_top-5-accuracy: 0.9689\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 2s 70ms/step - loss: 1.2055 - accuracy: 0.5401 - top-5-accuracy: 0.9434 - val_loss: 0.9336 - val_accuracy: 0.6398 - val_top-5-accuracy: 0.9689\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 2s 70ms/step - loss: 1.1590 - accuracy: 0.5710 - top-5-accuracy: 0.9455 - val_loss: 0.9430 - val_accuracy: 0.6335 - val_top-5-accuracy: 0.9752\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 2s 75ms/step - loss: 1.0833 - accuracy: 0.5988 - top-5-accuracy: 0.9588 - val_loss: 0.8828 - val_accuracy: 0.7267 - val_top-5-accuracy: 0.9627\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 2s 76ms/step - loss: 1.0334 - accuracy: 0.6183 - top-5-accuracy: 0.9650 - val_loss: 0.9792 - val_accuracy: 0.6087 - val_top-5-accuracy: 0.9689\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 3s 108ms/step - loss: 0.9780 - accuracy: 0.6307 - top-5-accuracy: 0.9702 - val_loss: 0.9149 - val_accuracy: 0.6025 - val_top-5-accuracy: 0.9689\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 2s 71ms/step - loss: 0.9369 - accuracy: 0.6677 - top-5-accuracy: 0.9753 - val_loss: 0.8642 - val_accuracy: 0.6957 - val_top-5-accuracy: 0.9627\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 2s 71ms/step - loss: 0.8635 - accuracy: 0.7047 - top-5-accuracy: 0.9805 - val_loss: 0.7243 - val_accuracy: 0.7950 - val_top-5-accuracy: 0.9752\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 2s 72ms/step - loss: 0.8266 - accuracy: 0.7202 - top-5-accuracy: 0.9784 - val_loss: 0.7733 - val_accuracy: 0.7702 - val_top-5-accuracy: 0.9689\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 2s 71ms/step - loss: 0.7629 - accuracy: 0.7418 - top-5-accuracy: 0.9846 - val_loss: 0.7287 - val_accuracy: 0.8012 - val_top-5-accuracy: 0.9627\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 2s 70ms/step - loss: 0.7677 - accuracy: 0.7387 - top-5-accuracy: 0.9815 - val_loss: 0.8149 - val_accuracy: 0.7329 - val_top-5-accuracy: 0.9627\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 1.3311 - accuracy: 0.5492 - top-5-accuracy: 0.9525\n",
            "Test accuracy: 54.92%\n",
            "Test top 5 accuracy: 95.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "An_dliKKk_O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CBmXgyMYpjbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded "
      ],
      "metadata": {
        "id": "hVzpK7b2pjc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_att_Lstm_classifier(\n",
        "    tubelet_embedder,\n",
        "    positional_encoder,\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    transformer_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    embed_dim=PROJECTION_DIM,\n",
        "    layer_norm_eps=LAYER_NORM_EPS,\n",
        "    num_classes=NUM_CLASSES,\n",
        "):\n",
        "    # Get the input layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    y1 =  TimeDistributed(Conv2D(2, (3, 3), strides=(1,1),activation='relu'))  (inputs)\n",
        "    features = TimeDistributed(MaxPooling2D(2,2)) (y1)\n",
        "\n",
        "    frames = TimeDistributed ( Flatten() ) (features)\n",
        "    patches = LSTM( 128 ,return_sequences= True , dropout=0.2) (frames)\n",
        "    \n",
        "\n",
        "    # Encode patches.\n",
        "    encoded_patches = positional_encoder(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization and MHSA\n",
        "\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
        "        )(x1, x1)\n",
        "\n",
        "        # Skip connection\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        # Layer Normalization and MLP\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = keras.Sequential(LSTM(128,return_sequences=False,dropout=0.2) )(x3)\n",
        "\n",
        "        # Skip connection\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Layer normalization and Global average pooling.\n",
        "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
        "    representation = LSTM(100,return_sequences=False,dropout=0.2)(representation)\n",
        "\n",
        "    # Classify outputs.\n",
        "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
        "\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# TUBELET EMBEDDING\n",
        "PATCH_SIZE = (8, 8, 8)\n",
        "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
        "\n",
        "NUM_HEADS = 1\n",
        "NUM_LAYERS = 1\n",
        "\n",
        "md = create_att_Lstm_classifier(\n",
        "        tubelet_embedder=TubeletEmbedding(\n",
        "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
        "        ),\n",
        "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
        "        transformer_layers=NUM_LAYERS,\n",
        "        num_heads=NUM_HEADS,\n",
        "        embed_dim=PROJECTION_DIM\n",
        "\n",
        "    )\n",
        "\n",
        "md.summary()"
      ],
      "metadata": {
        "id": "mdbtmSM-k_TA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe2b7f2-d6da-4241-8b47-01db176a3850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_19 (InputLayer)          [(None, 28, 28, 28,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " time_distributed_85 (TimeDistr  (None, 28, 26, 26,   20         ['input_19[0][0]']               \n",
            " ibuted)                        2)                                                                \n",
            "                                                                                                  \n",
            " time_distributed_86 (TimeDistr  (None, 28, 13, 13,   0          ['time_distributed_85[0][0]']    \n",
            " ibuted)                        2)                                                                \n",
            "                                                                                                  \n",
            " time_distributed_87 (TimeDistr  (None, 28, 338)     0           ['time_distributed_86[0][0]']    \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " lstm_23 (LSTM)                 (None, 28, 128)      239104      ['time_distributed_87[0][0]']    \n",
            "                                                                                                  \n",
            " positional_encoder_18 (Positio  (None, 28, 128)     3584        ['lstm_23[0][0]']                \n",
            " nalEncoder)                                                                                      \n",
            "                                                                                                  \n",
            " layer_normalization_48 (LayerN  (None, 28, 128)     256         ['positional_encoder_18[0][0]']  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_16 (Multi  (None, 28, 128)     66048       ['layer_normalization_48[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " add_32 (Add)                   (None, 28, 128)      0           ['multi_head_attention_16[0][0]',\n",
            "                                                                  'positional_encoder_18[0][0]']  \n",
            "                                                                                                  \n",
            " layer_normalization_49 (LayerN  (None, 28, 128)     256         ['add_32[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_12 (Sequential)     (None, 128)          131584      ['layer_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " add_33 (Add)                   (None, 28, 128)      0           ['sequential_12[0][0]',          \n",
            "                                                                  'add_32[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_50 (LayerN  (None, 28, 128)     256         ['add_33[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " lstm_25 (LSTM)                 (None, 100)          91600       ['layer_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 11)           1111        ['lstm_25[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 533,819\n",
            "Trainable params: 533,819\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2-fcOSzk_T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "EPOCHS = 20\n",
        "\n",
        "def run_experiment():\n",
        "    # Initialize model\n",
        "    model = create_att_Lstm_classifier(\n",
        "        tubelet_embedder=TubeletEmbedding(\n",
        "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
        "        ),\n",
        "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
        "    )\n",
        "\n",
        "    # Compile the model with the optimizer, loss function\n",
        "    # and the metrics.\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Train the model.\n",
        "    _ = model.fit(trainloader, epochs=EPOCHS, validation_data=validloader)\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = run_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7M4kAkkk_YP",
        "outputId": "ae3bdf40-75e5-4b44-e87b-047c7689879d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 18s 364ms/step - loss: 2.2069 - accuracy: 0.2274 - top-5-accuracy: 0.7068 - val_loss: 1.8243 - val_accuracy: 0.4907 - val_top-5-accuracy: 0.9317\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 10s 311ms/step - loss: 1.8398 - accuracy: 0.4126 - top-5-accuracy: 0.8971 - val_loss: 1.4665 - val_accuracy: 0.6832 - val_top-5-accuracy: 0.9689\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 10s 311ms/step - loss: 1.5679 - accuracy: 0.5216 - top-5-accuracy: 0.9372 - val_loss: 1.1687 - val_accuracy: 0.7391 - val_top-5-accuracy: 0.9627\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 10s 313ms/step - loss: 1.3743 - accuracy: 0.5885 - top-5-accuracy: 0.9516 - val_loss: 0.9596 - val_accuracy: 0.8012 - val_top-5-accuracy: 0.9876\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 10s 317ms/step - loss: 1.1892 - accuracy: 0.6626 - top-5-accuracy: 0.9619 - val_loss: 0.8100 - val_accuracy: 0.8261 - val_top-5-accuracy: 0.9938\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 11s 350ms/step - loss: 1.0483 - accuracy: 0.6934 - top-5-accuracy: 0.9722 - val_loss: 0.6436 - val_accuracy: 0.8509 - val_top-5-accuracy: 0.9938\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 10s 318ms/step - loss: 0.9974 - accuracy: 0.6800 - top-5-accuracy: 0.9722 - val_loss: 0.5528 - val_accuracy: 0.8758 - val_top-5-accuracy: 0.9938\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 10s 313ms/step - loss: 0.8651 - accuracy: 0.7397 - top-5-accuracy: 0.9753 - val_loss: 0.5247 - val_accuracy: 0.8509 - val_top-5-accuracy: 0.9938\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 10s 307ms/step - loss: 0.8202 - accuracy: 0.7654 - top-5-accuracy: 0.9733 - val_loss: 0.4824 - val_accuracy: 0.8696 - val_top-5-accuracy: 0.9938\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 10s 311ms/step - loss: 0.8006 - accuracy: 0.7541 - top-5-accuracy: 0.9784 - val_loss: 0.4539 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9938\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 10s 314ms/step - loss: 0.7418 - accuracy: 0.7634 - top-5-accuracy: 0.9846 - val_loss: 0.3957 - val_accuracy: 0.9006 - val_top-5-accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 10s 314ms/step - loss: 0.6839 - accuracy: 0.8025 - top-5-accuracy: 0.9856 - val_loss: 0.3910 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 10s 311ms/step - loss: 0.6765 - accuracy: 0.7881 - top-5-accuracy: 0.9835 - val_loss: 0.3666 - val_accuracy: 0.8944 - val_top-5-accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 10s 312ms/step - loss: 0.6276 - accuracy: 0.8025 - top-5-accuracy: 0.9856 - val_loss: 0.3353 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9938\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 10s 309ms/step - loss: 0.5910 - accuracy: 0.8117 - top-5-accuracy: 0.9887 - val_loss: 0.3318 - val_accuracy: 0.8944 - val_top-5-accuracy: 0.9938\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 10s 310ms/step - loss: 0.5681 - accuracy: 0.8220 - top-5-accuracy: 0.9887 - val_loss: 0.2973 - val_accuracy: 0.9068 - val_top-5-accuracy: 0.9938\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 10s 313ms/step - loss: 0.5227 - accuracy: 0.8436 - top-5-accuracy: 0.9907 - val_loss: 0.2858 - val_accuracy: 0.9193 - val_top-5-accuracy: 0.9876\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 10s 311ms/step - loss: 0.5149 - accuracy: 0.8405 - top-5-accuracy: 0.9907 - val_loss: 0.2542 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9938\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 10s 311ms/step - loss: 0.4856 - accuracy: 0.8477 - top-5-accuracy: 0.9938 - val_loss: 0.2717 - val_accuracy: 0.9193 - val_top-5-accuracy: 0.9938\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 10s 309ms/step - loss: 0.4752 - accuracy: 0.8560 - top-5-accuracy: 0.9887 - val_loss: 0.2692 - val_accuracy: 0.9255 - val_top-5-accuracy: 0.9938\n",
            "20/20 [==============================] - 2s 106ms/step - loss: 0.7348 - accuracy: 0.7393 - top-5-accuracy: 0.9820\n",
            "Test accuracy: 73.93%\n",
            "Test top 5 accuracy: 98.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q8yVDBSg3f7O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ih1zeBsO3fEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ohg4ryQk_ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ap3V15fbk_dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qlAfielKk_es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_att_Lstm_classifier(\n",
        "    tubelet_embedder,\n",
        "    positional_encoder,\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    transformer_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    embed_dim=PROJECTION_DIM,\n",
        "    layer_norm_eps=LAYER_NORM_EPS,\n",
        "    num_classes=NUM_CLASSES,\n",
        "):\n",
        "    # Get the input layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    y1 =  TimeDistributed(Conv2D(2, (3, 3), strides=(1,1),activation='relu'))  (inputs)\n",
        "    features = TimeDistributed(MaxPooling2D(2,2)) (y1)\n",
        "\n",
        "    frames = TimeDistributed ( Flatten() ) (features)\n",
        "    patches = layers.Dense(units=128, activation=\"relu\") (frames)\n",
        "    \n",
        "\n",
        "    # Encode patches.\n",
        "    encoded_patches = positional_encoder(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization and MHSA\n",
        "\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
        "        )(x1, x1)\n",
        "\n",
        "        # Skip connection\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        # Layer Normalization and MLP\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
        "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
        "            ]\n",
        "        )(x3)\n",
        "\n",
        "        # Skip connection\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Layer normalization and Global average pooling.\n",
        "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
        "    representation = layers.GlobalAvgPool1D()(representation)\n",
        "\n",
        "    # Classify outputs.\n",
        "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
        "\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# TUBELET EMBEDDING\n",
        "PATCH_SIZE = (8, 8, 8)\n",
        "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
        "\n",
        "NUM_HEADS = 1\n",
        "NUM_LAYERS = 1\n",
        "\n",
        "md = create_att_Lstm_classifier(\n",
        "        tubelet_embedder=TubeletEmbedding(\n",
        "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
        "        ),\n",
        "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
        "        transformer_layers=NUM_LAYERS,\n",
        "        num_heads=NUM_HEADS,\n",
        "        embed_dim=PROJECTION_DIM\n",
        "\n",
        "    )\n",
        "\n",
        "md.summary()"
      ],
      "metadata": {
        "id": "yXr4ai1Zk_jB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8301e0-caa3-44de-e9fb-cb66996b5760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_22 (InputLayer)          [(None, 28, 28, 28,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " time_distributed_94 (TimeDistr  (None, 28, 26, 26,   20         ['input_22[0][0]']               \n",
            " ibuted)                        2)                                                                \n",
            "                                                                                                  \n",
            " time_distributed_95 (TimeDistr  (None, 28, 13, 13,   0          ['time_distributed_94[0][0]']    \n",
            " ibuted)                        2)                                                                \n",
            "                                                                                                  \n",
            " time_distributed_96 (TimeDistr  (None, 28, 338)     0           ['time_distributed_95[0][0]']    \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " dense_36 (Dense)               (None, 28, 128)      43392       ['time_distributed_96[0][0]']    \n",
            "                                                                                                  \n",
            " positional_encoder_21 (Positio  (None, 28, 128)     3584        ['dense_36[0][0]']               \n",
            " nalEncoder)                                                                                      \n",
            "                                                                                                  \n",
            " layer_normalization_54 (LayerN  (None, 28, 128)     256         ['positional_encoder_21[0][0]']  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_18 (Multi  (None, 28, 128)     66048       ['layer_normalization_54[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " add_36 (Add)                   (None, 28, 128)      0           ['multi_head_attention_18[0][0]',\n",
            "                                                                  'positional_encoder_21[0][0]']  \n",
            "                                                                                                  \n",
            " layer_normalization_55 (LayerN  (None, 28, 128)     256         ['add_36[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " sequential_14 (Sequential)     (None, 28, 128)      131712      ['layer_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " add_37 (Add)                   (None, 28, 128)      0           ['sequential_14[0][0]',          \n",
            "                                                                  'add_36[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_56 (LayerN  (None, 28, 128)     256         ['add_37[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling1d_10 (G  (None, 128)         0           ['layer_normalization_56[0][0]'] \n",
            " lobalAveragePooling1D)                                                                           \n",
            "                                                                                                  \n",
            " dense_39 (Dense)               (None, 11)           1419        ['global_average_pooling1d_10[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 246,943\n",
            "Trainable params: 246,943\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "EPOCHS = 20\n",
        "\n",
        "def run_experiment():\n",
        "    # Initialize model\n",
        "    model = create_att_Lstm_classifier(\n",
        "        tubelet_embedder=TubeletEmbedding(\n",
        "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
        "        ),\n",
        "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
        "    )\n",
        "\n",
        "    # Compile the model with the optimizer, loss function\n",
        "    # and the metrics.\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Train the model.\n",
        "    _ = model.fit(trainloader, epochs=EPOCHS, validation_data=validloader)\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = run_experiment()"
      ],
      "metadata": {
        "id": "vRkH1_DSk_j6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d5bf64-e1a9-4f15-9f21-0085e9041e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 9s 209ms/step - loss: 2.2823 - accuracy: 0.1687 - top-5-accuracy: 0.6656 - val_loss: 2.0098 - val_accuracy: 0.3478 - val_top-5-accuracy: 0.7764\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 6s 192ms/step - loss: 1.8505 - accuracy: 0.3447 - top-5-accuracy: 0.8580 - val_loss: 1.4652 - val_accuracy: 0.4907 - val_top-5-accuracy: 0.9689\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 6s 196ms/step - loss: 1.5185 - accuracy: 0.4691 - top-5-accuracy: 0.9228 - val_loss: 1.1379 - val_accuracy: 0.6211 - val_top-5-accuracy: 0.9689\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 6s 197ms/step - loss: 1.2881 - accuracy: 0.5525 - top-5-accuracy: 0.9516 - val_loss: 0.9831 - val_accuracy: 0.6708 - val_top-5-accuracy: 0.9876\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 6s 199ms/step - loss: 1.1376 - accuracy: 0.6008 - top-5-accuracy: 0.9681 - val_loss: 0.8137 - val_accuracy: 0.6957 - val_top-5-accuracy: 0.9876\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 6s 197ms/step - loss: 0.9948 - accuracy: 0.6471 - top-5-accuracy: 0.9753 - val_loss: 0.7694 - val_accuracy: 0.7143 - val_top-5-accuracy: 0.9938\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 6s 198ms/step - loss: 0.8772 - accuracy: 0.7243 - top-5-accuracy: 0.9835 - val_loss: 0.6774 - val_accuracy: 0.7950 - val_top-5-accuracy: 0.9938\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 6s 190ms/step - loss: 0.7619 - accuracy: 0.7634 - top-5-accuracy: 0.9877 - val_loss: 0.6060 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 6s 196ms/step - loss: 0.6663 - accuracy: 0.7963 - top-5-accuracy: 0.9907 - val_loss: 0.5511 - val_accuracy: 0.8137 - val_top-5-accuracy: 0.9876\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 6s 189ms/step - loss: 0.5993 - accuracy: 0.8230 - top-5-accuracy: 0.9959 - val_loss: 0.5240 - val_accuracy: 0.8137 - val_top-5-accuracy: 0.9876\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 7s 228ms/step - loss: 0.5365 - accuracy: 0.8344 - top-5-accuracy: 0.9969 - val_loss: 0.4966 - val_accuracy: 0.8199 - val_top-5-accuracy: 0.9938\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 6s 189ms/step - loss: 0.4772 - accuracy: 0.8693 - top-5-accuracy: 0.9979 - val_loss: 0.4856 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9876\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 6s 190ms/step - loss: 0.4180 - accuracy: 0.8920 - top-5-accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.8261 - val_top-5-accuracy: 0.9938\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 6s 190ms/step - loss: 0.3816 - accuracy: 0.8940 - top-5-accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9938\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 6s 195ms/step - loss: 0.3458 - accuracy: 0.9167 - top-5-accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.8447 - val_top-5-accuracy: 0.9938\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 6s 197ms/step - loss: 0.3016 - accuracy: 0.9311 - top-5-accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.8385 - val_top-5-accuracy: 0.9938\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 6s 191ms/step - loss: 0.2808 - accuracy: 0.9362 - top-5-accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.8385 - val_top-5-accuracy: 0.9938\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 6s 190ms/step - loss: 0.2502 - accuracy: 0.9486 - top-5-accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8571 - val_top-5-accuracy: 0.9938\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 6s 191ms/step - loss: 0.2203 - accuracy: 0.9599 - top-5-accuracy: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.8385 - val_top-5-accuracy: 0.9876\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 6s 190ms/step - loss: 0.1956 - accuracy: 0.9681 - top-5-accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.8323 - val_top-5-accuracy: 0.9938\n",
            "20/20 [==============================] - 2s 81ms/step - loss: 1.1818 - accuracy: 0.6180 - top-5-accuracy: 0.9557\n",
            "Test accuracy: 61.8%\n",
            "Test top 5 accuracy: 95.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCmCFlN1k_oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7xpb8coKk_pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qozw98-ik_uH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}