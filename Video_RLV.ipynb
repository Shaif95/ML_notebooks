{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5419b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fca053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn='D:/RLV_data/*/'\n",
    "tr= glob(trn)\n",
    "\n",
    "len(tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273abbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "test_y = []\n",
    "\n",
    "y = 0\n",
    "for i in tr:\n",
    "    \n",
    "    #print(i)\n",
    "    x = glob(i+'/*/')\n",
    "    \n",
    "    #shuffle(x)\n",
    "    t,tt = train_test_split( x , test_size=0.1, random_state=42)\n",
    "    t, vv = train_test_split( t , test_size=0.1, random_state=42)\n",
    "    \n",
    "    for j in t:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "        \n",
    "        train.append(j)\n",
    "        train_y.append(y)\n",
    "    \n",
    "    for j in vv:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        val.append(j)\n",
    "        val_y.append(y)\n",
    "        \n",
    "    for j in tt:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        test.append(j)\n",
    "        test_y.append(y)\n",
    "        \n",
    "    y = y+1\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tra_y =  np.array(to_categorical(train_y))\n",
    "va_y  =  np.array(to_categorical(val_y))\n",
    "te_y  =  np.array(to_categorical(test_y))\n",
    "\n",
    "(train, tra_y) = shuffle(train, tra_y)\n",
    "(val, va_y) = shuffle(val, va_y)\n",
    "(test, te_y) = shuffle(test, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "798d6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    for i in range(0,20):\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((40, 40))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(40,40,3))\n",
    "        \n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e352d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b004fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , batch_size) :\n",
    "    self.filename = filename\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28523f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(train, tra_y, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(val, va_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bded865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(My_Test_Generator(test, batch_size).__getitem__(1))\n",
    "for i in range(2,len(x)):\n",
    "    x = My_Test_Generator(test, batch_size).__getitem__(i)\n",
    "    arr = np.concatenate((arr,x),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe4a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20, 40, 40, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eb0f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_14 (TimeDi  (None, 20, 38, 38, 8)    224       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_15 (TimeDi  (None, 20, 19, 19, 8)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_16 (TimeDi  (None, 20, 17, 17, 16)   1168      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_17 (TimeDi  (None, 20, 8, 8, 16)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_18 (TimeDi  (None, 20, 6, 6, 32)     4640      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_19 (TimeDi  (None, 20, 3, 3, 32)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_20 (TimeDi  (None, 20, 288)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 25)                31400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 52        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,484\n",
      "Trainable params: 37,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "num_frames = 20\n",
    "frame_height = 40\n",
    "frame_width = 40\n",
    "num_channels = 3\n",
    "num_classes = 2  # Change this to the number of classes in your dataset\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CNN\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu'), input_shape=(num_frames, frame_height, frame_width, num_channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(25))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81e2a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67fd3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_4360\\3350080984.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_4360\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 273s 5s/step - loss: 0.6900 - accuracy: 0.5228 - val_loss: 0.6729 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 269s 5s/step - loss: 0.6426 - accuracy: 0.5963 - val_loss: 0.5769 - val_accuracy: 0.6833\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 504s 10s/step - loss: 0.6008 - accuracy: 0.6759 - val_loss: 0.4772 - val_accuracy: 0.7778\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 844s 16s/step - loss: 0.5588 - accuracy: 0.6969 - val_loss: 0.4583 - val_accuracy: 0.8000\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 856s 17s/step - loss: 0.5311 - accuracy: 0.7259 - val_loss: 0.4554 - val_accuracy: 0.7611\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 846s 17s/step - loss: 0.4784 - accuracy: 0.7679 - val_loss: 0.4302 - val_accuracy: 0.8000\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 802s 16s/step - loss: 0.4523 - accuracy: 0.7809 - val_loss: 0.3925 - val_accuracy: 0.8556\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 825s 16s/step - loss: 0.3989 - accuracy: 0.8105 - val_loss: 0.3782 - val_accuracy: 0.8667\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 909s 18s/step - loss: 0.3737 - accuracy: 0.8346 - val_loss: 0.4165 - val_accuracy: 0.8111\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 816s 16s/step - loss: 0.3490 - accuracy: 0.8519 - val_loss: 0.3911 - val_accuracy: 0.8389\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 798s 16s/step - loss: 0.3219 - accuracy: 0.8580 - val_loss: 0.3299 - val_accuracy: 0.8778\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 799s 16s/step - loss: 0.2611 - accuracy: 0.8914 - val_loss: 0.3940 - val_accuracy: 0.8167\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 794s 15s/step - loss: 0.2350 - accuracy: 0.8988 - val_loss: 0.3903 - val_accuracy: 0.8444\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 792s 16s/step - loss: 0.2115 - accuracy: 0.9154 - val_loss: 0.3639 - val_accuracy: 0.8389\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 793s 16s/step - loss: 0.1798 - accuracy: 0.9321 - val_loss: 0.4429 - val_accuracy: 0.8167\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 797s 16s/step - loss: 0.1851 - accuracy: 0.9235 - val_loss: 0.4692 - val_accuracy: 0.8444\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 797s 16s/step - loss: 0.1426 - accuracy: 0.9451 - val_loss: 0.4238 - val_accuracy: 0.8444\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 794s 16s/step - loss: 0.1330 - accuracy: 0.9506 - val_loss: 0.4711 - val_accuracy: 0.8444\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 794s 16s/step - loss: 0.1129 - accuracy: 0.9500 - val_loss: 0.4563 - val_accuracy: 0.8556\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 796s 16s/step - loss: 0.0814 - accuracy: 0.9691 - val_loss: 0.4338 - val_accuracy: 0.8556\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 797s 16s/step - loss: 0.0599 - accuracy: 0.9778 - val_loss: 0.5531 - val_accuracy: 0.8500\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 795s 16s/step - loss: 0.1004 - accuracy: 0.9580 - val_loss: 0.6187 - val_accuracy: 0.8333\n",
      "Epoch 23/50\n",
      "45/51 [=========================>....] - ETA: 52:28 - loss: 0.0983 - accuracy: 0.9608  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4360\\3350080984.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_training_batch_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_validation_batch_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[1;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m         stacklevel=2)\n\u001b[1;32m-> 2016\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   2017\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(My_Test_Generator(test, batch_size), verbose=0)\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import Ofrom sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "scoreneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "p = np.argmax(predictions, axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ab8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossAndMetrics = model.evaluate(arr, te_y)\n",
    "lossAndMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649eb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a501e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831105e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
