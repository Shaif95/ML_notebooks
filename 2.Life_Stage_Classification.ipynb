{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696d630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (49227, 32, 32, 3)\n",
      "Y_train shape: (49227,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r'C:\\Users\\shaif\\Downloads\\Compressed\\Invasive_Life_Stage'\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for folder in os.listdir(directory_path):\n",
    "    #print(class_folder)\n",
    "    clsp = os.path.join(directory_path,folder)  \n",
    "    for class_folder in os.listdir(clsp):\n",
    "        #print(class_folder)\n",
    "        class_path = os.path.join(clsp, class_folder)    \n",
    "        #print(class_path)\n",
    "        for image_file in os.listdir(class_path):\n",
    "            if image_file.endswith('.png'):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                img = img.resize((32, 32))\n",
    "                img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(class_label)\n",
    "                #print(class_label)\n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884830c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "Y_train_encoded = to_categorical(Y_train)\n",
    "indices = np.arange(len(X_train))\n",
    "np.random.shuffle(indices)\n",
    "X_train_shuffled = X_train[indices]\n",
    "Y_train_encoded_shuffled = Y_train_encoded[indices]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_shuffled, Y_train_encoded_shuffled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0102e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af25d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "985/985 [==============================] - 48s 43ms/step - loss: 10.7192 - accuracy: 0.4295 - val_loss: 1.3779 - val_accuracy: 0.5109\n",
      "Epoch 2/100\n",
      "985/985 [==============================] - 63s 64ms/step - loss: 1.8887 - accuracy: 0.5161 - val_loss: 1.2095 - val_accuracy: 0.5055\n",
      "Epoch 3/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 1.6468 - accuracy: 0.5680 - val_loss: 1.0804 - val_accuracy: 0.6082\n",
      "Epoch 4/100\n",
      "985/985 [==============================] - 66s 67ms/step - loss: 1.5297 - accuracy: 0.6193 - val_loss: 0.9018 - val_accuracy: 0.6562\n",
      "Epoch 5/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 1.5980 - accuracy: 0.6341 - val_loss: 2.0388 - val_accuracy: 0.6290\n",
      "Epoch 6/100\n",
      "985/985 [==============================] - 56s 57ms/step - loss: 1.0381 - accuracy: 0.6601 - val_loss: 0.8070 - val_accuracy: 0.6979\n",
      "Epoch 7/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 1.1082 - accuracy: 0.6613 - val_loss: 13.8118 - val_accuracy: 0.7070\n",
      "Epoch 8/100\n",
      "985/985 [==============================] - 55s 55ms/step - loss: 1.0147 - accuracy: 0.6681 - val_loss: 1.1931 - val_accuracy: 0.5932\n",
      "Epoch 9/100\n",
      "985/985 [==============================] - 70s 71ms/step - loss: 1.1417 - accuracy: 0.6847 - val_loss: 14.7764 - val_accuracy: 0.7198\n",
      "Epoch 10/100\n",
      "985/985 [==============================] - 68s 69ms/step - loss: 0.8902 - accuracy: 0.7050 - val_loss: 15.6384 - val_accuracy: 0.7161\n",
      "Epoch 11/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.7659 - accuracy: 0.7230 - val_loss: 32.2106 - val_accuracy: 0.6387\n",
      "Epoch 12/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.8912 - accuracy: 0.7101 - val_loss: 222.4779 - val_accuracy: 0.6535\n",
      "Epoch 13/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.8382 - accuracy: 0.7185 - val_loss: 112.4261 - val_accuracy: 0.5981\n",
      "Epoch 14/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 1.5726 - accuracy: 0.6826 - val_loss: 68.0038 - val_accuracy: 0.7105\n",
      "Epoch 15/100\n",
      "985/985 [==============================] - 63s 64ms/step - loss: 0.7880 - accuracy: 0.7238 - val_loss: 38.0403 - val_accuracy: 0.7231\n",
      "Epoch 16/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 1.0861 - accuracy: 0.7053 - val_loss: 57.6438 - val_accuracy: 0.7130\n",
      "Epoch 17/100\n",
      "985/985 [==============================] - 67s 68ms/step - loss: 0.7360 - accuracy: 0.7276 - val_loss: 69.2454 - val_accuracy: 0.7263\n",
      "Epoch 18/100\n",
      "985/985 [==============================] - 72s 74ms/step - loss: 0.9385 - accuracy: 0.7090 - val_loss: 236.3158 - val_accuracy: 0.6844\n",
      "Epoch 19/100\n",
      "985/985 [==============================] - 68s 69ms/step - loss: 0.8574 - accuracy: 0.7079 - val_loss: 55.3587 - val_accuracy: 0.7084\n",
      "Epoch 20/100\n",
      "985/985 [==============================] - 74s 75ms/step - loss: 0.8173 - accuracy: 0.7204 - val_loss: 302.2008 - val_accuracy: 0.7272\n",
      "Epoch 21/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.7285 - accuracy: 0.7309 - val_loss: 168.3580 - val_accuracy: 0.7222\n",
      "Epoch 22/100\n",
      "985/985 [==============================] - 60s 60ms/step - loss: 0.8484 - accuracy: 0.7294 - val_loss: 456.8649 - val_accuracy: 0.7168\n",
      "Epoch 23/100\n",
      "985/985 [==============================] - 51s 52ms/step - loss: 0.7431 - accuracy: 0.7366 - val_loss: 66.7902 - val_accuracy: 0.7427\n",
      "Epoch 24/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.7390 - accuracy: 0.7436 - val_loss: 1057.9353 - val_accuracy: 0.7357\n",
      "Epoch 25/100\n",
      "985/985 [==============================] - 49s 50ms/step - loss: 0.8091 - accuracy: 0.7292 - val_loss: 279.8658 - val_accuracy: 0.7078\n",
      "Epoch 26/100\n",
      "985/985 [==============================] - 52s 52ms/step - loss: 0.9441 - accuracy: 0.7258 - val_loss: 211.0532 - val_accuracy: 0.7099\n",
      "Epoch 27/100\n",
      "985/985 [==============================] - 54s 55ms/step - loss: 0.7747 - accuracy: 0.7393 - val_loss: 1.4973 - val_accuracy: 0.7470\n",
      "Epoch 28/100\n",
      "985/985 [==============================] - 51s 52ms/step - loss: 0.8472 - accuracy: 0.7238 - val_loss: 262.4333 - val_accuracy: 0.7279\n",
      "Epoch 29/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.8201 - accuracy: 0.7325 - val_loss: 632.3724 - val_accuracy: 0.7121\n",
      "Epoch 30/100\n",
      "985/985 [==============================] - 64s 65ms/step - loss: 0.7163 - accuracy: 0.7368 - val_loss: 25.0606 - val_accuracy: 0.7469\n",
      "Epoch 31/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.9987 - accuracy: 0.7266 - val_loss: 1557.5911 - val_accuracy: 0.7397\n",
      "Epoch 32/100\n",
      "985/985 [==============================] - 60s 61ms/step - loss: 0.7230 - accuracy: 0.7420 - val_loss: 1125.2383 - val_accuracy: 0.7485\n",
      "Epoch 33/100\n",
      "985/985 [==============================] - 67s 68ms/step - loss: 0.7797 - accuracy: 0.7369 - val_loss: 1734.7864 - val_accuracy: 0.7425\n",
      "Epoch 34/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 1.2194 - accuracy: 0.6879 - val_loss: 279.7732 - val_accuracy: 0.7262\n",
      "Epoch 35/100\n",
      "985/985 [==============================] - 60s 61ms/step - loss: 0.7421 - accuracy: 0.7280 - val_loss: 70.2632 - val_accuracy: 0.7413\n",
      "Epoch 36/100\n",
      "985/985 [==============================] - 68s 69ms/step - loss: 0.7368 - accuracy: 0.7349 - val_loss: 514.3162 - val_accuracy: 0.7382\n",
      "Epoch 37/100\n",
      "985/985 [==============================] - 63s 64ms/step - loss: 0.7688 - accuracy: 0.7350 - val_loss: 1358.3221 - val_accuracy: 0.7331\n",
      "Epoch 38/100\n",
      "985/985 [==============================] - 60s 61ms/step - loss: 0.7985 - accuracy: 0.7340 - val_loss: 6.3336 - val_accuracy: 0.7588\n",
      "Epoch 39/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.8080 - accuracy: 0.7424 - val_loss: 7.2477 - val_accuracy: 0.7608\n",
      "Epoch 40/100\n",
      "985/985 [==============================] - 61s 62ms/step - loss: 0.7799 - accuracy: 0.7443 - val_loss: 0.6341 - val_accuracy: 0.7679\n",
      "Epoch 41/100\n",
      "985/985 [==============================] - 67s 68ms/step - loss: 0.7923 - accuracy: 0.7499 - val_loss: 1166.0710 - val_accuracy: 0.7050\n",
      "Epoch 42/100\n",
      "985/985 [==============================] - 64s 65ms/step - loss: 0.7466 - accuracy: 0.7536 - val_loss: 59.1016 - val_accuracy: 0.7592\n",
      "Epoch 43/100\n",
      "985/985 [==============================] - 44s 44ms/step - loss: 0.7108 - accuracy: 0.7595 - val_loss: 687.3445 - val_accuracy: 0.7587\n",
      "Epoch 44/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.6746 - accuracy: 0.7666 - val_loss: 139.6897 - val_accuracy: 0.7543\n",
      "Epoch 45/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.7163 - accuracy: 0.7656 - val_loss: 4.9612 - val_accuracy: 0.7844\n",
      "Epoch 46/100\n",
      "985/985 [==============================] - 61s 62ms/step - loss: 0.7847 - accuracy: 0.7560 - val_loss: 174.0325 - val_accuracy: 0.7504\n",
      "Epoch 47/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.7142 - accuracy: 0.7552 - val_loss: 1066.6960 - val_accuracy: 0.7504\n",
      "Epoch 48/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.7750 - accuracy: 0.7592 - val_loss: 598.9844 - val_accuracy: 0.7631\n",
      "Epoch 49/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.7085 - accuracy: 0.7711 - val_loss: 0.5972 - val_accuracy: 0.7851\n",
      "Epoch 50/100\n",
      "985/985 [==============================] - 48s 48ms/step - loss: 0.6581 - accuracy: 0.7779 - val_loss: 619.1027 - val_accuracy: 0.7335\n",
      "Epoch 51/100\n",
      "985/985 [==============================] - 54s 55ms/step - loss: 0.8312 - accuracy: 0.7690 - val_loss: 310.7119 - val_accuracy: 0.7681\n",
      "Epoch 52/100\n",
      "985/985 [==============================] - 53s 53ms/step - loss: 0.6376 - accuracy: 0.7821 - val_loss: 0.6009 - val_accuracy: 0.7678\n",
      "Epoch 53/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.7444 - accuracy: 0.7787 - val_loss: 0.5754 - val_accuracy: 0.7714\n",
      "Epoch 54/100\n",
      "985/985 [==============================] - 53s 54ms/step - loss: 0.7742 - accuracy: 0.7667 - val_loss: 2862.0422 - val_accuracy: 0.7602\n",
      "Epoch 55/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.7218 - accuracy: 0.7551 - val_loss: 3.2711 - val_accuracy: 0.7783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.8577 - accuracy: 0.7494 - val_loss: 14.5738 - val_accuracy: 0.7229\n",
      "Epoch 57/100\n",
      "985/985 [==============================] - 57s 57ms/step - loss: 0.8798 - accuracy: 0.7397 - val_loss: 664.8566 - val_accuracy: 0.6899\n",
      "Epoch 58/100\n",
      "985/985 [==============================] - 54s 54ms/step - loss: 0.8179 - accuracy: 0.7490 - val_loss: 6415.5513 - val_accuracy: 0.7543\n",
      "Epoch 59/100\n",
      "985/985 [==============================] - 63s 64ms/step - loss: 0.6796 - accuracy: 0.7640 - val_loss: 1710.9465 - val_accuracy: 0.7541\n",
      "Epoch 60/100\n",
      "985/985 [==============================] - 55s 56ms/step - loss: 0.7980 - accuracy: 0.7633 - val_loss: 1.8588 - val_accuracy: 0.7759\n",
      "Epoch 61/100\n",
      "985/985 [==============================] - 56s 57ms/step - loss: 0.7421 - accuracy: 0.7561 - val_loss: 17.0709 - val_accuracy: 0.7750\n",
      "Epoch 62/100\n",
      "985/985 [==============================] - 54s 55ms/step - loss: 0.6851 - accuracy: 0.7612 - val_loss: 259.7698 - val_accuracy: 0.7535\n",
      "Epoch 63/100\n",
      "985/985 [==============================] - 61s 62ms/step - loss: 0.7722 - accuracy: 0.7671 - val_loss: 601.4236 - val_accuracy: 0.7588\n",
      "Epoch 64/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.6968 - accuracy: 0.7608 - val_loss: 178.5918 - val_accuracy: 0.7590\n",
      "Epoch 65/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.7626 - accuracy: 0.7536 - val_loss: 2787.1482 - val_accuracy: 0.7627\n",
      "Epoch 66/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.8610 - accuracy: 0.7558 - val_loss: 893.6570 - val_accuracy: 0.7565\n",
      "Epoch 67/100\n",
      "985/985 [==============================] - 62s 63ms/step - loss: 0.6313 - accuracy: 0.7687 - val_loss: 2594.9570 - val_accuracy: 0.7559\n",
      "Epoch 68/100\n",
      "985/985 [==============================] - 56s 57ms/step - loss: 0.7462 - accuracy: 0.7565 - val_loss: 498.2641 - val_accuracy: 0.7543\n",
      "Epoch 69/100\n",
      "985/985 [==============================] - 53s 54ms/step - loss: 0.8067 - accuracy: 0.7547 - val_loss: 27.7690 - val_accuracy: 0.6982\n",
      "Epoch 70/100\n",
      "985/985 [==============================] - 40s 40ms/step - loss: 0.6923 - accuracy: 0.7535 - val_loss: 0.5918 - val_accuracy: 0.7676\n",
      "Epoch 71/100\n",
      "985/985 [==============================] - 38s 39ms/step - loss: 0.7259 - accuracy: 0.7603 - val_loss: 5.5875 - val_accuracy: 0.7745\n",
      "Epoch 72/100\n",
      "985/985 [==============================] - 39s 40ms/step - loss: 0.6820 - accuracy: 0.7667 - val_loss: 6.5025 - val_accuracy: 0.7703\n",
      "Epoch 73/100\n",
      "985/985 [==============================] - 39s 39ms/step - loss: 0.7001 - accuracy: 0.7680 - val_loss: 15.2905 - val_accuracy: 0.7813\n",
      "Epoch 74/100\n",
      "985/985 [==============================] - 38s 39ms/step - loss: 0.7232 - accuracy: 0.7635 - val_loss: 1754.7085 - val_accuracy: 0.7646\n",
      "Epoch 75/100\n",
      "985/985 [==============================] - 40s 41ms/step - loss: 0.6714 - accuracy: 0.7747 - val_loss: 1178.9629 - val_accuracy: 0.7627\n",
      "Epoch 76/100\n",
      "985/985 [==============================] - 39s 40ms/step - loss: 0.7076 - accuracy: 0.7698 - val_loss: 1410.3590 - val_accuracy: 0.7587\n",
      "Epoch 77/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.6643 - accuracy: 0.7739 - val_loss: 1092.8849 - val_accuracy: 0.7455\n",
      "Epoch 78/100\n",
      "985/985 [==============================] - 39s 40ms/step - loss: 0.6608 - accuracy: 0.7733 - val_loss: 717.1284 - val_accuracy: 0.7613\n",
      "Epoch 79/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.6995 - accuracy: 0.7711 - val_loss: 1286.2338 - val_accuracy: 0.7695\n",
      "Epoch 80/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.7137 - accuracy: 0.7802 - val_loss: 1446.0443 - val_accuracy: 0.7715\n",
      "Epoch 81/100\n",
      "538/985 [===============>..............] - ETA: 20s - loss: 0.6573 - accuracy: 0.7780"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D\n",
    "\n",
    "model_path = r\"C:\\Users\\shaif\\Downloads\\invasive_ssl.h5\"\n",
    "model = load_model(model_path)\n",
    "#model.layers[0].trainable = False\n",
    "x = model.layers[-8].output  \n",
    "output = Dense(5, activation='softmax')(x)\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=40, mode='max', verbose=1)\n",
    "new_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = new_model.fit(X_train, y_train, batch_size=32, epochs=100,validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df2a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527c8253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Balanced Accuracy: 0.3911037901869985\n",
      "Test Accuracy: 0.5926264472882389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "predictions = new_model.predict(np.array(X_test).astype('float32'))\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "balanced_accuracy = balanced_accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "print(\"Test Balanced Accuracy:\", balanced_accuracy)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e13845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ffb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc37585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "985/985 [==============================] - 55s 50ms/step - loss: 1.0012 - accuracy: 0.7235 - val_loss: 1196.4908 - val_accuracy: 0.4384\n",
      "Epoch 2/100\n",
      "985/985 [==============================] - 58s 58ms/step - loss: 0.8458 - accuracy: 0.7337 - val_loss: 0.9320 - val_accuracy: 0.6566\n",
      "Epoch 3/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.5347 - accuracy: 0.8039 - val_loss: 0.6323 - val_accuracy: 0.7695\n",
      "Epoch 4/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 0.5154 - accuracy: 0.8182 - val_loss: 1.3514 - val_accuracy: 0.6037\n",
      "Epoch 5/100\n",
      "985/985 [==============================] - 54s 55ms/step - loss: 0.5396 - accuracy: 0.8041 - val_loss: 0.5253 - val_accuracy: 0.8030\n",
      "Epoch 6/100\n",
      "985/985 [==============================] - 46s 46ms/step - loss: 0.4793 - accuracy: 0.8256 - val_loss: 2.4249 - val_accuracy: 0.6598\n",
      "Epoch 7/100\n",
      "985/985 [==============================] - 56s 56ms/step - loss: 0.5909 - accuracy: 0.7939 - val_loss: 0.6627 - val_accuracy: 0.7712\n",
      "Epoch 8/100\n",
      "985/985 [==============================] - 46s 46ms/step - loss: 0.5220 - accuracy: 0.8053 - val_loss: 2.2187 - val_accuracy: 0.6406\n",
      "Epoch 9/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.4481 - accuracy: 0.8367 - val_loss: 1.1745 - val_accuracy: 0.5525\n",
      "Epoch 10/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.4344 - accuracy: 0.8441 - val_loss: 0.4259 - val_accuracy: 0.8529\n",
      "Epoch 11/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.3835 - accuracy: 0.8613 - val_loss: 2.2309 - val_accuracy: 0.3825\n",
      "Epoch 12/100\n",
      "985/985 [==============================] - 51s 51ms/step - loss: 0.3655 - accuracy: 0.8651 - val_loss: 2.6930 - val_accuracy: 0.4395\n",
      "Epoch 13/100\n",
      "985/985 [==============================] - 43s 44ms/step - loss: 0.5040 - accuracy: 0.8361 - val_loss: 1.8054 - val_accuracy: 0.4942\n",
      "Epoch 14/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.3847 - accuracy: 0.8618 - val_loss: 1.1613 - val_accuracy: 0.5835\n",
      "Epoch 15/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.3388 - accuracy: 0.8773 - val_loss: 0.4782 - val_accuracy: 0.8180\n",
      "Epoch 16/100\n",
      "985/985 [==============================] - 43s 43ms/step - loss: 0.3117 - accuracy: 0.8845 - val_loss: 0.7180 - val_accuracy: 0.7719\n",
      "Epoch 17/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 0.2972 - accuracy: 0.8911 - val_loss: 0.8853 - val_accuracy: 0.6520\n",
      "Epoch 18/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.2746 - accuracy: 0.8976 - val_loss: 1.2685 - val_accuracy: 0.5982\n",
      "Epoch 19/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.2590 - accuracy: 0.9034 - val_loss: 0.5820 - val_accuracy: 0.7974\n",
      "Epoch 20/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.2488 - accuracy: 0.9094 - val_loss: 0.3071 - val_accuracy: 0.8860\n",
      "Epoch 21/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.2319 - accuracy: 0.9135 - val_loss: 0.4267 - val_accuracy: 0.8607\n",
      "Epoch 22/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 0.2127 - accuracy: 0.9217 - val_loss: 2.1867 - val_accuracy: 0.5298\n",
      "Epoch 23/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.1989 - accuracy: 0.9269 - val_loss: 0.7112 - val_accuracy: 0.7497\n",
      "Epoch 24/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.1926 - accuracy: 0.9323 - val_loss: 0.9084 - val_accuracy: 0.8035\n",
      "Epoch 25/100\n",
      "985/985 [==============================] - 45s 45ms/step - loss: 0.2650 - accuracy: 0.9097 - val_loss: 0.3831 - val_accuracy: 0.8591\n",
      "Epoch 26/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.2125 - accuracy: 0.9227 - val_loss: 0.9815 - val_accuracy: 0.7467\n",
      "Epoch 27/100\n",
      "985/985 [==============================] - 42s 42ms/step - loss: 0.1519 - accuracy: 0.9432 - val_loss: 0.5763 - val_accuracy: 0.8133\n",
      "Epoch 28/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.1356 - accuracy: 0.9498 - val_loss: 0.4765 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.1256 - accuracy: 0.9534 - val_loss: 0.5658 - val_accuracy: 0.8074\n",
      "Epoch 30/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.4376 - accuracy: 0.8459 - val_loss: 0.4088 - val_accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "985/985 [==============================] - 48s 48ms/step - loss: 0.3390 - accuracy: 0.8804 - val_loss: 0.4156 - val_accuracy: 0.8545\n",
      "Epoch 32/100\n",
      "985/985 [==============================] - 43s 44ms/step - loss: 0.2018 - accuracy: 0.9278 - val_loss: 0.3483 - val_accuracy: 0.8831\n",
      "Epoch 33/100\n",
      "985/985 [==============================] - 44s 44ms/step - loss: 0.1424 - accuracy: 0.9481 - val_loss: 0.3749 - val_accuracy: 0.8866\n",
      "Epoch 34/100\n",
      "985/985 [==============================] - 43s 44ms/step - loss: 0.2030 - accuracy: 0.9265 - val_loss: 0.8911 - val_accuracy: 0.7918\n",
      "Epoch 35/100\n",
      "985/985 [==============================] - 41s 41ms/step - loss: 0.2460 - accuracy: 0.9221 - val_loss: 0.3260 - val_accuracy: 0.8973\n",
      "Epoch 36/100\n",
      "985/985 [==============================] - 46s 46ms/step - loss: 0.1345 - accuracy: 0.9516 - val_loss: 0.4729 - val_accuracy: 0.8466\n",
      "Epoch 37/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.1116 - accuracy: 0.9584 - val_loss: 0.4887 - val_accuracy: 0.8606\n",
      "Epoch 38/100\n",
      "985/985 [==============================] - 60s 61ms/step - loss: 0.1053 - accuracy: 0.9616 - val_loss: 0.3312 - val_accuracy: 0.8996\n",
      "Epoch 39/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.1031 - accuracy: 0.9623 - val_loss: 1.0778 - val_accuracy: 0.7069\n",
      "Epoch 40/100\n",
      "985/985 [==============================] - 55s 55ms/step - loss: 0.0958 - accuracy: 0.9643 - val_loss: 1.1777 - val_accuracy: 0.7430\n",
      "Epoch 41/100\n",
      "985/985 [==============================] - 60s 61ms/step - loss: 0.0900 - accuracy: 0.9669 - val_loss: 0.6373 - val_accuracy: 0.8172\n",
      "Epoch 42/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.0895 - accuracy: 0.9673 - val_loss: 0.7052 - val_accuracy: 0.8428\n",
      "Epoch 43/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.0838 - accuracy: 0.9694 - val_loss: 1.0239 - val_accuracy: 0.7959\n",
      "Epoch 44/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.1027 - accuracy: 0.9672 - val_loss: 1.5935 - val_accuracy: 0.7362\n",
      "Epoch 45/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.0724 - accuracy: 0.9753 - val_loss: 0.6646 - val_accuracy: 0.8502\n",
      "Epoch 46/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.0635 - accuracy: 0.9777 - val_loss: 0.5024 - val_accuracy: 0.8803\n",
      "Epoch 47/100\n",
      "985/985 [==============================] - 58s 58ms/step - loss: 0.0686 - accuracy: 0.9750 - val_loss: 2.1208 - val_accuracy: 0.6379\n",
      "Epoch 48/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.0591 - accuracy: 0.9797 - val_loss: 1.0601 - val_accuracy: 0.7823\n",
      "Epoch 49/100\n",
      "138/985 [===>..........................] - ETA: 35s - loss: 0.0343 - accuracy: 0.9900"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m ne_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mne_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(32,32,3), pooling=\"avg\")\n",
    "x =  Dense(500)(base_model.output)\n",
    "output = Dense(5, activation='softmax')(x)\n",
    "ne_model = Model(inputs=base_model.input, outputs=output)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, mode='max', verbose=1)\n",
    "ne_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = ne_model.fit(X_train, y_train, batch_size=32, epochs=100,validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388753c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d77dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7316676823075361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = ne_model.predict(np.array(X_test).astype('float32'))\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ccc94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76349b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = MobileNetV2(include_top=False, weights=None, input_shape=(32,32,3), pooling=\"avg\")\n",
    "x =  Dense(500)(base_model.output)\n",
    "output = Dense(5, activation='softmax')(x) \n",
    "new_model = Model(inputs=base_model.input, outputs=output)\n",
    "new_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d64a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = new_model.predict(np.array(X_test).astype('float32'))\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a46cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b14ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49d284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8f928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c63c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552da65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
