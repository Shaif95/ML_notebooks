{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0f0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "invasive_dirs = [\n",
    "    r'E:\\VeligerData\\invasive',\n",
    "    r'E:\\VeligerData\\Baylor 2022-03-21_2\\Veligers',\n",
    "    r'E:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Pedi-Zebra Veligers',\n",
    "    r'E:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1a To Baylor\\Preserved Zebra Ped 1a To Baylor\\Sorted Images\\Preserved Zebra Ped 1a',    \n",
    "    r'E:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Zebra Pediveliger Image1a\\Zebra Pediveligers',\n",
    "    r'E:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal',\n",
    "    r'E:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Umbonal',\n",
    "    r'E:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Zebra D-Hinge',\n",
    "  ]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'E:\\VeligerData\\noninvasive',\n",
    "    r'E:\\VeligerData\\Baylor 2022-03-21_2\\NonVeligers\\Images_001',\n",
    "    r'E:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'E:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1a To Baylor\\Preserved Zebra Ped 1a To Baylor\\Sorted Images\\Not',  \n",
    "    r'E:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'E:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Not',\n",
    "    r'E:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Not',\n",
    "   ]\n",
    "\n",
    "# Ostracod category\n",
    "ostracod_dirs = [\n",
    "    r'E:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Ostracods',\n",
    "    r'E:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Ostracod Image1\\Ostracods1',\n",
    "    r'E:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Ostracod',\n",
    "    r'E:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'E:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Preserve Ostracods',\n",
    "    r'E:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Preserved Ostracods 1a',\n",
    "    r'E:\\VeligerData\\Ostracods Day 2 Image3 To Baylor_2\\Ostracods Day 2 Image3 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'E:\\VeligerData\\Ostracods Day 2 Image12 To Baylor_3\\Ostracods Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',  \n",
    "]\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "ostracod_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    \n",
    "for ostracod_dir in ostracod_dirs:\n",
    "    ostracod_subdirs.extend(glob.glob(ostracod_dir))\n",
    "    \n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n",
    "\n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n",
    "\n",
    "    \n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = ostracod_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y3 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y3.extend(subdirectories)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4d41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf57a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228e004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: E:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods\\Object_002\\._Image_032.png. Skipping...\n",
      "Error processing image: E:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods\\Object_002\\._Image_036.png. Skipping...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(40, 40)):\n",
    "    # List to store image files\n",
    "    image_files = []\n",
    "    # List to store labels\n",
    "    labels = []\n",
    "\n",
    "    # Retrieve image files and create labels for each directory in y1\n",
    "    for directory in y1:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    # Add the file path to the image_files list\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                    # Add the label to the labels list\n",
    "                    \n",
    "\n",
    "    # List to store preprocessed images\n",
    "    images = []\n",
    "\n",
    "    # Preprocess each image\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            # Read the image using PIL\n",
    "            image = Image.open(file)\n",
    "            # Resize the image using tf.image.resize_with_crop_or_pad()\n",
    "            image = tf.image.resize_with_crop_or_pad(\n",
    "                tf.keras.preprocessing.image.img_to_array(image),\n",
    "                target_size[0],\n",
    "                target_size[1]\n",
    "            )\n",
    "            # Normalize the image pixels for ML training\n",
    "            image = image / 255.0\n",
    "            # Add the preprocessed image to the images list\n",
    "            images.append(image)\n",
    "            labels.append(label_num)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "    # Convert the images and labels lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "X0,Y0 = preprocess_images(y1, label_num = 0)\n",
    "X1,Y1 = preprocess_images(y2, label_num = 1)\n",
    "X2,Y2 = preprocess_images(y3, label_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f73b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1, X2), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1, Y2), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "# Now the shuffled data is assigned to the same variable names\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485149fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167761, 40, 40, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d57838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f13ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 38, 38, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 19, 19, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 17, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 16)          4624      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,379\n",
      "Trainable params: 52,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(40, 40, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(16, (3, 3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(10))\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240d76e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [ 0.44741921  1.47039785 11.78250591]\n"
     ]
    }
   ],
   "source": [
    "class_weights = np.zeros(3)\n",
    "\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "total_samples = np.sum(counts)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    class_weights[label] = total_samples / (len(unique_labels) * counts[i])\n",
    "\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f16b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28aad665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4719/4719 [==============================] - 41s 6ms/step - loss: 0.2008 - accuracy: 0.9271 - val_loss: 0.1518 - val_accuracy: 0.9472\n",
      "Epoch 2/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.1578 - accuracy: 0.9427 - val_loss: 0.1435 - val_accuracy: 0.9487\n",
      "Epoch 3/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.1454 - accuracy: 0.9477 - val_loss: 0.1465 - val_accuracy: 0.9470\n",
      "Epoch 4/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.1353 - accuracy: 0.9506 - val_loss: 0.1289 - val_accuracy: 0.9526\n",
      "Epoch 5/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.1315 - accuracy: 0.9526 - val_loss: 0.1225 - val_accuracy: 0.9573\n",
      "Epoch 6/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.1264 - accuracy: 0.9543 - val_loss: 0.1290 - val_accuracy: 0.9526\n",
      "Epoch 7/100\n",
      "4719/4719 [==============================] - 35s 7ms/step - loss: 0.1225 - accuracy: 0.9552 - val_loss: 0.1637 - val_accuracy: 0.9418\n",
      "Epoch 8/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.1183 - accuracy: 0.9570 - val_loss: 0.1627 - val_accuracy: 0.9427\n",
      "Epoch 9/100\n",
      "4719/4719 [==============================] - 34s 7ms/step - loss: 0.1152 - accuracy: 0.9585 - val_loss: 0.1178 - val_accuracy: 0.9582\n",
      "Epoch 10/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.1132 - accuracy: 0.9586 - val_loss: 0.1157 - val_accuracy: 0.9593\n",
      "Epoch 11/100\n",
      "4719/4719 [==============================] - 31s 7ms/step - loss: 0.1121 - accuracy: 0.9594 - val_loss: 0.1171 - val_accuracy: 0.9588\n",
      "Epoch 12/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.1096 - accuracy: 0.9600 - val_loss: 0.1178 - val_accuracy: 0.9582\n",
      "Epoch 13/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.1072 - accuracy: 0.9611 - val_loss: 0.1119 - val_accuracy: 0.9597\n",
      "Epoch 14/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.1063 - accuracy: 0.9608 - val_loss: 0.1179 - val_accuracy: 0.9598\n",
      "Epoch 15/100\n",
      "4719/4719 [==============================] - 37s 8ms/step - loss: 0.1032 - accuracy: 0.9625 - val_loss: 0.1127 - val_accuracy: 0.9579\n",
      "Epoch 16/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.1020 - accuracy: 0.9626 - val_loss: 0.1195 - val_accuracy: 0.9592\n",
      "Epoch 17/100\n",
      "4719/4719 [==============================] - 31s 7ms/step - loss: 0.1006 - accuracy: 0.9634 - val_loss: 0.1130 - val_accuracy: 0.9595\n",
      "Epoch 18/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0996 - accuracy: 0.9637 - val_loss: 0.1072 - val_accuracy: 0.9611\n",
      "Epoch 19/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0984 - accuracy: 0.9640 - val_loss: 0.1102 - val_accuracy: 0.9602\n",
      "Epoch 20/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0966 - accuracy: 0.9645 - val_loss: 0.1129 - val_accuracy: 0.9608\n",
      "Epoch 21/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0961 - accuracy: 0.9644 - val_loss: 0.1093 - val_accuracy: 0.9613\n",
      "Epoch 22/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0943 - accuracy: 0.9659 - val_loss: 0.1061 - val_accuracy: 0.9632\n",
      "Epoch 23/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0931 - accuracy: 0.9663 - val_loss: 0.1062 - val_accuracy: 0.9619\n",
      "Epoch 24/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.0920 - accuracy: 0.9659 - val_loss: 0.1137 - val_accuracy: 0.9594\n",
      "Epoch 25/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0920 - accuracy: 0.9665 - val_loss: 0.1071 - val_accuracy: 0.9618\n",
      "Epoch 26/100\n",
      "4719/4719 [==============================] - 31s 6ms/step - loss: 0.0914 - accuracy: 0.9664 - val_loss: 0.1294 - val_accuracy: 0.9532\n",
      "Epoch 27/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.0899 - accuracy: 0.9670 - val_loss: 0.1154 - val_accuracy: 0.9596\n",
      "Epoch 28/100\n",
      "4719/4719 [==============================] - 27s 6ms/step - loss: 0.0890 - accuracy: 0.9672 - val_loss: 0.1232 - val_accuracy: 0.9571\n",
      "Epoch 29/100\n",
      "4719/4719 [==============================] - 26s 5ms/step - loss: 0.0880 - accuracy: 0.9676 - val_loss: 0.1125 - val_accuracy: 0.9609\n",
      "Epoch 30/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0882 - accuracy: 0.9675 - val_loss: 0.1125 - val_accuracy: 0.9610\n",
      "Epoch 31/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.0876 - accuracy: 0.9677 - val_loss: 0.1182 - val_accuracy: 0.9610\n",
      "Epoch 32/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0859 - accuracy: 0.9687 - val_loss: 0.1128 - val_accuracy: 0.9615\n",
      "Epoch 33/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0861 - accuracy: 0.9681 - val_loss: 0.1104 - val_accuracy: 0.9616\n",
      "Epoch 34/100\n",
      "4719/4719 [==============================] - 27s 6ms/step - loss: 0.0852 - accuracy: 0.9691 - val_loss: 0.1123 - val_accuracy: 0.9595\n",
      "Epoch 35/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.0852 - accuracy: 0.9688 - val_loss: 0.1225 - val_accuracy: 0.9560\n",
      "Epoch 36/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0834 - accuracy: 0.9693 - val_loss: 0.1149 - val_accuracy: 0.9598\n",
      "Epoch 37/100\n",
      "4719/4719 [==============================] - 31s 7ms/step - loss: 0.0833 - accuracy: 0.9692 - val_loss: 0.1182 - val_accuracy: 0.9593\n",
      "Epoch 38/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.0830 - accuracy: 0.9696 - val_loss: 0.1081 - val_accuracy: 0.9622\n",
      "Epoch 39/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0826 - accuracy: 0.9695 - val_loss: 0.1261 - val_accuracy: 0.9565\n",
      "Epoch 40/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0819 - accuracy: 0.9697 - val_loss: 0.1286 - val_accuracy: 0.9554\n",
      "Epoch 41/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0814 - accuracy: 0.9700 - val_loss: 0.1145 - val_accuracy: 0.9592\n",
      "Epoch 42/100\n",
      "4719/4719 [==============================] - 26s 6ms/step - loss: 0.0803 - accuracy: 0.9700 - val_loss: 0.1137 - val_accuracy: 0.9600\n",
      "Epoch 43/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0810 - accuracy: 0.9704 - val_loss: 0.1122 - val_accuracy: 0.9589\n",
      "Epoch 44/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0791 - accuracy: 0.9709 - val_loss: 0.1153 - val_accuracy: 0.9591\n",
      "Epoch 45/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0791 - accuracy: 0.9708 - val_loss: 0.1186 - val_accuracy: 0.9589\n",
      "Epoch 46/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.0786 - accuracy: 0.9713 - val_loss: 0.1118 - val_accuracy: 0.9630\n",
      "Epoch 47/100\n",
      "4719/4719 [==============================] - 31s 7ms/step - loss: 0.0780 - accuracy: 0.9713 - val_loss: 0.1252 - val_accuracy: 0.9571\n",
      "Epoch 48/100\n",
      "4719/4719 [==============================] - 27s 6ms/step - loss: 0.0780 - accuracy: 0.9711 - val_loss: 0.1102 - val_accuracy: 0.9617\n",
      "Epoch 49/100\n",
      "4719/4719 [==============================] - 26s 6ms/step - loss: 0.0773 - accuracy: 0.9712 - val_loss: 0.1296 - val_accuracy: 0.9561\n",
      "Epoch 50/100\n",
      "4719/4719 [==============================] - 26s 6ms/step - loss: 0.0773 - accuracy: 0.9718 - val_loss: 0.1126 - val_accuracy: 0.9606\n",
      "Epoch 51/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.0764 - accuracy: 0.9719 - val_loss: 0.1251 - val_accuracy: 0.9583\n",
      "Epoch 52/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0766 - accuracy: 0.9715 - val_loss: 0.1182 - val_accuracy: 0.9598\n",
      "Epoch 53/100\n",
      "4719/4719 [==============================] - 31s 7ms/step - loss: 0.0760 - accuracy: 0.9718 - val_loss: 0.1220 - val_accuracy: 0.9585\n",
      "Epoch 54/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0752 - accuracy: 0.9723 - val_loss: 0.1134 - val_accuracy: 0.9617\n",
      "Epoch 55/100\n",
      "4719/4719 [==============================] - 35s 7ms/step - loss: 0.0747 - accuracy: 0.9728 - val_loss: 0.1313 - val_accuracy: 0.9564\n",
      "Epoch 56/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0746 - accuracy: 0.9723 - val_loss: 0.1132 - val_accuracy: 0.9599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0743 - accuracy: 0.9727 - val_loss: 0.1211 - val_accuracy: 0.9596\n",
      "Epoch 58/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0736 - accuracy: 0.9730 - val_loss: 0.1080 - val_accuracy: 0.9614\n",
      "Epoch 59/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.0736 - accuracy: 0.9728 - val_loss: 0.1236 - val_accuracy: 0.9596\n",
      "Epoch 60/100\n",
      "4719/4719 [==============================] - 27s 6ms/step - loss: 0.0728 - accuracy: 0.9731 - val_loss: 0.1246 - val_accuracy: 0.9636\n",
      "Epoch 61/100\n",
      "4719/4719 [==============================] - 37s 8ms/step - loss: 0.0732 - accuracy: 0.9730 - val_loss: 0.1327 - val_accuracy: 0.9587\n",
      "Epoch 62/100\n",
      "4719/4719 [==============================] - 35s 7ms/step - loss: 0.0727 - accuracy: 0.9730 - val_loss: 0.1204 - val_accuracy: 0.9610\n",
      "Epoch 63/100\n",
      "4719/4719 [==============================] - 31s 7ms/step - loss: 0.0726 - accuracy: 0.9728 - val_loss: 0.1122 - val_accuracy: 0.9600\n",
      "Epoch 64/100\n",
      "4719/4719 [==============================] - 31s 7ms/step - loss: 0.0720 - accuracy: 0.9729 - val_loss: 0.1207 - val_accuracy: 0.9601\n",
      "Epoch 65/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0717 - accuracy: 0.9733 - val_loss: 0.1149 - val_accuracy: 0.9612\n",
      "Epoch 66/100\n",
      "4719/4719 [==============================] - 38s 8ms/step - loss: 0.0703 - accuracy: 0.9738 - val_loss: 0.1334 - val_accuracy: 0.9597\n",
      "Epoch 67/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0713 - accuracy: 0.9738 - val_loss: 0.1165 - val_accuracy: 0.9599\n",
      "Epoch 68/100\n",
      "4719/4719 [==============================] - 19s 4ms/step - loss: 0.0709 - accuracy: 0.9738 - val_loss: 0.1380 - val_accuracy: 0.9560\n",
      "Epoch 69/100\n",
      "4719/4719 [==============================] - 25s 5ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 0.1497 - val_accuracy: 0.9529\n",
      "Epoch 70/100\n",
      "4719/4719 [==============================] - 39s 8ms/step - loss: 0.0700 - accuracy: 0.9740 - val_loss: 0.1145 - val_accuracy: 0.9598\n",
      "Epoch 71/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0695 - accuracy: 0.9743 - val_loss: 0.1202 - val_accuracy: 0.9616\n",
      "Epoch 72/100\n",
      "4719/4719 [==============================] - 35s 7ms/step - loss: 0.0695 - accuracy: 0.9743 - val_loss: 0.1223 - val_accuracy: 0.9570\n",
      "Epoch 73/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.0693 - accuracy: 0.9745 - val_loss: 0.1258 - val_accuracy: 0.9601\n",
      "Epoch 74/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.0683 - accuracy: 0.9752 - val_loss: 0.1174 - val_accuracy: 0.9618\n",
      "Epoch 75/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0683 - accuracy: 0.9745 - val_loss: 0.1231 - val_accuracy: 0.9585\n",
      "Epoch 76/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0681 - accuracy: 0.9747 - val_loss: 0.1190 - val_accuracy: 0.9616\n",
      "Epoch 77/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.0688 - accuracy: 0.9747 - val_loss: 0.1146 - val_accuracy: 0.9613\n",
      "Epoch 78/100\n",
      "4719/4719 [==============================] - 43s 9ms/step - loss: 0.0677 - accuracy: 0.9745 - val_loss: 0.1537 - val_accuracy: 0.9551\n",
      "Epoch 79/100\n",
      "4719/4719 [==============================] - 37s 8ms/step - loss: 0.0672 - accuracy: 0.9752 - val_loss: 0.1276 - val_accuracy: 0.9586\n",
      "Epoch 80/100\n",
      "4719/4719 [==============================] - 38s 8ms/step - loss: 0.0675 - accuracy: 0.9749 - val_loss: 0.1266 - val_accuracy: 0.9619\n",
      "Epoch 81/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0661 - accuracy: 0.9754 - val_loss: 0.1312 - val_accuracy: 0.9569\n",
      "Epoch 82/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.0661 - accuracy: 0.9754 - val_loss: 0.1192 - val_accuracy: 0.9603\n",
      "Epoch 83/100\n",
      "4719/4719 [==============================] - 26s 6ms/step - loss: 0.0664 - accuracy: 0.9757 - val_loss: 0.1383 - val_accuracy: 0.9593\n",
      "Epoch 84/100\n",
      "4719/4719 [==============================] - 27s 6ms/step - loss: 0.0663 - accuracy: 0.9753 - val_loss: 0.1445 - val_accuracy: 0.9572\n",
      "Epoch 85/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0659 - accuracy: 0.9756 - val_loss: 0.1455 - val_accuracy: 0.9562\n",
      "Epoch 86/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.0659 - accuracy: 0.9757 - val_loss: 0.1437 - val_accuracy: 0.9551\n",
      "Epoch 87/100\n",
      "4719/4719 [==============================] - 32s 7ms/step - loss: 0.0655 - accuracy: 0.9756 - val_loss: 0.1337 - val_accuracy: 0.9607\n",
      "Epoch 88/100\n",
      "4719/4719 [==============================] - 35s 7ms/step - loss: 0.0659 - accuracy: 0.9754 - val_loss: 0.1225 - val_accuracy: 0.9587\n",
      "Epoch 89/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0649 - accuracy: 0.9763 - val_loss: 0.1348 - val_accuracy: 0.9594\n",
      "Epoch 90/100\n",
      "4719/4719 [==============================] - 30s 6ms/step - loss: 0.0651 - accuracy: 0.9761 - val_loss: 0.1360 - val_accuracy: 0.9551\n",
      "Epoch 91/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0653 - accuracy: 0.9757 - val_loss: 0.1265 - val_accuracy: 0.9595\n",
      "Epoch 92/100\n",
      "4719/4719 [==============================] - 33s 7ms/step - loss: 0.0646 - accuracy: 0.9760 - val_loss: 0.1379 - val_accuracy: 0.9600\n",
      "Epoch 93/100\n",
      "4719/4719 [==============================] - 31s 7ms/step - loss: 0.0638 - accuracy: 0.9762 - val_loss: 0.1187 - val_accuracy: 0.9608\n",
      "Epoch 94/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0637 - accuracy: 0.9763 - val_loss: 0.1334 - val_accuracy: 0.9598\n",
      "Epoch 95/100\n",
      "4719/4719 [==============================] - 28s 6ms/step - loss: 0.0631 - accuracy: 0.9766 - val_loss: 0.1393 - val_accuracy: 0.9527\n",
      "Epoch 96/100\n",
      "4719/4719 [==============================] - 27s 6ms/step - loss: 0.0640 - accuracy: 0.9760 - val_loss: 0.1258 - val_accuracy: 0.9597\n",
      "Epoch 97/100\n",
      "4719/4719 [==============================] - 29s 6ms/step - loss: 0.0641 - accuracy: 0.9758 - val_loss: 0.1205 - val_accuracy: 0.9605\n",
      "Epoch 98/100\n",
      "4719/4719 [==============================] - 27s 6ms/step - loss: 0.0632 - accuracy: 0.9769 - val_loss: 0.1379 - val_accuracy: 0.9575\n",
      "Epoch 99/100\n",
      "4719/4719 [==============================] - 26s 6ms/step - loss: 0.0635 - accuracy: 0.9762 - val_loss: 0.1322 - val_accuracy: 0.9590\n",
      "Epoch 100/100\n",
      "4719/4719 [==============================] - 27s 6ms/step - loss: 0.0627 - accuracy: 0.9764 - val_loss: 0.1414 - val_accuracy: 0.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e4426487c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "class_weights = [1,1,1]\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87928d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming you have a Keras model named \"model\"\n",
    "model.save(\"full_single_image.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d0ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6ecc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fadf0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the path to the model file\n",
    "model_path = r'E:\\ML_notebooks\\premodel.h5'\n",
    "\n",
    "# Load the model with custom_objects argument\n",
    "#model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944258e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7cef385",
   "metadata": {},
   "outputs": [],
   "source": [
    "invasive_dirs = [\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Zebra Pediveliger Image1a\\Zebra Pediveligers',\n",
    "]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Not Veligers\\Z-P',\n",
    "]\n",
    "\n",
    "# Ostracod category\n",
    "ostracod_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "  ]\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "ostracod_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    \n",
    "for ostracod_dir in ostracod_dirs:\n",
    "    ostracod_subdirs.extend(glob.glob(ostracod_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc1ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82d08ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods\\Object_002\\._Image_032.png. Skipping...\n",
      "Error processing image: D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods\\Object_002\\._Image_036.png. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n",
    "\n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n",
    "\n",
    "    \n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = ostracod_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y3 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y3.extend(subdirectories)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(40, 40)):\n",
    "    # List to store image files\n",
    "    image_files = []\n",
    "    # List to store labels\n",
    "    labels = []\n",
    "\n",
    "    # Retrieve image files and create labels for each directory in y1\n",
    "    for directory in y1:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    # Add the file path to the image_files list\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                    # Add the label to the labels list\n",
    "                    \n",
    "\n",
    "    # List to store preprocessed images\n",
    "    images = []\n",
    "\n",
    "    # Preprocess each image\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            # Read the image using PIL\n",
    "            image = Image.open(file)\n",
    "            # Resize the image using tf.image.resize_with_crop_or_pad()\n",
    "            image = tf.image.resize_with_crop_or_pad(\n",
    "                tf.keras.preprocessing.image.img_to_array(image),\n",
    "                target_size[0],\n",
    "                target_size[1]\n",
    "            )\n",
    "            # Normalize the image pixels for ML training\n",
    "            image = image / 255.0\n",
    "            # Add the preprocessed image to the images list\n",
    "            images.append(image)\n",
    "            labels.append(label_num)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "    # Convert the images and labels lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "X0,Y0 = preprocess_images(y1, label_num = 0)\n",
    "X1,Y1 = preprocess_images(y2, label_num = 1)\n",
    "X2,Y2 = preprocess_images(y3, label_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23670c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef91f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1, X2), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1, Y2), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming you have the original train_images and train_labels_categorical\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "# Now the shuffled data is assigned to the same variable names\n",
    "\n",
    "X_train, X_test1, Y_train, Y_test1 = train_test_split(train_images, train_labels_categorical, test_size=0.01, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde28d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65ac6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming you have a Keras model named \"model\"\n",
    "model.save(\"premodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f396a53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62657, 40, 40, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b9c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a10bb4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [0.51307619 1.11912719 6.35250427]\n"
     ]
    }
   ],
   "source": [
    "class_weights = np.zeros(3)\n",
    "\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "total_samples = np.sum(counts)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    class_weights[label] = total_samples / (len(unique_labels) * counts[i])\n",
    "\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a28019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b47e44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1763/1763 [==============================] - 19s 11ms/step - loss: 0.3414 - accuracy: 0.8741 - val_loss: 0.3145 - val_accuracy: 0.8726\n",
      "Epoch 2/50\n",
      "1763/1763 [==============================] - 18s 10ms/step - loss: 0.2565 - accuracy: 0.8975 - val_loss: 0.2602 - val_accuracy: 0.8974\n",
      "Epoch 3/50\n",
      "1763/1763 [==============================] - 19s 11ms/step - loss: 0.2364 - accuracy: 0.9075 - val_loss: 0.2490 - val_accuracy: 0.8995\n",
      "Epoch 4/50\n",
      "1763/1763 [==============================] - 15s 9ms/step - loss: 0.2257 - accuracy: 0.9107 - val_loss: 0.2619 - val_accuracy: 0.8974\n",
      "Epoch 5/50\n",
      "1763/1763 [==============================] - 17s 10ms/step - loss: 0.2126 - accuracy: 0.9161 - val_loss: 0.2389 - val_accuracy: 0.9055\n",
      "Epoch 6/50\n",
      "1763/1763 [==============================] - 17s 9ms/step - loss: 0.2043 - accuracy: 0.9189 - val_loss: 0.2602 - val_accuracy: 0.9015\n",
      "Epoch 7/50\n",
      "1763/1763 [==============================] - 18s 10ms/step - loss: 0.1962 - accuracy: 0.9217 - val_loss: 0.3115 - val_accuracy: 0.8832\n",
      "Epoch 8/50\n",
      "1763/1763 [==============================] - 18s 10ms/step - loss: 0.1907 - accuracy: 0.9248 - val_loss: 0.2224 - val_accuracy: 0.9138\n",
      "Epoch 9/50\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 0.1862 - accuracy: 0.9270 - val_loss: 0.2138 - val_accuracy: 0.9188\n",
      "Epoch 10/50\n",
      "1763/1763 [==============================] - 12s 7ms/step - loss: 0.1811 - accuracy: 0.9284 - val_loss: 0.2257 - val_accuracy: 0.9116\n",
      "Epoch 11/50\n",
      "1763/1763 [==============================] - 12s 7ms/step - loss: 0.1776 - accuracy: 0.9296 - val_loss: 0.2275 - val_accuracy: 0.9143\n",
      "Epoch 12/50\n",
      "1763/1763 [==============================] - 12s 7ms/step - loss: 0.1737 - accuracy: 0.9314 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
      "Epoch 13/50\n",
      "1763/1763 [==============================] - 11s 6ms/step - loss: 0.1693 - accuracy: 0.9328 - val_loss: 0.2519 - val_accuracy: 0.9052\n",
      "Epoch 14/50\n",
      "1763/1763 [==============================] - 13s 8ms/step - loss: 0.1680 - accuracy: 0.9337 - val_loss: 0.2253 - val_accuracy: 0.9157\n",
      "Epoch 15/50\n",
      "1763/1763 [==============================] - 11s 6ms/step - loss: 0.1662 - accuracy: 0.9356 - val_loss: 0.2106 - val_accuracy: 0.9192\n",
      "Epoch 16/50\n",
      "1763/1763 [==============================] - 11s 6ms/step - loss: 0.1632 - accuracy: 0.9353 - val_loss: 0.2229 - val_accuracy: 0.9138\n",
      "Epoch 17/50\n",
      "1763/1763 [==============================] - 12s 7ms/step - loss: 0.1599 - accuracy: 0.9374 - val_loss: 0.2239 - val_accuracy: 0.9138\n",
      "Epoch 18/50\n",
      "1763/1763 [==============================] - 13s 7ms/step - loss: 0.1589 - accuracy: 0.9382 - val_loss: 0.2229 - val_accuracy: 0.9135\n",
      "Epoch 19/50\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 0.1568 - accuracy: 0.9387 - val_loss: 0.2170 - val_accuracy: 0.9172\n",
      "Epoch 20/50\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 0.1541 - accuracy: 0.9397 - val_loss: 0.2197 - val_accuracy: 0.9159\n",
      "Epoch 21/50\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 0.1546 - accuracy: 0.9393 - val_loss: 0.2080 - val_accuracy: 0.9186\n",
      "Epoch 22/50\n",
      "1763/1763 [==============================] - 13s 7ms/step - loss: 0.1503 - accuracy: 0.9406 - val_loss: 0.2224 - val_accuracy: 0.9183\n",
      "Epoch 23/50\n",
      "1763/1763 [==============================] - 18s 10ms/step - loss: 0.1520 - accuracy: 0.9402 - val_loss: 0.2229 - val_accuracy: 0.9213\n",
      "Epoch 24/50\n",
      "1763/1763 [==============================] - 19s 11ms/step - loss: 0.1481 - accuracy: 0.9428 - val_loss: 0.2084 - val_accuracy: 0.9199\n",
      "Epoch 25/50\n",
      "1763/1763 [==============================] - 15s 8ms/step - loss: 0.1482 - accuracy: 0.9419 - val_loss: 0.2376 - val_accuracy: 0.9181\n",
      "Epoch 26/50\n",
      "1763/1763 [==============================] - 10s 6ms/step - loss: 0.1452 - accuracy: 0.9433 - val_loss: 0.2206 - val_accuracy: 0.9170\n",
      "Epoch 27/50\n",
      "1763/1763 [==============================] - 11s 6ms/step - loss: 0.1441 - accuracy: 0.9436 - val_loss: 0.2330 - val_accuracy: 0.9162\n",
      "Epoch 28/50\n",
      "1763/1763 [==============================] - 16s 9ms/step - loss: 0.1410 - accuracy: 0.9445 - val_loss: 0.2292 - val_accuracy: 0.9180\n",
      "Epoch 29/50\n",
      "1763/1763 [==============================] - 15s 8ms/step - loss: 0.1427 - accuracy: 0.9439 - val_loss: 0.2510 - val_accuracy: 0.9106\n",
      "Epoch 30/50\n",
      "1763/1763 [==============================] - 17s 10ms/step - loss: 0.1403 - accuracy: 0.9453 - val_loss: 0.2159 - val_accuracy: 0.9212\n",
      "Epoch 31/50\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 0.1381 - accuracy: 0.9450 - val_loss: 0.2391 - val_accuracy: 0.9109\n",
      "Epoch 32/50\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 0.1382 - accuracy: 0.9458 - val_loss: 0.2175 - val_accuracy: 0.9210\n",
      "Epoch 33/50\n",
      "1763/1763 [==============================] - 17s 10ms/step - loss: 0.1354 - accuracy: 0.9476 - val_loss: 0.2331 - val_accuracy: 0.9208\n",
      "Epoch 34/50\n",
      "1763/1763 [==============================] - 21s 12ms/step - loss: 0.1325 - accuracy: 0.9484 - val_loss: 0.2584 - val_accuracy: 0.9156\n",
      "Epoch 35/50\n",
      "1763/1763 [==============================] - 19s 11ms/step - loss: 0.1357 - accuracy: 0.9462 - val_loss: 0.2644 - val_accuracy: 0.9086\n",
      "Epoch 36/50\n",
      "1763/1763 [==============================] - 21s 12ms/step - loss: 0.1328 - accuracy: 0.9490 - val_loss: 0.2132 - val_accuracy: 0.9215\n",
      "Epoch 37/50\n",
      "1763/1763 [==============================] - 13s 8ms/step - loss: 0.1301 - accuracy: 0.9490 - val_loss: 0.2286 - val_accuracy: 0.9175\n",
      "Epoch 38/50\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 0.1314 - accuracy: 0.9485 - val_loss: 0.2124 - val_accuracy: 0.9199\n",
      "Epoch 39/50\n",
      "1763/1763 [==============================] - 14s 8ms/step - loss: 0.1278 - accuracy: 0.9507 - val_loss: 0.2203 - val_accuracy: 0.9208\n",
      "Epoch 40/50\n",
      "1763/1763 [==============================] - 19s 10ms/step - loss: 0.1282 - accuracy: 0.9491 - val_loss: 0.2298 - val_accuracy: 0.9202\n",
      "Epoch 41/50\n",
      "1763/1763 [==============================] - 16s 9ms/step - loss: 0.1266 - accuracy: 0.9498 - val_loss: 0.2233 - val_accuracy: 0.9226\n",
      "Epoch 42/50\n",
      "1763/1763 [==============================] - 15s 8ms/step - loss: 0.1260 - accuracy: 0.9509 - val_loss: 0.2313 - val_accuracy: 0.9220\n",
      "Epoch 43/50\n",
      "1763/1763 [==============================] - 12s 7ms/step - loss: 0.1235 - accuracy: 0.9521 - val_loss: 0.2376 - val_accuracy: 0.9208\n",
      "Epoch 44/50\n",
      "1763/1763 [==============================] - 12s 7ms/step - loss: 0.1240 - accuracy: 0.9518 - val_loss: 0.2182 - val_accuracy: 0.9237\n",
      "Epoch 45/50\n",
      "1763/1763 [==============================] - 11s 6ms/step - loss: 0.1237 - accuracy: 0.9512 - val_loss: 0.2231 - val_accuracy: 0.9229\n",
      "Epoch 46/50\n",
      "1763/1763 [==============================] - 11s 6ms/step - loss: 0.1203 - accuracy: 0.9529 - val_loss: 0.2430 - val_accuracy: 0.9157\n",
      "Epoch 47/50\n",
      "1763/1763 [==============================] - 17s 10ms/step - loss: 0.1200 - accuracy: 0.9530 - val_loss: 0.2263 - val_accuracy: 0.9186\n",
      "Epoch 48/50\n",
      "1763/1763 [==============================] - 13s 7ms/step - loss: 0.1199 - accuracy: 0.9535 - val_loss: 0.2342 - val_accuracy: 0.9199\n",
      "Epoch 49/50\n",
      "1763/1763 [==============================] - 16s 9ms/step - loss: 0.1182 - accuracy: 0.9537 - val_loss: 0.2248 - val_accuracy: 0.9247\n",
      "Epoch 50/50\n",
      "1763/1763 [==============================] - 20s 12ms/step - loss: 0.1173 - accuracy: 0.9541 - val_loss: 0.2315 - val_accuracy: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1740c5d9910>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "class_weights = [1,1,1]\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebf030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d1e4030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "p = np.argmax(pred, axis=1)\n",
    "res = p\n",
    "        \n",
    "test = []\n",
    "for i in Y_test:\n",
    "    if(i[0]==1):\n",
    "        test.append(0)\n",
    "    elif(i[1]==1):\n",
    "        test.append(1)\n",
    "    else:\n",
    "        test.append(2)\n",
    "        \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(test,np.argmax(Y_test, axis=1))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9ca5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d18ca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c56058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image path\n",
    "from PIL import Image\n",
    "image_path = r\"D:\\VeligerData\\Baylor 2022-03-21_2\\Veligers\\Object_031\\Image_009.png\"\n",
    "# Read the image using PIL\n",
    "image = Image.open(image_path)\n",
    "# Define the target size for resizing\n",
    "target_size = (40, 40)\n",
    "# Resize the image using TensorFlow's resize_with_crop_or_pad function\n",
    "resized_image = tf.image.resize_with_crop_or_pad( tf.keras.preprocessing.image.img_to_array(image), target_size[0],   target_size[1]\n",
    ")\n",
    "# Expand the dimensions to match the model's input shape\n",
    "expanded_image = tf.expand_dims(resized_image, axis=0)\n",
    "# Evaluate the TensorFlow tensor and obtain the NumPy array\n",
    "resized_array = tf.keras.backend.eval(expanded_image)\n",
    "normalized_image = resized_array / 255.0\n",
    "x = model.predict(normalized_image)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3a4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2728b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming you have a Keras model named \"model\"\n",
    "model.save(\"single_image_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323db2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b43a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176ce90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40858074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83318ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959fa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e72d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3390b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851f28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce8676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e28fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685075ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cb231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530aff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d803ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f519a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03133f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd83d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ed44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22da3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00c417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2f255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
