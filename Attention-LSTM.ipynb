{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acba090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf0822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeab214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a504b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn1='D:/Inv_Data_Imbalance/data/invasive-aquatic-species-data/invasive/*/'\n",
    "trn2='D:/Inv_Data_Imbalance/data/invasive-aquatic-species-data/noninvasive/*/'\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)\n",
    "tr1= shuffle(tr1)\n",
    "tr2= shuffle(tr2)\n",
    "\n",
    "tran_index_inv = np.round( len(tr1)* .7 )\n",
    "tran_index_noninv = np.round( len(tr2)* .7  )\n",
    "tran_index_noninv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c51980",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[:(int) (tran_index_inv)]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[:(int) (tran_index_noninv)]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[:(int) (tran_index_inv)])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr2[:(int) (tran_index_noninv)])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((15, 15))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(15,15,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),15,15,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079c6d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3062, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "train_df= []\n",
    "breath = 6\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*6+k)\n",
    "        \n",
    "        deff.append(X_train[index])\n",
    "        \n",
    "    train_df.append(deff)\n",
    "\n",
    "Y_train = to_categorical(label)\n",
    "train_df = np.array(train_df)\n",
    "train_df,Y_train = shuffle(train_df,Y_train)\n",
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d262b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[(int) (tran_index_inv) + 1 :]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[ (int)(tran_index_noninv) + 1:]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[(int) (tran_index_inv) + 1 :])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr2[ (int)(tran_index_noninv) + 1:])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((15, 15))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(15,15,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),15,15,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661c2759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "test_df= []\n",
    "breath = 6\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*6+k)\n",
    "        \n",
    "        deff.append(X_test[index])\n",
    "        \n",
    "    test_df.append(deff)\n",
    "    \n",
    "Y_test = to_categorical(label)\n",
    "test_df = np.array(test_df)\n",
    "test_df,Y_test = shuffle(test_df,Y_test)\n",
    "np.shape(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "56c507ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3062, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "52b5cc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6123, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "new_train= []\n",
    "rand_df  = []\n",
    "\n",
    "new_y = []\n",
    "\n",
    "rand_y = []\n",
    "\n",
    "for i in range(1,len(train_df)):\n",
    "    \n",
    "    X = train_df[i]\n",
    "    res = np.take(X,np.random.permutation(X.shape[0]),axis=0,out=X)\n",
    "    rand_df.append(res)\n",
    "    rand_y.append(Y_train[i])\n",
    "    \n",
    "new_train = np.concatenate( [ train_df,rand_df ] , axis=0)\n",
    "new_y = np.concatenate( [ Y_train , rand_y ] )\n",
    "from sklearn.utils import shuffle\n",
    "X , Y = shuffle( new_train , new_y ) \n",
    "np.shape(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c674b1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6123, 2)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31947b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc77872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_20 (TimeDi  (None, 6, 13, 13, 32)    896       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_21 (TimeDi  (None, 6, 11, 11, 16)    4624      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 6, 9, 9, 8)       1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_23 (TimeDi  (None, 6, 7, 7, 4)       292       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_24 (TimeDi  (None, 6, 196)           0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 6, 10)             8280      \n",
      "                                                                 \n",
      " Attention (SeqSelfAttention  (None, 6, 10)            101       \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                1952      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,371\n",
      "Trainable params: 17,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "model= models.Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'),input_shape=(6, 15, 15, 3)))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(10,return_sequences=True,dropout=0.2)) # used 32 units\n",
    "model.add(SeqSelfAttention(attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,name='Attention'))\n",
    "\n",
    "model.add((Flatten()))\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8262812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_66 (TimeDi  (None, 6, 13, 13, 16)    448       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_67 (TimeDi  (None, 6, 6, 6, 16)      0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_68 (TimeDi  (None, 6, 4, 4, 8)       1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_69 (TimeDi  (None, 6, 2, 2, 8)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_70 (TimeDi  (None, 6, 32)            0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " patch_encoder_10 (PatchEnco  (None, 6, 64)            2496      \n",
      " der)                                                            \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 50)                23000     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                3264      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,498\n",
      "Trainable params: 30,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "model= models.Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), strides=(1,1),activation='relu'),input_shape=(6, 15, 15, 3)))\n",
    "model.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), strides=(1,1),activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(PatchEncoder(6, 64 )) \n",
    "\n",
    "model.add(LSTM(50,return_sequences=False,dropout=0.2)) # used 32 units \n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2676f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 5s 25ms/step - loss: 0.4491 - accuracy: 0.8387 - val_loss: 0.4022 - val_accuracy: 0.8418\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.2616 - accuracy: 0.8771 - val_loss: 0.2461 - val_accuracy: 0.8891\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.1913 - accuracy: 0.9122 - val_loss: 0.1882 - val_accuracy: 0.9021\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.1803 - accuracy: 0.9183 - val_loss: 0.1829 - val_accuracy: 0.9152\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.1897 - accuracy: 0.9106 - val_loss: 0.2577 - val_accuracy: 0.8940\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.1668 - accuracy: 0.9290 - val_loss: 0.2015 - val_accuracy: 0.9135\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.1637 - accuracy: 0.9281 - val_loss: 0.1737 - val_accuracy: 0.9119\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.1506 - accuracy: 0.9351 - val_loss: 0.1671 - val_accuracy: 0.9266\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.1519 - accuracy: 0.9318 - val_loss: 0.1804 - val_accuracy: 0.9184\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.1358 - accuracy: 0.9441 - val_loss: 0.1520 - val_accuracy: 0.9380\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.1315 - accuracy: 0.9502 - val_loss: 0.1820 - val_accuracy: 0.9315\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.1483 - accuracy: 0.9428 - val_loss: 0.1769 - val_accuracy: 0.9184\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.1213 - accuracy: 0.9530 - val_loss: 0.1533 - val_accuracy: 0.9396\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.1171 - accuracy: 0.9530 - val_loss: 0.2265 - val_accuracy: 0.8972\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.1256 - accuracy: 0.9465 - val_loss: 0.1417 - val_accuracy: 0.9364\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.1228 - accuracy: 0.9477 - val_loss: 0.1703 - val_accuracy: 0.9331\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.1225 - accuracy: 0.9506 - val_loss: 0.1409 - val_accuracy: 0.9413\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.1175 - accuracy: 0.9530 - val_loss: 0.1461 - val_accuracy: 0.9396\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.1100 - accuracy: 0.9551 - val_loss: 0.1318 - val_accuracy: 0.9511\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.1104 - accuracy: 0.9559 - val_loss: 0.1364 - val_accuracy: 0.9478\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.1030 - accuracy: 0.9579 - val_loss: 0.1582 - val_accuracy: 0.9331\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 0.1007 - accuracy: 0.9559 - val_loss: 0.1341 - val_accuracy: 0.9445\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0990 - accuracy: 0.9620 - val_loss: 0.1268 - val_accuracy: 0.9511\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.1011 - accuracy: 0.9551 - val_loss: 0.1932 - val_accuracy: 0.9250\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0955 - accuracy: 0.9592 - val_loss: 0.1295 - val_accuracy: 0.9494\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0989 - accuracy: 0.9567 - val_loss: 0.1183 - val_accuracy: 0.9543\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0900 - accuracy: 0.9633 - val_loss: 0.1319 - val_accuracy: 0.9543\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0927 - accuracy: 0.9612 - val_loss: 0.1135 - val_accuracy: 0.9527\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0977 - accuracy: 0.9612 - val_loss: 0.1326 - val_accuracy: 0.9494\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.1090 - accuracy: 0.9526 - val_loss: 0.1337 - val_accuracy: 0.9527\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0878 - accuracy: 0.9649 - val_loss: 0.1363 - val_accuracy: 0.9429\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0818 - accuracy: 0.9645 - val_loss: 0.1246 - val_accuracy: 0.9494\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0802 - accuracy: 0.9694 - val_loss: 0.1241 - val_accuracy: 0.9511\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0818 - accuracy: 0.9653 - val_loss: 0.1285 - val_accuracy: 0.9511\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0822 - accuracy: 0.9694 - val_loss: 0.1392 - val_accuracy: 0.9445\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0717 - accuracy: 0.9686 - val_loss: 0.1844 - val_accuracy: 0.9364\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 2s 32ms/step - loss: 0.0714 - accuracy: 0.9706 - val_loss: 0.1558 - val_accuracy: 0.9429\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0755 - accuracy: 0.9653 - val_loss: 0.1759 - val_accuracy: 0.9299\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0731 - accuracy: 0.9673 - val_loss: 0.1524 - val_accuracy: 0.9462\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0693 - accuracy: 0.9747 - val_loss: 0.1351 - val_accuracy: 0.9527\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0716 - accuracy: 0.9694 - val_loss: 0.1399 - val_accuracy: 0.9462\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0644 - accuracy: 0.9735 - val_loss: 0.1685 - val_accuracy: 0.9462\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0695 - accuracy: 0.9702 - val_loss: 0.1765 - val_accuracy: 0.9429\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0745 - accuracy: 0.9661 - val_loss: 0.1824 - val_accuracy: 0.9429\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 2s 31ms/step - loss: 0.0612 - accuracy: 0.9747 - val_loss: 0.1585 - val_accuracy: 0.9429\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0651 - accuracy: 0.9690 - val_loss: 0.1545 - val_accuracy: 0.9429\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 2s 31ms/step - loss: 0.0641 - accuracy: 0.9751 - val_loss: 0.1505 - val_accuracy: 0.9527\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0585 - accuracy: 0.9767 - val_loss: 0.1704 - val_accuracy: 0.9315\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0706 - accuracy: 0.9686 - val_loss: 0.1566 - val_accuracy: 0.9445\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0538 - accuracy: 0.9784 - val_loss: 0.2060 - val_accuracy: 0.9478\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0563 - accuracy: 0.9751 - val_loss: 0.1827 - val_accuracy: 0.9396\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0699 - accuracy: 0.9726 - val_loss: 0.1445 - val_accuracy: 0.9429\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0569 - accuracy: 0.9796 - val_loss: 0.1652 - val_accuracy: 0.9462\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0519 - accuracy: 0.9804 - val_loss: 0.1714 - val_accuracy: 0.9396\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0468 - accuracy: 0.9824 - val_loss: 0.1990 - val_accuracy: 0.9445\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0581 - accuracy: 0.9780 - val_loss: 0.1857 - val_accuracy: 0.9478\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0415 - accuracy: 0.9857 - val_loss: 0.2078 - val_accuracy: 0.9445\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0582 - accuracy: 0.9804 - val_loss: 0.1774 - val_accuracy: 0.9364\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0458 - accuracy: 0.9808 - val_loss: 0.2003 - val_accuracy: 0.9380\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0433 - accuracy: 0.9812 - val_loss: 0.2719 - val_accuracy: 0.9282\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0548 - accuracy: 0.9775 - val_loss: 0.2023 - val_accuracy: 0.9429\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0388 - accuracy: 0.9837 - val_loss: 0.1847 - val_accuracy: 0.9462\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 2s 31ms/step - loss: 0.0303 - accuracy: 0.9886 - val_loss: 0.2183 - val_accuracy: 0.9445\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 0.2037 - val_accuracy: 0.9396\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 2s 31ms/step - loss: 0.0436 - accuracy: 0.9824 - val_loss: 0.2010 - val_accuracy: 0.9396\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0393 - accuracy: 0.9837 - val_loss: 0.2188 - val_accuracy: 0.9413\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0298 - accuracy: 0.9878 - val_loss: 0.1739 - val_accuracy: 0.9543\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.2283 - val_accuracy: 0.9445\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0258 - accuracy: 0.9886 - val_loss: 0.1913 - val_accuracy: 0.9445\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.2658 - val_accuracy: 0.9429\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0325 - accuracy: 0.9869 - val_loss: 0.2970 - val_accuracy: 0.9380\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0317 - accuracy: 0.9865 - val_loss: 0.1902 - val_accuracy: 0.9413\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.2233 - val_accuracy: 0.9494\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0452 - accuracy: 0.9808 - val_loss: 0.1967 - val_accuracy: 0.9511\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0432 - accuracy: 0.9820 - val_loss: 0.1872 - val_accuracy: 0.9478\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.2069 - val_accuracy: 0.9462\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0223 - accuracy: 0.9918 - val_loss: 0.1947 - val_accuracy: 0.9527\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.2685 - val_accuracy: 0.9429\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.2502 - val_accuracy: 0.9347\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0353 - accuracy: 0.9857 - val_loss: 0.2255 - val_accuracy: 0.9445\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0173 - accuracy: 0.9922 - val_loss: 0.2747 - val_accuracy: 0.9462\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0324 - accuracy: 0.9878 - val_loss: 0.3214 - val_accuracy: 0.9364\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0327 - accuracy: 0.9873 - val_loss: 0.2056 - val_accuracy: 0.9445\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.2526 - val_accuracy: 0.9445\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0200 - accuracy: 0.9918 - val_loss: 0.2273 - val_accuracy: 0.9478\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.0237 - accuracy: 0.9906 - val_loss: 0.3024 - val_accuracy: 0.9445\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0252 - accuracy: 0.9894 - val_loss: 0.2570 - val_accuracy: 0.9462\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.2457 - val_accuracy: 0.9478\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.2492 - val_accuracy: 0.9511\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.2987 - val_accuracy: 0.9445\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0100 - accuracy: 0.9951 - val_loss: 0.2635 - val_accuracy: 0.9576\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.4872 - val_accuracy: 0.9413\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0527 - accuracy: 0.9853 - val_loss: 0.2587 - val_accuracy: 0.9445\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 0.2620 - val_accuracy: 0.9494\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0243 - accuracy: 0.9906 - val_loss: 0.2543 - val_accuracy: 0.9478\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.2945 - val_accuracy: 0.9462\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0120 - accuracy: 0.9947 - val_loss: 0.2272 - val_accuracy: 0.9494\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.2872 - val_accuracy: 0.9429\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0138 - accuracy: 0.9939 - val_loss: 0.3226 - val_accuracy: 0.9380\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.2719 - val_accuracy: 0.9543\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9462\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9560\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.2908 - val_accuracy: 0.9511\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9494\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 9.8222e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9494\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9462\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 6.4599e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9494\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 7.5797e-04 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9527\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 5.7244e-04 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9527\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9494\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 8.4315e-04 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9494\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.3940 - val_accuracy: 0.9429\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.2569 - val_accuracy: 0.9511\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0378 - accuracy: 0.9857 - val_loss: 0.2626 - val_accuracy: 0.9511\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.2816 - val_accuracy: 0.9413\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.9478\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9462\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.2857 - val_accuracy: 0.9462\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.2902 - val_accuracy: 0.9413\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.0188 - accuracy: 0.9914 - val_loss: 0.3720 - val_accuracy: 0.9429\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0262 - accuracy: 0.9898 - val_loss: 0.2902 - val_accuracy: 0.9494\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0173 - accuracy: 0.9935 - val_loss: 0.3264 - val_accuracy: 0.9347\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0097 - accuracy: 0.9984 - val_loss: 0.2789 - val_accuracy: 0.9494\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.2832 - val_accuracy: 0.9494\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 5s 62ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.2907 - val_accuracy: 0.9494\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.2975 - val_accuracy: 0.9413\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.2854 - val_accuracy: 0.9494\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 5s 65ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.3281 - val_accuracy: 0.9429\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3425 - val_accuracy: 0.9413\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 5.0596e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9429\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 5s 71ms/step - loss: 7.5764e-04 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9478\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 5s 65ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9511\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 4.3685e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9478\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 2.4482e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9445\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 5s 64ms/step - loss: 1.5172e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9462\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 2.1935e-04 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9462\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 5s 67ms/step - loss: 2.0545e-04 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.9494\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 5s 68ms/step - loss: 2.0474e-04 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9445\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 5s 65ms/step - loss: 1.3475e-04 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9478\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 5s 70ms/step - loss: 1.7908e-04 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9494\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 5s 65ms/step - loss: 1.6776e-04 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9494\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 5s 69ms/step - loss: 1.2739e-04 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9494\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 1.1026e-04 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9494\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 6.5743e-04 - accuracy: 0.9996 - val_loss: 0.3723 - val_accuracy: 0.9462\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 5s 67ms/step - loss: 0.1085 - accuracy: 0.9735 - val_loss: 0.2203 - val_accuracy: 0.9413\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 5s 67ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.2066 - val_accuracy: 0.9380\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 5s 64ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.2436 - val_accuracy: 0.9560\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 5s 65ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.2723 - val_accuracy: 0.9494\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 5s 66ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9511\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 7.4543e-04 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ba1541d4f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_df,Y_train,validation_split=0.20,batch_size=32,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef7bac82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1103,    8],\n",
       "       [   6,  193]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y_test[:2000]\n",
    "pred = model.predict(test_df[:2000])\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b4d89f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36be08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cf3e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cc7dc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 15, 15, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f4f081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 15  # We'll resize input images to this size\n",
    "patch_size = 15  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 128\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6b82757",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(6,15,15,3)) \n",
    "patches = TimeDistributed(Flatten()) (inputs)\n",
    "en = PatchEncoder(6, projection_dim)(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "28803bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 6, 128])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf326e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60360ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aa5b504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6df61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75542c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199466a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3eb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257102bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
