{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2666249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89cd60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 58s 69ms/step - loss: 1.5338 - accuracy: 0.5219 - val_loss: 3.7809 - val_accuracy: 0.1289\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 1.4451 - accuracy: 0.5713 - val_loss: 14.0260 - val_accuracy: 0.4127\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 69s 111ms/step - loss: 1.1658 - accuracy: 0.6386 - val_loss: 1.7072 - val_accuracy: 0.6115\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 46s 73ms/step - loss: 1.1961 - accuracy: 0.6276 - val_loss: 11.9820 - val_accuracy: 0.4146\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 1.3461 - accuracy: 0.5743 - val_loss: 1.3456 - val_accuracy: 0.5531\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 1.1746 - accuracy: 0.6329 - val_loss: 1.5345 - val_accuracy: 0.5032\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 1.1361 - accuracy: 0.6393 - val_loss: 2.2089 - val_accuracy: 0.3231\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 1.4486 - accuracy: 0.5459 - val_loss: 2.6791 - val_accuracy: 0.4977\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 1.0149 - accuracy: 0.6612 - val_loss: 1.8352 - val_accuracy: 0.4700\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 40s 65ms/step - loss: 1.0330 - accuracy: 0.6447 - val_loss: 0.8994 - val_accuracy: 0.6963\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 40s 65ms/step - loss: 0.7469 - accuracy: 0.7423 - val_loss: 0.8437 - val_accuracy: 0.7108\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6403 - accuracy: 0.7800 - val_loss: 0.9213 - val_accuracy: 0.7104\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.5952 - accuracy: 0.7976 - val_loss: 1.2694 - val_accuracy: 0.6059\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.5168 - accuracy: 0.8228 - val_loss: 0.9492 - val_accuracy: 0.7034\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.4729 - accuracy: 0.8385 - val_loss: 1.0623 - val_accuracy: 0.6709\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.3764 - accuracy: 0.8714 - val_loss: 0.8417 - val_accuracy: 0.7353\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 0.3192 - accuracy: 0.8903 - val_loss: 1.0562 - val_accuracy: 0.7090\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.3458 - accuracy: 0.8844 - val_loss: 1.0416 - val_accuracy: 0.7109\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5049 - accuracy: 0.8390 - val_loss: 1.8457 - val_accuracy: 0.5051\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.5064 - accuracy: 0.8325 - val_loss: 0.8001 - val_accuracy: 0.7559\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 40s 63ms/step - loss: 0.2357 - accuracy: 0.9207 - val_loss: 1.3296 - val_accuracy: 0.6841\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.1794 - accuracy: 0.9388 - val_loss: 1.0704 - val_accuracy: 0.7338\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.1309 - accuracy: 0.9533 - val_loss: 0.9798 - val_accuracy: 0.7583\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.1255 - accuracy: 0.9560 - val_loss: 1.1733 - val_accuracy: 0.7257\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.2141 - accuracy: 0.9317 - val_loss: 2.0974 - val_accuracy: 0.5348\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.1573 - accuracy: 0.9460 - val_loss: 1.0313 - val_accuracy: 0.7515\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.0885 - accuracy: 0.9704 - val_loss: 1.3165 - val_accuracy: 0.7167\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 0.0865 - accuracy: 0.9711 - val_loss: 1.0838 - val_accuracy: 0.7577\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.1003 - accuracy: 0.9659 - val_loss: 1.1555 - val_accuracy: 0.7498\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0944 - accuracy: 0.9678 - val_loss: 1.1254 - val_accuracy: 0.7640\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 40s 63ms/step - loss: 0.0858 - accuracy: 0.9710 - val_loss: 1.2318 - val_accuracy: 0.7363\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.0777 - accuracy: 0.9738 - val_loss: 1.2205 - val_accuracy: 0.7481\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 38s 62ms/step - loss: 0.0748 - accuracy: 0.9749 - val_loss: 1.3061 - val_accuracy: 0.7356\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.0720 - accuracy: 0.9758 - val_loss: 1.3011 - val_accuracy: 0.7269\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0806 - accuracy: 0.9741 - val_loss: 2.1376 - val_accuracy: 0.7068\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.0649 - accuracy: 0.9782 - val_loss: 1.2188 - val_accuracy: 0.7601\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 44s 71ms/step - loss: 0.0572 - accuracy: 0.9809 - val_loss: 1.3957 - val_accuracy: 0.7398\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0556 - accuracy: 0.9809 - val_loss: 1.1776 - val_accuracy: 0.7592\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.0561 - accuracy: 0.9805 - val_loss: 1.6570 - val_accuracy: 0.7139\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.1411 - accuracy: 0.9593 - val_loss: 1.8890 - val_accuracy: 0.6633\n",
      "Epoch 41/50\n",
      "292/625 [=============>................] - ETA: 20s - loss: 0.1837 - accuracy: 0.9395"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960bd789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4173\n",
      "F1 Score (Micro): 0.4173\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed19658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37bb84f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 76s 56ms/step - loss: 4.7709 - accuracy: 0.0882 - val_loss: 9.7738 - val_accuracy: 0.0770\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 3.8521 - accuracy: 0.1632 - val_loss: 11.2839 - val_accuracy: 0.1536\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 4.2407 - accuracy: 0.1103 - val_loss: 4.9235 - val_accuracy: 0.1387\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 3.5522 - accuracy: 0.1843 - val_loss: 3.2345 - val_accuracy: 0.2243\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 79s 63ms/step - loss: 3.4598 - accuracy: 0.2080 - val_loss: 4.3741 - val_accuracy: 0.2218\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 77s 62ms/step - loss: 3.2729 - accuracy: 0.2324 - val_loss: 3.8303 - val_accuracy: 0.1687\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 67s 54ms/step - loss: 2.9956 - accuracy: 0.2679 - val_loss: 3.5045 - val_accuracy: 0.2781\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 67s 53ms/step - loss: 2.8172 - accuracy: 0.3046 - val_loss: 15.7024 - val_accuracy: 0.2142\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 74s 60ms/step - loss: 2.6219 - accuracy: 0.3340 - val_loss: 4.0493 - val_accuracy: 0.2919\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 73s 59ms/step - loss: 2.4778 - accuracy: 0.3627 - val_loss: 3.8484 - val_accuracy: 0.3255\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 77s 61ms/step - loss: 2.2788 - accuracy: 0.3973 - val_loss: 4.6688 - val_accuracy: 0.3395\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 77s 62ms/step - loss: 2.1129 - accuracy: 0.4354 - val_loss: 8.7757 - val_accuracy: 0.3234\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 1.9776 - accuracy: 0.4630 - val_loss: 3.3874 - val_accuracy: 0.3724\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 1.7787 - accuracy: 0.5078 - val_loss: 4.0675 - val_accuracy: 0.3504\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 74s 60ms/step - loss: 1.6532 - accuracy: 0.5360 - val_loss: 5.6994 - val_accuracy: 0.3724\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 78s 62ms/step - loss: 1.6828 - accuracy: 0.5332 - val_loss: 4.6576 - val_accuracy: 0.2576\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 1.8091 - accuracy: 0.4972 - val_loss: 3.2015 - val_accuracy: 0.3640\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 1.3710 - accuracy: 0.6026 - val_loss: 2.8181 - val_accuracy: 0.3785\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 81s 65ms/step - loss: 1.3298 - accuracy: 0.6161 - val_loss: 3.9674 - val_accuracy: 0.3766\n",
      "Epoch 20/50\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 1.5522 - accuracy: 0.5609 - val_loss: 3.2944 - val_accuracy: 0.3486\n",
      "Epoch 21/50\n",
      "1250/1250 [==============================] - 64s 52ms/step - loss: 1.2315 - accuracy: 0.6400 - val_loss: 4.4289 - val_accuracy: 0.3164\n",
      "Epoch 22/50\n",
      "1250/1250 [==============================] - 69s 55ms/step - loss: 1.1715 - accuracy: 0.6541 - val_loss: 4.1704 - val_accuracy: 0.2440\n",
      "Epoch 23/50\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 1.3982 - accuracy: 0.5919 - val_loss: 3.9264 - val_accuracy: 0.3656\n",
      "Epoch 24/50\n",
      "1250/1250 [==============================] - 70s 56ms/step - loss: 1.0485 - accuracy: 0.6890 - val_loss: 3.5487 - val_accuracy: 0.3619\n",
      "Epoch 25/50\n",
      "1250/1250 [==============================] - 65s 52ms/step - loss: 0.9077 - accuracy: 0.7255 - val_loss: 5.4436 - val_accuracy: 0.3542\n",
      "Epoch 26/50\n",
      "1250/1250 [==============================] - 76s 61ms/step - loss: 0.7483 - accuracy: 0.7689 - val_loss: 4.3369 - val_accuracy: 0.3569\n",
      "Epoch 27/50\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.6399 - accuracy: 0.8043 - val_loss: 3.9589 - val_accuracy: 0.3457\n",
      "Epoch 28/50\n",
      "1250/1250 [==============================] - 72s 58ms/step - loss: 0.5863 - accuracy: 0.8191 - val_loss: 7.2028 - val_accuracy: 0.3278\n",
      "Epoch 29/50\n",
      "1250/1250 [==============================] - 83s 67ms/step - loss: 0.5233 - accuracy: 0.8350 - val_loss: 5.6869 - val_accuracy: 0.3757\n",
      "Epoch 30/50\n",
      "1250/1250 [==============================] - 72s 58ms/step - loss: 0.5796 - accuracy: 0.8196 - val_loss: 4.9408 - val_accuracy: 0.3762\n",
      "Epoch 31/50\n",
      "1250/1250 [==============================] - 72s 58ms/step - loss: 0.7819 - accuracy: 0.7667 - val_loss: 4.0451 - val_accuracy: 0.3409\n",
      "Epoch 32/50\n",
      "1250/1250 [==============================] - 85s 68ms/step - loss: 0.4204 - accuracy: 0.8689 - val_loss: 5.6581 - val_accuracy: 0.3726\n",
      "Epoch 33/50\n",
      "1250/1250 [==============================] - 74s 60ms/step - loss: 0.5753 - accuracy: 0.8234 - val_loss: 9.1849 - val_accuracy: 0.3480\n",
      "Epoch 34/50\n",
      "1250/1250 [==============================] - 76s 61ms/step - loss: 0.3707 - accuracy: 0.8824 - val_loss: 6.4730 - val_accuracy: 0.3704\n",
      "Epoch 35/50\n",
      "1250/1250 [==============================] - 87s 69ms/step - loss: 0.3446 - accuracy: 0.8905 - val_loss: 12.5591 - val_accuracy: 0.3183\n",
      "Epoch 36/50\n",
      "1250/1250 [==============================] - 77s 61ms/step - loss: 0.4329 - accuracy: 0.8640 - val_loss: 10.3018 - val_accuracy: 0.3293\n",
      "Epoch 37/50\n",
      "1250/1250 [==============================] - 79s 63ms/step - loss: 0.3719 - accuracy: 0.8832 - val_loss: 9.3933 - val_accuracy: 0.3738\n",
      "Epoch 38/50\n",
      "1250/1250 [==============================] - 86s 69ms/step - loss: 0.2921 - accuracy: 0.9082 - val_loss: 38.3523 - val_accuracy: 0.2128\n",
      "Epoch 39/50\n",
      "1250/1250 [==============================] - 74s 59ms/step - loss: 0.2891 - accuracy: 0.9086 - val_loss: 8.4584 - val_accuracy: 0.3441\n",
      "Epoch 40/50\n",
      "1250/1250 [==============================] - 81s 65ms/step - loss: 0.3331 - accuracy: 0.8951 - val_loss: 9.3509 - val_accuracy: 0.3692\n",
      "Epoch 41/50\n",
      "1250/1250 [==============================] - 85s 68ms/step - loss: 0.3672 - accuracy: 0.8867 - val_loss: 23.5930 - val_accuracy: 0.3512\n",
      "Epoch 42/50\n",
      "1250/1250 [==============================] - 80s 64ms/step - loss: 0.2073 - accuracy: 0.9348 - val_loss: 13.5913 - val_accuracy: 0.3651\n",
      "Epoch 43/50\n",
      "1250/1250 [==============================] - 80s 64ms/step - loss: 0.3888 - accuracy: 0.8838 - val_loss: 16.5380 - val_accuracy: 0.3644\n",
      "Epoch 44/50\n",
      "1250/1250 [==============================] - 92s 74ms/step - loss: 0.3258 - accuracy: 0.8981 - val_loss: 10.7089 - val_accuracy: 0.3538\n",
      "Epoch 45/50\n",
      "1250/1250 [==============================] - 80s 64ms/step - loss: 0.2867 - accuracy: 0.9108 - val_loss: 13.8516 - val_accuracy: 0.3441\n",
      "Epoch 46/50\n",
      "1250/1250 [==============================] - 80s 64ms/step - loss: 0.3401 - accuracy: 0.8976 - val_loss: 36.8370 - val_accuracy: 0.3448\n",
      "Epoch 47/50\n",
      "1250/1250 [==============================] - 87s 70ms/step - loss: 0.3730 - accuracy: 0.8868 - val_loss: 9.9153 - val_accuracy: 0.3429\n",
      "Epoch 48/50\n",
      "1250/1250 [==============================] - 68s 54ms/step - loss: 0.2755 - accuracy: 0.9134 - val_loss: 11.5521 - val_accuracy: 0.3652\n",
      "Epoch 49/50\n",
      "1250/1250 [==============================] - 77s 62ms/step - loss: 0.2194 - accuracy: 0.9302 - val_loss: 14.4983 - val_accuracy: 0.3720\n",
      "Epoch 50/50\n",
      "1250/1250 [==============================] - 87s 70ms/step - loss: 0.2008 - accuracy: 0.9381 - val_loss: 44.3621 - val_accuracy: 0.3196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec2984d3a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"D:\\res_cifar100_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    \n",
    "num_classes = 100  # Update with the actual number of classes in your target data\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(x_train, y_train, batch_size=32, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd0d6e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.321\n",
      "F1 Score (Micro): 0.321\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = new_model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf6c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd0e08c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1250/1250 [==============================] - 63s 51ms/step - loss: 0.4244 - accuracy: 0.8748 - val_loss: 25.6878 - val_accuracy: 0.3579\n",
      "Epoch 2/2\n",
      "1250/1250 [==============================] - 66s 53ms/step - loss: 0.1734 - accuracy: 0.9444 - val_loss: 14.1329 - val_accuracy: 0.3706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f06462eca0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(x_train, y_train, batch_size=32, epochs=2, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d1eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaeb1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd75a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab04b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aaefb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9fe711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d3286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1b34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
