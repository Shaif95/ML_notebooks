{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52be38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r'C:\\Users\\shaif\\Downloads\\Compressed\\archive'\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in os.listdir(directory_path):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    class_label = class_folder\n",
    "    \n",
    "    # Encode class labels\n",
    "    encoded_label = label_encoder.fit_transform([class_label])[0]\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.jpg'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(encoded_label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d41dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5295a5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8199, 32, 32, 3)\n",
      "Y_train shape: (8199, 23)\n",
      "X_test shape: (5467, 32, 32, 3)\n",
      "Y_test shape: (5467, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to categorical format with 23 classes\n",
    "Y_train = to_categorical(Y_train,23)\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.4, random_state=42)\n",
    "\n",
    "# Check the shapes\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'Y_test shape: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9b4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c1dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 82/103 [======================>.......] - ETA: 1s - loss: 0.1300 - accuracy: 0.9720"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(23, activation='softmax'))  # Change the number of units and activation\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83db64e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 2s 41ms/step - loss: 1.8533e-09 - accuracy: 1.0000\n",
      "35/35 [==============================] - 2s 18ms/step\n",
      "Test Loss: 1.8532748669031207e-09\n",
      "Test Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "batch_size = 64\n",
    "import tensorflow as tf\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "Y_test = np.argmax(Y_test , axis=1)\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b3919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"D:\\1.Image_List\\SeaAnimals_400\\combo_list.pickle\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(23, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d153b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(test_dataset)\n",
    "\n",
    "Y_test = np.argmax(Y_test , axis=1)\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291dd22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d07f32a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
