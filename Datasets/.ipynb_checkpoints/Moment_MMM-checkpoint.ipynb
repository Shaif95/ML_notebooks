{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccff503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 345/345 [06:14<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (75759, 32, 32, 3)\n",
      "Y_train shape: (75759,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 512\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "hidden_units = 512\n",
    "projection_units = 256\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r'C:\\Users\\shaif\\Downloads\\Compressed\\painting\\painting'\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.jpg'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8db053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1081c193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 345/345 [13:40<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (175327, 32, 32, 3)\n",
      "Y_train shape: (175327,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r'C:\\Users\\shaif\\Downloads\\Compressed\\real\\real'\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_test = []\n",
    "Y_test = []\n",
    "class_label = 0\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "\n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.jpg'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_test.append(img_array)\n",
    "            Y_test.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print(f'X_train shape: {X_test.shape}')\n",
    "print(f'Y_train shape: {Y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c270d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "num_classes = 345\n",
    "Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test_categorical = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808281fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fef8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_encode, X_test, y_encode, Y_test = train_test_split(X_test, Y_test_categorical, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356d5704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 32, 32, 3)         7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "548/548 [==============================] - 197s 297ms/step - loss: 2.4547\n",
      "Epoch 2/10\n",
      "548/548 [==============================] - 146s 266ms/step - loss: 2.2637\n",
      "Epoch 3/10\n",
      "548/548 [==============================] - 143s 262ms/step - loss: 2.2042\n",
      "Epoch 4/10\n",
      "548/548 [==============================] - 149s 272ms/step - loss: 2.1610\n",
      "Epoch 5/10\n",
      "548/548 [==============================] - 145s 264ms/step - loss: 2.1325\n",
      "Epoch 6/10\n",
      "548/548 [==============================] - 146s 267ms/step - loss: 2.0951\n",
      "Epoch 7/10\n",
      "548/548 [==============================] - 142s 259ms/step - loss: 2.0716\n",
      "Epoch 8/10\n",
      "548/548 [==============================] - 143s 260ms/step - loss: 2.0507\n",
      "Epoch 9/10\n",
      "548/548 [==============================] - 147s 268ms/step - loss: 2.0256\n",
      "Epoch 10/10\n",
      "548/548 [==============================] - 143s 260ms/step - loss: 2.0008\n",
      "Epoch 1/20\n",
      "2368/2368 [==============================] - 131s 53ms/step - loss: 5.5371 - sparse_categorical_accuracy: 0.0408\n",
      "Epoch 2/20\n",
      "2368/2368 [==============================] - 115s 48ms/step - loss: 5.0019 - sparse_categorical_accuracy: 0.0848\n",
      "Epoch 3/20\n",
      "2368/2368 [==============================] - 120s 51ms/step - loss: 4.8042 - sparse_categorical_accuracy: 0.1026\n",
      "Epoch 4/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.6730 - sparse_categorical_accuracy: 0.1150\n",
      "Epoch 5/20\n",
      "2368/2368 [==============================] - 119s 50ms/step - loss: 4.5886 - sparse_categorical_accuracy: 0.1207\n",
      "Epoch 6/20\n",
      "2368/2368 [==============================] - 113s 48ms/step - loss: 4.5222 - sparse_categorical_accuracy: 0.1258\n",
      "Epoch 7/20\n",
      "2368/2368 [==============================] - 121s 51ms/step - loss: 4.4714 - sparse_categorical_accuracy: 0.1306\n",
      "Epoch 8/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.4345 - sparse_categorical_accuracy: 0.1356\n",
      "Epoch 9/20\n",
      "2368/2368 [==============================] - 123s 52ms/step - loss: 4.3983 - sparse_categorical_accuracy: 0.1401\n",
      "Epoch 10/20\n",
      "2368/2368 [==============================] - 116s 49ms/step - loss: 4.3690 - sparse_categorical_accuracy: 0.1416\n",
      "Epoch 11/20\n",
      "2368/2368 [==============================] - 117s 49ms/step - loss: 4.3394 - sparse_categorical_accuracy: 0.1457\n",
      "Epoch 12/20\n",
      "2368/2368 [==============================] - 113s 48ms/step - loss: 4.3290 - sparse_categorical_accuracy: 0.1454\n",
      "Epoch 13/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.3086 - sparse_categorical_accuracy: 0.1472\n",
      "Epoch 14/20\n",
      "2368/2368 [==============================] - 111s 47ms/step - loss: 4.2877 - sparse_categorical_accuracy: 0.1500\n",
      "Epoch 15/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.2737 - sparse_categorical_accuracy: 0.1525\n",
      "Epoch 16/20\n",
      "2368/2368 [==============================] - 115s 49ms/step - loss: 4.2568 - sparse_categorical_accuracy: 0.1524\n",
      "Epoch 17/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.2425 - sparse_categorical_accuracy: 0.1544\n",
      "Epoch 18/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.2349 - sparse_categorical_accuracy: 0.1559\n",
      "Epoch 19/20\n",
      "2368/2368 [==============================] - 118s 50ms/step - loss: 4.2226 - sparse_categorical_accuracy: 0.1583\n",
      "Epoch 20/20\n",
      "2368/2368 [==============================] - 116s 49ms/step - loss: 4.2153 - sparse_categorical_accuracy: 0.1571\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.02),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(x_encode)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 345\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "def create_encoder():\n",
    "    resnet = tf.keras.applications.ResNet50V2( include_top=False, weights=\"imagenet\", input_shape=input_shape, pooling=\"avg\" )\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = resnet(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n",
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "\n",
    "        logits = tf.divide( tf.matmul(  \n",
    "            feature_vectors_normalized, tf.transpose(feature_vectors_normalized)),self.temperature,)\n",
    "        \n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "encoder = create_encoder()\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "history = encoder_with_projection_head.fit(x=x_encode, y=y_encode, batch_size=256, epochs=20)\n",
    "classifier = create_classifier(encoder, trainable=False) \n",
    "from keras.callbacks import EarlyStopping\n",
    "# Define early stopping criteria\n",
    "early_stopping_monitor = EarlyStopping(patience=3, monitor='val_loss', verbose=1)\n",
    "# Train the model with early stopping\n",
    "history = classifier.fit(X_train.astype('float32'), np.argmax(Y_train_categorical, axis=1), \n",
    "                         batch_size=32, epochs=80, \n",
    "                         callbacks=[early_stopping_monitor],\n",
    "                         validation_data=(X_val.astype('float32'), np.argmax(Y_val_categorical, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f3576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38698e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548/548 [==============================] - 8s 12ms/step\n",
      "Accuracy: 0.14016426167797866\n",
      "F1 Score (Micro): 0.14016426167797866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = classifier.predict(X_test,batch_size= 64)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax((y_pred_prob), axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels =  (Y_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "947/947 [==============================] - 69s 63ms/step - loss: 5.7224 - accuracy: 0.0354 - val_loss: 12.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "758/947 [=======================>......] - ETA: 11s - loss: 5.1404 - accuracy: 0.0472"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757329e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8cbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11976ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 32, 32, 3)         7         \n",
      "                                                                 \n",
      " model (Functional)          (None, 400)               24842000  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,842,007\n",
      "Trainable params: 24,788,880\n",
      "Non-trainable params: 53,127\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "548/548 [==============================] - 159s 268ms/step - loss: 2.7224\n",
      "Epoch 2/10\n",
      "548/548 [==============================] - 142s 260ms/step - loss: 2.4235\n",
      "Epoch 3/10\n",
      "548/548 [==============================] - 142s 259ms/step - loss: 2.3471\n",
      "Epoch 4/10\n",
      "548/548 [==============================] - 142s 259ms/step - loss: 2.3209\n",
      "Epoch 5/10\n",
      "548/548 [==============================] - 143s 261ms/step - loss: 2.2983\n",
      "Epoch 6/10\n",
      "548/548 [==============================] - 142s 258ms/step - loss: 2.2871\n",
      "Epoch 7/10\n",
      "548/548 [==============================] - 144s 263ms/step - loss: 2.2781\n",
      "Epoch 8/10\n",
      "548/548 [==============================] - 141s 257ms/step - loss: 2.2538\n",
      "Epoch 9/10\n",
      "548/548 [==============================] - 143s 260ms/step - loss: 2.2435\n",
      "Epoch 10/10\n",
      "548/548 [==============================] - 197s 360ms/step - loss: 2.2358\n",
      "Epoch 1/20\n",
      "2368/2368 [==============================] - 118s 48ms/step - loss: 5.6194 - sparse_categorical_accuracy: 0.0112\n",
      "Epoch 2/20\n",
      "2368/2368 [==============================] - 116s 49ms/step - loss: 5.5456 - sparse_categorical_accuracy: 0.0124\n",
      "Epoch 3/20\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 5.5344 - sparse_categorical_accuracy: 0.0142\n",
      "Epoch 4/20\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 5.5165 - sparse_categorical_accuracy: 0.0164\n",
      "Epoch 5/20\n",
      "2368/2368 [==============================] - 111s 47ms/step - loss: 5.4874 - sparse_categorical_accuracy: 0.0215\n",
      "Epoch 6/20\n",
      "2368/2368 [==============================] - 118s 50ms/step - loss: 5.4478 - sparse_categorical_accuracy: 0.0261\n",
      "Epoch 7/20\n",
      "2368/2368 [==============================] - 121s 51ms/step - loss: 5.4019 - sparse_categorical_accuracy: 0.0295\n",
      "Epoch 8/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 5.3528 - sparse_categorical_accuracy: 0.0318\n",
      "Epoch 9/20\n",
      "2368/2368 [==============================] - 113s 48ms/step - loss: 5.3063 - sparse_categorical_accuracy: 0.0337\n",
      "Epoch 10/20\n",
      "2368/2368 [==============================] - 115s 49ms/step - loss: 5.2627 - sparse_categorical_accuracy: 0.0372\n",
      "Epoch 11/20\n",
      "2368/2368 [==============================] - 113s 48ms/step - loss: 5.2262 - sparse_categorical_accuracy: 0.0389\n",
      "Epoch 12/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 5.1916 - sparse_categorical_accuracy: 0.0413\n",
      "Epoch 13/20\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 5.1640 - sparse_categorical_accuracy: 0.0430\n",
      "Epoch 14/20\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 5.1395 - sparse_categorical_accuracy: 0.0442\n",
      "Epoch 15/20\n",
      "2368/2368 [==============================] - 117s 49ms/step - loss: 5.1159 - sparse_categorical_accuracy: 0.0468\n",
      "Epoch 16/20\n",
      "2368/2368 [==============================] - 113s 48ms/step - loss: 5.1003 - sparse_categorical_accuracy: 0.0488\n",
      "Epoch 17/20\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 5.0828 - sparse_categorical_accuracy: 0.0497\n",
      "Epoch 18/20\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 5.0672 - sparse_categorical_accuracy: 0.0510\n",
      "Epoch 19/20\n",
      "2368/2368 [==============================] - 101s 43ms/step - loss: 5.0495 - sparse_categorical_accuracy: 0.0537\n",
      "Epoch 20/20\n",
      "2368/2368 [==============================] - 100s 42ms/step - loss: 5.0370 - sparse_categorical_accuracy: 0.0537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.02),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(x_encode)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 345\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "def create_encoder():\n",
    "    resnet = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\realm_32_model.h5\")\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = resnet(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n",
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "\n",
    "        logits = tf.divide( tf.matmul(  \n",
    "            feature_vectors_normalized, tf.transpose(feature_vectors_normalized)),self.temperature,)\n",
    "        \n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "encoder = create_encoder()\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "history = encoder_with_projection_head.fit(x=x_encode, y=y_encode, batch_size=256, epochs=10)\n",
    "classifier = create_classifier(encoder, trainable=False) \n",
    "history = classifier.fit(X_train.astype('float32'), np.argmax(Y_train_categorical,axis = 1), batch_size=32, epochs=20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "116f7f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2368/2368 [==============================] - 108s 46ms/step - loss: 5.0265 - sparse_categorical_accuracy: 0.0549\n",
      "Epoch 2/40\n",
      "2368/2368 [==============================] - 110s 46ms/step - loss: 5.0174 - sparse_categorical_accuracy: 0.0568\n",
      "Epoch 3/40\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 5.0058 - sparse_categorical_accuracy: 0.0575\n",
      "Epoch 4/40\n",
      "2368/2368 [==============================] - 111s 47ms/step - loss: 4.9982 - sparse_categorical_accuracy: 0.0583\n",
      "Epoch 5/40\n",
      "2368/2368 [==============================] - 120s 51ms/step - loss: 4.9873 - sparse_categorical_accuracy: 0.0598\n",
      "Epoch 6/40\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 4.9792 - sparse_categorical_accuracy: 0.0605\n",
      "Epoch 7/40\n",
      "2368/2368 [==============================] - 111s 47ms/step - loss: 4.9710 - sparse_categorical_accuracy: 0.0614\n",
      "Epoch 8/40\n",
      "2368/2368 [==============================] - 111s 47ms/step - loss: 4.9661 - sparse_categorical_accuracy: 0.0619\n",
      "Epoch 9/40\n",
      "2368/2368 [==============================] - 111s 47ms/step - loss: 4.9608 - sparse_categorical_accuracy: 0.0637\n",
      "Epoch 10/40\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 4.9540 - sparse_categorical_accuracy: 0.0628\n",
      "Epoch 11/40\n",
      "2368/2368 [==============================] - 115s 48ms/step - loss: 4.9483 - sparse_categorical_accuracy: 0.0652\n",
      "Epoch 12/40\n",
      "2368/2368 [==============================] - 119s 50ms/step - loss: 4.9433 - sparse_categorical_accuracy: 0.0657\n",
      "Epoch 13/40\n",
      "2368/2368 [==============================] - 115s 49ms/step - loss: 4.9375 - sparse_categorical_accuracy: 0.0654\n",
      "Epoch 14/40\n",
      "2368/2368 [==============================] - 116s 49ms/step - loss: 4.9307 - sparse_categorical_accuracy: 0.0659\n",
      "Epoch 15/40\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.9290 - sparse_categorical_accuracy: 0.0669\n",
      "Epoch 16/40\n",
      "2368/2368 [==============================] - 122s 51ms/step - loss: 4.9246 - sparse_categorical_accuracy: 0.0671\n",
      "Epoch 17/40\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.9215 - sparse_categorical_accuracy: 0.0674\n",
      "Epoch 18/40\n",
      "2368/2368 [==============================] - 118s 50ms/step - loss: 4.9149 - sparse_categorical_accuracy: 0.0679\n",
      "Epoch 19/40\n",
      "2368/2368 [==============================] - 113s 48ms/step - loss: 4.9095 - sparse_categorical_accuracy: 0.0690\n",
      "Epoch 20/40\n",
      "2368/2368 [==============================] - 120s 51ms/step - loss: 4.9095 - sparse_categorical_accuracy: 0.0686\n",
      "Epoch 21/40\n",
      "2368/2368 [==============================] - 116s 49ms/step - loss: 4.9043 - sparse_categorical_accuracy: 0.0679\n",
      "Epoch 22/40\n",
      "2368/2368 [==============================] - 118s 50ms/step - loss: 4.9010 - sparse_categorical_accuracy: 0.0683\n",
      "Epoch 23/40\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.8984 - sparse_categorical_accuracy: 0.0707\n",
      "Epoch 24/40\n",
      "2368/2368 [==============================] - 115s 49ms/step - loss: 4.8955 - sparse_categorical_accuracy: 0.0695\n",
      "Epoch 25/40\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.8898 - sparse_categorical_accuracy: 0.0708\n",
      "Epoch 26/40\n",
      "2368/2368 [==============================] - 118s 50ms/step - loss: 4.8895 - sparse_categorical_accuracy: 0.0700\n",
      "Epoch 27/40\n",
      "2368/2368 [==============================] - 117s 49ms/step - loss: 4.8871 - sparse_categorical_accuracy: 0.0714\n",
      "Epoch 28/40\n",
      "2368/2368 [==============================] - 116s 49ms/step - loss: 4.8860 - sparse_categorical_accuracy: 0.0710\n",
      "Epoch 29/40\n",
      "2368/2368 [==============================] - 116s 49ms/step - loss: 4.8795 - sparse_categorical_accuracy: 0.0732\n",
      "Epoch 30/40\n",
      "2368/2368 [==============================] - 115s 48ms/step - loss: 4.8769 - sparse_categorical_accuracy: 0.0725\n",
      "Epoch 31/40\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 4.8764 - sparse_categorical_accuracy: 0.0732\n",
      "Epoch 32/40\n",
      "2368/2368 [==============================] - 120s 51ms/step - loss: 4.8738 - sparse_categorical_accuracy: 0.0729\n",
      "Epoch 33/40\n",
      "2368/2368 [==============================] - 116s 49ms/step - loss: 4.8712 - sparse_categorical_accuracy: 0.0730\n",
      "Epoch 34/40\n",
      "2368/2368 [==============================] - 114s 48ms/step - loss: 4.8648 - sparse_categorical_accuracy: 0.0741\n",
      "Epoch 35/40\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 4.8649 - sparse_categorical_accuracy: 0.0741\n",
      "Epoch 36/40\n",
      "2368/2368 [==============================] - 112s 47ms/step - loss: 4.8652 - sparse_categorical_accuracy: 0.0725\n",
      "Epoch 37/40\n",
      "2368/2368 [==============================] - 113s 48ms/step - loss: 4.8658 - sparse_categorical_accuracy: 0.0747\n",
      "Epoch 38/40\n",
      "2368/2368 [==============================] - 113s 48ms/step - loss: 4.8562 - sparse_categorical_accuracy: 0.0754\n",
      "Epoch 39/40\n",
      " 784/2368 [========>.....................] - ETA: 1:14 - loss: 4.8484 - sparse_categorical_accuracy: 0.0727"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train.astype('float32'), np.argmax(Y_train_categorical,axis = 1), batch_size=32, epochs=40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f56f401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da3c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = classifier.predict(X_test,batch_size= 64)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax((y_pred_prob), axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels =  (Y_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460cfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58c2b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb2f99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a0d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e73a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
