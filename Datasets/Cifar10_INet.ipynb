{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2666249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89cd60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - 45s 52ms/step - loss: 1.6497 - accuracy: 0.5011 - val_loss: 10.3680 - val_accuracy: 0.1042\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 1.5602 - accuracy: 0.4969 - val_loss: 1.5544 - val_accuracy: 0.4796\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 1.5290 - accuracy: 0.5150 - val_loss: 1.5452 - val_accuracy: 0.4807\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 1.3304 - accuracy: 0.5757 - val_loss: 1.7253 - val_accuracy: 0.4928\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 1.4298 - accuracy: 0.5616 - val_loss: 5.2943 - val_accuracy: 0.4565\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 1.2845 - accuracy: 0.6013 - val_loss: 2.1488 - val_accuracy: 0.2441\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 1.2680 - accuracy: 0.5948 - val_loss: 1.3837 - val_accuracy: 0.5044\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 1.1636 - accuracy: 0.6189 - val_loss: 1.2728 - val_accuracy: 0.5462\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 0.9373 - accuracy: 0.6881 - val_loss: 1.4238 - val_accuracy: 0.5407\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 0.8401 - accuracy: 0.7192 - val_loss: 0.8486 - val_accuracy: 0.6989\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.9712 - accuracy: 0.6881 - val_loss: 1.8533 - val_accuracy: 0.4308\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 1.0207 - accuracy: 0.6646 - val_loss: 0.9447 - val_accuracy: 0.6694\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 27s 43ms/step - loss: 0.6879 - accuracy: 0.7617 - val_loss: 0.7823 - val_accuracy: 0.7312\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.5888 - accuracy: 0.7987 - val_loss: 1.0786 - val_accuracy: 0.6496\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.5270 - accuracy: 0.8198 - val_loss: 0.7513 - val_accuracy: 0.7522\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.4821 - accuracy: 0.8360 - val_loss: 0.9461 - val_accuracy: 0.7039\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.4151 - accuracy: 0.8581 - val_loss: 0.7662 - val_accuracy: 0.7534\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.3895 - accuracy: 0.8671 - val_loss: 0.8102 - val_accuracy: 0.7502\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.3147 - accuracy: 0.8935 - val_loss: 1.0106 - val_accuracy: 0.7282\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.2264 - accuracy: 0.9221 - val_loss: 0.9510 - val_accuracy: 0.7458\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 0.1880 - accuracy: 0.9355 - val_loss: 1.0123 - val_accuracy: 0.7479\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 0.1618 - accuracy: 0.9445 - val_loss: 1.1699 - val_accuracy: 0.7026\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 0.1422 - accuracy: 0.9511 - val_loss: 1.4017 - val_accuracy: 0.6870\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.1491 - accuracy: 0.9498 - val_loss: 1.2752 - val_accuracy: 0.7205\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.1199 - accuracy: 0.9588 - val_loss: 1.2373 - val_accuracy: 0.7321\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0999 - accuracy: 0.9665 - val_loss: 1.1722 - val_accuracy: 0.7366\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.0905 - accuracy: 0.9683 - val_loss: 1.3656 - val_accuracy: 0.7056\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0934 - accuracy: 0.9678 - val_loss: 1.0907 - val_accuracy: 0.7602\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 1.2349 - val_accuracy: 0.7355\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.0751 - accuracy: 0.9746 - val_loss: 1.1095 - val_accuracy: 0.7599\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 0.1563 - accuracy: 0.9518 - val_loss: 1.1469 - val_accuracy: 0.7438\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 30s 47ms/step - loss: 0.2405 - accuracy: 0.9240 - val_loss: 0.9835 - val_accuracy: 0.7488\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 29s 46ms/step - loss: 0.0592 - accuracy: 0.9808 - val_loss: 1.4046 - val_accuracy: 0.7278\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 0.0449 - accuracy: 0.9845 - val_loss: 1.4270 - val_accuracy: 0.7350\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.0609 - accuracy: 0.9799 - val_loss: 1.3233 - val_accuracy: 0.7543\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 1.2352 - val_accuracy: 0.7530\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.0636 - accuracy: 0.9785 - val_loss: 1.2679 - val_accuracy: 0.7395\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 32s 50ms/step - loss: 0.0525 - accuracy: 0.9826 - val_loss: 1.1262 - val_accuracy: 0.7702\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 1.2858 - val_accuracy: 0.7494\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0482 - accuracy: 0.9836 - val_loss: 1.2878 - val_accuracy: 0.7460\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.1565 - accuracy: 0.9524 - val_loss: 1.0609 - val_accuracy: 0.7447\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0755 - accuracy: 0.9751 - val_loss: 1.2164 - val_accuracy: 0.7583\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 1.2549 - val_accuracy: 0.7662\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 1.6513 - val_accuracy: 0.7215\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 1.6060 - val_accuracy: 0.7135\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 1.3201 - val_accuracy: 0.7637\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 1.5625 - val_accuracy: 0.7138\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.0421 - accuracy: 0.9858 - val_loss: 1.4383 - val_accuracy: 0.7359\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 45s 73ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 1.5390 - val_accuracy: 0.7061\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.0397 - accuracy: 0.9866 - val_loss: 1.3245 - val_accuracy: 0.7586\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 1.3734 - val_accuracy: 0.7473\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 1.3543 - val_accuracy: 0.7660\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 0.0372 - accuracy: 0.9878 - val_loss: 1.3176 - val_accuracy: 0.7553\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 1.4719 - val_accuracy: 0.7405\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0580 - accuracy: 0.9821 - val_loss: 2.5846 - val_accuracy: 0.7079\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 38s 62ms/step - loss: 0.1540 - accuracy: 0.9586 - val_loss: 1.3017 - val_accuracy: 0.7143\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0693 - accuracy: 0.9768 - val_loss: 1.2224 - val_accuracy: 0.7678\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 1.3260 - val_accuracy: 0.7765\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 35s 57ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 1.5561 - val_accuracy: 0.7570\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 1.3372 - val_accuracy: 0.7674\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 1.9001 - val_accuracy: 0.6986\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 2.0570 - val_accuracy: 0.6872\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 1.4501 - val_accuracy: 0.7347\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0300 - accuracy: 0.9897 - val_loss: 1.2548 - val_accuracy: 0.7734\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0332 - accuracy: 0.9888 - val_loss: 1.4168 - val_accuracy: 0.7511\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0305 - accuracy: 0.9894 - val_loss: 1.4921 - val_accuracy: 0.7499\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0303 - accuracy: 0.9901 - val_loss: 1.6147 - val_accuracy: 0.7409\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.0228 - accuracy: 0.9922 - val_loss: 1.7062 - val_accuracy: 0.7637\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 1.4883 - val_accuracy: 0.7503\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 1.4663 - val_accuracy: 0.7556\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - 32s 50ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 1.8090 - val_accuracy: 0.7344\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0429 - accuracy: 0.9865 - val_loss: 1.3889 - val_accuracy: 0.7592\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 1.4474 - val_accuracy: 0.7655\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 1.3489 - val_accuracy: 0.7693\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 1.3583 - val_accuracy: 0.7696\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 1.6149 - val_accuracy: 0.7349\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.0250 - accuracy: 0.9917 - val_loss: 1.3741 - val_accuracy: 0.7702\n",
      "Epoch 78/100\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 1.4158 - val_accuracy: 0.7532\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 1.4045 - val_accuracy: 0.7675\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 1.5817 - val_accuracy: 0.7529\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 1.4379 - val_accuracy: 0.7537\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 1.3502 - val_accuracy: 0.7718\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 1.3598 - val_accuracy: 0.7707\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 1.7565 - val_accuracy: 0.7401\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 1.3613 - val_accuracy: 0.7699\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 1.6379 - val_accuracy: 0.7463\n",
      "Epoch 87/100\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 1.3054 - val_accuracy: 0.7730\n",
      "Epoch 88/100\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 1.7701 - val_accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 1.4435 - val_accuracy: 0.7657\n",
      "Epoch 90/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.7592 - val_accuracy: 0.7493\n",
      "Epoch 91/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 1.4301 - val_accuracy: 0.7731\n",
      "Epoch 92/100\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.2591 - accuracy: 0.9304 - val_loss: 2.8360 - val_accuracy: 0.7215\n",
      "Epoch 93/100\n",
      "625/625 [==============================] - 35s 57ms/step - loss: 0.1243 - accuracy: 0.9610 - val_loss: 1.0354 - val_accuracy: 0.7809\n",
      "Epoch 94/100\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 1.2933 - val_accuracy: 0.7860\n",
      "Epoch 95/100\n",
      "625/625 [==============================] - 40s 63ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 1.4562 - val_accuracy: 0.7840\n",
      "Epoch 96/100\n",
      "625/625 [==============================] - 46s 73ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 1.6040 - val_accuracy: 0.7746\n",
      "Epoch 97/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.5470 - val_accuracy: 0.7834\n",
      "Epoch 98/100\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 1.4064 - val_accuracy: 0.7715\n",
      "Epoch 99/100\n",
      "625/625 [==============================] - 40s 65ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 1.5084 - val_accuracy: 0.7679\n",
      "Epoch 100/100\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 1.6680 - val_accuracy: 0.7605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f5c38ee20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960bd789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 13ms/step\n",
      "Accuracy: 0.7536\n",
      "F1 Score (Micro): 0.7535999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed19658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bb84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\Cifar10_32_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    \n",
    "num_classes = 10  # Update with the actual number of classes in your target data\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(x_train, y_train, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d6e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(ds_test)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Manually generate ground truth labels for evaluation\n",
    "true_labels = []\n",
    "for _, label in ds_test:\n",
    "    true_labels.extend(label.numpy())\n",
    "\n",
    "true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Assuming you have test_loss and test_accuracy available\n",
    "# If not, you'll need to calculate them based on your model and test dataset\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e08c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d1eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaeb1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd75a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab04b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aaefb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9fe711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d3286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1b34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
