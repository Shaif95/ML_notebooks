{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2666249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - 61s 75ms/step - loss: 1.3320 - accuracy: 0.5833 - val_loss: 4.8567 - val_accuracy: 0.1497\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 1.2579 - accuracy: 0.5983 - val_loss: 1.8139 - val_accuracy: 0.5826\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.4459 - accuracy: 0.5526 - val_loss: 1.6472 - val_accuracy: 0.4411\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 1.2679 - accuracy: 0.6069 - val_loss: 2.0750 - val_accuracy: 0.3564\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 1.2919 - accuracy: 0.5968 - val_loss: 1.2640 - val_accuracy: 0.5713\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 1.0794 - accuracy: 0.6562 - val_loss: 16.9821 - val_accuracy: 0.4890\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 1.2016 - accuracy: 0.6258 - val_loss: 7.7911 - val_accuracy: 0.1579\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 1.1004 - accuracy: 0.6429 - val_loss: 0.9412 - val_accuracy: 0.6728\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.7959 - accuracy: 0.7299 - val_loss: 1.0764 - val_accuracy: 0.6310\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.8492 - accuracy: 0.7218 - val_loss: 9.5272 - val_accuracy: 0.3826\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.9983 - accuracy: 0.6769 - val_loss: 1.1957 - val_accuracy: 0.6461\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 45s 72ms/step - loss: 0.7574 - accuracy: 0.7431 - val_loss: 0.9446 - val_accuracy: 0.6769\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.8710 - accuracy: 0.7100 - val_loss: 1.1319 - val_accuracy: 0.6035\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.8032 - accuracy: 0.7349 - val_loss: 0.7901 - val_accuracy: 0.7312\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 35s 55ms/step - loss: 0.5877 - accuracy: 0.8016 - val_loss: 0.8090 - val_accuracy: 0.7310\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.5060 - accuracy: 0.8279 - val_loss: 0.8548 - val_accuracy: 0.7239\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 46s 73ms/step - loss: 0.4000 - accuracy: 0.8634 - val_loss: 0.7884 - val_accuracy: 0.7471\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.4696 - accuracy: 0.8428 - val_loss: 3.1426 - val_accuracy: 0.4353\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 0.4533 - accuracy: 0.8478 - val_loss: 0.8216 - val_accuracy: 0.7426\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 45s 72ms/step - loss: 0.2548 - accuracy: 0.9116 - val_loss: 0.9138 - val_accuracy: 0.7466\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.2178 - accuracy: 0.9270 - val_loss: 0.9739 - val_accuracy: 0.7357\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.2343 - accuracy: 0.9212 - val_loss: 0.9210 - val_accuracy: 0.7455\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.2662 - accuracy: 0.9113 - val_loss: 0.8961 - val_accuracy: 0.7563\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1509 - accuracy: 0.9489 - val_loss: 1.0345 - val_accuracy: 0.7444\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - 40s 63ms/step - loss: 0.1578 - accuracy: 0.9471 - val_loss: 1.1001 - val_accuracy: 0.7424\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 43s 70ms/step - loss: 0.1223 - accuracy: 0.9602 - val_loss: 1.5385 - val_accuracy: 0.6472\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.1500 - accuracy: 0.9495 - val_loss: 1.2481 - val_accuracy: 0.7159\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 0.1045 - accuracy: 0.9647 - val_loss: 1.1976 - val_accuracy: 0.7335\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.0853 - accuracy: 0.9700 - val_loss: 1.1083 - val_accuracy: 0.7600\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.0784 - accuracy: 0.9732 - val_loss: 1.2800 - val_accuracy: 0.7286\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.0881 - accuracy: 0.9683 - val_loss: 1.2574 - val_accuracy: 0.7411\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.0711 - accuracy: 0.9765 - val_loss: 1.3095 - val_accuracy: 0.7389\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.0739 - accuracy: 0.9743 - val_loss: 1.1734 - val_accuracy: 0.7565\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.0737 - accuracy: 0.9747 - val_loss: 1.2296 - val_accuracy: 0.7465\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 0.0681 - accuracy: 0.9775 - val_loss: 1.4986 - val_accuracy: 0.7047\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0640 - accuracy: 0.9788 - val_loss: 1.1940 - val_accuracy: 0.7622\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 0.1751 - accuracy: 0.9457 - val_loss: 1.0606 - val_accuracy: 0.7615\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.0456 - accuracy: 0.9845 - val_loss: 1.2781 - val_accuracy: 0.7562\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.0419 - accuracy: 0.9859 - val_loss: 1.3754 - val_accuracy: 0.7413\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 0.0455 - accuracy: 0.9845 - val_loss: 1.4442 - val_accuracy: 0.7387\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.0485 - accuracy: 0.9830 - val_loss: 1.4264 - val_accuracy: 0.7306\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.1332 - accuracy: 0.9588 - val_loss: 1.2170 - val_accuracy: 0.7347\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 35s 55ms/step - loss: 0.0552 - accuracy: 0.9825 - val_loss: 1.2083 - val_accuracy: 0.7670\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 1.6011 - val_accuracy: 0.7163\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 35s 57ms/step - loss: 0.0856 - accuracy: 0.9732 - val_loss: 1.3953 - val_accuracy: 0.7297\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 1.2825 - val_accuracy: 0.7671\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 1.5992 - val_accuracy: 0.7278\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 1.9414 - val_accuracy: 0.6693\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 0.0425 - accuracy: 0.9858 - val_loss: 1.5850 - val_accuracy: 0.7113\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.0448 - accuracy: 0.9851 - val_loss: 1.8911 - val_accuracy: 0.6780\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0432 - accuracy: 0.9856 - val_loss: 1.4636 - val_accuracy: 0.7279\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0401 - accuracy: 0.9862 - val_loss: 1.2476 - val_accuracy: 0.7675\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 1.3927 - val_accuracy: 0.7529\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 1.5623 - val_accuracy: 0.7348\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0377 - accuracy: 0.9882 - val_loss: 1.2626 - val_accuracy: 0.7581\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 1.4400 - val_accuracy: 0.7450\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0475 - accuracy: 0.9850 - val_loss: 1.3821 - val_accuracy: 0.7508\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 37s 60ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 1.2809 - val_accuracy: 0.7641\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 40s 63ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 1.3667 - val_accuracy: 0.7595\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 1.4628 - val_accuracy: 0.7541\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 1.3608 - val_accuracy: 0.7526\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0720 - accuracy: 0.9779 - val_loss: 1.2630 - val_accuracy: 0.7569\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.1545 - accuracy: 0.9581 - val_loss: 1.0911 - val_accuracy: 0.7606\n",
      "Epoch 64/100\n",
      "568/625 [==========================>...] - ETA: 3s - loss: 0.0555 - accuracy: 0.9828"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed19658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\icifar10_32_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    \n",
    "num_classes = 10  # Update with the actual number of classes in your target data\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(x_train, y_train, batch_size=64, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d6e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(ds_test)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Manually generate ground truth labels for evaluation\n",
    "true_labels = []\n",
    "for _, label in ds_test:\n",
    "    true_labels.extend(label.numpy())\n",
    "\n",
    "true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Assuming you have test_loss and test_accuracy available\n",
    "# If not, you'll need to calculate them based on your model and test dataset\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e08c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d1eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaeb1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd75a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab04b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aaefb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9fe711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d3286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1b34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
