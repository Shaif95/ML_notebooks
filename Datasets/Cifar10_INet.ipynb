{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2666249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89cd60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - 921s 1s/step - loss: 2.0239 - accuracy: 0.3523 - val_loss: 103.8279 - val_accuracy: 0.1456\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 617s 989ms/step - loss: 1.9168 - accuracy: 0.3932 - val_loss: 2.6435 - val_accuracy: 0.3400\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 610s 978ms/step - loss: 1.9784 - accuracy: 0.3668 - val_loss: 4.8523 - val_accuracy: 0.2069\n",
      "Epoch 4/100\n",
      "  6/625 [..............................] - ETA: 30s - loss: 1.9013 - accuracy: 0.3385"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c251624",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed19658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\icifar10_32_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    \n",
    "num_classes = 10  # Update with the actual number of classes in your target data\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(x_train, y_train, batch_size=64, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d6e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(ds_test)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Manually generate ground truth labels for evaluation\n",
    "true_labels = []\n",
    "for _, label in ds_test:\n",
    "    true_labels.extend(label.numpy())\n",
    "\n",
    "true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Assuming you have test_loss and test_accuracy available\n",
    "# If not, you'll need to calculate them based on your model and test dataset\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e08c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13d1eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/50\n",
      "625/625 [==============================] - 53s 61ms/step - loss: 203.8366 - accuracy: 0.1258 - val_loss: 43.9520 - val_accuracy: 0.1038\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 28.3405 - accuracy: 0.1404 - val_loss: 16.8303 - val_accuracy: 0.1133\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 15.6686 - accuracy: 0.1416 - val_loss: 17.6664 - val_accuracy: 0.1268\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 12.2672 - accuracy: 0.1488 - val_loss: 13.5249 - val_accuracy: 0.1573\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 9.2341 - accuracy: 0.1548 - val_loss: 8.3344 - val_accuracy: 0.1637\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 66s 105ms/step - loss: 7.6482 - accuracy: 0.1589 - val_loss: 5.1322 - val_accuracy: 0.1730\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 54s 87ms/step - loss: 5.3921 - accuracy: 0.1675 - val_loss: 2.7296 - val_accuracy: 0.1799\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 4.8700 - accuracy: 0.1735 - val_loss: 4.4934 - val_accuracy: 0.1568\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 45s 71ms/step - loss: 3.7112 - accuracy: 0.1832 - val_loss: 3.6429 - val_accuracy: 0.1621\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 3.2924 - accuracy: 0.1828 - val_loss: 3.1712 - val_accuracy: 0.1994\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 2.8597 - accuracy: 0.1940 - val_loss: 3.0051 - val_accuracy: 0.1784\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 46s 73ms/step - loss: 2.6779 - accuracy: 0.1993 - val_loss: 2.5692 - val_accuracy: 0.2148\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 2.4830 - accuracy: 0.1997 - val_loss: 2.2710 - val_accuracy: 0.2304\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 2.3600 - accuracy: 0.2127 - val_loss: 2.2630 - val_accuracy: 0.2052\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 45s 72ms/step - loss: 2.3035 - accuracy: 0.2164 - val_loss: 2.2427 - val_accuracy: 0.2133\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 2.2106 - accuracy: 0.2273 - val_loss: 2.2347 - val_accuracy: 0.2026\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 2.1985 - accuracy: 0.2311 - val_loss: 2.1418 - val_accuracy: 0.2194\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 29s 47ms/step - loss: 2.1440 - accuracy: 0.2422 - val_loss: 2.0803 - val_accuracy: 0.2581\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 32s 52ms/step - loss: 2.1028 - accuracy: 0.2547 - val_loss: 2.0743 - val_accuracy: 0.2556\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 2.0631 - accuracy: 0.2704 - val_loss: 1.9904 - val_accuracy: 0.2804\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 2.0076 - accuracy: 0.2830 - val_loss: 2.0652 - val_accuracy: 0.2396\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 1.9444 - accuracy: 0.3040 - val_loss: 1.9867 - val_accuracy: 0.2881\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 1.8707 - accuracy: 0.3274 - val_loss: 1.8581 - val_accuracy: 0.3061\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 1.8074 - accuracy: 0.3474 - val_loss: 1.7539 - val_accuracy: 0.3461\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 1.7761 - accuracy: 0.3564 - val_loss: 1.8458 - val_accuracy: 0.3392\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 1.7340 - accuracy: 0.3721 - val_loss: 1.7445 - val_accuracy: 0.3680\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 35s 55ms/step - loss: 1.6934 - accuracy: 0.3826 - val_loss: 1.6573 - val_accuracy: 0.3894\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 1.6573 - accuracy: 0.3988 - val_loss: 1.6388 - val_accuracy: 0.4052\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 33s 52ms/step - loss: 1.6389 - accuracy: 0.4045 - val_loss: 1.7695 - val_accuracy: 0.3809\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 1.6210 - accuracy: 0.4130 - val_loss: 1.5903 - val_accuracy: 0.4130\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 1.5939 - accuracy: 0.4206 - val_loss: 1.6726 - val_accuracy: 0.4312\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.5700 - accuracy: 0.4274 - val_loss: 1.6075 - val_accuracy: 0.4174\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 44s 71ms/step - loss: 1.5595 - accuracy: 0.4327 - val_loss: 1.5194 - val_accuracy: 0.4500\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 1.5346 - accuracy: 0.4394 - val_loss: 1.4904 - val_accuracy: 0.4537\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 1.5177 - accuracy: 0.4464 - val_loss: 1.5147 - val_accuracy: 0.4488\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.5053 - accuracy: 0.4503 - val_loss: 1.5270 - val_accuracy: 0.4370\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 44s 71ms/step - loss: 1.4739 - accuracy: 0.4621 - val_loss: 1.4857 - val_accuracy: 0.4657\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 1.4747 - accuracy: 0.4622 - val_loss: 1.4921 - val_accuracy: 0.4588\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 1.4476 - accuracy: 0.4725 - val_loss: 1.4984 - val_accuracy: 0.4503\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 45s 72ms/step - loss: 1.4410 - accuracy: 0.4742 - val_loss: 1.4990 - val_accuracy: 0.4573\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 1.4190 - accuracy: 0.4808 - val_loss: 1.5836 - val_accuracy: 0.4277\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 1.4281 - accuracy: 0.4789 - val_loss: 1.4784 - val_accuracy: 0.4767\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 1.3919 - accuracy: 0.4949 - val_loss: 1.4135 - val_accuracy: 0.4997\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 1.3767 - accuracy: 0.4994 - val_loss: 1.4850 - val_accuracy: 0.4733\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 48s 78ms/step - loss: 1.3812 - accuracy: 0.4992 - val_loss: 1.4343 - val_accuracy: 0.4865\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 1.3579 - accuracy: 0.5041 - val_loss: 1.4554 - val_accuracy: 0.4752\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 1.3488 - accuracy: 0.5106 - val_loss: 1.4373 - val_accuracy: 0.4838\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 45s 73ms/step - loss: 1.3284 - accuracy: 0.5200 - val_loss: 1.3075 - val_accuracy: 0.5238\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 1.3147 - accuracy: 0.5273 - val_loss: 1.2932 - val_accuracy: 0.5218\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 1.3055 - accuracy: 0.5264 - val_loss: 1.3073 - val_accuracy: 0.5311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2338e551e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    \n",
    "num_classes = 10  \n",
    "model = keras.models.load_model(r\"C:\\Users\\shaif\\Downloads\\ciafr10_ssl.h5\")\n",
    "x = model.layers[-8].output  \n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.fit(x_train, y_train, batch_size=64, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcaeb1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 45s 71ms/step - loss: 1.3064 - accuracy: 0.5269 - val_loss: 1.4667 - val_accuracy: 0.4734\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 1.2862 - accuracy: 0.5343 - val_loss: 1.3153 - val_accuracy: 0.5336\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.2682 - accuracy: 0.5390 - val_loss: 1.3803 - val_accuracy: 0.5044\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 1.2541 - accuracy: 0.5493 - val_loss: 1.4365 - val_accuracy: 0.5098\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 40s 63ms/step - loss: 1.2464 - accuracy: 0.5505 - val_loss: 1.3416 - val_accuracy: 0.5216\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 1.2453 - accuracy: 0.5513 - val_loss: 1.3816 - val_accuracy: 0.5014\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 44s 71ms/step - loss: 1.2195 - accuracy: 0.5613 - val_loss: 1.2997 - val_accuracy: 0.5333\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 1.2085 - accuracy: 0.5671 - val_loss: 1.3568 - val_accuracy: 0.5163\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 1.2102 - accuracy: 0.5660 - val_loss: 1.3492 - val_accuracy: 0.5300\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 35s 56ms/step - loss: 1.1841 - accuracy: 0.5743 - val_loss: 1.3425 - val_accuracy: 0.5242\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 38s 60ms/step - loss: 1.1944 - accuracy: 0.5701 - val_loss: 1.3197 - val_accuracy: 0.5331\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 37s 60ms/step - loss: 1.1909 - accuracy: 0.5753 - val_loss: 1.2571 - val_accuracy: 0.5549\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 36s 58ms/step - loss: 1.1505 - accuracy: 0.5880 - val_loss: 1.3521 - val_accuracy: 0.5383\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 1.1463 - accuracy: 0.5910 - val_loss: 1.2202 - val_accuracy: 0.5686\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 1.1362 - accuracy: 0.5922 - val_loss: 1.3306 - val_accuracy: 0.5388\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 37s 59ms/step - loss: 1.1292 - accuracy: 0.5965 - val_loss: 1.2777 - val_accuracy: 0.5621\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.1231 - accuracy: 0.5982 - val_loss: 1.2492 - val_accuracy: 0.5623\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.1072 - accuracy: 0.6032 - val_loss: 1.2882 - val_accuracy: 0.5448\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 1.0936 - accuracy: 0.6117 - val_loss: 1.2395 - val_accuracy: 0.5691\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 1.0871 - accuracy: 0.6126 - val_loss: 1.1762 - val_accuracy: 0.5824\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 1.0949 - accuracy: 0.6106 - val_loss: 1.2851 - val_accuracy: 0.5542\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.0545 - accuracy: 0.6257 - val_loss: 1.2476 - val_accuracy: 0.5712\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 43s 68ms/step - loss: 1.0515 - accuracy: 0.6247 - val_loss: 1.2910 - val_accuracy: 0.5633\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 38s 61ms/step - loss: 1.0706 - accuracy: 0.6226 - val_loss: 1.3916 - val_accuracy: 0.5065\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 39s 62ms/step - loss: 1.0556 - accuracy: 0.6226 - val_loss: 1.2291 - val_accuracy: 0.5649\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 1.0561 - accuracy: 0.6227 - val_loss: 1.2496 - val_accuracy: 0.5727\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 1.0353 - accuracy: 0.6326 - val_loss: 1.2214 - val_accuracy: 0.5708\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 1.0073 - accuracy: 0.6458 - val_loss: 1.2227 - val_accuracy: 0.5612\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 1.0350 - accuracy: 0.6330 - val_loss: 1.3432 - val_accuracy: 0.5573\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 1.0059 - accuracy: 0.6460 - val_loss: 1.2882 - val_accuracy: 0.5506\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 40s 65ms/step - loss: 1.0267 - accuracy: 0.6343 - val_loss: 1.2737 - val_accuracy: 0.5720\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 0.9844 - accuracy: 0.6501 - val_loss: 1.3245 - val_accuracy: 0.5632\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 40s 63ms/step - loss: 0.9798 - accuracy: 0.6540 - val_loss: 1.2679 - val_accuracy: 0.5641\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 44s 70ms/step - loss: 1.0103 - accuracy: 0.6437 - val_loss: 1.4541 - val_accuracy: 0.5233\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.9923 - accuracy: 0.6475 - val_loss: 1.1640 - val_accuracy: 0.5976\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 0.9998 - accuracy: 0.6462 - val_loss: 1.5407 - val_accuracy: 0.5029\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.9787 - accuracy: 0.6524 - val_loss: 1.1397 - val_accuracy: 0.6013\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.9619 - accuracy: 0.6610 - val_loss: 1.2238 - val_accuracy: 0.5878\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.9341 - accuracy: 0.6700 - val_loss: 1.3841 - val_accuracy: 0.5408\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 45s 71ms/step - loss: 1.0722 - accuracy: 0.6244 - val_loss: 1.1934 - val_accuracy: 0.5785\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.9911 - accuracy: 0.6477 - val_loss: 1.1814 - val_accuracy: 0.5970\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.9440 - accuracy: 0.6642 - val_loss: 1.4789 - val_accuracy: 0.5239\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.9413 - accuracy: 0.6664 - val_loss: 1.1197 - val_accuracy: 0.6101\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.9450 - accuracy: 0.6635 - val_loss: 1.2270 - val_accuracy: 0.5888\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 37s 60ms/step - loss: 0.9160 - accuracy: 0.6762 - val_loss: 1.2397 - val_accuracy: 0.5760\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 43s 69ms/step - loss: 0.9374 - accuracy: 0.6665 - val_loss: 1.1554 - val_accuracy: 0.6078\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 40s 65ms/step - loss: 0.9425 - accuracy: 0.6663 - val_loss: 1.3283 - val_accuracy: 0.5593\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 39s 63ms/step - loss: 0.9086 - accuracy: 0.6790 - val_loss: 1.6297 - val_accuracy: 0.5051\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 42s 68ms/step - loss: 0.9176 - accuracy: 0.6767 - val_loss: 1.2298 - val_accuracy: 0.5942\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.9063 - accuracy: 0.6803 - val_loss: 1.1994 - val_accuracy: 0.5920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237a4ab7a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(x_train, y_train, batch_size=64, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fd75a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5969\n",
      "F1 Score (Micro): 0.5969\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = new_model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab04b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aaefb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9fe711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d3286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1b34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
