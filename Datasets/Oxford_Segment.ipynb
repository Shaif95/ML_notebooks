{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a475f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load Oxford Pets dataset from TFDS\n",
    "(train_ds, test_ds), info = tfds.load('oxford_iiit_pet:3.*.*', split=['train', 'test'], with_info=True)\n",
    "\n",
    "# Define preprocessing functions\n",
    "def preprocess_image(data):\n",
    "    image = tf.image.resize(data['image'], (32, 32))  # Resize image\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    label = tf.image.resize(data['segmentation_mask'], (32, 32))  # Resize label\n",
    "    label = tf.cast(label, tf.int32)  # Ensure labels are integers\n",
    "    \n",
    "    # Convert labels to one-hot categorical\n",
    "    num_classes = info.features['label'].num_classes\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    \n",
    "    # Reshape labels\n",
    "    label = tf.reshape(label, (32, 32, num_classes))  # Reshape to (32, 32, num_classes)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing to datasets\n",
    "train_ds = train_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350eb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 32, 3)\n",
      "Label shape: (32, 32, 37)\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Label shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d1c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9744cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5c0eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 25s 99ms/step - loss: 1.2329 - accuracy: 0.5305\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.9223 - accuracy: 0.5886\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 11s 100ms/step - loss: 0.8912 - accuracy: 0.5999\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8794 - accuracy: 0.6110\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8744 - accuracy: 0.6155\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 11s 98ms/step - loss: 0.8622 - accuracy: 0.6202\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8658 - accuracy: 0.6204\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8543 - accuracy: 0.6253\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 12s 101ms/step - loss: 0.8546 - accuracy: 0.6265\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8710 - accuracy: 0.6181\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.8580 - accuracy: 0.6216\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 12s 105ms/step - loss: 0.8491 - accuracy: 0.6279\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 10s 90ms/step - loss: 0.8501 - accuracy: 0.6283\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 12s 102ms/step - loss: 0.8556 - accuracy: 0.6237\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 12s 101ms/step - loss: 0.8678 - accuracy: 0.6185\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 12s 97ms/step - loss: 0.8587 - accuracy: 0.6241\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8596 - accuracy: 0.6223\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 10s 85ms/step - loss: 0.8595 - accuracy: 0.6207\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8487 - accuracy: 0.6283\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - 10s 86ms/step - loss: 0.8558 - accuracy: 0.6243\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.8650 - accuracy: 0.6182\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - 12s 108ms/step - loss: 0.8509 - accuracy: 0.6263\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - 12s 101ms/step - loss: 0.8426 - accuracy: 0.6299\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - 12s 103ms/step - loss: 0.8433 - accuracy: 0.6283\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - 13s 109ms/step - loss: 0.8479 - accuracy: 0.6286\n",
      "Epoch 26/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8628 - accuracy: 0.6197\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.8516 - accuracy: 0.6269\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8460 - accuracy: 0.6302\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.8452 - accuracy: 0.6298\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8411 - accuracy: 0.6328\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - 12s 102ms/step - loss: 0.8385 - accuracy: 0.6321\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - 10s 89ms/step - loss: 0.8407 - accuracy: 0.6334\n",
      "Epoch 33/100\n",
      "115/115 [==============================] - 12s 99ms/step - loss: 0.8409 - accuracy: 0.6328\n",
      "Epoch 34/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8446 - accuracy: 0.6306\n",
      "Epoch 35/100\n",
      "115/115 [==============================] - 11s 91ms/step - loss: 0.8451 - accuracy: 0.6299\n",
      "Epoch 36/100\n",
      "115/115 [==============================] - 10s 86ms/step - loss: 0.8460 - accuracy: 0.6293\n",
      "Epoch 37/100\n",
      "115/115 [==============================] - 11s 98ms/step - loss: 0.8594 - accuracy: 0.6184\n",
      "Epoch 38/100\n",
      "115/115 [==============================] - 12s 101ms/step - loss: 0.8679 - accuracy: 0.6159\n",
      "Epoch 39/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8655 - accuracy: 0.6141\n",
      "Epoch 40/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8659 - accuracy: 0.6144\n",
      "Epoch 41/100\n",
      "115/115 [==============================] - 11s 89ms/step - loss: 0.8544 - accuracy: 0.6225\n",
      "Epoch 00041: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edba10c970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eaeab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0541199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 5s 38ms/step - loss: 0.8985 - accuracy: 0.5988\n",
      "Test Loss: 0.898495078086853\n",
      "Test Accuracy: 0.5987706780433655\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88ad4de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU: 1.0\n",
      "Mean Dice Coefficient: 1.7932538751048765\n",
      "Mean Pixel Accuracy: 0.5804755106125647\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f67d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\oxf_32_model.h5\")\n",
    "    \n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.layers[-4].output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20538483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 17s 94ms/step - loss: 1.0449 - accuracy: 0.5741\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.9010 - accuracy: 0.5994\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 12s 101ms/step - loss: 0.9052 - accuracy: 0.6057\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.9077 - accuracy: 0.5928\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.9280 - accuracy: 0.5998\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 9s 76ms/step - loss: 0.9049 - accuracy: 0.6066\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8972 - accuracy: 0.6072\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8860 - accuracy: 0.6079\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.9062 - accuracy: 0.6037\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 12s 102ms/step - loss: 0.9165 - accuracy: 0.5920\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.9365 - accuracy: 0.5858\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.9218 - accuracy: 0.5879\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 11s 91ms/step - loss: 0.9050 - accuracy: 0.5947\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 11s 99ms/step - loss: 0.9024 - accuracy: 0.5997\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 11s 89ms/step - loss: 0.8967 - accuracy: 0.6034\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 12s 101ms/step - loss: 0.8950 - accuracy: 0.5993\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.8989 - accuracy: 0.6071\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.9189 - accuracy: 0.5921\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1f9a88160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462272ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "496dfc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 6s 36ms/step - loss: 1.4048 - accuracy: 0.5843\n",
      "Test Loss: 1.4048324823379517\n",
      "Test Accuracy: 0.5842569470405579\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b9b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd487aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\rnd_32_model.h5\")\n",
    "    \n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.layers[-4].output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e76b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2960f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 16s 95ms/step - loss: 1.0902 - accuracy: 0.5686\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8914 - accuracy: 0.6006\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 10s 86ms/step - loss: 0.9031 - accuracy: 0.6096\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.9010 - accuracy: 0.6006\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.9058 - accuracy: 0.5953\n",
      "Epoch 6/100\n",
      " 82/115 [====================>.........] - ETA: 3s - loss: 0.9401 - accuracy: 0.5894"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d046a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83c7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26515e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa87ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81685401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cb67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
