{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a475f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load Oxford Pets dataset from TFDS\n",
    "(train_ds, test_ds), info = tfds.load('oxford_iiit_pet:3.*.*', split=['train', 'test'], with_info=True)\n",
    "\n",
    "# Define preprocessing functions\n",
    "def preprocess_image(data):\n",
    "    image = tf.image.resize(data['image'], (32, 32))  # Resize image\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    label = tf.image.resize(data['segmentation_mask'], (32, 32))  # Resize label\n",
    "    label = tf.cast(label, tf.int32)  # Ensure labels are integers\n",
    "    \n",
    "    # Convert labels to one-hot categorical\n",
    "    num_classes = info.features['label'].num_classes\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    \n",
    "    # Reshape labels\n",
    "    label = tf.reshape(label, (32, 32, num_classes))  # Reshape to (32, 32, num_classes)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing to datasets\n",
    "train_ds = train_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350eb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 32, 3)\n",
      "Label shape: (32, 32, 37)\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Label shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d1c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9744cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c0eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 26s 101ms/step - loss: 1.2500 - accuracy: 0.5311\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.9253 - accuracy: 0.5891\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 12s 99ms/step - loss: 0.9004 - accuracy: 0.5989\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8929 - accuracy: 0.6051\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 11s 100ms/step - loss: 0.8814 - accuracy: 0.6123\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8689 - accuracy: 0.6178\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 10s 90ms/step - loss: 0.8602 - accuracy: 0.6226\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8539 - accuracy: 0.6264\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 8s 71ms/step - loss: 0.8532 - accuracy: 0.6281\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 12s 108ms/step - loss: 0.8514 - accuracy: 0.6279\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 9s 79ms/step - loss: 0.8541 - accuracy: 0.6283\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8542 - accuracy: 0.6285\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 9s 81ms/step - loss: 0.8582 - accuracy: 0.6286\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 10s 83ms/step - loss: 0.8488 - accuracy: 0.6302\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 9s 79ms/step - loss: 0.8444 - accuracy: 0.6322\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 11s 98ms/step - loss: 0.8463 - accuracy: 0.6319\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 11s 96ms/step - loss: 0.8487 - accuracy: 0.6312\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 12s 102ms/step - loss: 0.8541 - accuracy: 0.6307\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - 12s 102ms/step - loss: 0.8615 - accuracy: 0.6243\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - 10s 85ms/step - loss: 0.8534 - accuracy: 0.6273\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - 12s 106ms/step - loss: 0.8465 - accuracy: 0.6317\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8440 - accuracy: 0.6316\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8425 - accuracy: 0.6327\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8523 - accuracy: 0.6285\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - 13s 107ms/step - loss: 0.8551 - accuracy: 0.6254\n",
      "Epoch 26/100\n",
      "115/115 [==============================] - 12s 102ms/step - loss: 0.8475 - accuracy: 0.6303\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - 9s 72ms/step - loss: 0.8456 - accuracy: 0.6330\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - 8s 73ms/step - loss: 0.8500 - accuracy: 0.6279\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - 11s 99ms/step - loss: 0.8505 - accuracy: 0.6277\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.8411 - accuracy: 0.6325\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8430 - accuracy: 0.6328\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - 12s 101ms/step - loss: 0.8399 - accuracy: 0.6342\n",
      "Epoch 33/100\n",
      " 73/115 [==================>...........] - ETA: 3s - loss: 0.8483 - accuracy: 0.6337"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eaeab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0541199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad4de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\oxf_32_model.h5\")\n",
    "    \n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.layers[-4].output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b6638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20538483",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462272ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496dfc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b9b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd487aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\rnd_32_model.h5\")\n",
    "    \n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.layers[-4].output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e76b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe344e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d046a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e320c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db5f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3cef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b7947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cb67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
