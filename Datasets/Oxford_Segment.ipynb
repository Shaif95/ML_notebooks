{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a475f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load Oxford Pets dataset from TFDS\n",
    "(train_ds, test_ds), info = tfds.load('oxford_iiit_pet:3.*.*', split=['train', 'test'], with_info=True)\n",
    "\n",
    "# Define preprocessing functions\n",
    "def preprocess_image(data):\n",
    "    image = tf.image.resize(data['image'], (32, 32))  # Resize image\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    label = tf.image.resize(data['segmentation_mask'], (32, 32))  # Resize label\n",
    "    label = tf.cast(label, tf.int32)  # Ensure labels are integers\n",
    "    \n",
    "    # Convert labels to one-hot categorical\n",
    "    num_classes = info.features['label'].num_classes\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    \n",
    "    # Reshape labels\n",
    "    label = tf.reshape(label, (32, 32, num_classes))  # Reshape to (32, 32, num_classes)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing to datasets\n",
    "train_ds = train_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350eb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 32, 3)\n",
      "Label shape: (32, 32, 37)\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Label shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d1c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9744cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5c0eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 15s 93ms/step - loss: 1.2946 - accuracy: 0.5301\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.9293 - accuracy: 0.5855\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8935 - accuracy: 0.6028\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8849 - accuracy: 0.6097\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8801 - accuracy: 0.6155\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 10s 87ms/step - loss: 0.8822 - accuracy: 0.6090\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8759 - accuracy: 0.6115\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 11s 98ms/step - loss: 0.8650 - accuracy: 0.6210\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 11s 98ms/step - loss: 0.8500 - accuracy: 0.6291\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8470 - accuracy: 0.6303\n",
      "Epoch 11/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8503 - accuracy: 0.6292\n",
      "Epoch 12/100\n",
      "115/115 [==============================] - 11s 89ms/step - loss: 0.8589 - accuracy: 0.6241\n",
      "Epoch 13/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8472 - accuracy: 0.6306\n",
      "Epoch 14/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8416 - accuracy: 0.6320\n",
      "Epoch 15/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8397 - accuracy: 0.6316\n",
      "Epoch 16/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8417 - accuracy: 0.6327\n",
      "Epoch 17/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8474 - accuracy: 0.6306\n",
      "Epoch 18/100\n",
      "115/115 [==============================] - 10s 85ms/step - loss: 0.8482 - accuracy: 0.6312\n",
      "Epoch 19/100\n",
      "115/115 [==============================] - 11s 98ms/step - loss: 0.8425 - accuracy: 0.6324\n",
      "Epoch 20/100\n",
      "115/115 [==============================] - 10s 83ms/step - loss: 0.8402 - accuracy: 0.6338\n",
      "Epoch 21/100\n",
      "115/115 [==============================] - 10s 87ms/step - loss: 0.8415 - accuracy: 0.6333\n",
      "Epoch 22/100\n",
      "115/115 [==============================] - 10s 88ms/step - loss: 0.8423 - accuracy: 0.6329\n",
      "Epoch 23/100\n",
      "115/115 [==============================] - 10s 85ms/step - loss: 0.8396 - accuracy: 0.6335\n",
      "Epoch 24/100\n",
      "115/115 [==============================] - 10s 87ms/step - loss: 0.8426 - accuracy: 0.6328\n",
      "Epoch 25/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8402 - accuracy: 0.6330\n",
      "Epoch 26/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8428 - accuracy: 0.6333\n",
      "Epoch 27/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8408 - accuracy: 0.6340\n",
      "Epoch 28/100\n",
      "115/115 [==============================] - 12s 99ms/step - loss: 0.8385 - accuracy: 0.6342\n",
      "Epoch 29/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8398 - accuracy: 0.6342\n",
      "Epoch 30/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8403 - accuracy: 0.6336\n",
      "Epoch 31/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8376 - accuracy: 0.6342\n",
      "Epoch 32/100\n",
      "115/115 [==============================] - 11s 92ms/step - loss: 0.8404 - accuracy: 0.6343\n",
      "Epoch 33/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8540 - accuracy: 0.6301\n",
      "Epoch 34/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8507 - accuracy: 0.6279\n",
      "Epoch 35/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8426 - accuracy: 0.6328\n",
      "Epoch 36/100\n",
      "115/115 [==============================] - 10s 91ms/step - loss: 0.8395 - accuracy: 0.6333\n",
      "Epoch 37/100\n",
      "115/115 [==============================] - 12s 103ms/step - loss: 0.8367 - accuracy: 0.6347\n",
      "Epoch 38/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8381 - accuracy: 0.6351\n",
      "Epoch 39/100\n",
      "115/115 [==============================] - 11s 99ms/step - loss: 0.8359 - accuracy: 0.6356\n",
      "Epoch 40/100\n",
      "115/115 [==============================] - 11s 95ms/step - loss: 0.8346 - accuracy: 0.6359\n",
      "Epoch 41/100\n",
      "115/115 [==============================] - 11s 100ms/step - loss: 0.8341 - accuracy: 0.6357\n",
      "Epoch 42/100\n",
      "115/115 [==============================] - 11s 94ms/step - loss: 0.8343 - accuracy: 0.6355\n",
      "Epoch 43/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8363 - accuracy: 0.6360\n",
      "Epoch 44/100\n",
      "115/115 [==============================] - 10s 89ms/step - loss: 0.8425 - accuracy: 0.6345\n",
      "Epoch 45/100\n",
      "115/115 [==============================] - 10s 89ms/step - loss: 0.8370 - accuracy: 0.6346\n",
      "Epoch 46/100\n",
      "115/115 [==============================] - 11s 97ms/step - loss: 0.8439 - accuracy: 0.6329\n",
      "Epoch 47/100\n",
      "115/115 [==============================] - 11s 91ms/step - loss: 0.8384 - accuracy: 0.6335\n",
      "Epoch 48/100\n",
      "115/115 [==============================] - 11s 93ms/step - loss: 0.8372 - accuracy: 0.6339\n",
      "Epoch 49/100\n",
      "115/115 [==============================] - 9s 76ms/step - loss: 0.8390 - accuracy: 0.6340\n",
      "Epoch 50/100\n",
      "115/115 [==============================] - 10s 91ms/step - loss: 0.9149 - accuracy: 0.5984\n",
      "Epoch 51/100\n",
      "115/115 [==============================] - 10s 89ms/step - loss: 0.9262 - accuracy: 0.5873\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f236184580>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eaeab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0541199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 9s 67ms/step - loss: 0.9845 - accuracy: 0.5411\n",
      "Test Loss: 0.9845007658004761\n",
      "Test Accuracy: 0.5410877466201782\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad4de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f67d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\oxf_32_model.h5\")\n",
    "    \n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.layers[-4].output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20538483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 15s 92ms/step - loss: 1.0559 - accuracy: 0.5731\n",
      "Epoch 2/100\n",
      " 98/115 [========================>.....] - ETA: 1s - loss: 0.9041 - accuracy: 0.6021"
     ]
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462272ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496dfc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b9b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd487aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import keras\n",
    "\n",
    "def create_segmentation_model(input_shape, num_classes):\n",
    "    # Load ResNet50 backbone\n",
    "    resnet50_base = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\rnd_32_model.h5\")\n",
    "    \n",
    "    # Add segmentation-specific layers on top of ResNet50\n",
    "    x = resnet50_base.layers[-4].output\n",
    "    x = tf.keras.layers.UpSampling2D(size=(32, 32))(x)  # Upsample to match original image size\n",
    "    x = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), activation='softmax')(x)\n",
    "\n",
    "    # Create segmentation model\n",
    "    model = tf.keras.models.Model(inputs=resnet50_base.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "input_shape = (32, 32, 3)  # Adjust input shape as per your dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "model = create_segmentation_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e76b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e233796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(patience=10, monitor='loss', verbose=1)\n",
    "model.fit(train_ds.batch(32), epochs=100,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(test_ds.batch(32))\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d046a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43162392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53edaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dda0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780879d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cb67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
