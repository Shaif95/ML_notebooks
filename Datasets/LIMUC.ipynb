{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14666713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (9590, 32, 32, 3)\n",
      "Shape of Y_train_categorical: (9590, 4)\n",
      "Shape of X_test: (1686, 32, 32, 3)\n",
      "Shape of Y_test_categorical: (1686, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the paths to your dataset folders\n",
    "train_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\train_and_validation_sets\\train_and_validation_sets\"\n",
    "test_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\test_set\\test_set\"\n",
    "\n",
    "# Initialize empty lists for X_train, Y_train, X_test, and Y_test\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# Initialize an empty list to store categorical labels\n",
    "categorical_labels = []\n",
    "\n",
    "# Define a function to read and preprocess images\n",
    "def process_images(folder_path, label, is_train_set=True):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".bmp\"):  # Check if it's a file and ends with .bmp\n",
    "            # Open and resize the image to (32, 32, 3)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((32, 32))\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "            # Convert image data to a NumPy array\n",
    "            img_array = np.array(img).astype('float32')  # Convert to float\n",
    "            \n",
    "            # Normalize the image data (optional)\n",
    "            img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "            \n",
    "            # Append the image data to the appropriate list\n",
    "            if is_train_set:\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(label)  # Append the numerical label\n",
    "            else:\n",
    "                X_test.append(img_array)\n",
    "                Y_test.append(label)  # Append the numerical label\n",
    "            \n",
    "            # Append the label for categorical encoding\n",
    "            categorical_labels.append(label)  # Append the numerical label\n",
    "\n",
    "# List the folders inside the training dataset directory\n",
    "train_folders = os.listdir(train_dataset_dir)\n",
    "\n",
    "# Create a label encoder for categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through the training folders and process images\n",
    "for label, folder_name in enumerate(train_folders):\n",
    "    folder_path = os.path.join(train_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label)\n",
    "\n",
    "# List the folders inside the test dataset directory\n",
    "test_folders = os.listdir(test_dataset_dir)\n",
    "\n",
    "# Loop through the test folders and process images\n",
    "for label, folder_name in enumerate(test_folders):\n",
    "    folder_path = os.path.join(test_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label, is_train_set=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Encode Y_train and Y_test categorically\n",
    "num_classes = len(np.unique(categorical_labels))\n",
    "  # Update this to match the number of classes\n",
    "\n",
    "# Convert Y_train and Y_test to NumPy arrays\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Make sure your labels are integers ranging from 0 to num_classes - 1\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "# One-hot encode the labels\n",
    "Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# # Encode Y_train and Y_test categorically using the label encoder\n",
    "# num_classes = len(np.unique(Y_train))  # Automatically determine the number of classes\n",
    "# Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "# Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Check the shape of X_train, Y_train_categorical, X_test, and Y_test_categorical\n",
    "print(\"Shape of X_train:\", np.shape(X_train))\n",
    "print(\"Shape of Y_train_categorical:\", np.shape(Y_train_categorical))\n",
    "print(\"Shape of X_test:\", np.shape(X_test))\n",
    "print(\"Shape of Y_test_categorical:\", np.shape(Y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4596ee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_and_validation_sets']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96837b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df1def5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_11  (None, 2048)             0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 8196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,595,908\n",
      "Trainable params: 23,542,788\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Change units to match the number of classes\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30e7cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 14s 62ms/step - loss: 0.8970 - accuracy: 0.6856 - val_loss: 77.4025 - val_accuracy: 0.0501\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5434 - accuracy: 0.7363 - val_loss: 7.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5167 - accuracy: 0.7561 - val_loss: 7.4836 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.5515 - accuracy: 0.7407 - val_loss: 14.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5609 - accuracy: 0.7329 - val_loss: 9.1021 - val_accuracy: 5.2138e-04\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.5550 - accuracy: 0.7277 - val_loss: 9.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.5719 - accuracy: 0.7323 - val_loss: 9.6457 - val_accuracy: 5.2138e-04\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5112 - accuracy: 0.7600 - val_loss: 9.9065 - val_accuracy: 0.0036\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5600 - accuracy: 0.7323 - val_loss: 85.8176 - val_accuracy: 5.2138e-04\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5050 - accuracy: 0.7531 - val_loss: 9.4616 - val_accuracy: 0.0073\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.4992 - accuracy: 0.7509 - val_loss: 9.2974 - val_accuracy: 0.0125\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.4839 - accuracy: 0.7633 - val_loss: 10.7873 - val_accuracy: 0.0151\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.4778 - accuracy: 0.7685 - val_loss: 11.8993 - val_accuracy: 0.0036\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.4685 - accuracy: 0.7699 - val_loss: 12.5885 - val_accuracy: 0.0292\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.4649 - accuracy: 0.7766 - val_loss: 10.2905 - val_accuracy: 0.0318\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.4654 - accuracy: 0.7782 - val_loss: 9.8073 - val_accuracy: 0.0073\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.4466 - accuracy: 0.7874 - val_loss: 11.2948 - val_accuracy: 0.0141\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.4267 - accuracy: 0.7982 - val_loss: 10.8538 - val_accuracy: 0.0255\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.4472 - accuracy: 0.7947 - val_loss: 182.3582 - val_accuracy: 0.0125\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.4806 - accuracy: 0.7805 - val_loss: 10.7683 - val_accuracy: 0.0214\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.4199 - accuracy: 0.8032 - val_loss: 10.7241 - val_accuracy: 0.0104\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.4164 - accuracy: 0.8070 - val_loss: 10.7478 - val_accuracy: 0.0255\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.3735 - accuracy: 0.8281 - val_loss: 11.8244 - val_accuracy: 0.0224\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.3427 - accuracy: 0.8465 - val_loss: 10.0548 - val_accuracy: 0.0188\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3174 - accuracy: 0.8545 - val_loss: 12.0365 - val_accuracy: 0.0370\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.2938 - accuracy: 0.8668 - val_loss: 14.3161 - val_accuracy: 0.0104\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.2685 - accuracy: 0.8792 - val_loss: 11.6680 - val_accuracy: 0.0198\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.2461 - accuracy: 0.8917 - val_loss: 15.4490 - val_accuracy: 0.0391\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.2319 - accuracy: 0.8972 - val_loss: 12.4837 - val_accuracy: 0.0188\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.1962 - accuracy: 0.9166 - val_loss: 14.9777 - val_accuracy: 0.0313\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.1861 - accuracy: 0.9198 - val_loss: 18.4279 - val_accuracy: 0.0375\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.1735 - accuracy: 0.9251 - val_loss: 13.8950 - val_accuracy: 0.0323\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.1621 - accuracy: 0.9350 - val_loss: 16.7938 - val_accuracy: 0.0229\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.1578 - accuracy: 0.9380 - val_loss: 12.9008 - val_accuracy: 0.0235\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.1414 - accuracy: 0.9454 - val_loss: 14.7763 - val_accuracy: 0.0224\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.1894 - accuracy: 0.9300 - val_loss: 29.8464 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.1926 - accuracy: 0.9271 - val_loss: 32.0129 - val_accuracy: 0.0104\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 7s 54ms/step - loss: 0.1111 - accuracy: 0.9600 - val_loss: 21.0028 - val_accuracy: 0.0146\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0943 - accuracy: 0.9647 - val_loss: 13.3033 - val_accuracy: 0.0193\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0830 - accuracy: 0.9718 - val_loss: 15.6380 - val_accuracy: 0.0141\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0924 - accuracy: 0.9651 - val_loss: 13.9069 - val_accuracy: 0.0156\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0682 - accuracy: 0.9763 - val_loss: 15.5741 - val_accuracy: 0.0162\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0797 - accuracy: 0.9715 - val_loss: 24.7544 - val_accuracy: 0.0068\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.0781 - accuracy: 0.9702 - val_loss: 12.9044 - val_accuracy: 0.0198\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0685 - accuracy: 0.9738 - val_loss: 16.8309 - val_accuracy: 0.0360\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.0577 - accuracy: 0.9802 - val_loss: 31.3626 - val_accuracy: 0.0068\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0615 - accuracy: 0.9775 - val_loss: 15.0134 - val_accuracy: 0.0146\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0505 - accuracy: 0.9812 - val_loss: 20.3509 - val_accuracy: 0.0308\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.0524 - accuracy: 0.9814 - val_loss: 19.0587 - val_accuracy: 0.0109\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.0511 - accuracy: 0.9806 - val_loss: 14.0717 - val_accuracy: 0.0266\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 32.9043 - val_accuracy: 0.0120\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 0.0541 - accuracy: 0.9801 - val_loss: 14.0796 - val_accuracy: 0.0308\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 6s 48ms/step - loss: 0.0504 - accuracy: 0.9806 - val_loss: 13.3227 - val_accuracy: 0.0271\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0440 - accuracy: 0.9851 - val_loss: 17.8036 - val_accuracy: 0.0308\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 13.9701 - val_accuracy: 0.0250\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0410 - accuracy: 0.9838 - val_loss: 16.5448 - val_accuracy: 0.0266\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0527 - accuracy: 0.9814 - val_loss: 15.8379 - val_accuracy: 0.0360\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.0402 - accuracy: 0.9849 - val_loss: 16.1822 - val_accuracy: 0.0282\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0390 - accuracy: 0.9863 - val_loss: 18.3845 - val_accuracy: 0.0323\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0432 - accuracy: 0.9838 - val_loss: 20.9187 - val_accuracy: 0.0146\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.0549 - accuracy: 0.9798 - val_loss: 15.2083 - val_accuracy: 0.0276\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0326 - accuracy: 0.9885 - val_loss: 16.5366 - val_accuracy: 0.0188\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0327 - accuracy: 0.9892 - val_loss: 14.7296 - val_accuracy: 0.0177\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 22.2332 - val_accuracy: 0.0156\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 19.1837 - val_accuracy: 0.0167\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0378 - accuracy: 0.9879 - val_loss: 34.0176 - val_accuracy: 0.0209\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0322 - accuracy: 0.9892 - val_loss: 15.6517 - val_accuracy: 0.0297\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0379 - accuracy: 0.9862 - val_loss: 17.1987 - val_accuracy: 0.0282\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0292 - accuracy: 0.9884 - val_loss: 18.2628 - val_accuracy: 0.0339\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 20.1747 - val_accuracy: 0.0219\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 16.0992 - val_accuracy: 0.0167\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 18.2342 - val_accuracy: 0.0078\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0329 - accuracy: 0.9883 - val_loss: 26.6967 - val_accuracy: 0.0417\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0373 - accuracy: 0.9861 - val_loss: 16.0583 - val_accuracy: 0.0193\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0331 - accuracy: 0.9876 - val_loss: 17.0010 - val_accuracy: 0.0235\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 16.7571 - val_accuracy: 0.0250\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 16.3425 - val_accuracy: 0.0240\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 16.8843 - val_accuracy: 0.0276\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 17.2223 - val_accuracy: 0.0271\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 18.7110 - val_accuracy: 0.0172\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.0434 - accuracy: 0.9867 - val_loss: 19.1442 - val_accuracy: 0.0198\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 18.6256 - val_accuracy: 0.0323\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 20.1850 - val_accuracy: 0.0318\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.0288 - accuracy: 0.9889 - val_loss: 15.5104 - val_accuracy: 0.0235\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 17.7191 - val_accuracy: 0.0214\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 17.6045 - val_accuracy: 0.0292\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.0230 - accuracy: 0.9900 - val_loss: 18.3425 - val_accuracy: 0.0172\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 5s 46ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 18.4726 - val_accuracy: 0.0261\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 18.5587 - val_accuracy: 0.0203\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0209 - accuracy: 0.9923 - val_loss: 23.0945 - val_accuracy: 0.0323\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0266 - accuracy: 0.9900 - val_loss: 17.5518 - val_accuracy: 0.0360\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 19.7883 - val_accuracy: 0.0177\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0251 - accuracy: 0.9900 - val_loss: 17.7274 - val_accuracy: 0.0365\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 17.7447 - val_accuracy: 0.0109\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 22.0954 - val_accuracy: 0.0266\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 17.1412 - val_accuracy: 0.0328\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 17.7502 - val_accuracy: 0.0177\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 6s 49ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 18.3948 - val_accuracy: 0.0099\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 17.8394 - val_accuracy: 0.0360\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 18.3502 - val_accuracy: 0.0224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2861c053d60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c9a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba630814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 22ms/step - loss: 4.7276 - accuracy: 0.5824\n",
      "27/27 [==============================] - 2s 23ms/step\n",
      "Test Loss: 4.727602481842041\n",
      "Test Accuracy: 0.5824436545372009\n",
      "Accuracy: 0.5824436536180309\n",
      "F1 Score: 0.5196370738142837\n",
      "Balanced Accuracy: 0.31803588070829447\n",
      "Cohen Kappa Score:\n",
      "0.2170779668872913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(\"Cohen Kappa Score:\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf79af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3add546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 19s 88ms/step - loss: 0.7508 - accuracy: 0.7135 - val_loss: 29.1215 - val_accuracy: 0.0255\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 7s 54ms/step - loss: 0.5469 - accuracy: 0.7449 - val_loss: 18.4478 - val_accuracy: 0.0255\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.5527 - accuracy: 0.7499 - val_loss: 400.8427 - val_accuracy: 0.0245\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.5307 - accuracy: 0.7563 - val_loss: 9.4444 - val_accuracy: 0.0271\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5172 - accuracy: 0.7587 - val_loss: 12.0613 - val_accuracy: 0.0501\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.5254 - accuracy: 0.7543 - val_loss: 12.4562 - val_accuracy: 0.0443\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5375 - accuracy: 0.7581 - val_loss: 10.6288 - val_accuracy: 0.0156\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.5355 - accuracy: 0.7593 - val_loss: 303.0681 - val_accuracy: 0.0078\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5124 - accuracy: 0.7566 - val_loss: 20.6176 - val_accuracy: 0.0198\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5089 - accuracy: 0.7606 - val_loss: 11.5556 - val_accuracy: 0.0365\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5518 - accuracy: 0.7374 - val_loss: 11.6802 - val_accuracy: 0.0428\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5582 - accuracy: 0.7437 - val_loss: 158.3419 - val_accuracy: 0.0198\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5789 - accuracy: 0.7384 - val_loss: 11.2791 - val_accuracy: 0.0344\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 7s 54ms/step - loss: 0.5062 - accuracy: 0.7553 - val_loss: 12.1398 - val_accuracy: 0.0313\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 7s 54ms/step - loss: 0.4964 - accuracy: 0.7578 - val_loss: 10.9227 - val_accuracy: 0.0318\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.4790 - accuracy: 0.7651 - val_loss: 10.9904 - val_accuracy: 0.0448\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4797 - accuracy: 0.7709 - val_loss: 10.1237 - val_accuracy: 0.0235\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.4898 - accuracy: 0.7664 - val_loss: 10.9308 - val_accuracy: 0.0188\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.4726 - accuracy: 0.7762 - val_loss: 11.5971 - val_accuracy: 0.0334\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4635 - accuracy: 0.7758 - val_loss: 64272.4648 - val_accuracy: 0.0501\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5433 - accuracy: 0.7538 - val_loss: 15.2840 - val_accuracy: 0.0261\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.5061 - accuracy: 0.7508 - val_loss: 28.4521 - val_accuracy: 0.0469\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.5442 - accuracy: 0.7267 - val_loss: 24.9147 - val_accuracy: 0.0417\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.5364 - accuracy: 0.7318 - val_loss: 602.5223 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.5241 - accuracy: 0.7479 - val_loss: 12.1752 - val_accuracy: 0.0266\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.4868 - accuracy: 0.7623 - val_loss: 11.8553 - val_accuracy: 0.0318\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.4835 - accuracy: 0.7621 - val_loss: 11.2262 - val_accuracy: 0.0240\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.4837 - accuracy: 0.7638 - val_loss: 12.0928 - val_accuracy: 0.0287\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.4927 - accuracy: 0.7679 - val_loss: 14.3788 - val_accuracy: 0.0078\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.4976 - accuracy: 0.7612 - val_loss: 10.8079 - val_accuracy: 0.0271\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.5401 - accuracy: 0.7473 - val_loss: 769.1617 - val_accuracy: 0.0151\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.5215 - accuracy: 0.7467 - val_loss: 27.5273 - val_accuracy: 0.0036\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.5415 - accuracy: 0.7518 - val_loss: 13.0600 - val_accuracy: 0.0412\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.5033 - accuracy: 0.7572 - val_loss: 13.7354 - val_accuracy: 0.0276\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.4936 - accuracy: 0.7643 - val_loss: 11.5601 - val_accuracy: 0.0266\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.4810 - accuracy: 0.7701 - val_loss: 11.3476 - val_accuracy: 0.0177\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.4786 - accuracy: 0.7719 - val_loss: 10.1558 - val_accuracy: 0.0104\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.4678 - accuracy: 0.7818 - val_loss: 12.2420 - val_accuracy: 0.0313\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.5041 - accuracy: 0.7642 - val_loss: 233029.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5496 - accuracy: 0.7297 - val_loss: 40.3419 - val_accuracy: 0.0365\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5092 - accuracy: 0.7504 - val_loss: 15.6333 - val_accuracy: 0.0370\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5273 - accuracy: 0.7555 - val_loss: 15.3785 - val_accuracy: 0.0412\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5051 - accuracy: 0.7602 - val_loss: 11.5874 - val_accuracy: 0.0052\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.4907 - accuracy: 0.7690 - val_loss: 12.3883 - val_accuracy: 0.0334\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.4864 - accuracy: 0.7705 - val_loss: 12.1122 - val_accuracy: 0.0188\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.4937 - accuracy: 0.7770 - val_loss: 12.5045 - val_accuracy: 0.0328\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.4925 - accuracy: 0.7720 - val_loss: 12.3521 - val_accuracy: 0.0266\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.4713 - accuracy: 0.7759 - val_loss: 12.5745 - val_accuracy: 0.0099\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.4821 - accuracy: 0.7728 - val_loss: 173.3017 - val_accuracy: 0.0021\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.4724 - accuracy: 0.7788 - val_loss: 14.1876 - val_accuracy: 0.0407\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.4702 - accuracy: 0.7858 - val_loss: 13.3138 - val_accuracy: 0.0396\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5002 - accuracy: 0.7870 - val_loss: 14.9040 - val_accuracy: 0.0365\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.4651 - accuracy: 0.7901 - val_loss: 14.7643 - val_accuracy: 0.0276\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.4899 - accuracy: 0.7834 - val_loss: 1541.2113 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5314 - accuracy: 0.7662 - val_loss: 14.7104 - val_accuracy: 0.0391\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.4679 - accuracy: 0.7755 - val_loss: 15.0545 - val_accuracy: 0.0480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.4843 - accuracy: 0.7761 - val_loss: 15.2531 - val_accuracy: 0.0396\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.4342 - accuracy: 0.7960 - val_loss: 21.6545 - val_accuracy: 0.0115\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.4470 - accuracy: 0.7907 - val_loss: 12.0982 - val_accuracy: 0.0214\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 6s 50ms/step - loss: 0.4054 - accuracy: 0.8126 - val_loss: 12.8923 - val_accuracy: 0.0302\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.3834 - accuracy: 0.8253 - val_loss: 12.7548 - val_accuracy: 0.0193\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.3538 - accuracy: 0.8410 - val_loss: 13.8214 - val_accuracy: 0.0151\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.3344 - accuracy: 0.8526 - val_loss: 15.1009 - val_accuracy: 0.0328\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.3041 - accuracy: 0.8661 - val_loss: 15.0193 - val_accuracy: 0.0339\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.2829 - accuracy: 0.8725 - val_loss: 16.2627 - val_accuracy: 0.0245\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.3007 - accuracy: 0.8715 - val_loss: 15.7402 - val_accuracy: 0.0282\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.3727 - accuracy: 0.8397 - val_loss: 20.6958 - val_accuracy: 0.0464\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5743 - accuracy: 0.7233 - val_loss: 22.3401 - val_accuracy: 0.0386\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5854 - accuracy: 0.7278 - val_loss: 27.8765 - val_accuracy: 0.0412\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5109 - accuracy: 0.7538 - val_loss: 14.9631 - val_accuracy: 0.0209\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.4884 - accuracy: 0.7750 - val_loss: 17.3357 - val_accuracy: 0.0245\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.4546 - accuracy: 0.7836 - val_loss: 19.9301 - val_accuracy: 0.0443\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.4077 - accuracy: 0.8124 - val_loss: 18.5288 - val_accuracy: 0.0172\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.3704 - accuracy: 0.8341 - val_loss: 17.2033 - val_accuracy: 0.0287\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 6s 48ms/step - loss: 0.3261 - accuracy: 0.8581 - val_loss: 19.7740 - val_accuracy: 0.0094\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 6s 48ms/step - loss: 0.2865 - accuracy: 0.8755 - val_loss: 21.0271 - val_accuracy: 0.0172\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.2592 - accuracy: 0.8903 - val_loss: 20.7451 - val_accuracy: 0.0198\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.2602 - accuracy: 0.8899 - val_loss: 24.8695 - val_accuracy: 0.0292\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.2036 - accuracy: 0.9151 - val_loss: 24.6126 - val_accuracy: 0.0334\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.1750 - accuracy: 0.9265 - val_loss: 25.8834 - val_accuracy: 0.0235\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.1513 - accuracy: 0.9377 - val_loss: 26.9485 - val_accuracy: 0.0297\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 6s 49ms/step - loss: 0.1377 - accuracy: 0.9466 - val_loss: 27.0456 - val_accuracy: 0.0146\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.1284 - accuracy: 0.9459 - val_loss: 24.5275 - val_accuracy: 0.0318\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.1030 - accuracy: 0.9591 - val_loss: 25.2247 - val_accuracy: 0.0229\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0965 - accuracy: 0.9647 - val_loss: 28.4646 - val_accuracy: 0.0302\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0989 - accuracy: 0.9605 - val_loss: 23.8366 - val_accuracy: 0.0287\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0840 - accuracy: 0.9666 - val_loss: 27.1579 - val_accuracy: 0.0224\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0767 - accuracy: 0.9724 - val_loss: 23.7366 - val_accuracy: 0.0287\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0811 - accuracy: 0.9683 - val_loss: 29.7649 - val_accuracy: 0.0209\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0654 - accuracy: 0.9746 - val_loss: 27.4139 - val_accuracy: 0.0255\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0737 - accuracy: 0.9729 - val_loss: 25.5130 - val_accuracy: 0.0271\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0628 - accuracy: 0.9778 - val_loss: 27.3327 - val_accuracy: 0.0198\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.0604 - accuracy: 0.9781 - val_loss: 24.7949 - val_accuracy: 0.0318\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0584 - accuracy: 0.9772 - val_loss: 24.9306 - val_accuracy: 0.0355\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0546 - accuracy: 0.9807 - val_loss: 23.5310 - val_accuracy: 0.0172\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0604 - accuracy: 0.9760 - val_loss: 26.8341 - val_accuracy: 0.0172\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0429 - accuracy: 0.9847 - val_loss: 27.9573 - val_accuracy: 0.0318\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.0440 - accuracy: 0.9853 - val_loss: 28.7208 - val_accuracy: 0.0302\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0401 - accuracy: 0.9831 - val_loss: 30.3746 - val_accuracy: 0.0235\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.0447 - accuracy: 0.9829 - val_loss: 27.1405 - val_accuracy: 0.0282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2864dbc8550>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"C:\\Users\\shaif\\Downloads\\LIMUC_32_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "394bdf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 31ms/step - loss: 6.1165 - accuracy: 0.5652\n",
      "27/27 [==============================] - 2s 27ms/step\n",
      "Test Loss: 6.116485118865967\n",
      "Test Accuracy: 0.5652431845664978\n",
      "Accuracy: 0.5652431791221827\n",
      "F1 Score: 0.5180683586315646\n",
      "Balanced Accuracy: 0.327920549860205\n",
      "Cohen Kappa Score:\n",
      "0.21644955920001474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = new_model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(\"Cohen Kappa Score:\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d9482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a65728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2399a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f8666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
