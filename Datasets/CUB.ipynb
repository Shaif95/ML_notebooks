{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aed39a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_19088\\1941233865.py:24: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((32, 32), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_and_process_images(base_dir):\n",
    "    images = []\n",
    "    labels = []  # Collecting labels\n",
    "    label_dict = {}  # A dictionary to map subfolder names to unique labels\n",
    "    label_counter = 0\n",
    "\n",
    "    # Iterate through all subdirectories\n",
    "    for subdir, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            try:\n",
    "                # Open the image\n",
    "                with Image.open(filepath) as img:\n",
    "                    # Convert to RGB\n",
    "                    img = img.convert('RGB')\n",
    "                    # Resize to 32x32\n",
    "                    img = img.resize((32, 32), Image.ANTIALIAS)\n",
    "                    # Convert to numpy array and scale\n",
    "                    img_array = np.asarray(img, dtype=np.float32) / 255\n",
    "                    images.append(img_array)\n",
    "                    # Assign label based on the subdirectory name\n",
    "                    label = subdir.split(os.path.sep)[-1]\n",
    "                    if label not in label_dict:\n",
    "                        label_dict[label] = label_counter\n",
    "                        label_counter += 1\n",
    "                    labels.append(label_dict[label])\n",
    "            except IOError:\n",
    "                # Handle the case where the file could not be opened as an image\n",
    "                print(f\"Cannot open {file} as an image.\")\n",
    "                \n",
    "    return images, labels\n",
    "\n",
    "base_dir = r\"C:\\Users\\shaif\\Downloads\\Compressed\\CUB_200_2011\\CUB_200_2011\\images\"\n",
    "X_train, YT = read_and_process_images(base_dir)\n",
    "\n",
    "# Convert YT to categorical\n",
    "num_classes = len(np.unique(YT))\n",
    "YT_categorical = to_categorical(YT, num_classes=num_classes)\n",
    "from sklearn.utils import shuffle\n",
    "X_train, YT_categorical = shuffle(X_train, YT_categorical)\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, YT_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d1e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60070b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "#base_model = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b7ec4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 16s 58ms/step - loss: 5.6966 - accuracy: 0.0137 - val_loss: 7.6640 - val_accuracy: 0.0037\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 5.1256 - accuracy: 0.0338 - val_loss: 9.8491 - val_accuracy: 0.0037\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 5.1173 - accuracy: 0.0346 - val_loss: 7.0990 - val_accuracy: 0.0032\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 4.8100 - accuracy: 0.0537 - val_loss: 7.8615 - val_accuracy: 0.0058\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 4.5938 - accuracy: 0.0762 - val_loss: 6.6128 - val_accuracy: 0.0058\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 5s 41ms/step - loss: 4.5346 - accuracy: 0.0842 - val_loss: 2160.5320 - val_accuracy: 0.0037\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 5s 41ms/step - loss: 4.1328 - accuracy: 0.1237 - val_loss: 5.5835 - val_accuracy: 0.0127\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 5s 41ms/step - loss: 4.0875 - accuracy: 0.1310 - val_loss: 16.1307 - val_accuracy: 0.0175\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 3.7246 - accuracy: 0.1640 - val_loss: 733.8248 - val_accuracy: 0.0191\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 5s 47ms/step - loss: 3.3739 - accuracy: 0.2232 - val_loss: 5.9390 - val_accuracy: 0.0456\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 3.9998 - accuracy: 0.1361 - val_loss: 5.7952 - val_accuracy: 0.0615\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 3.1303 - accuracy: 0.2374 - val_loss: 5.6105 - val_accuracy: 0.0689\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 2.5999 - accuracy: 0.3309 - val_loss: 5.5900 - val_accuracy: 0.0917\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 2.0100 - accuracy: 0.4594 - val_loss: 5.2520 - val_accuracy: 0.1029\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 1.5792 - accuracy: 0.5668 - val_loss: 5.6234 - val_accuracy: 0.0912\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 1.2458 - accuracy: 0.6595 - val_loss: 5.7961 - val_accuracy: 0.0965\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.9510 - accuracy: 0.7378 - val_loss: 6.1992 - val_accuracy: 0.0848\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 0.7049 - accuracy: 0.8086 - val_loss: 6.3122 - val_accuracy: 0.0970\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.5679 - accuracy: 0.8428 - val_loss: 6.4342 - val_accuracy: 0.1060\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 7s 57ms/step - loss: 0.5013 - accuracy: 0.8633 - val_loss: 6.8482 - val_accuracy: 0.0838\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 7s 56ms/step - loss: 0.4574 - accuracy: 0.8743 - val_loss: 6.9807 - val_accuracy: 0.0923\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 6s 55ms/step - loss: 0.3698 - accuracy: 0.8974 - val_loss: 6.8798 - val_accuracy: 0.1023\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 7s 59ms/step - loss: 0.3190 - accuracy: 0.9104 - val_loss: 7.0866 - val_accuracy: 0.0970\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 0.2301 - accuracy: 0.9378 - val_loss: 7.1154 - val_accuracy: 0.0875\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 7s 57ms/step - loss: 0.1846 - accuracy: 0.9494 - val_loss: 7.4028 - val_accuracy: 0.0907\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2108 - accuracy: 0.9431 - val_loss: 8.0209 - val_accuracy: 0.0954\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2433 - accuracy: 0.9305 - val_loss: 7.7126 - val_accuracy: 0.0976\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.2267 - accuracy: 0.9361 - val_loss: 7.8389 - val_accuracy: 0.0891\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.2937 - accuracy: 0.9141 - val_loss: 8.4304 - val_accuracy: 0.0785\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.2328 - accuracy: 0.9328 - val_loss: 8.0204 - val_accuracy: 0.0885\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1644 - accuracy: 0.9544 - val_loss: 7.9002 - val_accuracy: 0.0960\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1192 - accuracy: 0.9687 - val_loss: 7.8964 - val_accuracy: 0.0949\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 7s 56ms/step - loss: 0.0888 - accuracy: 0.9752 - val_loss: 7.9687 - val_accuracy: 0.0838\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.0895 - accuracy: 0.9749 - val_loss: 8.0412 - val_accuracy: 0.0970\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 5s 47ms/step - loss: 0.0791 - accuracy: 0.9801 - val_loss: 7.9668 - val_accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 0.0862 - accuracy: 0.9749 - val_loss: 8.0604 - val_accuracy: 0.1076\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.0792 - accuracy: 0.9785 - val_loss: 8.1687 - val_accuracy: 0.1018\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.1200 - accuracy: 0.9657 - val_loss: 8.5704 - val_accuracy: 0.0970\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.2043 - accuracy: 0.9409 - val_loss: 8.8139 - val_accuracy: 0.0859\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 8s 64ms/step - loss: 0.2645 - accuracy: 0.9218 - val_loss: 8.5955 - val_accuracy: 0.0854\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 7s 58ms/step - loss: 0.2860 - accuracy: 0.9119 - val_loss: 8.2874 - val_accuracy: 0.0917\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.2458 - accuracy: 0.9319 - val_loss: 8.8366 - val_accuracy: 0.0859\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 7s 56ms/step - loss: 0.1811 - accuracy: 0.9459 - val_loss: 8.1319 - val_accuracy: 0.1076\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 7s 58ms/step - loss: 0.1045 - accuracy: 0.9694 - val_loss: 9.0732 - val_accuracy: 0.0806\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.1093 - accuracy: 0.9711 - val_loss: 8.5024 - val_accuracy: 0.0933\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.1128 - accuracy: 0.9678 - val_loss: 8.1623 - val_accuracy: 0.1007\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 0.0766 - accuracy: 0.9799 - val_loss: 8.6162 - val_accuracy: 0.0981\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 5s 47ms/step - loss: 0.0667 - accuracy: 0.9818 - val_loss: 8.6823 - val_accuracy: 0.0970\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.0609 - accuracy: 0.9834 - val_loss: 8.6868 - val_accuracy: 0.1050\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.0765 - accuracy: 0.9772 - val_loss: 9.5019 - val_accuracy: 0.0901\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.1083 - accuracy: 0.9699 - val_loss: 9.8483 - val_accuracy: 0.0827\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.1192 - accuracy: 0.9654 - val_loss: 9.5101 - val_accuracy: 0.0822\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 0.1118 - accuracy: 0.9661 - val_loss: 8.9420 - val_accuracy: 0.0928\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1252 - accuracy: 0.9637 - val_loss: 9.2172 - val_accuracy: 0.0885\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.1086 - accuracy: 0.9686 - val_loss: 9.3405 - val_accuracy: 0.0848\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1133 - accuracy: 0.9686 - val_loss: 9.0393 - val_accuracy: 0.0864\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1505 - accuracy: 0.9589 - val_loss: 9.2485 - val_accuracy: 0.0986\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.0821 - accuracy: 0.9768 - val_loss: 9.0488 - val_accuracy: 0.0981\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.0816 - accuracy: 0.9755 - val_loss: 10.0602 - val_accuracy: 0.0758\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.0672 - accuracy: 0.9806 - val_loss: 9.2624 - val_accuracy: 0.0923\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.1079 - accuracy: 0.9677 - val_loss: 9.5058 - val_accuracy: 0.0917\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.1026 - accuracy: 0.9700 - val_loss: 9.5571 - val_accuracy: 0.0986\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.1000 - accuracy: 0.9699 - val_loss: 9.8288 - val_accuracy: 0.0848\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.0921 - accuracy: 0.9734 - val_loss: 9.1262 - val_accuracy: 0.0976\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.0945 - accuracy: 0.9724 - val_loss: 9.7540 - val_accuracy: 0.0923\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.0701 - accuracy: 0.9793 - val_loss: 9.6691 - val_accuracy: 0.0832\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.0470 - accuracy: 0.9856 - val_loss: 9.2353 - val_accuracy: 0.1034\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.0388 - accuracy: 0.9894 - val_loss: 9.6589 - val_accuracy: 0.0885\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.0456 - accuracy: 0.9863 - val_loss: 9.3362 - val_accuracy: 0.0944\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.0468 - accuracy: 0.9867 - val_loss: 9.3360 - val_accuracy: 0.0949\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.0482 - accuracy: 0.9861 - val_loss: 9.5064 - val_accuracy: 0.0901\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.0492 - accuracy: 0.9869 - val_loss: 9.4203 - val_accuracy: 0.0970\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.0607 - accuracy: 0.9840 - val_loss: 9.8220 - val_accuracy: 0.0790\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.1267 - accuracy: 0.9653 - val_loss: 9.7502 - val_accuracy: 0.0912\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.1341 - accuracy: 0.9618 - val_loss: 10.2111 - val_accuracy: 0.0806\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.1195 - accuracy: 0.9625 - val_loss: 10.3889 - val_accuracy: 0.0811\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.0923 - accuracy: 0.9722 - val_loss: 9.8477 - val_accuracy: 0.0885\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 8s 69ms/step - loss: 0.1021 - accuracy: 0.9710 - val_loss: 9.6371 - val_accuracy: 0.0917\n",
      "Epoch 79/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.1038 - accuracy: 0.9716 - val_loss: 9.7961 - val_accuracy: 0.0838\n",
      "Epoch 80/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.0769 - accuracy: 0.9781 - val_loss: 10.1290 - val_accuracy: 0.0864\n",
      "Epoch 81/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.0394 - accuracy: 0.9897 - val_loss: 9.4451 - val_accuracy: 0.0938\n",
      "Epoch 82/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.0386 - accuracy: 0.9909 - val_loss: 10.1066 - val_accuracy: 0.0859\n",
      "Epoch 83/100\n",
      "118/118 [==============================] - 7s 59ms/step - loss: 0.0437 - accuracy: 0.9881 - val_loss: 9.5879 - val_accuracy: 0.0880\n",
      "Epoch 84/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 10.2359 - val_accuracy: 0.0965\n",
      "Epoch 85/100\n",
      "118/118 [==============================] - 8s 70ms/step - loss: 0.0568 - accuracy: 0.9848 - val_loss: 10.4684 - val_accuracy: 0.0726\n",
      "Epoch 86/100\n",
      "118/118 [==============================] - 7s 60ms/step - loss: 0.0779 - accuracy: 0.9783 - val_loss: 9.8160 - val_accuracy: 0.0764\n",
      "Epoch 87/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 0.0893 - accuracy: 0.9753 - val_loss: 10.2098 - val_accuracy: 0.0795\n",
      "Epoch 88/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 0.1244 - accuracy: 0.9653 - val_loss: 10.6997 - val_accuracy: 0.0737\n",
      "Epoch 89/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 0.1130 - accuracy: 0.9674 - val_loss: 10.1852 - val_accuracy: 0.0769\n",
      "Epoch 90/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.0695 - accuracy: 0.9817 - val_loss: 10.1307 - val_accuracy: 0.0896\n",
      "Epoch 91/100\n",
      "118/118 [==============================] - 7s 56ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 10.0853 - val_accuracy: 0.0960\n",
      "Epoch 92/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.0200 - accuracy: 0.9960 - val_loss: 9.7926 - val_accuracy: 0.0859\n",
      "Epoch 93/100\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0156 - accuracy: 0.9963 - val_loss: 9.6995 - val_accuracy: 0.0970\n",
      "Epoch 94/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.0566 - accuracy: 0.9865 - val_loss: 10.3745 - val_accuracy: 0.0801\n",
      "Epoch 95/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.0986 - accuracy: 0.9739 - val_loss: 10.7201 - val_accuracy: 0.0795\n",
      "Epoch 96/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.1075 - accuracy: 0.9695 - val_loss: 11.7652 - val_accuracy: 0.0673\n",
      "Epoch 97/100\n",
      "118/118 [==============================] - 5s 43ms/step - loss: 0.0796 - accuracy: 0.9801 - val_loss: 10.6101 - val_accuracy: 0.0907\n",
      "Epoch 98/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.0445 - accuracy: 0.9875 - val_loss: 10.5650 - val_accuracy: 0.0811\n",
      "Epoch 99/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 0.0375 - accuracy: 0.9913 - val_loss: 10.8233 - val_accuracy: 0.0732\n",
      "Epoch 100/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.1129 - accuracy: 0.9718 - val_loss: 10.1294 - val_accuracy: 0.0923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26e762998b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(np.array(X_train).astype('float32'), Y_train, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dac6007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 2s 15ms/step\n",
      "Accuracy: 0.08269720101781171\n",
      "F1 Score: 0.0783020091317103\n",
      "Balanced Accuracy: 0.08489964528935116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(np.array(X_test).astype('float32'))\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(np.argmax(Y_test, axis=1), predicted_labels)\n",
    "f1 = f1_score(np.argmax(Y_test, axis=1), predicted_labels, average='weighted')\n",
    "balanced_acc = balanced_accuracy_score(np.argmax(Y_test, axis=1), predicted_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6af460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66734536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 14s 65ms/step - loss: 5.8759 - accuracy: 0.0264 - val_loss: 584.3374 - val_accuracy: 0.0058\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 7s 60ms/step - loss: 5.3840 - accuracy: 0.0611 - val_loss: 116.4643 - val_accuracy: 0.0042\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 8s 65ms/step - loss: 5.6141 - accuracy: 0.0457 - val_loss: 438.2541 - val_accuracy: 0.0048\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 7s 57ms/step - loss: 5.4862 - accuracy: 0.0532 - val_loss: 57.9661 - val_accuracy: 0.0064\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 7s 60ms/step - loss: 5.5074 - accuracy: 0.0437 - val_loss: 457.6206 - val_accuracy: 0.0239\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 4.9445 - accuracy: 0.0714 - val_loss: 12.3051 - val_accuracy: 0.0361\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 4.8526 - accuracy: 0.0798 - val_loss: 54.1530 - val_accuracy: 0.0265\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 4.6863 - accuracy: 0.0937 - val_loss: 6.4927 - val_accuracy: 0.0509\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 4.3974 - accuracy: 0.1238 - val_loss: 10.7553 - val_accuracy: 0.0562\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 4.1312 - accuracy: 0.1421 - val_loss: 5.3878 - val_accuracy: 0.0726\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 3.8706 - accuracy: 0.1809 - val_loss: 8.1254 - val_accuracy: 0.0472\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 3.7168 - accuracy: 0.2104 - val_loss: 26.6638 - val_accuracy: 0.0811\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 3.4846 - accuracy: 0.2477 - val_loss: 6.0490 - val_accuracy: 0.0848\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 3.1719 - accuracy: 0.2929 - val_loss: 7.7837 - val_accuracy: 0.0848\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 7s 57ms/step - loss: 4.4223 - accuracy: 0.1454 - val_loss: 59.9871 - val_accuracy: 0.0244\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 4.4423 - accuracy: 0.1088 - val_loss: 9.9366 - val_accuracy: 0.0562\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 6s 55ms/step - loss: 3.9896 - accuracy: 0.1676 - val_loss: 4.5464 - val_accuracy: 0.0742\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 3.8931 - accuracy: 0.1754 - val_loss: 4.9756 - val_accuracy: 0.0456\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 3.7026 - accuracy: 0.1921 - val_loss: 4.7607 - val_accuracy: 0.0573\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 3.9227 - accuracy: 0.1793 - val_loss: 5.3370 - val_accuracy: 0.0286\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 3.7832 - accuracy: 0.1872 - val_loss: 4.7765 - val_accuracy: 0.0520\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 3.5849 - accuracy: 0.2316 - val_loss: 5.2346 - val_accuracy: 0.0451\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 3.5507 - accuracy: 0.2174 - val_loss: 7.2491 - val_accuracy: 0.0445\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 3.2595 - accuracy: 0.2747 - val_loss: 5.1529 - val_accuracy: 0.0652\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 2.9678 - accuracy: 0.3401 - val_loss: 6.1111 - val_accuracy: 0.0626\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 2.9368 - accuracy: 0.3368 - val_loss: 149.3233 - val_accuracy: 0.0355\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 7s 56ms/step - loss: 2.9029 - accuracy: 0.3397 - val_loss: 5.7346 - val_accuracy: 0.0504\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 2.7393 - accuracy: 0.3596 - val_loss: 6.5628 - val_accuracy: 0.0615\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 2.1614 - accuracy: 0.4983 - val_loss: 6.2531 - val_accuracy: 0.0668\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 1.8126 - accuracy: 0.5766 - val_loss: 6.3179 - val_accuracy: 0.0753\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 1.6119 - accuracy: 0.6258 - val_loss: 7.4689 - val_accuracy: 0.0806\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 1.1636 - accuracy: 0.7316 - val_loss: 6.4417 - val_accuracy: 0.0790\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 1.1383 - accuracy: 0.7515 - val_loss: 7.3238 - val_accuracy: 0.0758\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.9061 - accuracy: 0.8085 - val_loss: 8.1530 - val_accuracy: 0.0408\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 7s 56ms/step - loss: 1.1991 - accuracy: 0.7239 - val_loss: 21.6488 - val_accuracy: 0.0467\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 1.0082 - accuracy: 0.7507 - val_loss: 10.3869 - val_accuracy: 0.0647\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 5s 42ms/step - loss: 0.6712 - accuracy: 0.8598 - val_loss: 8.8274 - val_accuracy: 0.0631\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.6123 - accuracy: 0.8720 - val_loss: 13.0855 - val_accuracy: 0.0652\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.5918 - accuracy: 0.8716 - val_loss: 8.5914 - val_accuracy: 0.0642\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 0.5508 - accuracy: 0.8705 - val_loss: 9.4648 - val_accuracy: 0.0673\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 0.3885 - accuracy: 0.9222 - val_loss: 9.1787 - val_accuracy: 0.0689\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 7s 59ms/step - loss: 0.3034 - accuracy: 0.9418 - val_loss: 8.5566 - val_accuracy: 0.0732\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.2837 - accuracy: 0.9449 - val_loss: 8.4460 - val_accuracy: 0.0758\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.2158 - accuracy: 0.9561 - val_loss: 8.7653 - val_accuracy: 0.0710\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 0.2118 - accuracy: 0.9560 - val_loss: 8.8287 - val_accuracy: 0.0774\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 0.1817 - accuracy: 0.9602 - val_loss: 9.0124 - val_accuracy: 0.0742\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.2097 - accuracy: 0.9544 - val_loss: 9.1277 - val_accuracy: 0.0817\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.1590 - accuracy: 0.9650 - val_loss: 9.3003 - val_accuracy: 0.0753\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 0.1218 - accuracy: 0.9714 - val_loss: 9.3266 - val_accuracy: 0.0700\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 5s 44ms/step - loss: 0.1427 - accuracy: 0.9646 - val_loss: 9.2532 - val_accuracy: 0.0764\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.1714 - accuracy: 0.9571 - val_loss: 9.7558 - val_accuracy: 0.0801\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.2121 - accuracy: 0.9402 - val_loss: 10.0869 - val_accuracy: 0.0663\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 0.2318 - accuracy: 0.9400 - val_loss: 10.9249 - val_accuracy: 0.0589\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.1514 - accuracy: 0.9596 - val_loss: 9.5413 - val_accuracy: 0.0742\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.1063 - accuracy: 0.9742 - val_loss: 9.6039 - val_accuracy: 0.0790\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 7s 56ms/step - loss: 0.0977 - accuracy: 0.9757 - val_loss: 9.6325 - val_accuracy: 0.0652\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 7s 62ms/step - loss: 0.0689 - accuracy: 0.9832 - val_loss: 9.7158 - val_accuracy: 0.0689\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.1125 - accuracy: 0.9739 - val_loss: 9.6481 - val_accuracy: 0.0732\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 0.1193 - accuracy: 0.9681 - val_loss: 9.8928 - val_accuracy: 0.0626\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 0.1924 - accuracy: 0.9479 - val_loss: 10.5270 - val_accuracy: 0.0657\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.2312 - accuracy: 0.9357 - val_loss: 10.3689 - val_accuracy: 0.0705\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 7s 58ms/step - loss: 0.2095 - accuracy: 0.9410 - val_loss: 10.3723 - val_accuracy: 0.0689\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 0.1901 - accuracy: 0.9453 - val_loss: 10.0452 - val_accuracy: 0.0742\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 6s 55ms/step - loss: 0.1429 - accuracy: 0.9581 - val_loss: 10.4645 - val_accuracy: 0.0732\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 0.0958 - accuracy: 0.9736 - val_loss: 9.9400 - val_accuracy: 0.0801\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 0.1075 - accuracy: 0.9707 - val_loss: 10.2967 - val_accuracy: 0.0758\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.0709 - accuracy: 0.9813 - val_loss: 10.0325 - val_accuracy: 0.0764\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 6s 51ms/step - loss: 0.0490 - accuracy: 0.9871 - val_loss: 9.7971 - val_accuracy: 0.0684\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.0617 - accuracy: 0.9840 - val_loss: 10.0617 - val_accuracy: 0.0689\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.0927 - accuracy: 0.9765 - val_loss: 10.4531 - val_accuracy: 0.0716\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 7s 57ms/step - loss: 0.1694 - accuracy: 0.9502 - val_loss: 11.1305 - val_accuracy: 0.0620\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 0.1668 - accuracy: 0.9514 - val_loss: 10.8839 - val_accuracy: 0.0684\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 0.1392 - accuracy: 0.9589 - val_loss: 10.6525 - val_accuracy: 0.0647\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 6s 50ms/step - loss: 0.1045 - accuracy: 0.9720 - val_loss: 10.1502 - val_accuracy: 0.0769\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 7s 55ms/step - loss: 0.0898 - accuracy: 0.9752 - val_loss: 10.6259 - val_accuracy: 0.0657\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 7s 58ms/step - loss: 0.0854 - accuracy: 0.9761 - val_loss: 10.5261 - val_accuracy: 0.0668\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 6s 55ms/step - loss: 0.0872 - accuracy: 0.9747 - val_loss: 10.4864 - val_accuracy: 0.0716\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 7s 55ms/step - loss: 0.1048 - accuracy: 0.9686 - val_loss: 10.5067 - val_accuracy: 0.0779\n",
      "Epoch 79/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.1084 - accuracy: 0.9678 - val_loss: 10.6455 - val_accuracy: 0.0753\n",
      "Epoch 80/100\n",
      "118/118 [==============================] - 7s 64ms/step - loss: 0.0872 - accuracy: 0.9732 - val_loss: 11.2089 - val_accuracy: 0.0732\n",
      "Epoch 81/100\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.1248 - accuracy: 0.9643 - val_loss: 10.9863 - val_accuracy: 0.0578\n",
      "Epoch 82/100\n",
      "118/118 [==============================] - 6s 55ms/step - loss: 0.0949 - accuracy: 0.9740 - val_loss: 11.2369 - val_accuracy: 0.0764\n",
      "Epoch 83/100\n",
      "118/118 [==============================] - 7s 59ms/step - loss: 0.0740 - accuracy: 0.9809 - val_loss: 10.5633 - val_accuracy: 0.0726\n",
      "Epoch 84/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.0913 - accuracy: 0.9739 - val_loss: 11.0403 - val_accuracy: 0.0652\n",
      "Epoch 85/100\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.1063 - accuracy: 0.9708 - val_loss: 10.9412 - val_accuracy: 0.0737\n",
      "Epoch 86/100\n",
      "118/118 [==============================] - 8s 66ms/step - loss: 0.1113 - accuracy: 0.9695 - val_loss: 11.0664 - val_accuracy: 0.0663\n",
      "Epoch 87/100\n",
      "118/118 [==============================] - 7s 62ms/step - loss: 0.0893 - accuracy: 0.9747 - val_loss: 10.8587 - val_accuracy: 0.0753\n",
      "Epoch 88/100\n",
      "118/118 [==============================] - 7s 58ms/step - loss: 0.0964 - accuracy: 0.9708 - val_loss: 10.8625 - val_accuracy: 0.0716\n",
      "Epoch 89/100\n",
      "118/118 [==============================] - 6s 52ms/step - loss: 0.0994 - accuracy: 0.9740 - val_loss: 10.9988 - val_accuracy: 0.0668\n",
      "Epoch 90/100\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 0.0632 - accuracy: 0.9830 - val_loss: 10.5481 - val_accuracy: 0.0769\n",
      "Epoch 91/100\n",
      "118/118 [==============================] - 6s 53ms/step - loss: 0.0727 - accuracy: 0.9805 - val_loss: 10.3322 - val_accuracy: 0.0705\n",
      "Epoch 92/100\n",
      "118/118 [==============================] - 7s 59ms/step - loss: 0.0427 - accuracy: 0.9898 - val_loss: 10.4554 - val_accuracy: 0.0710\n",
      "Epoch 93/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 10.3207 - val_accuracy: 0.0726\n",
      "Epoch 94/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.0336 - accuracy: 0.9910 - val_loss: 10.1797 - val_accuracy: 0.0726\n",
      "Epoch 95/100\n",
      "118/118 [==============================] - 7s 63ms/step - loss: 0.0503 - accuracy: 0.9863 - val_loss: 11.0264 - val_accuracy: 0.0689\n",
      "Epoch 96/100\n",
      "118/118 [==============================] - 7s 61ms/step - loss: 0.0525 - accuracy: 0.9854 - val_loss: 11.4133 - val_accuracy: 0.0604\n",
      "Epoch 97/100\n",
      "118/118 [==============================] - 7s 60ms/step - loss: 0.0821 - accuracy: 0.9767 - val_loss: 11.8333 - val_accuracy: 0.0615\n",
      "Epoch 98/100\n",
      "114/118 [===========================>..] - ETA: 0s - loss: 0.1086 - accuracy: 0.9645"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\cub_32_model.h5\")\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(np.array(X_train).astype('float32'), Y_train, batch_size=64, epochs=100, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eeae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(np.array(X_test).astype('float32'))\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(np.argmax(Y_test, axis=1), predicted_labels)\n",
    "f1 = f1_score(np.argmax(Y_test, axis=1), predicted_labels, average='weighted')\n",
    "balanced_acc = balanced_accuracy_score(np.argmax(Y_test, axis=1), predicted_labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235cfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40fc47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
