{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14666713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (9590, 224, 224, 3)\n",
      "Shape of Y_train_categorical: (9590, 4)\n",
      "Shape of X_test: (1686, 224, 224, 3)\n",
      "Shape of Y_test_categorical: (1686, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the paths to your dataset folders\n",
    "train_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\train_and_validation_sets\\train_and_validation_sets\"\n",
    "test_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\test_set\\test_set\"\n",
    "\n",
    "# Initialize empty lists for X_train, Y_train, X_test, and Y_test\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# Initialize an empty list to store categorical labels\n",
    "categorical_labels = []\n",
    "\n",
    "# Define a function to read and preprocess images\n",
    "def process_images(folder_path, label, is_train_set=True):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".bmp\"):  # Check if it's a file and ends with .bmp\n",
    "            # Open and resize the image to (32, 32, 3)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((224, 224))\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "            # Convert image data to a NumPy array\n",
    "            img_array = np.array(img).astype('float32')  # Convert to float\n",
    "            \n",
    "            # Normalize the image data (optional)\n",
    "            img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "            \n",
    "            # Append the image data to the appropriate list\n",
    "            if is_train_set:\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(label)  # Append the numerical label\n",
    "            else:\n",
    "                X_test.append(img_array)\n",
    "                Y_test.append(label)  # Append the numerical label\n",
    "            \n",
    "            # Append the label for categorical encoding\n",
    "            categorical_labels.append(label)  # Append the numerical label\n",
    "\n",
    "# List the folders inside the training dataset directory\n",
    "train_folders = os.listdir(train_dataset_dir)\n",
    "\n",
    "# Create a label encoder for categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through the training folders and process images\n",
    "for label, folder_name in enumerate(train_folders):\n",
    "    folder_path = os.path.join(train_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label)\n",
    "\n",
    "# List the folders inside the test dataset directory\n",
    "test_folders = os.listdir(test_dataset_dir)\n",
    "\n",
    "# Loop through the test folders and process images\n",
    "for label, folder_name in enumerate(test_folders):\n",
    "    folder_path = os.path.join(test_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label, is_train_set=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Encode Y_train and Y_test categorically\n",
    "num_classes = len(np.unique(categorical_labels))\n",
    "  # Update this to match the number of classes\n",
    "\n",
    "# Convert Y_train and Y_test to NumPy arrays\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Make sure your labels are integers ranging from 0 to num_classes - 1\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "# One-hot encode the labels\n",
    "Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# # Encode Y_train and Y_test categorically using the label encoder\n",
    "# num_classes = len(np.unique(Y_train))  # Automatically determine the number of classes\n",
    "# Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "# Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Check the shape of X_train, Y_train_categorical, X_test, and Y_test_categorical\n",
    "print(\"Shape of X_train:\", np.shape(X_train))\n",
    "print(\"Shape of Y_train_categorical:\", np.shape(Y_train_categorical))\n",
    "print(\"Shape of X_test:\", np.shape(X_test))\n",
    "print(\"Shape of Y_test_categorical:\", np.shape(Y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4596ee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mayo 0', 'Mayo 1', 'Mayo 2', 'Mayo 3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96837b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1def5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 48s 267ms/step - loss: 0.5845 - accuracy: 0.7147 - val_loss: 9.3724 - val_accuracy: 0.0308\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 30s 253ms/step - loss: 0.5052 - accuracy: 0.7499 - val_loss: 9.2943 - val_accuracy: 0.0355\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 31s 258ms/step - loss: 0.4886 - accuracy: 0.7569 - val_loss: 9.0711 - val_accuracy: 0.0089\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 30s 254ms/step - loss: 0.4666 - accuracy: 0.7702 - val_loss: 8.6791 - val_accuracy: 0.0396\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 30s 248ms/step - loss: 0.4632 - accuracy: 0.7769 - val_loss: 10.7530 - val_accuracy: 0.0302\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 31s 256ms/step - loss: 0.4561 - accuracy: 0.7739 - val_loss: 9.2236 - val_accuracy: 0.0344\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 31s 262ms/step - loss: 0.4462 - accuracy: 0.7886 - val_loss: 10.2220 - val_accuracy: 0.0391\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 31s 260ms/step - loss: 0.4370 - accuracy: 0.7909 - val_loss: 10.3022 - val_accuracy: 0.0266\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 31s 261ms/step - loss: 0.4228 - accuracy: 0.7997 - val_loss: 9.6974 - val_accuracy: 0.0355\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 31s 262ms/step - loss: 0.3971 - accuracy: 0.8174 - val_loss: 9.6762 - val_accuracy: 0.0339\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 32s 268ms/step - loss: 0.3741 - accuracy: 0.8294 - val_loss: 11.5247 - val_accuracy: 0.0308\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 31s 260ms/step - loss: 0.3279 - accuracy: 0.8549 - val_loss: 12.0976 - val_accuracy: 0.0203\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 31s 259ms/step - loss: 0.2926 - accuracy: 0.8768 - val_loss: 11.3013 - val_accuracy: 0.0349\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 31s 258ms/step - loss: 0.2522 - accuracy: 0.8932 - val_loss: 11.1821 - val_accuracy: 0.0381\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 32s 264ms/step - loss: 0.2294 - accuracy: 0.9069 - val_loss: 12.3851 - val_accuracy: 0.0407\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 32s 269ms/step - loss: 0.1905 - accuracy: 0.9223 - val_loss: 11.2295 - val_accuracy: 0.0328\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 32s 266ms/step - loss: 0.1663 - accuracy: 0.9337 - val_loss: 10.4906 - val_accuracy: 0.0349\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 0.1372 - accuracy: 0.9473 - val_loss: 12.2383 - val_accuracy: 0.0454\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 32s 271ms/step - loss: 0.1092 - accuracy: 0.9580 - val_loss: 12.4693 - val_accuracy: 0.0198\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 31s 261ms/step - loss: 0.0979 - accuracy: 0.9635 - val_loss: 14.4372 - val_accuracy: 0.0151\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 32s 265ms/step - loss: 0.0999 - accuracy: 0.9629 - val_loss: 12.0775 - val_accuracy: 0.0287\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 0.0838 - accuracy: 0.9675 - val_loss: 14.1964 - val_accuracy: 0.0412\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 32s 262ms/step - loss: 0.0697 - accuracy: 0.9769 - val_loss: 13.9732 - val_accuracy: 0.0255\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 32s 267ms/step - loss: 0.0683 - accuracy: 0.9781 - val_loss: 14.1313 - val_accuracy: 0.0334\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 0.0731 - accuracy: 0.9737 - val_loss: 14.3012 - val_accuracy: 0.0198\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 0.0879 - accuracy: 0.9674 - val_loss: 13.7035 - val_accuracy: 0.0245\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 32s 266ms/step - loss: 0.0601 - accuracy: 0.9797 - val_loss: 13.4341 - val_accuracy: 0.0339\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 31s 261ms/step - loss: 0.0417 - accuracy: 0.9850 - val_loss: 14.3301 - val_accuracy: 0.0156\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 32s 269ms/step - loss: 0.0488 - accuracy: 0.9815 - val_loss: 13.2667 - val_accuracy: 0.0214\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 32s 267ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 14.4272 - val_accuracy: 0.0396\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 31s 260ms/step - loss: 0.0762 - accuracy: 0.9716 - val_loss: 14.3881 - val_accuracy: 0.0266\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 32s 266ms/step - loss: 0.0595 - accuracy: 0.9785 - val_loss: 12.8472 - val_accuracy: 0.0339\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 0.0515 - accuracy: 0.9810 - val_loss: 14.5356 - val_accuracy: 0.0193\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 0.0562 - accuracy: 0.9794 - val_loss: 15.6847 - val_accuracy: 0.0229\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 32s 269ms/step - loss: 0.0451 - accuracy: 0.9847 - val_loss: 15.5378 - val_accuracy: 0.0370\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 31s 262ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 13.7180 - val_accuracy: 0.0287\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 0.0357 - accuracy: 0.9868 - val_loss: 14.3695 - val_accuracy: 0.0396\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 32s 269ms/step - loss: 0.0506 - accuracy: 0.9827 - val_loss: 13.7443 - val_accuracy: 0.0355\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 32s 269ms/step - loss: 0.0539 - accuracy: 0.9815 - val_loss: 15.5957 - val_accuracy: 0.0297\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 0.0500 - accuracy: 0.9818 - val_loss: 14.8935 - val_accuracy: 0.0391\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 32s 264ms/step - loss: 0.0327 - accuracy: 0.9898 - val_loss: 16.3346 - val_accuracy: 0.0141\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 30s 250ms/step - loss: 0.0302 - accuracy: 0.9887 - val_loss: 15.2373 - val_accuracy: 0.0318\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 32s 265ms/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 13.8145 - val_accuracy: 0.0245\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 0.0375 - accuracy: 0.9870 - val_loss: 15.6586 - val_accuracy: 0.0240\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 33s 277ms/step - loss: 0.0304 - accuracy: 0.9894 - val_loss: 14.4075 - val_accuracy: 0.0287\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 32s 267ms/step - loss: 0.0362 - accuracy: 0.9867 - val_loss: 17.5165 - val_accuracy: 0.0162\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 32s 268ms/step - loss: 0.0458 - accuracy: 0.9836 - val_loss: 15.2192 - val_accuracy: 0.0255\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 33s 276ms/step - loss: 0.0494 - accuracy: 0.9815 - val_loss: 15.4755 - val_accuracy: 0.0375\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 31s 261ms/step - loss: 0.0352 - accuracy: 0.9871 - val_loss: 15.2538 - val_accuracy: 0.0235\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 31s 262ms/step - loss: 0.0429 - accuracy: 0.9851 - val_loss: 14.6463 - val_accuracy: 0.0318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2970f9a1ee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\mob_limuc_224_model.h5\")\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "# Compile the model\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "new_model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=64, epochs=50, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7cde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c9a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba630814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 111ms/step - loss: 3.8580 - accuracy: 0.5724\n",
      "Test Loss: 3.8579745292663574\n",
      "Test Accuracy: 0.572360634803772\n",
      "Accuracy: 0.5723606168446026\n",
      "F1 Score: 0.5272983848005814\n",
      "Balanced Accuracy: 0.34163618359739045\n",
      "Cohen Kappa Score:\n",
      "0.21757578366214403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = new_model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(\"Cohen Kappa Score:\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf79af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3add546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "959/959 [==============================] - 1166s 1s/step - loss: 0.6776 - accuracy: 0.6590 - val_loss: 11.2546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "959/959 [==============================] - 1169s 1s/step - loss: 0.6356 - accuracy: 0.6752 - val_loss: 11.9915 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "959/959 [==============================] - 1192s 1s/step - loss: 0.6337 - accuracy: 0.6752 - val_loss: 12.4448 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "959/959 [==============================] - 1195s 1s/step - loss: 0.6337 - accuracy: 0.6752 - val_loss: 12.1596 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "959/959 [==============================] - 1204s 1s/step - loss: 0.6330 - accuracy: 0.6752 - val_loss: 12.6865 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "959/959 [==============================] - 1202s 1s/step - loss: 0.6321 - accuracy: 0.6752 - val_loss: 13.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "959/959 [==============================] - 1202s 1s/step - loss: 0.6328 - accuracy: 0.6752 - val_loss: 14.1246 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "959/959 [==============================] - 1209s 1s/step - loss: 0.6319 - accuracy: 0.6752 - val_loss: 14.6718 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "959/959 [==============================] - 1211s 1s/step - loss: 0.6318 - accuracy: 0.6752 - val_loss: 15.0833 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "959/959 [==============================] - 1206s 1s/step - loss: 0.6334 - accuracy: 0.6752 - val_loss: 15.3305 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "959/959 [==============================] - 1221s 1s/step - loss: 0.6318 - accuracy: 0.6752 - val_loss: 16.1942 - val_accuracy: 0.0000e+00\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1da73be7790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "class LayerScale(layers.Layer):\n",
    "    \"\"\"Layer scale module.\n",
    "\n",
    "    References:\n",
    "      - https://arxiv.org/abs/2103.17239\n",
    "\n",
    "    Args:\n",
    "      init_values (float): Initial value for layer scale. Should be within\n",
    "        [0, 1].\n",
    "      projection_dim (int): Projection dimensionality.\n",
    "\n",
    "    Returns:\n",
    "      Tensor multiplied to the scale.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, init_values, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.init_values = init_values\n",
    "        self.projection_dim = projection_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = tensorflow.Variable(\n",
    "            self.init_values * tensorflow.ones((self.projection_dim,))\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.gamma\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"init_values\": self.init_values,\n",
    "                \"projection_dim\": self.projection_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "model = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\conv_limuc_224_model.h5\",custom_objects={ \"LayerScale\": LayerScale })\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "# Create the new model with the updated head\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "from keras.callbacks import EarlyStopping\n",
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "new_model.fit(np.array(X_train).astype('float32'), Y_train_categorical, batch_size=8, epochs=50, validation_split = .2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85875e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394bdf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 23s 765ms/step - loss: 2.6233 - accuracy: 0.5486\n",
      "Test Loss: 2.6233296394348145\n",
      "Test Accuracy: 0.5486358404159546\n",
      "Accuracy: 0.5486358244365361\n",
      "F1 Score: 0.38873085990332895\n",
      "Balanced Accuracy: 0.25\n",
      "Cohen Kappa Score:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "batch_size = 64\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = new_model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(\"Cohen Kappa Score:\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d9482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a65728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2399a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f8666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
