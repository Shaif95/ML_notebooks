{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14666713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 19/19 [05:00<00:00, 15.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2872, 32, 32, 3)\n",
      "Y_train shape: (2872,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"D:\\datasets\\Underwater_Image\\WHOI\\archive\\dataset_pm\\training\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7087f698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 19/19 [03:59<00:00, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2872, 32, 32, 3)\n",
      "Y_train shape: (2872,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"D:\\datasets\\Underwater_Image\\WHOI\\archive\\dataset_pm\\training\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_val = []\n",
    "Y_val = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_val.append(img_array)\n",
    "            Y_val.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "print(f'X_train shape: {X_val.shape}')\n",
    "print(f'Y_train shape: {Y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecf1ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 19/19 [04:27<00:00, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2872, 32, 32, 3)\n",
      "Y_train shape: (2872,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"D:\\datasets\\Underwater_Image\\WHOI\\archive\\dataset_pm\\training\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_test = []\n",
    "Y_test = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_test.append(img_array)\n",
    "            Y_test.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print(f'X_train shape: {X_test.shape}')\n",
    "\n",
    "print(f'Y_train shape: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88c23d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df1def5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/90 [==============================] - 13s 65ms/step - loss: 2.1164 - accuracy: 0.4979 - val_loss: 35.7810 - val_accuracy: 0.1020\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 1.2610 - accuracy: 0.6863 - val_loss: 186.6438 - val_accuracy: 0.1584\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 1.5813 - accuracy: 0.6396 - val_loss: 11.1308 - val_accuracy: 0.3409\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 1.3609 - accuracy: 0.6891 - val_loss: 6.2813 - val_accuracy: 0.2026\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.4168 - accuracy: 0.6825 - val_loss: 118.8330 - val_accuracy: 0.3231\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 1.1098 - accuracy: 0.7430 - val_loss: 1.0281 - val_accuracy: 0.7308\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.9764 - accuracy: 0.7845 - val_loss: 3.5206 - val_accuracy: 0.2855\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.7387 - accuracy: 0.8012 - val_loss: 1.9190 - val_accuracy: 0.6779\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.5712 - accuracy: 0.8632 - val_loss: 1.5240 - val_accuracy: 0.6476\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.3952 - accuracy: 0.8910 - val_loss: 1.0400 - val_accuracy: 0.7194\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.3804 - accuracy: 0.9022 - val_loss: 0.6320 - val_accuracy: 0.8203\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.4788 - accuracy: 0.8997 - val_loss: 2.3207 - val_accuracy: 0.4401\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.7034 - accuracy: 0.8339 - val_loss: 0.9089 - val_accuracy: 0.7009\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.7723 - accuracy: 0.8520 - val_loss: 1.9588 - val_accuracy: 0.4937\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.6860 - accuracy: 0.8510 - val_loss: 891.1633 - val_accuracy: 0.0575\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 1.3226 - accuracy: 0.7180 - val_loss: 3.3628 - val_accuracy: 0.3217\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 1.4492 - accuracy: 0.6943 - val_loss: 18.9846 - val_accuracy: 0.0846\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 1.9000 - accuracy: 0.5456 - val_loss: 7.1707 - val_accuracy: 0.0982\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.2619 - accuracy: 0.6939 - val_loss: 1.8911 - val_accuracy: 0.4808\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 1.1339 - accuracy: 0.7507 - val_loss: 9.3721 - val_accuracy: 0.2914\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.9083 - accuracy: 0.7775 - val_loss: 2.3530 - val_accuracy: 0.3795\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.7730 - accuracy: 0.6532 - val_loss: 165.6544 - val_accuracy: 0.1595\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 1.4535 - accuracy: 0.6922 - val_loss: 7.4199 - val_accuracy: 0.2006\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.9597 - accuracy: 0.7618 - val_loss: 5.2040 - val_accuracy: 0.3189\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.7134 - accuracy: 0.8266 - val_loss: 1.5274 - val_accuracy: 0.6476\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.7269 - accuracy: 0.8210 - val_loss: 6.9682 - val_accuracy: 0.1957\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.7568 - accuracy: 0.8210 - val_loss: 2.3686 - val_accuracy: 0.6191\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.7008 - accuracy: 0.8357 - val_loss: 21.5614 - val_accuracy: 0.2577\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.9069 - accuracy: 0.7967 - val_loss: 4.0926 - val_accuracy: 0.3646\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.7401 - accuracy: 0.8346 - val_loss: 2.0443 - val_accuracy: 0.5794\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.4217 - accuracy: 0.8827 - val_loss: 2.8086 - val_accuracy: 0.6379\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.4895 - accuracy: 0.8844 - val_loss: 0.8177 - val_accuracy: 0.7712\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.3514 - accuracy: 0.9227 - val_loss: 2.4854 - val_accuracy: 0.6410\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3615 - accuracy: 0.9189 - val_loss: 0.9660 - val_accuracy: 0.7744\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 1.2047 - accuracy: 0.6929 - val_loss: 30.6150 - val_accuracy: 0.2319\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 1.2983 - accuracy: 0.6960 - val_loss: 21.3268 - val_accuracy: 0.1657\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 1.1546 - accuracy: 0.7413 - val_loss: 8.1970 - val_accuracy: 0.1473\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 1.2022 - accuracy: 0.7169 - val_loss: 3.8893 - val_accuracy: 0.3569\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.6752 - accuracy: 0.8287 - val_loss: 1.2344 - val_accuracy: 0.6706\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 1.4143 - accuracy: 0.7639 - val_loss: 9051.0332 - val_accuracy: 0.0682\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 1.0611 - accuracy: 0.8141 - val_loss: 3.0631 - val_accuracy: 0.5111\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.5463 - accuracy: 0.8729 - val_loss: 0.6796 - val_accuracy: 0.7810\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.4212 - accuracy: 0.8931 - val_loss: 0.4691 - val_accuracy: 0.8513\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.3733 - accuracy: 0.9123 - val_loss: 1.3150 - val_accuracy: 0.8614\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.4028 - accuracy: 0.9109 - val_loss: 0.7097 - val_accuracy: 0.7991\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.3219 - accuracy: 0.9126 - val_loss: 4.2181 - val_accuracy: 0.4102\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.4027 - accuracy: 0.9192 - val_loss: 0.4680 - val_accuracy: 0.8928\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.3447 - accuracy: 0.9189 - val_loss: 5.8012 - val_accuracy: 0.4251\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.4003 - accuracy: 0.9029 - val_loss: 1.1167 - val_accuracy: 0.8175\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.2351 - accuracy: 0.9432 - val_loss: 1.2891 - val_accuracy: 0.7305\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.4138 - accuracy: 0.9217 - val_loss: 1.9086 - val_accuracy: 0.6090\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.5154 - accuracy: 0.8928 - val_loss: 13.9958 - val_accuracy: 0.4157\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.4799 - accuracy: 0.8795 - val_loss: 0.7091 - val_accuracy: 0.8179\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.9117 - accuracy: 0.7994 - val_loss: 6.3085 - val_accuracy: 0.4453\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.4454 - accuracy: 0.8851 - val_loss: 0.5591 - val_accuracy: 0.8294\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.2996 - accuracy: 0.9154 - val_loss: 1.4719 - val_accuracy: 0.7709\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.2301 - accuracy: 0.9297 - val_loss: 0.1733 - val_accuracy: 0.9502\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 5s 53ms/step - loss: 0.1797 - accuracy: 0.9474 - val_loss: 0.2014 - val_accuracy: 0.9331\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.1176 - accuracy: 0.9645 - val_loss: 0.1371 - val_accuracy: 0.9488\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.1215 - accuracy: 0.9607 - val_loss: 1.5369 - val_accuracy: 0.6717\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.1773 - accuracy: 0.9572 - val_loss: 8.9764 - val_accuracy: 0.3269\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.6682 - accuracy: 0.8137 - val_loss: 4.5268 - val_accuracy: 0.6020\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2963 - accuracy: 0.9168 - val_loss: 3.8790 - val_accuracy: 0.6198\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.2760 - accuracy: 0.9265 - val_loss: 14.5608 - val_accuracy: 0.2845\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.4129 - accuracy: 0.8858 - val_loss: 3.0653 - val_accuracy: 0.5237\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.1914 - accuracy: 0.9506 - val_loss: 1.6727 - val_accuracy: 0.7754\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.3601 - accuracy: 0.9133 - val_loss: 0.5669 - val_accuracy: 0.8510\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.1546 - accuracy: 0.9519 - val_loss: 0.5346 - val_accuracy: 0.8694\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0865 - accuracy: 0.9697 - val_loss: 0.9694 - val_accuracy: 0.8165\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0812 - accuracy: 0.9739 - val_loss: 0.4085 - val_accuracy: 0.9060\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0707 - accuracy: 0.9760 - val_loss: 1.3623 - val_accuracy: 0.7761\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0597 - accuracy: 0.9798 - val_loss: 1.0907 - val_accuracy: 0.8008\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0585 - accuracy: 0.9808 - val_loss: 0.1962 - val_accuracy: 0.9419\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 3.6525 - val_accuracy: 0.6337\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0779 - accuracy: 0.9812 - val_loss: 0.4183 - val_accuracy: 0.9112\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0547 - accuracy: 0.9836 - val_loss: 0.0486 - val_accuracy: 0.9850\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0848 - accuracy: 0.9822 - val_loss: 2.1036 - val_accuracy: 0.7406\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.0660 - accuracy: 0.9784 - val_loss: 1.4561 - val_accuracy: 0.7416\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 6s 69ms/step - loss: 0.0583 - accuracy: 0.9826 - val_loss: 0.0714 - val_accuracy: 0.9770\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.0628 - accuracy: 0.9784 - val_loss: 2.8002 - val_accuracy: 0.5811\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.1150 - accuracy: 0.9673 - val_loss: 2.4388 - val_accuracy: 0.7169\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 6s 67ms/step - loss: 0.0798 - accuracy: 0.9746 - val_loss: 0.2054 - val_accuracy: 0.9377\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0680 - accuracy: 0.9802 - val_loss: 1.8617 - val_accuracy: 0.7260\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0464 - accuracy: 0.9854 - val_loss: 0.1915 - val_accuracy: 0.9439\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.1735 - accuracy: 0.9603 - val_loss: 7.6118 - val_accuracy: 0.3231\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.2157 - accuracy: 0.9453 - val_loss: 0.6944 - val_accuracy: 0.8597\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.1076 - accuracy: 0.9680 - val_loss: 0.5972 - val_accuracy: 0.9387\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0928 - accuracy: 0.9708 - val_loss: 3.0909 - val_accuracy: 0.6264\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0680 - accuracy: 0.9805 - val_loss: 2.0974 - val_accuracy: 0.6386\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.0893 - accuracy: 0.9742 - val_loss: 1.0248 - val_accuracy: 0.8123\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.2396 - accuracy: 0.9412 - val_loss: 5.7841 - val_accuracy: 0.4579\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.1064 - accuracy: 0.9659 - val_loss: 3.9015 - val_accuracy: 0.7347\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0766 - accuracy: 0.9763 - val_loss: 2.4352 - val_accuracy: 0.6929\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0443 - accuracy: 0.9861 - val_loss: 2.4977 - val_accuracy: 0.6870\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.4079 - val_accuracy: 0.8959\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 6s 69ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 1.2462 - val_accuracy: 0.7984\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.0115 - val_accuracy: 0.9965\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0287 - accuracy: 0.9899 - val_loss: 1.2213 - val_accuracy: 0.7507\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0795 - accuracy: 0.9777 - val_loss: 0.5790 - val_accuracy: 0.8572\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.6710 - val_accuracy: 0.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ef2fb98d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "num_classes = 19\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Change units to match the number of classes\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.summary()\n",
    "#YT = to_categorical(Y_train)\n",
    "#VT = to_categorical(Y_val)\n",
    "epochs = 100\n",
    "model.fit(X_train,YT, epochs=epochs,batch_size=32, validation_data=(X_val,VT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3add546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db00aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8614206128133705\n",
      "F1 Score: 0.8524633915777378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf7968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "394bdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "num_classes = 19\n",
    "model = keras.models.load_model(r\"F:\\Pre-Trained_Models\\Pre-Trained_Models\\che_32_model.h5\")\n",
    "\n",
    "x = model.layers[-4].output  # Access the last 4th layer from the end\n",
    "x = GlobalAveragePooling2D(keepdims=False)(x)  # Explicitly specify keepdims\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36d9482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 12s 64ms/step - loss: 2.1105 - accuracy: 0.5097 - val_loss: 381.2758 - val_accuracy: 0.1309\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 1.3422 - accuracy: 0.6724 - val_loss: 317.2044 - val_accuracy: 0.1323\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.3647 - accuracy: 0.6466 - val_loss: 27.4235 - val_accuracy: 0.1790\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.9531 - accuracy: 0.7657 - val_loss: 2.8835 - val_accuracy: 0.6240\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.8256 - accuracy: 0.7977 - val_loss: 0.6366 - val_accuracy: 0.8458\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.5886 - accuracy: 0.8496 - val_loss: 1.6253 - val_accuracy: 0.6657\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.9931 - accuracy: 0.7469 - val_loss: 289.9047 - val_accuracy: 0.0616\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.7666 - accuracy: 0.7914 - val_loss: 1.4548 - val_accuracy: 0.6692\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 4s 50ms/step - loss: 0.8134 - accuracy: 0.8217 - val_loss: 7.5227 - val_accuracy: 0.1560\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 1.4464 - accuracy: 0.7486 - val_loss: 72.5876 - val_accuracy: 0.2573\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 1.3231 - accuracy: 0.7761 - val_loss: 36.5556 - val_accuracy: 0.3628\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 1.1350 - accuracy: 0.7820 - val_loss: 80.3595 - val_accuracy: 0.5874\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.7009 - accuracy: 0.8458 - val_loss: 3.0091 - val_accuracy: 0.5362\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 0.4657 - accuracy: 0.8962 - val_loss: 0.9287 - val_accuracy: 0.7026\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.3702 - accuracy: 0.9255 - val_loss: 1.4587 - val_accuracy: 0.7040\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.3839 - accuracy: 0.9109 - val_loss: 0.2334 - val_accuracy: 0.9318\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2789 - accuracy: 0.9293 - val_loss: 0.4110 - val_accuracy: 0.8747\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2056 - accuracy: 0.9540 - val_loss: 0.2415 - val_accuracy: 0.9133\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.4993 - accuracy: 0.9168 - val_loss: 12.8585 - val_accuracy: 0.1825\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.6558 - accuracy: 0.6539 - val_loss: 11.6759 - val_accuracy: 0.2497\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.7115 - accuracy: 0.8047 - val_loss: 1.5836 - val_accuracy: 0.6431\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.5665 - accuracy: 0.8973 - val_loss: 0.4215 - val_accuracy: 0.8771\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 0.4440 - accuracy: 0.9091 - val_loss: 1.0812 - val_accuracy: 0.7730\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.2409 - accuracy: 0.9432 - val_loss: 3.6207 - val_accuracy: 0.3562\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.4270 - accuracy: 0.9109 - val_loss: 3.2519 - val_accuracy: 0.8409\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.3808 - accuracy: 0.9161 - val_loss: 1.7185 - val_accuracy: 0.5710\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.3600 - accuracy: 0.9049 - val_loss: 1.0656 - val_accuracy: 0.6936\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.4406 - accuracy: 0.9042 - val_loss: 2.3384 - val_accuracy: 0.5066\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.3313 - accuracy: 0.9297 - val_loss: 0.3902 - val_accuracy: 0.8642\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.2826 - accuracy: 0.9345 - val_loss: 3.1828 - val_accuracy: 0.5519\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.2714 - accuracy: 0.9419 - val_loss: 0.2772 - val_accuracy: 0.9178\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 0.0810 - accuracy: 0.9721 - val_loss: 0.5969 - val_accuracy: 0.8064\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.1720 - accuracy: 0.9718 - val_loss: 1.1411 - val_accuracy: 0.8099\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 0.7074 - accuracy: 0.8503 - val_loss: 7.9563 - val_accuracy: 0.5682\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.7687 - accuracy: 0.8088 - val_loss: 9.0976 - val_accuracy: 0.4060\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.4721 - accuracy: 0.8847 - val_loss: 1.8063 - val_accuracy: 0.6253\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.3224 - accuracy: 0.9244 - val_loss: 0.5699 - val_accuracy: 0.8186\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.5536 - accuracy: 0.8743 - val_loss: 513.1193 - val_accuracy: 0.0738\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.5132 - accuracy: 0.8875 - val_loss: 2.0034 - val_accuracy: 0.7322\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.5029 - accuracy: 0.9001 - val_loss: 0.8947 - val_accuracy: 0.8276\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.2213 - accuracy: 0.9464 - val_loss: 0.2437 - val_accuracy: 0.9478\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.6628 - accuracy: 0.8753 - val_loss: 43.2340 - val_accuracy: 0.2671\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.4902 - accuracy: 0.8910 - val_loss: 6.2684 - val_accuracy: 0.8875\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2839 - accuracy: 0.9457 - val_loss: 1.9363 - val_accuracy: 0.6375\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2781 - accuracy: 0.9492 - val_loss: 0.1729 - val_accuracy: 0.9551\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.2794 - accuracy: 0.9572 - val_loss: 0.8310 - val_accuracy: 0.8280\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.3184 - accuracy: 0.9300 - val_loss: 4.5965 - val_accuracy: 0.9011\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.2959 - accuracy: 0.9453 - val_loss: 0.5990 - val_accuracy: 0.8684\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.1957 - accuracy: 0.9683 - val_loss: 0.1271 - val_accuracy: 0.9600\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.2496 - accuracy: 0.9513 - val_loss: 0.6896 - val_accuracy: 0.8583\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2685 - accuracy: 0.9631 - val_loss: 0.3271 - val_accuracy: 0.9561\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.1497 - accuracy: 0.9781 - val_loss: 0.2865 - val_accuracy: 0.9523\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.1587 - accuracy: 0.9770 - val_loss: 0.4424 - val_accuracy: 0.9627\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.1041 - accuracy: 0.9822 - val_loss: 0.0481 - val_accuracy: 0.9885\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.2535 - accuracy: 0.9652 - val_loss: 2.4934 - val_accuracy: 0.5808\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2515 - accuracy: 0.9572 - val_loss: 0.7476 - val_accuracy: 0.7900\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.6312 - accuracy: 0.8861 - val_loss: 118.9505 - val_accuracy: 0.1010\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 5s 56ms/step - loss: 0.8078 - accuracy: 0.8377 - val_loss: 1.9193 - val_accuracy: 0.5780\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.5438 - accuracy: 0.8889 - val_loss: 0.4650 - val_accuracy: 0.8639\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.3928 - accuracy: 0.9081 - val_loss: 0.5001 - val_accuracy: 0.8311\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 0.3596 - accuracy: 0.9244 - val_loss: 0.3279 - val_accuracy: 0.9453\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.3527 - accuracy: 0.9220 - val_loss: 0.3326 - val_accuracy: 0.9022\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2821 - accuracy: 0.9352 - val_loss: 3.1289 - val_accuracy: 0.5327\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.5608 - accuracy: 0.8962 - val_loss: 1.0793 - val_accuracy: 0.7291\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 1.0241 - accuracy: 0.7984 - val_loss: 0.5150 - val_accuracy: 0.8381\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.6254 - accuracy: 0.8625 - val_loss: 1.2882 - val_accuracy: 0.6288\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.5281 - accuracy: 0.8719 - val_loss: 0.2099 - val_accuracy: 0.9325\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 6s 69ms/step - loss: 0.2444 - accuracy: 0.9363 - val_loss: 0.1155 - val_accuracy: 0.9645\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 0.1832 - accuracy: 0.9540 - val_loss: 0.2294 - val_accuracy: 0.9325\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.5218 - accuracy: 0.8750 - val_loss: 2.3556 - val_accuracy: 0.8050\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.2860 - accuracy: 0.9325 - val_loss: 2.0321 - val_accuracy: 0.5494\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.1783 - accuracy: 0.9509 - val_loss: 0.1861 - val_accuracy: 0.9648\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 6s 68ms/step - loss: 0.1749 - accuracy: 0.9474 - val_loss: 0.2342 - val_accuracy: 0.9304\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.1017 - accuracy: 0.9694 - val_loss: 0.0894 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.1458 - accuracy: 0.9701 - val_loss: 0.1979 - val_accuracy: 0.9398\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.1368 - accuracy: 0.9673 - val_loss: 2.5821 - val_accuracy: 0.8297\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.1252 - accuracy: 0.9673 - val_loss: 0.0461 - val_accuracy: 0.9927\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0901 - accuracy: 0.9812 - val_loss: 0.1226 - val_accuracy: 0.9614\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.1348 - accuracy: 0.9753 - val_loss: 0.2066 - val_accuracy: 0.9345\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.0976 - accuracy: 0.9850 - val_loss: 0.0790 - val_accuracy: 0.9614\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 0.0962 - accuracy: 0.9760 - val_loss: 0.1462 - val_accuracy: 0.9537\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 0.0752 - accuracy: 0.9788 - val_loss: 0.6416 - val_accuracy: 0.8224\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.0693 - accuracy: 0.9767 - val_loss: 0.0434 - val_accuracy: 0.9854\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0718 - accuracy: 0.9788 - val_loss: 0.1130 - val_accuracy: 0.9603\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0913 - accuracy: 0.9777 - val_loss: 0.6872 - val_accuracy: 0.8440\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 5s 55ms/step - loss: 0.0540 - accuracy: 0.9847 - val_loss: 0.0266 - val_accuracy: 0.9944\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.5921 - val_accuracy: 0.8632\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 0.0975 - accuracy: 0.9721 - val_loss: 0.0287 - val_accuracy: 0.9916\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0600 - accuracy: 0.9836 - val_loss: 0.2431 - val_accuracy: 0.9255\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 7s 74ms/step - loss: 0.0593 - accuracy: 0.9871 - val_loss: 0.1805 - val_accuracy: 0.9412\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.0726 - accuracy: 0.9815 - val_loss: 1.6585 - val_accuracy: 0.7155\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.0753 - accuracy: 0.9819 - val_loss: 0.3749 - val_accuracy: 0.9140\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 5s 61ms/step - loss: 0.0427 - accuracy: 0.9878 - val_loss: 0.0519 - val_accuracy: 0.9802\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 5s 54ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.0107 - val_accuracy: 0.9965\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.0818 - val_accuracy: 0.9714\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 0.0687 - accuracy: 0.9861 - val_loss: 0.0183 - val_accuracy: 0.9951\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 5s 57ms/step - loss: 0.0730 - accuracy: 0.9815 - val_loss: 0.2213 - val_accuracy: 0.9387\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 0.0753 - accuracy: 0.9798 - val_loss: 0.6589 - val_accuracy: 0.8158\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 0.0637 - accuracy: 0.9868 - val_loss: 0.0723 - val_accuracy: 0.9843\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.1029 - accuracy: 0.9746 - val_loss: 0.0446 - val_accuracy: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ee92d78b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "epochs = 100\n",
    "new_model.fit(X_train,YT, epochs=epochs,batch_size=32, validation_data=(X_val,VT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a65728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d47a7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987116991643454\n",
      "F1 Score: 0.9871682615273469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = new_model.predict(X_test)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2399a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7138ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5d206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123599f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f8666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
