{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c075420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13efb1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "trn1='D:/Inv_Data_Imbalance/data/invasive-aquatic-species-data/invasive/*/'\n",
    "trn2='D:/Inv_Data_Imbalance/data/invasive-aquatic-species-data/noninvasive/*/'\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6184889",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1= shuffle(tr1)\n",
    "tr2= shuffle(tr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d97c0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3330.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_index_inv = np.round( len(tr1)* .9  )\n",
    "tran_index_noninv = np.round( len(tr2)* .9  )\n",
    "tran_index_noninv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066c1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dee10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7555d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8fcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f2b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[:(int) (tran_index_inv)]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[:(int) (tran_index_noninv)]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[:(int) (tran_index_inv)])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in a:\n",
    "        data.append(k)\n",
    "\n",
    "for j in range(0,len(tr2[:(int) (tran_index_noninv)])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in a:\n",
    "        data.append(k)        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((15, 15))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(15,15,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),15,15,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715c325c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3937, 25, 15, 15, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "train_df= []\n",
    "limit = 25\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for i in range(0, len(breath)):\n",
    "    deff = []\n",
    "    index = 0\n",
    "    if (breath[i] >= limit):\n",
    "        for k in range(0, limit):\n",
    "        \n",
    "            index = (j+k)\n",
    "        \n",
    "            deff.append(X_train[index])\n",
    "        \n",
    "        j = j + breath[i]\n",
    "        train_df.append(deff)\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        for k in range(0, breath[i]):\n",
    "        \n",
    "            index = (j+k)\n",
    "        \n",
    "            deff.append(X_train[index])\n",
    "            \n",
    "        for k in range(breath[i], limit):\n",
    "            \n",
    "            img = np.zeros((15,15,3), np.uint16)\n",
    "            deff.append(img)\n",
    "        \n",
    "        j = j + breath[i]\n",
    "        train_df.append(deff)\n",
    "        \n",
    "\n",
    "Y_train = to_categorical(label)\n",
    "train_df = np.array(train_df)\n",
    "train_df,Y_train = shuffle(train_df,Y_train)\n",
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31f33a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 15, 15, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc16cc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4155, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245bccf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428f91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da0f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[(int) (tran_index_inv) +2 :]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[ (int)(tran_index_noninv) +2 :]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[(int) (tran_index_inv)  :])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in a:\n",
    "        data.append(k)\n",
    "\n",
    "for j in range(0,len(tr2[ (int)(tran_index_noninv)  :])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in a:\n",
    "        data.append(k)        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((15, 15))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(15,15,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),15,15,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92182c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fd8f6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 25, 15, 15, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "test_df= []\n",
    "limit = 25\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for i in range(0, len(breath)):\n",
    "    deff = []\n",
    "    index = 0\n",
    "    if (breath[i] >= limit):\n",
    "        for k in range(0, limit):\n",
    "        \n",
    "            index = (j+k)\n",
    "        \n",
    "            deff.append(X_train[index])\n",
    "        \n",
    "        j = j + breath[i]\n",
    "        test_df.append(deff)\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        for k in range(0, breath[i]):\n",
    "        \n",
    "            index = (j+k)\n",
    "        \n",
    "            deff.append(X_train[index])\n",
    "            \n",
    "        for k in range(breath[i], limit):\n",
    "            \n",
    "            img = np.zeros((15,15,3), np.uint16)\n",
    "            deff.append(img)\n",
    "        \n",
    "        j = j + breath[i]\n",
    "        test_df.append(deff)\n",
    "        \n",
    "\n",
    "Y_test = to_categorical(label)\n",
    "test_df = np.array(test_df)\n",
    "test_df,Y_test = shuffle(test_df,Y_test)\n",
    "np.shape(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff28de71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa4d2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57d074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7316528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 25, 13, 13, 16)   448       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 25, 6, 6, 16)     0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 25, 4, 4, 8)      1160      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 25, 2, 2, 8)      0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 25, 2, 2, 8)      32        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 25, 32)           0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 6)                 936       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,650\n",
      "Trainable params: 2,634\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "model= models.Sequential()\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), strides=(1,1),activation='relu'),input_shape=(25, 15, 15, 3)))\n",
    "model.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), strides=(1,1),activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(6,return_sequences=False,dropout=0.2)) # used 32 units\n",
    "\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b308f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca578de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "99/99 [==============================] - 23s 150ms/step - loss: 0.5453 - accuracy: 0.7672 - val_loss: 0.4988 - val_accuracy: 0.8274\n",
      "Epoch 2/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.2906 - accuracy: 0.8901 - val_loss: 0.3345 - val_accuracy: 0.8376\n",
      "Epoch 3/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.1969 - accuracy: 0.9209 - val_loss: 0.2028 - val_accuracy: 0.9137\n",
      "Epoch 4/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.1671 - accuracy: 0.9251 - val_loss: 0.2058 - val_accuracy: 0.9061\n",
      "Epoch 5/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.1552 - accuracy: 0.9390 - val_loss: 0.4080 - val_accuracy: 0.8820\n",
      "Epoch 6/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.1444 - accuracy: 0.9413 - val_loss: 0.1518 - val_accuracy: 0.9264\n",
      "Epoch 7/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.1358 - accuracy: 0.9447 - val_loss: 0.1479 - val_accuracy: 0.9391\n",
      "Epoch 8/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.1310 - accuracy: 0.9454 - val_loss: 0.1543 - val_accuracy: 0.9429\n",
      "Epoch 9/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.1337 - accuracy: 0.9454 - val_loss: 0.2472 - val_accuracy: 0.8934\n",
      "Epoch 10/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.1255 - accuracy: 0.9454 - val_loss: 0.1542 - val_accuracy: 0.9518\n",
      "Epoch 11/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.1169 - accuracy: 0.9489 - val_loss: 0.1388 - val_accuracy: 0.9429\n",
      "Epoch 12/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.1190 - accuracy: 0.9486 - val_loss: 0.1200 - val_accuracy: 0.9505\n",
      "Epoch 13/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.1178 - accuracy: 0.9520 - val_loss: 0.1692 - val_accuracy: 0.9137\n",
      "Epoch 14/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.1164 - accuracy: 0.9524 - val_loss: 0.1615 - val_accuracy: 0.9416\n",
      "Epoch 15/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.1091 - accuracy: 0.9533 - val_loss: 0.1397 - val_accuracy: 0.9429\n",
      "Epoch 16/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.1085 - accuracy: 0.9511 - val_loss: 0.1523 - val_accuracy: 0.9429\n",
      "Epoch 17/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.1078 - accuracy: 0.9530 - val_loss: 0.1201 - val_accuracy: 0.9530\n",
      "Epoch 18/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.1016 - accuracy: 0.9562 - val_loss: 0.1063 - val_accuracy: 0.9607\n",
      "Epoch 19/200\n",
      "99/99 [==============================] - 13s 132ms/step - loss: 0.0972 - accuracy: 0.9587 - val_loss: 0.2050 - val_accuracy: 0.9251\n",
      "Epoch 20/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.1008 - accuracy: 0.9590 - val_loss: 0.2042 - val_accuracy: 0.9175\n",
      "Epoch 21/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.0923 - accuracy: 0.9619 - val_loss: 0.0982 - val_accuracy: 0.9607\n",
      "Epoch 22/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.0860 - accuracy: 0.9641 - val_loss: 0.0956 - val_accuracy: 0.9619\n",
      "Epoch 23/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0905 - accuracy: 0.9632 - val_loss: 0.1527 - val_accuracy: 0.9518\n",
      "Epoch 24/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.0922 - accuracy: 0.9635 - val_loss: 0.1790 - val_accuracy: 0.9404\n",
      "Epoch 25/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0881 - accuracy: 0.9644 - val_loss: 0.1829 - val_accuracy: 0.9213\n",
      "Epoch 26/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.0893 - accuracy: 0.9638 - val_loss: 0.1692 - val_accuracy: 0.9416\n",
      "Epoch 27/200\n",
      "99/99 [==============================] - 13s 126ms/step - loss: 0.0896 - accuracy: 0.9606 - val_loss: 0.1295 - val_accuracy: 0.9416\n",
      "Epoch 28/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0869 - accuracy: 0.9644 - val_loss: 0.0898 - val_accuracy: 0.9645\n",
      "Epoch 29/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0839 - accuracy: 0.9648 - val_loss: 0.1128 - val_accuracy: 0.9480\n",
      "Epoch 30/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.0813 - accuracy: 0.9660 - val_loss: 0.2139 - val_accuracy: 0.9162\n",
      "Epoch 31/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0775 - accuracy: 0.9692 - val_loss: 0.0892 - val_accuracy: 0.9632\n",
      "Epoch 32/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.0834 - accuracy: 0.9644 - val_loss: 0.0913 - val_accuracy: 0.9619\n",
      "Epoch 33/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0822 - accuracy: 0.9679 - val_loss: 0.1607 - val_accuracy: 0.9365\n",
      "Epoch 34/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0812 - accuracy: 0.9673 - val_loss: 0.1061 - val_accuracy: 0.9569\n",
      "Epoch 35/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.0919 - accuracy: 0.9603 - val_loss: 0.1152 - val_accuracy: 0.9530\n",
      "Epoch 36/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.0902 - accuracy: 0.9597 - val_loss: 0.2469 - val_accuracy: 0.8921\n",
      "Epoch 37/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0774 - accuracy: 0.9663 - val_loss: 0.1316 - val_accuracy: 0.9454\n",
      "Epoch 38/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0755 - accuracy: 0.9708 - val_loss: 0.2299 - val_accuracy: 0.9175\n",
      "Epoch 39/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0698 - accuracy: 0.9730 - val_loss: 0.0881 - val_accuracy: 0.9670\n",
      "Epoch 40/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0714 - accuracy: 0.9705 - val_loss: 0.1074 - val_accuracy: 0.9569\n",
      "Epoch 41/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.0666 - accuracy: 0.9692 - val_loss: 0.0924 - val_accuracy: 0.9581\n",
      "Epoch 42/200\n",
      "99/99 [==============================] - 13s 131ms/step - loss: 0.0698 - accuracy: 0.9727 - val_loss: 0.0907 - val_accuracy: 0.9670\n",
      "Epoch 43/200\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 0.0588 - accuracy: 0.9775 - val_loss: 0.1094 - val_accuracy: 0.9594\n",
      "Epoch 44/200\n",
      "99/99 [==============================] - 13s 136ms/step - loss: 0.0796 - accuracy: 0.9679 - val_loss: 0.0817 - val_accuracy: 0.9619\n",
      "Epoch 45/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.0689 - accuracy: 0.9717 - val_loss: 0.1090 - val_accuracy: 0.9594\n",
      "Epoch 46/200\n",
      "99/99 [==============================] - 13s 134ms/step - loss: 0.0652 - accuracy: 0.9689 - val_loss: 0.1128 - val_accuracy: 0.9569\n",
      "Epoch 47/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0677 - accuracy: 0.9730 - val_loss: 0.1724 - val_accuracy: 0.9378\n",
      "Epoch 48/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0645 - accuracy: 0.9717 - val_loss: 0.1448 - val_accuracy: 0.9480\n",
      "Epoch 49/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0676 - accuracy: 0.9727 - val_loss: 0.1597 - val_accuracy: 0.9391\n",
      "Epoch 50/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0538 - accuracy: 0.9765 - val_loss: 0.0920 - val_accuracy: 0.9619\n",
      "Epoch 51/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0588 - accuracy: 0.9768 - val_loss: 0.1200 - val_accuracy: 0.9556\n",
      "Epoch 52/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0622 - accuracy: 0.9765 - val_loss: 0.1161 - val_accuracy: 0.9543\n",
      "Epoch 53/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0684 - accuracy: 0.9711 - val_loss: 0.1017 - val_accuracy: 0.9594\n",
      "Epoch 54/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.0616 - accuracy: 0.9743 - val_loss: 0.1173 - val_accuracy: 0.9543\n",
      "Epoch 55/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0613 - accuracy: 0.9736 - val_loss: 0.0910 - val_accuracy: 0.9594\n",
      "Epoch 56/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0559 - accuracy: 0.9762 - val_loss: 0.0843 - val_accuracy: 0.9619\n",
      "Epoch 57/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0539 - accuracy: 0.9790 - val_loss: 0.0996 - val_accuracy: 0.9569\n",
      "Epoch 58/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0638 - accuracy: 0.9740 - val_loss: 0.0807 - val_accuracy: 0.9607\n",
      "Epoch 59/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0522 - accuracy: 0.9816 - val_loss: 0.1187 - val_accuracy: 0.9581\n",
      "Epoch 60/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0545 - accuracy: 0.9771 - val_loss: 0.0865 - val_accuracy: 0.9695\n",
      "Epoch 61/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0519 - accuracy: 0.9794 - val_loss: 0.0986 - val_accuracy: 0.9619\n",
      "Epoch 62/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0643 - accuracy: 0.9724 - val_loss: 0.2062 - val_accuracy: 0.9239\n",
      "Epoch 63/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0522 - accuracy: 0.9781 - val_loss: 0.1001 - val_accuracy: 0.9670\n",
      "Epoch 64/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0545 - accuracy: 0.9762 - val_loss: 0.0970 - val_accuracy: 0.9632\n",
      "Epoch 65/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0558 - accuracy: 0.9765 - val_loss: 0.1365 - val_accuracy: 0.9530\n",
      "Epoch 66/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0476 - accuracy: 0.9806 - val_loss: 0.0892 - val_accuracy: 0.9683\n",
      "Epoch 67/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0529 - accuracy: 0.9768 - val_loss: 0.0906 - val_accuracy: 0.9695\n",
      "Epoch 68/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0504 - accuracy: 0.9787 - val_loss: 0.1546 - val_accuracy: 0.9353\n",
      "Epoch 69/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0609 - accuracy: 0.9746 - val_loss: 0.1210 - val_accuracy: 0.9530\n",
      "Epoch 70/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0610 - accuracy: 0.9755 - val_loss: 0.0922 - val_accuracy: 0.9594\n",
      "Epoch 71/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0519 - accuracy: 0.9775 - val_loss: 0.0942 - val_accuracy: 0.9619\n",
      "Epoch 72/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0478 - accuracy: 0.9819 - val_loss: 0.1288 - val_accuracy: 0.9492\n",
      "Epoch 73/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0531 - accuracy: 0.9768 - val_loss: 0.1187 - val_accuracy: 0.9569\n",
      "Epoch 74/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.1120 - val_accuracy: 0.9607\n",
      "Epoch 75/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0452 - accuracy: 0.9816 - val_loss: 0.2062 - val_accuracy: 0.9327\n",
      "Epoch 76/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0471 - accuracy: 0.9822 - val_loss: 0.1002 - val_accuracy: 0.9619\n",
      "Epoch 77/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0484 - accuracy: 0.9822 - val_loss: 0.0918 - val_accuracy: 0.9632\n",
      "Epoch 78/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0439 - accuracy: 0.9825 - val_loss: 0.3083 - val_accuracy: 0.9150\n",
      "Epoch 79/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0519 - accuracy: 0.9797 - val_loss: 0.0868 - val_accuracy: 0.9645\n",
      "Epoch 80/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0437 - accuracy: 0.9829 - val_loss: 0.0883 - val_accuracy: 0.9670\n",
      "Epoch 81/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0526 - accuracy: 0.9800 - val_loss: 0.1815 - val_accuracy: 0.9454\n",
      "Epoch 82/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0522 - accuracy: 0.9800 - val_loss: 0.3937 - val_accuracy: 0.9162\n",
      "Epoch 83/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0433 - accuracy: 0.9848 - val_loss: 0.1446 - val_accuracy: 0.9518\n",
      "Epoch 84/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0400 - accuracy: 0.9832 - val_loss: 0.1441 - val_accuracy: 0.9530\n",
      "Epoch 85/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0361 - accuracy: 0.9860 - val_loss: 0.1077 - val_accuracy: 0.9581\n",
      "Epoch 86/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0377 - accuracy: 0.9870 - val_loss: 0.1121 - val_accuracy: 0.9645\n",
      "Epoch 87/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0446 - accuracy: 0.9797 - val_loss: 0.1312 - val_accuracy: 0.9581\n",
      "Epoch 88/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0417 - accuracy: 0.9835 - val_loss: 0.1044 - val_accuracy: 0.9607\n",
      "Epoch 89/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0406 - accuracy: 0.9838 - val_loss: 0.1372 - val_accuracy: 0.9556\n",
      "Epoch 90/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0427 - accuracy: 0.9813 - val_loss: 0.1088 - val_accuracy: 0.9581\n",
      "Epoch 91/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.0438 - accuracy: 0.9800 - val_loss: 0.1169 - val_accuracy: 0.9543\n",
      "Epoch 92/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.0441 - accuracy: 0.9809 - val_loss: 0.1520 - val_accuracy: 0.9492\n",
      "Epoch 93/200\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 0.0528 - accuracy: 0.9803 - val_loss: 0.1953 - val_accuracy: 0.9442\n",
      "Epoch 94/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0579 - accuracy: 0.9762 - val_loss: 0.1080 - val_accuracy: 0.9619\n",
      "Epoch 95/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0353 - accuracy: 0.9851 - val_loss: 0.0891 - val_accuracy: 0.9670\n",
      "Epoch 96/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0386 - accuracy: 0.9854 - val_loss: 0.0815 - val_accuracy: 0.9695\n",
      "Epoch 97/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0348 - accuracy: 0.9838 - val_loss: 0.0891 - val_accuracy: 0.9683\n",
      "Epoch 98/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0361 - accuracy: 0.9838 - val_loss: 0.1857 - val_accuracy: 0.9442\n",
      "Epoch 99/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0433 - accuracy: 0.9832 - val_loss: 0.1124 - val_accuracy: 0.9619\n",
      "Epoch 100/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0326 - accuracy: 0.9876 - val_loss: 0.2471 - val_accuracy: 0.9239\n",
      "Epoch 101/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0373 - accuracy: 0.9854 - val_loss: 0.0953 - val_accuracy: 0.9569\n",
      "Epoch 102/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0337 - accuracy: 0.9863 - val_loss: 0.1041 - val_accuracy: 0.9594\n",
      "Epoch 103/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0390 - accuracy: 0.9829 - val_loss: 0.1193 - val_accuracy: 0.9594\n",
      "Epoch 104/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.1290 - val_accuracy: 0.9518\n",
      "Epoch 105/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0436 - accuracy: 0.9825 - val_loss: 0.1006 - val_accuracy: 0.9645\n",
      "Epoch 106/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 0.1059 - val_accuracy: 0.9645\n",
      "Epoch 107/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0336 - accuracy: 0.9867 - val_loss: 0.0847 - val_accuracy: 0.9657\n",
      "Epoch 108/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0297 - accuracy: 0.9889 - val_loss: 0.0983 - val_accuracy: 0.9657\n",
      "Epoch 109/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.0523 - accuracy: 0.9787 - val_loss: 0.1570 - val_accuracy: 0.9505\n",
      "Epoch 110/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0407 - accuracy: 0.9822 - val_loss: 0.1034 - val_accuracy: 0.9683\n",
      "Epoch 111/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0320 - accuracy: 0.9883 - val_loss: 0.1183 - val_accuracy: 0.9581\n",
      "Epoch 112/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0354 - accuracy: 0.9851 - val_loss: 0.1588 - val_accuracy: 0.9543\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.1179 - val_accuracy: 0.9543\n",
      "Epoch 114/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0258 - accuracy: 0.9895 - val_loss: 0.0980 - val_accuracy: 0.9708\n",
      "Epoch 115/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.1210 - val_accuracy: 0.9607\n",
      "Epoch 116/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.1404 - val_accuracy: 0.9619\n",
      "Epoch 117/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0353 - accuracy: 0.9844 - val_loss: 0.1001 - val_accuracy: 0.9632\n",
      "Epoch 118/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.0339 - accuracy: 0.9883 - val_loss: 0.1817 - val_accuracy: 0.9454\n",
      "Epoch 119/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0379 - accuracy: 0.9857 - val_loss: 0.1009 - val_accuracy: 0.9581\n",
      "Epoch 120/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.0865 - val_accuracy: 0.9594\n",
      "Epoch 121/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0324 - accuracy: 0.9870 - val_loss: 0.4143 - val_accuracy: 0.8858\n",
      "Epoch 122/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0416 - accuracy: 0.9825 - val_loss: 0.1056 - val_accuracy: 0.9594\n",
      "Epoch 123/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0353 - accuracy: 0.9857 - val_loss: 0.1124 - val_accuracy: 0.9569\n",
      "Epoch 124/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0319 - accuracy: 0.9867 - val_loss: 0.1174 - val_accuracy: 0.9683\n",
      "Epoch 125/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0274 - accuracy: 0.9895 - val_loss: 0.2153 - val_accuracy: 0.9442\n",
      "Epoch 126/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.1462 - val_accuracy: 0.9581\n",
      "Epoch 127/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0345 - accuracy: 0.9863 - val_loss: 0.0894 - val_accuracy: 0.9632\n",
      "Epoch 128/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0272 - accuracy: 0.9902 - val_loss: 0.0917 - val_accuracy: 0.9581\n",
      "Epoch 129/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 0.0977 - val_accuracy: 0.9670\n",
      "Epoch 130/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0288 - accuracy: 0.9886 - val_loss: 0.1707 - val_accuracy: 0.9492\n",
      "Epoch 131/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0290 - accuracy: 0.9889 - val_loss: 0.1365 - val_accuracy: 0.9569\n",
      "Epoch 132/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0307 - accuracy: 0.9870 - val_loss: 0.1345 - val_accuracy: 0.9530\n",
      "Epoch 133/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0261 - accuracy: 0.9889 - val_loss: 0.0967 - val_accuracy: 0.9632\n",
      "Epoch 134/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 0.1795 - val_accuracy: 0.9480\n",
      "Epoch 135/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0288 - accuracy: 0.9895 - val_loss: 0.1048 - val_accuracy: 0.9657\n",
      "Epoch 136/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0275 - accuracy: 0.9870 - val_loss: 0.1069 - val_accuracy: 0.9645\n",
      "Epoch 137/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0378 - accuracy: 0.9867 - val_loss: 0.1123 - val_accuracy: 0.9543\n",
      "Epoch 138/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0345 - accuracy: 0.9879 - val_loss: 0.0906 - val_accuracy: 0.9632\n",
      "Epoch 139/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0261 - accuracy: 0.9892 - val_loss: 0.1795 - val_accuracy: 0.9416\n",
      "Epoch 140/200\n",
      "99/99 [==============================] - 13s 127ms/step - loss: 0.0284 - accuracy: 0.9867 - val_loss: 0.1108 - val_accuracy: 0.9569\n",
      "Epoch 141/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 0.1324 - val_accuracy: 0.9530\n",
      "Epoch 142/200\n",
      "99/99 [==============================] - 13s 130ms/step - loss: 0.0210 - accuracy: 0.9914 - val_loss: 0.0956 - val_accuracy: 0.9594\n",
      "Epoch 143/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0250 - accuracy: 0.9905 - val_loss: 0.1117 - val_accuracy: 0.9695\n",
      "Epoch 144/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0227 - accuracy: 0.9917 - val_loss: 0.1908 - val_accuracy: 0.9492\n",
      "Epoch 145/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0394 - accuracy: 0.9838 - val_loss: 0.1142 - val_accuracy: 0.9607\n",
      "Epoch 146/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.1011 - val_accuracy: 0.9645\n",
      "Epoch 147/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0246 - accuracy: 0.9902 - val_loss: 0.1321 - val_accuracy: 0.9594\n",
      "Epoch 148/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.1896 - val_accuracy: 0.9505\n",
      "Epoch 149/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0259 - accuracy: 0.9886 - val_loss: 0.1694 - val_accuracy: 0.9581\n",
      "Epoch 150/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0265 - accuracy: 0.9879 - val_loss: 0.1192 - val_accuracy: 0.9619\n",
      "Epoch 151/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.0810 - val_accuracy: 0.9695\n",
      "Epoch 152/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.1134 - val_accuracy: 0.9670\n",
      "Epoch 153/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.1155 - val_accuracy: 0.9619\n",
      "Epoch 154/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0267 - accuracy: 0.9895 - val_loss: 0.1404 - val_accuracy: 0.9530\n",
      "Epoch 155/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0264 - accuracy: 0.9883 - val_loss: 0.1447 - val_accuracy: 0.9556\n",
      "Epoch 156/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0224 - accuracy: 0.9905 - val_loss: 0.1056 - val_accuracy: 0.9594\n",
      "Epoch 157/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.1432 - val_accuracy: 0.9632\n",
      "Epoch 158/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0277 - accuracy: 0.9886 - val_loss: 0.1007 - val_accuracy: 0.9645\n",
      "Epoch 159/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0235 - accuracy: 0.9902 - val_loss: 0.1174 - val_accuracy: 0.9556\n",
      "Epoch 160/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0230 - accuracy: 0.9917 - val_loss: 0.1483 - val_accuracy: 0.9543\n",
      "Epoch 161/200\n",
      "99/99 [==============================] - 12s 125ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0930 - val_accuracy: 0.9594\n",
      "Epoch 162/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0258 - accuracy: 0.9898 - val_loss: 0.1575 - val_accuracy: 0.9543\n",
      "Epoch 163/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.1679 - val_accuracy: 0.9530\n",
      "Epoch 164/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.1094 - val_accuracy: 0.9695\n",
      "Epoch 165/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.1187 - val_accuracy: 0.9607\n",
      "Epoch 166/200\n",
      "99/99 [==============================] - 12s 124ms/step - loss: 0.0182 - accuracy: 0.9927 - val_loss: 0.1226 - val_accuracy: 0.9708\n",
      "Epoch 167/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0355 - accuracy: 0.9876 - val_loss: 0.1199 - val_accuracy: 0.9657\n",
      "Epoch 168/200\n",
      "99/99 [==============================] - 12s 126ms/step - loss: 0.0311 - accuracy: 0.9889 - val_loss: 0.1165 - val_accuracy: 0.9670\n",
      "Epoch 169/200\n",
      "99/99 [==============================] - 12s 123ms/step - loss: 0.0229 - accuracy: 0.9908 - val_loss: 0.1248 - val_accuracy: 0.9569\n",
      "Epoch 170/200\n",
      "99/99 [==============================] - 12s 122ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 0.0973 - val_accuracy: 0.9670\n",
      "Epoch 171/200\n",
      "99/99 [==============================] - 14s 142ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.1447 - val_accuracy: 0.9619\n",
      "Epoch 172/200\n",
      "99/99 [==============================] - 18s 179ms/step - loss: 0.0248 - accuracy: 0.9898 - val_loss: 0.1521 - val_accuracy: 0.9607\n",
      "Epoch 173/200\n",
      "99/99 [==============================] - 17s 172ms/step - loss: 0.0260 - accuracy: 0.9902 - val_loss: 0.1620 - val_accuracy: 0.9619\n",
      "Epoch 174/200\n",
      "99/99 [==============================] - 16s 161ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.1544 - val_accuracy: 0.9645\n",
      "Epoch 175/200\n",
      "99/99 [==============================] - 16s 161ms/step - loss: 0.0257 - accuracy: 0.9886 - val_loss: 0.1404 - val_accuracy: 0.9607\n",
      "Epoch 176/200\n",
      "99/99 [==============================] - 18s 178ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.1582 - val_accuracy: 0.9556\n",
      "Epoch 177/200\n",
      "99/99 [==============================] - 16s 161ms/step - loss: 0.0188 - accuracy: 0.9924 - val_loss: 0.1771 - val_accuracy: 0.9594\n",
      "Epoch 178/200\n",
      "99/99 [==============================] - 15s 155ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.1120 - val_accuracy: 0.9632\n",
      "Epoch 179/200\n",
      "99/99 [==============================] - 16s 165ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.1768 - val_accuracy: 0.9518\n",
      "Epoch 180/200\n",
      "99/99 [==============================] - 16s 157ms/step - loss: 0.0195 - accuracy: 0.9914 - val_loss: 0.1117 - val_accuracy: 0.9645\n",
      "Epoch 181/200\n",
      "99/99 [==============================] - 17s 172ms/step - loss: 0.0280 - accuracy: 0.9895 - val_loss: 0.1503 - val_accuracy: 0.9543\n",
      "Epoch 182/200\n",
      "99/99 [==============================] - 17s 169ms/step - loss: 0.0332 - accuracy: 0.9851 - val_loss: 0.1552 - val_accuracy: 0.9607\n",
      "Epoch 183/200\n",
      "99/99 [==============================] - 15s 156ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.0986 - val_accuracy: 0.9683\n",
      "Epoch 184/200\n",
      "99/99 [==============================] - 14s 141ms/step - loss: 0.0219 - accuracy: 0.9914 - val_loss: 0.1159 - val_accuracy: 0.9670\n",
      "Epoch 185/200\n",
      "99/99 [==============================] - 15s 155ms/step - loss: 0.0285 - accuracy: 0.9883 - val_loss: 0.1269 - val_accuracy: 0.9607\n",
      "Epoch 186/200\n",
      "99/99 [==============================] - 16s 165ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 0.1357 - val_accuracy: 0.9530\n",
      "Epoch 187/200\n",
      "99/99 [==============================] - 16s 157ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.1174 - val_accuracy: 0.9645\n",
      "Epoch 188/200\n",
      "99/99 [==============================] - 14s 146ms/step - loss: 0.0220 - accuracy: 0.9898 - val_loss: 0.1856 - val_accuracy: 0.9518\n",
      "Epoch 189/200\n",
      "99/99 [==============================] - 17s 168ms/step - loss: 0.0205 - accuracy: 0.9914 - val_loss: 0.1049 - val_accuracy: 0.9619\n",
      "Epoch 190/200\n",
      "99/99 [==============================] - 17s 167ms/step - loss: 0.0261 - accuracy: 0.9895 - val_loss: 0.1071 - val_accuracy: 0.9670\n",
      "Epoch 191/200\n",
      "99/99 [==============================] - 18s 182ms/step - loss: 0.0200 - accuracy: 0.9914 - val_loss: 0.1130 - val_accuracy: 0.9581\n",
      "Epoch 192/200\n",
      "99/99 [==============================] - 15s 155ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.1419 - val_accuracy: 0.9581\n",
      "Epoch 193/200\n",
      "99/99 [==============================] - 13s 136ms/step - loss: 0.0178 - accuracy: 0.9924 - val_loss: 0.1166 - val_accuracy: 0.9581\n",
      "Epoch 194/200\n",
      "99/99 [==============================] - 14s 137ms/step - loss: 0.0167 - accuracy: 0.9930 - val_loss: 0.1419 - val_accuracy: 0.9695\n",
      "Epoch 195/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.0219 - accuracy: 0.9924 - val_loss: 0.1952 - val_accuracy: 0.9518\n",
      "Epoch 196/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0355 - accuracy: 0.9860 - val_loss: 0.1180 - val_accuracy: 0.9569\n",
      "Epoch 197/200\n",
      "99/99 [==============================] - 13s 128ms/step - loss: 0.0274 - accuracy: 0.9889 - val_loss: 0.1085 - val_accuracy: 0.9645\n",
      "Epoch 198/200\n",
      "99/99 [==============================] - 13s 135ms/step - loss: 0.0219 - accuracy: 0.9895 - val_loss: 0.1789 - val_accuracy: 0.9480\n",
      "Epoch 199/200\n",
      "99/99 [==============================] - 13s 129ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.1144 - val_accuracy: 0.9581\n",
      "Epoch 200/200\n",
      "99/99 [==============================] - 14s 139ms/step - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.1285 - val_accuracy: 0.9594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e80aeb100>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34c30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f7c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3edaf8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18,   7],\n",
       "       [153,  22]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y_test[:200]\n",
    "pred = model.predict(test_df[:200])\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9b69d0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.2>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4656ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd5bdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 10, 5)             520       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10, 1)             6         \n",
      "=================================================================\n",
      "Total params: 526\n",
      "Trainable params: 526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (10, 20), return_sequences = True))\n",
    "model.add((Dense(1)))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ab4b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 10, 5)             520       \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 10, 1)             6         \n",
      "=================================================================\n",
      "Total params: 526\n",
      "Trainable params: 526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (10, 20), return_sequences = True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e3d6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('TimeDist30.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae16464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd283d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3dadee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadef525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59333c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99cab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38003c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587f4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b7243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c9698e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdc48c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081f926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
