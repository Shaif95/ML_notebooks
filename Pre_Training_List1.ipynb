{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "775ed160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4739769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3c63e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f3cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef193f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d854baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d280fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the path to the ImageNet dataset\n",
    "dataset_path = 'D:/data/imagenet'\n",
    "\n",
    "# Get the list of class folders in the dataset\n",
    "class_folders = glob.glob(dataset_path+'/*/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3841f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import gc\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features_from_directory(directory):\n",
    "    image_list = []\n",
    "    valid_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif']  # Add more valid extensions if needed\n",
    "\n",
    "    # Load the ResNet50 model\n",
    "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "    # Get the total number of files to process\n",
    "    total_files = sum(len(glob.glob(os.path.join(directory, extension))) for extension in valid_extensions)\n",
    "\n",
    "    # Iterate over the files and show progress using tqdm\n",
    "    progress_bar = tqdm(total=total_files)\n",
    "    for extension in valid_extensions:\n",
    "        for image_path in glob.glob(os.path.join(directory, extension)):\n",
    "            # Load and resize the image using PIL\n",
    "            image = Image.open(image_path)\n",
    "            image = image.resize((224, 224))\n",
    "\n",
    "            # Convert image to array and normalize pixel values\n",
    "            image = np.array(image) / 255.0\n",
    "\n",
    "            # Add batch dimension to match ResNet input shape\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "\n",
    "            # Preprocess the image\n",
    "            image = preprocess_input(image)\n",
    "\n",
    "            # Extract features using ResNet model\n",
    "            features = model.predict(image)\n",
    "\n",
    "            # Append the features to the list\n",
    "            image_list.append(features)\n",
    "\n",
    "            # Delete variables to clear memory\n",
    "            del image_path, image\n",
    "            gc.collect()\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Delete the ResNet model\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    return image_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07e03aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▋                                                      | 407/1300 [02:04<05:06,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 224, 224).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"resnet50\" (type Functional).\n    \n    Input 0 of layer \"conv1_pad\" is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, 224, 224)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 224, 224), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_folders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 36\u001b[0m, in \u001b[0;36mextract_features_from_directory\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     33\u001b[0m image \u001b[38;5;241m=\u001b[39m preprocess_input(image)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Extract features using ResNet model\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Append the features to the list\u001b[39;00m\n\u001b[0;32m     39\u001b[0m image_list\u001b[38;5;241m.\u001b[39mappend(features)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1130\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"resnet50\" (type Functional).\n    \n    Input 0 of layer \"conv1_pad\" is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: (None, 224, 224)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 224, 224), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "x = extract_features_from_directory(class_folders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db654982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79941a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2538ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
