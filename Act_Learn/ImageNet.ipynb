{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32957d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'imagenet64.tar'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2ad10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ImageNetDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, image_paths, labels, batch_size):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_paths[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        \n",
    "        batch_x_images = [img_to_array(load_img(img_path, target_size=(64, 64))) for img_path in batch_x]\n",
    "        batch_x_array = np.array(batch_x_images)\n",
    "\n",
    "        return batch_x_array, np.array(batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b5a8020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 'imagenet64.tar' to 'imagenet64' directory\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4a085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aaa0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def active_learning_random_sampling(image_paths, labels, model, batch_size, n_initial, n_queries, n_samples_per_query):\n",
    "    # Split data into labeled and unlabeled sets\n",
    "    labeled_indices = np.random.choice(len(image_paths), size=n_initial, replace=False)\n",
    "    unlabeled_indices = np.array([i for i in range(len(image_paths)) if i not in labeled_indices])\n",
    "    labeled_image_paths = np.array(image_paths)[labeled_indices]\n",
    "    labeled_labels = np.array(labels)[labeled_indices]\n",
    "    unlabeled_image_paths = np.array(image_paths)[unlabeled_indices]\n",
    "    unlabeled_labels = np.array(labels)[unlabeled_indices]\n",
    "\n",
    "    for query in range(n_queries):\n",
    "        print(f\"Query {query + 1}/{n_queries}\")\n",
    "        \n",
    "        # Train the model on the labeled data\n",
    "        labeled_data_generator = tqdm( ImageNetDataGenerator(labeled_image_paths, labeled_labels, batch_size))\n",
    "        model.fit(labeled_data_generator, epochs=1)\n",
    "\n",
    "        # Randomly sample the data for the next query\n",
    "        sampled_indices = np.random.choice(len(unlabeled_image_paths), size=n_samples_per_query, replace=False)\n",
    "        new_labeled_image_paths = unlabeled_image_paths[sampled_indices]\n",
    "        new_labeled_labels = unlabeled_labels[sampled_indices]\n",
    "\n",
    "        # Update the labeled and unlabeled sets\n",
    "        labeled_image_paths = np.concatenate([labeled_image_paths, new_labeled_image_paths])\n",
    "        labeled_labels = np.concatenate([labeled_labels, new_labeled_labels])\n",
    "        unlabeled_indices = np.array([i for i in range(len(unlabeled_image_paths)) if i not in sampled_indices])\n",
    "        unlabeled_image_paths = unlabeled_image_paths[unlabeled_indices]\n",
    "        unlabeled_labels = unlabeled_labels[unlabeled_indices]\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe26d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890c9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths_and_labels(root_dir):\n",
    "    class_dirs = [os.path.join(root_dir, class_name) for class_name in os.listdir(root_dir)]\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for label, class_dir in enumerate(class_dirs):\n",
    "        class_image_paths = [os.path.join(class_dir, image_name) for image_name in os.listdir(class_dir)]\n",
    "        image_paths.extend(class_image_paths)\n",
    "        labels.extend([label] * len(class_image_paths))\n",
    "\n",
    "    return image_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29506811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c55681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the ImageNet training and validation data\n",
    "train_root = \"E:/ML_notebooks/Act_Learn/imagenet64/imagenet64/train\"\n",
    "val_root = \"E:/ML_notebooks/Act_Learn/imagenet64/imagenet64/val\"\n",
    "train_image_paths, train_labels = get_image_paths_and_labels(train_root)\n",
    "val_image_paths, val_labels = get_image_paths_and_labels(val_root)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.applications.ResNet50V2(weights=None, input_shape=(64, 64, 3), classes=1000)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e29e1cb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10156\\3240589906.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_samples_per_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m24000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m model = active_learning_random_sampling(\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_image_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_initial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_per_query\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10156\\921844586.py\u001b[0m in \u001b[0;36mactive_learning_random_sampling\u001b[1;34m(image_paths, labels, model, batch_size, n_initial, n_queries, n_samples_per_query)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Split data into labeled and unlabeled sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlabeled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_initial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0munlabeled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabeled_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mlabeled_image_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabeled_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlabeled_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabeled_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10156\\921844586.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Split data into labeled and unlabeled sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlabeled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_initial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0munlabeled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabeled_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mlabeled_image_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabeled_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlabeled_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabeled_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_initial = 240000\n",
    "n_queries = 10\n",
    "n_samples_per_query = 24000\n",
    "\n",
    "model = active_learning_random_sampling(\n",
    "    train_image_paths, train_labels, model, batch_size, n_initial, n_queries, n_samples_per_query\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "val_data_generator = ImageNetDataGenerator(val_image_paths, val_labels, batch_size)\n",
    "val_accuracy = model.evaluate(val_data_generator)[1]\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92268504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da1749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c03e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d0b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
