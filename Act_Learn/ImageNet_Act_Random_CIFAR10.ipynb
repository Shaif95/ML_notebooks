{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0626244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69c22186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the path to the ImageNet dataset\n",
    "dataset_path = 'D:/data/imagenet'\n",
    "\n",
    "# Get the list of class folders in the dataset\n",
    "class_folders = glob.glob(dataset_path+'/*/')\n",
    "\n",
    "tr_folders = []\n",
    "labels = []\n",
    "x  = 0\n",
    "for i in class_folders:\n",
    "    a = glob.glob(i+'/*')\n",
    "    for j in a:\n",
    "        labels.append(x)\n",
    "        tr_folders.append(j)\n",
    "        \n",
    "    x=x+1\n",
    "#tr_labels = to_categorical ( labels )\n",
    "tr_labels = ( labels )\n",
    "# Split the class folders into train and test sets\n",
    "x_train = tr_folders\n",
    "y_train = tr_labels\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( x_train, y_train , test_size=0.1, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c31e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d8a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a09f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    imgdata = []\n",
    "    a = Image.open(k)\n",
    "    if a.mode != \"RGB\":\n",
    "        a = a.convert(\"RGB\")\n",
    "    b = a.resize((32, 32))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(32, 32,3))\n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train.reshape(32, 32,3)\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445dfc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5a7935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52943830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path, target_size=(32, 32)):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    \n",
    "    image = image.resize(target_size)\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  # Normalize to range [0, 1]\n",
    "    return image.astype(np.float32)\n",
    "\n",
    "X_test_processed = []\n",
    "for image_path in X_test:\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    X_test_processed.append(processed_image)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "X_test_processed = np.array(X_test_processed)\n",
    "X_test = X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "320e4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_unlab, Y_train, y_unlab = train_test_split( X_train, Y_train, test_size=0.9, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf2923f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6399/6399 [01:10<00:00, 91.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_images(X_test, target_size=(32, 32)):\n",
    "\n",
    "    def preprocess_image(image_path):\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Convert the image to RGB if it's not already\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        image = image.resize(target_size)\n",
    "        image = img_to_array(image)\n",
    "        image = image / 255.0  # Normalize to range [0, 1]\n",
    "        return image.astype(np.float32)\n",
    "\n",
    "    X_test_processed = []\n",
    "    \n",
    "    for image_path in tqdm(X_test):\n",
    "        processed_image = preprocess_image(image_path)\n",
    "        X_test_processed.append(processed_image)\n",
    "\n",
    "    # Convert the list to a numpy array\n",
    "    X_test_processed = np.array(X_test_processed)\n",
    "\n",
    "    return X_test_processed\n",
    "\n",
    "X_train = preprocess_images(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53211b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f1c6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bbe0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test, Y_test):\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Test set evaluation: \", model.evaluate( X_test, Y_test , verbose=0, return_dict=True, batch_size = 2000), )\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "def train(model,X_train, Y_train, epoch):\n",
    "    \n",
    "    print(f\"Starting to train with {len(Y_train)} samples\")\n",
    "\n",
    "    history = model.fit(X_train, Y_train, batch_size = 2000, epochs=epoch,validation_split=.20)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04deb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00944a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train with 115305 samples\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 39s 380ms/step - loss: 6.9199 - accuracy: 0.0034 - val_loss: 6.9368 - val_accuracy: 9.9735e-04\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 13s 272ms/step - loss: 6.5344 - accuracy: 0.0109 - val_loss: 6.9669 - val_accuracy: 0.0012\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 13s 272ms/step - loss: 6.2636 - accuracy: 0.0193 - val_loss: 11.0061 - val_accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 13s 274ms/step - loss: 5.9809 - accuracy: 0.0308 - val_loss: 6.9760 - val_accuracy: 0.0014\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 13s 280ms/step - loss: 5.8664 - accuracy: 0.0368 - val_loss: 8.1901 - val_accuracy: 0.0026\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 5.6285 - accuracy: 0.0528 - val_loss: 6.9510 - val_accuracy: 0.0053\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 13s 276ms/step - loss: 5.3557 - accuracy: 0.0689 - val_loss: 7.1477 - val_accuracy: 0.0077\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 13s 276ms/step - loss: 5.1368 - accuracy: 0.0848 - val_loss: 6.3587 - val_accuracy: 0.0207\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 13s 276ms/step - loss: 4.8298 - accuracy: 0.1090 - val_loss: 6.3216 - val_accuracy: 0.0236\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 4.5500 - accuracy: 0.1355 - val_loss: 6.3627 - val_accuracy: 0.0237\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 13s 277ms/step - loss: 4.0780 - accuracy: 0.1870 - val_loss: 6.3561 - val_accuracy: 0.0299\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 3.5632 - accuracy: 0.2553 - val_loss: 6.4074 - val_accuracy: 0.0318\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 13s 281ms/step - loss: 2.9911 - accuracy: 0.3500 - val_loss: 6.5547 - val_accuracy: 0.0376\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 2.4429 - accuracy: 0.4540 - val_loss: 6.9110 - val_accuracy: 0.0369\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 13s 281ms/step - loss: 1.8744 - accuracy: 0.5746 - val_loss: 7.3142 - val_accuracy: 0.0343\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 1.3284 - accuracy: 0.7020 - val_loss: 7.9162 - val_accuracy: 0.0343\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 0.9171 - accuracy: 0.8009 - val_loss: 8.3155 - val_accuracy: 0.0282\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.6866 - accuracy: 0.8537 - val_loss: 8.4471 - val_accuracy: 0.0326\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 13s 277ms/step - loss: 0.4287 - accuracy: 0.9173 - val_loss: 8.3361 - val_accuracy: 0.0375\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 13s 277ms/step - loss: 0.1796 - accuracy: 0.9736 - val_loss: 8.4462 - val_accuracy: 0.0403\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 13s 277ms/step - loss: 0.0757 - accuracy: 0.9923 - val_loss: 8.4716 - val_accuracy: 0.0430\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 13s 277ms/step - loss: 0.0377 - accuracy: 0.9965 - val_loss: 8.5102 - val_accuracy: 0.0458\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 0.0233 - accuracy: 0.9977 - val_loss: 8.5950 - val_accuracy: 0.0457\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 13s 280ms/step - loss: 0.0166 - accuracy: 0.9983 - val_loss: 8.6576 - val_accuracy: 0.0484\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.0149 - accuracy: 0.9982 - val_loss: 8.7465 - val_accuracy: 0.0470\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.0122 - accuracy: 0.9986 - val_loss: 8.7842 - val_accuracy: 0.0479\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 13s 282ms/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 8.8642 - val_accuracy: 0.0475\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.0086 - accuracy: 0.9990 - val_loss: 8.8866 - val_accuracy: 0.0491\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 8.9255 - val_accuracy: 0.0480\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 13s 280ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 8.9663 - val_accuracy: 0.0480\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 13s 283ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 9.0132 - val_accuracy: 0.0484\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 13s 281ms/step - loss: 0.0064 - accuracy: 0.9993 - val_loss: 9.0546 - val_accuracy: 0.0478\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 13s 280ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 9.0801 - val_accuracy: 0.0482\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 13s 283ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 9.0885 - val_accuracy: 0.0485\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 9.1447 - val_accuracy: 0.0487\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 9.1816 - val_accuracy: 0.0481\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 13s 277ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 9.1932 - val_accuracy: 0.0477\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 13s 280ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 9.2459 - val_accuracy: 0.0480\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 9.2616 - val_accuracy: 0.0487\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 9.2734 - val_accuracy: 0.0487\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 9.3074 - val_accuracy: 0.0486\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 13s 278ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 9.3749 - val_accuracy: 0.0475\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 13s 281ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 9.3746 - val_accuracy: 0.0472\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 13s 281ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 9.3878 - val_accuracy: 0.0473\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 13s 281ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 9.4470 - val_accuracy: 0.0493\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 9.4383 - val_accuracy: 0.0484\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 13s 280ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 9.4642 - val_accuracy: 0.0490\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 13s 282ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 9.5620 - val_accuracy: 0.0454\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 13s 282ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 9.4902 - val_accuracy: 0.0480\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 13s 281ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 9.5195 - val_accuracy: 0.0480\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Test set evaluation:  {'loss': 9.476261138916016, 'accuracy': 0.04807324707508087}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 126835 samples\n",
      "Epoch 1/10\n",
      "51/51 [==============================] - 28s 449ms/step - loss: 1.1726 - accuracy: 0.8294 - val_loss: 9.1573 - val_accuracy: 0.0326\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 14s 276ms/step - loss: 0.4720 - accuracy: 0.9098 - val_loss: 8.9818 - val_accuracy: 0.0373\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 14s 279ms/step - loss: 0.1715 - accuracy: 0.9689 - val_loss: 9.0449 - val_accuracy: 0.0374\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 14s 280ms/step - loss: 0.0639 - accuracy: 0.9921 - val_loss: 9.2138 - val_accuracy: 0.0410\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 14s 280ms/step - loss: 0.0271 - accuracy: 0.9970 - val_loss: 9.2727 - val_accuracy: 0.0436\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 14s 284ms/step - loss: 0.0184 - accuracy: 0.9977 - val_loss: 9.4032 - val_accuracy: 0.0441\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 14s 280ms/step - loss: 0.0145 - accuracy: 0.9979 - val_loss: 9.5208 - val_accuracy: 0.0414\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 14s 281ms/step - loss: 0.0159 - accuracy: 0.9976 - val_loss: 9.7315 - val_accuracy: 0.0418\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 14s 280ms/step - loss: 0.0162 - accuracy: 0.9975 - val_loss: 9.7842 - val_accuracy: 0.0440\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 14s 279ms/step - loss: 0.0238 - accuracy: 0.9961 - val_loss: 9.9023 - val_accuracy: 0.0404\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test set evaluation:  {'loss': 9.888501167297363, 'accuracy': 0.0425158254802227}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 138365 samples\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 28s 408ms/step - loss: 1.1642 - accuracy: 0.8218 - val_loss: 9.7988 - val_accuracy: 0.0375\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 15s 274ms/step - loss: 0.4775 - accuracy: 0.9041 - val_loss: 9.6097 - val_accuracy: 0.0398\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 15s 277ms/step - loss: 0.1762 - accuracy: 0.9649 - val_loss: 9.4478 - val_accuracy: 0.0414\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 16s 278ms/step - loss: 0.0678 - accuracy: 0.9901 - val_loss: 9.5499 - val_accuracy: 0.0439\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 15s 277ms/step - loss: 0.0242 - accuracy: 0.9977 - val_loss: 9.5726 - val_accuracy: 0.0468\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 16s 278ms/step - loss: 0.0163 - accuracy: 0.9984 - val_loss: 9.6836 - val_accuracy: 0.0482\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 16s 279ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 9.7242 - val_accuracy: 0.0486\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 16s 280ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 9.7874 - val_accuracy: 0.0487\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 16s 279ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 9.8632 - val_accuracy: 0.0467\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 16s 279ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 9.9066 - val_accuracy: 0.0461\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test set evaluation:  {'loss': 9.86984920501709, 'accuracy': 0.046746332198381424}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 149895 samples\n",
      "Epoch 1/10\n",
      "60/60 [==============================] - 31s 410ms/step - loss: 1.0977 - accuracy: 0.8326 - val_loss: 9.8007 - val_accuracy: 0.0347\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 17s 278ms/step - loss: 0.4285 - accuracy: 0.9105 - val_loss: 9.5994 - val_accuracy: 0.0433\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 17s 280ms/step - loss: 0.1479 - accuracy: 0.9695 - val_loss: 9.4507 - val_accuracy: 0.0447\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 17s 283ms/step - loss: 0.0524 - accuracy: 0.9923 - val_loss: 9.5028 - val_accuracy: 0.0467\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 17s 282ms/step - loss: 0.0175 - accuracy: 0.9983 - val_loss: 9.5661 - val_accuracy: 0.0498\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 17s 284ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 9.6614 - val_accuracy: 0.0517\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 17s 286ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 9.6720 - val_accuracy: 0.0529\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 17s 285ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 9.7277 - val_accuracy: 0.0530\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 17s 283ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 9.7251 - val_accuracy: 0.0527\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 17s 281ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 9.8406 - val_accuracy: 0.0520\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test set evaluation:  {'loss': 9.856816291809082, 'accuracy': 0.050890982151031494}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 161425 samples\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 30s 385ms/step - loss: 1.0428 - accuracy: 0.8370 - val_loss: 9.7989 - val_accuracy: 0.0383\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 18s 276ms/step - loss: 0.4203 - accuracy: 0.9098 - val_loss: 9.7872 - val_accuracy: 0.0435\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 18s 278ms/step - loss: 0.1543 - accuracy: 0.9667 - val_loss: 9.7385 - val_accuracy: 0.0463\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 0.0564 - accuracy: 0.9910 - val_loss: 9.6642 - val_accuracy: 0.0485\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 0.0205 - accuracy: 0.9978 - val_loss: 9.6362 - val_accuracy: 0.0515\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 9.6596 - val_accuracy: 0.0535\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 9.6969 - val_accuracy: 0.0544\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 18s 283ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 9.7477 - val_accuracy: 0.0548\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 18s 281ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 9.8646 - val_accuracy: 0.0529\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 18s 283ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 9.8539 - val_accuracy: 0.0535\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test set evaluation:  {'loss': 9.903154373168945, 'accuracy': 0.051913484930992126}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 172955 samples\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - 32s 345ms/step - loss: 0.9865 - accuracy: 0.8453 - val_loss: 10.0660 - val_accuracy: 0.0395\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 19s 276ms/step - loss: 0.4248 - accuracy: 0.9057 - val_loss: 9.8505 - val_accuracy: 0.0443\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 20s 284ms/step - loss: 0.2014 - accuracy: 0.9514 - val_loss: 9.8815 - val_accuracy: 0.0433\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 20s 282ms/step - loss: 0.0982 - accuracy: 0.9789 - val_loss: 9.8489 - val_accuracy: 0.0467\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 19s 279ms/step - loss: 0.0445 - accuracy: 0.9928 - val_loss: 9.9079 - val_accuracy: 0.0504\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 19s 279ms/step - loss: 0.0200 - accuracy: 0.9972 - val_loss: 9.9922 - val_accuracy: 0.0509\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 19s 279ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 10.0612 - val_accuracy: 0.0520\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 19s 279ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 10.0442 - val_accuracy: 0.0537\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 20s 279ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 10.0286 - val_accuracy: 0.0536\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 20s 283ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 10.3462 - val_accuracy: 0.0499\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Test set evaluation:  {'loss': 10.367724418640137, 'accuracy': 0.04843229055404663}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "def train_active_learning_models(\n",
    "    model,\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    x_unlab,\n",
    "    y_unlab,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    num_iterations=5):\n",
    "    \n",
    "    test(model, X_test, Y_test)\n",
    "    \n",
    "    d = 100/num_iterations\n",
    "    l = len(y_unlab)\n",
    "    x = int(len(Y_train)/10)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "\n",
    "        model = tf.keras.models.load_model('saved_model/my_model')\n",
    "        \n",
    "        l = len(y_unlab)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        print(\"Iteration : \")\n",
    "        \n",
    "        print(iteration)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "         \n",
    "        #generate random number and substract from all numbers\n",
    "        rnd = random.sample(range(0, len(x_unlab)), x)\n",
    "        all_indices = list(range(1, l))\n",
    "        main_list = list(set(all_indices) - set(rnd))\n",
    "        \n",
    "        #add those index to from unlablled set to training set\n",
    "        img_list = ([x_unlab[i] for i in rnd])\n",
    "        new_lab = preprocess_images( img_list )\n",
    "        arr = np.concatenate((X_train, new_lab))\n",
    "        X_train = arr\n",
    "\n",
    "        #check labels in the set and add to training data\n",
    "        new_y = y_unlab[rnd]\n",
    "        arr = np.concatenate((Y_train, new_y))\n",
    "        Y_train = arr\n",
    "        \n",
    "        \n",
    "        #create the new unlabelled set\n",
    "        x_unlab = ([x_unlab[i] for i in main_list])\n",
    "\n",
    "        #create the new unlabelled label set\n",
    "        y_unlab = y_unlab[main_list]\n",
    "        \n",
    "        \n",
    "        #train on data\n",
    "        model = train(model,X_train, Y_train, 10)\n",
    "        \n",
    "        #test for final time\n",
    "        test(model, X_test, Y_test)\n",
    "\n",
    "        model.save('saved_model/my_model')\n",
    "\n",
    "        del model\n",
    "\n",
    "model = tf.keras.applications.ResNet50V2(input_shape=(32, 32, 3), weights=None, classes=1000)\n",
    "    \n",
    "model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=\"Adam\",\n",
    "        metrics='accuracy'   )\n",
    "    \n",
    "model = train(model,X_train, Y_train, 50)\n",
    "\n",
    "model.save('saved_model/my_model')\n",
    "\n",
    "active_learning_model = train_active_learning_models(model,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978929b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a8bba7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, None, None, 3)     7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "num_classes = 2\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "    # Add custom top layers\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 512\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "hidden_units = 512\n",
    "projection_units = 256\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.02),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(X_train[:50])\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "def create_encoder():\n",
    "    resnet = tf.keras.applications.ResNet50V2( include_top=False, weights=\"imagenet\", input_shape=input_shape, pooling=\"avg\" )\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = resnet(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "287ae7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "\n",
    "        logits = tf.divide( tf.matmul(  \n",
    "            feature_vectors_normalized, tf.transpose(feature_vectors_normalized)),self.temperature,)\n",
    "        \n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329f430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 8s 89ms/step - loss: 1.4947\n",
      "200/200 [==============================] - 11s 38ms/step - loss: nan - sparse_categorical_accuracy: 0.0011\n",
      "41/41 [==============================] - 2s 30ms/step - loss: nan - sparse_categorical_accuracy: 0.0023\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.0023400934878736734\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 80000/80000 [32:43<00:00, 40.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def train_active_learning_models(encoder,classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations,num_epochs=1):\n",
    "\n",
    "    l = len(y_unlab)\n",
    "    d = int ( np.round ( l/num_iterations ) )\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        l = len(y_unlab)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        print(\"Iteration : \")\n",
    "        \n",
    "        print(iteration+1)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "        nn_clusters = 1000\n",
    "        \n",
    "        budget =  1\n",
    "        print(\"\\n\")\n",
    "        print(\"Annotated in each iter : \")\n",
    "        print(budget*nn_clusters*12)\n",
    "\n",
    "        annotate_indices = []\n",
    "        \n",
    "        start = 0\n",
    "        step = 80000\n",
    "        \n",
    "        for i in range(3):\n",
    "            \n",
    "            end = start+step\n",
    "            \n",
    "            x_ulb_plholder = preprocess_images(x_unlab[start:end])\n",
    "            x_ulb = encoder.predict(x_ulb_plholder, batch_size=128)\n",
    "            start = end\n",
    "            print(\"lol1\")\n",
    "            kmeans = MiniBatchKMeans(n_clusters=nn_clusters, init='k-means++', batch_size=10000, n_init=10).fit(x_ulb)\n",
    "            \n",
    "            print(\"lol2\")\n",
    "        \n",
    "            for i in range(nn_clusters):\n",
    "            \n",
    "                cluster_center = kmeans.cluster_centers_[i]\n",
    "            \n",
    "                cluster_indices = np.where(kmeans.labels_ == i)[0]\n",
    "            \n",
    "                distances = np.linalg.norm(x_ulb[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                annotate = cluster_indices[np.argsort(distances,-1)[:budget]]\n",
    "            \n",
    "                pts = cluster_indices[np.argsort(distances,-1)[:1]]\n",
    "            \n",
    "                annotate_indices.extend(annotate)\n",
    "            \n",
    "\n",
    "        annt = annotate_indices      \n",
    "        \n",
    "        ante = x_ulb[annt]\n",
    "        \n",
    "        all = list(range(1, l))\n",
    "        main_list = list(set(all) - set(annt))\n",
    "        \n",
    "        img_list = ([x_unlab[i] for i in ante])\n",
    "        new_annt = preprocess_images( img_list )\n",
    "        arr = np.concatenate((X_train, new_annt.astype(\"float\")))\n",
    "        X_train = arr\n",
    "        \n",
    "        annt_y = y_unlab[annt]\n",
    "        arr = np.concatenate((Y_train, annt_y))\n",
    "        Y_train = arr\n",
    "        \n",
    "        \n",
    "        #create the new unlabelled set\n",
    "        x_unlab = ([x_unlab[i] for i in main_list])\n",
    "\n",
    "        #create the new unlabelled label set\n",
    "        y_unlab = y_unlab[main_list]\n",
    "        \n",
    "        history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=256, epochs=1)\n",
    "\n",
    "        history = classifier.fit(x=X_train, y=Y_train, batch_size=32, epochs=1) \n",
    "\n",
    "        print_acc(classifier, X_test, Y_test)\n",
    "        \n",
    "        print(\"Acc : \")\n",
    "        print(\"\\n\")\n",
    "        print(accuracy)\n",
    "       \n",
    "    \n",
    "    return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "\n",
    "data_augmentation.layers[0].adapt(X_train)\n",
    "encoder = create_encoder()\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                        loss=SupervisedContrastiveLoss(temperature))\n",
    "\n",
    "Y_test  = np.array((Y_test)).astype(\"float\")\n",
    "Y_train = np.array((Y_train)).astype(\"float\")\n",
    "\n",
    "history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=256, epochs=1)\n",
    "classifier = create_classifier(encoder, trainable=False) \n",
    "history = classifier.fit(x=X_train, y=Y_train, batch_size=32, epochs=1) \n",
    "\n",
    "try :\n",
    "  accuracy = classifier.evaluate(X_test, Y_test, batch_size=32)[1]\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "print(\"Acc : \")\n",
    "print(\"\\n\")\n",
    "print(accuracy)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "encoder, classifier,X_train,Y_train,x_unlab,y_unlab = train_active_learning_models(encoder, classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d419458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38bb0f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1037745"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test  = np.array(np.argmax(Y_test)).astype(\"float\")\n",
    "Y_train = np.array(np.argmax(Y_train)).astype(\"float\")\n",
    "X_train = np.array(X_train).astype(\"float\")\n",
    "X_test = np.array(X_test).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046e5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99ab00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecede22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb15a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bc8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c7370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9e2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89812f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae66eaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d97963b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bde3a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73b54d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829e9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12287d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1281166,) (1281166, 1000)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9d295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300b45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e25618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8977779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7b4ad58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bcdd178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d9eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f727dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a9f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43920b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b56b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa8ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffd22e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e69450f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa029be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e53ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294141c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49471793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
