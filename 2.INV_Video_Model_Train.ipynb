{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a459805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "invasive_dirs = [\n",
    "    r'E:\\invasive-aquatic-species-data\\inv\\invasive',\n",
    "    r'E:\\invasive-aquatic-species-data\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Zebra Pediveliger Image1a',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Baylor 2022-03-21\\Baylor 2022-03-21\\Davis Dam 2019-07-24\\Manually Reviewed\\Veligers\\Images_001',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Zebra Pediveliger Image1a\\Zebra Pediveligers',\n",
    "    \n",
    "    ]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Not Veligers\\Z-P',\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\NonVeligers\\Images_001',\n",
    "    r'E:\\invasive-aquatic-species-data\\inv\\noninvasive',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Baylor 2022-03-21\\Baylor 2022-03-21\\Davis Dam 2019-07-24\\Manually Reviewed\\NonVeligers\\Images_001', \n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1a Image1a\\D-Hinge',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1a Image1a\\D-Hinge',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra Ped 1a Image1a\\D-Hinge',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra Ped 1a Image1a\\Pedi',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra Umbo 1 Image1a\\Umbonal',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra Umbo 1a Image1a\\Umbonal',]\n",
    "\n",
    "# Ostracod category\n",
    "ostracod_dirs = [\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Ostracod Image1\\Ostracods1',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Ostracod Image1\\Ostracods1',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Ostracods Day 2 Image3 To Baylor\\Ostracods Day 2 Image3 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Ostracods Day 2 Image12 To Baylor\\Ostracods Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1a Image1a\\Ostracods',\n",
    "    r'',]\n",
    "\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "ostracod_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    \n",
    "for ostracod_dir in ostracod_dirs:\n",
    "    ostracod_subdirs.extend(glob.glob(ostracod_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "771cf805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_006\\._Image_001.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_011\\._Image_005.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_017\\._Image_002.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_017\\._Image_003.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_021\\._Image_006.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_024\\._Image_003.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_029\\._Image_004.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_038\\._Image_005.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_050\\._Image_005.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_050\\._Image_006.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_062\\._Image_009.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_165\\._Image_008.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_170\\._Image_009.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_171\\._Image_010.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_179\\._Image_011.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_195\\._Image_012.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_224\\._Image_013.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_225\\._Image_014.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_276\\._Image_016.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_322\\._Image_020.png. Skipping...\n",
      "Error processing image: E:\\invasive-aquatic-species-data\\Veligers\\Labeled Baylor 8-30-23\\Labeled Baylor 8-30-23\\Zebra D-Hinge 1 Image1a\\D-Hinge\\Object_322\\._Image_021.png. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n",
    "\n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n",
    "\n",
    "    \n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = ostracod_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y3 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y3.extend(subdirectories)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(28, 28)):\n",
    "    # List to store preprocessed images\n",
    "    images = []\n",
    "\n",
    "    # List to store labels for each directory\n",
    "    labels = []\n",
    "\n",
    "    # Loop through each directory in y1\n",
    "    for directory in y1:\n",
    "        # Count the number of images processed for this directory\n",
    "        images_processed = 0\n",
    "\n",
    "        # List to store images for this directory\n",
    "        directory_images = []\n",
    "\n",
    "        # Loop through the files in the directory\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    try:\n",
    "                        # Read the image using PIL\n",
    "                        image = Image.open(os.path.join(root, file))\n",
    "                        # Resize the image using PIL's resize function\n",
    "                        image = image.resize(target_size)\n",
    "                        # Convert to numpy array and normalize\n",
    "                        image = np.array(image) / 255.0\n",
    "                        # Add the image to the directory_images list\n",
    "                        directory_images.append(image)\n",
    "\n",
    "                        # Increment the count of processed images for this directory\n",
    "                        images_processed += 1\n",
    "\n",
    "                        # If we've processed 5 images for this directory, break out of the loop\n",
    "                        if images_processed >= 5:\n",
    "                            break\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing image: {os.path.join(root, file)}. Skipping...\")\n",
    "\n",
    "            # If we've processed 5 images for this directory, break out of the loop\n",
    "            if images_processed >= 5:\n",
    "                break\n",
    "\n",
    "        # Stack the images for this directory and append to the images list\n",
    "        if directory_images:\n",
    "            directory_images = np.array(directory_images)\n",
    "            images.append(directory_images)\n",
    "            labels.append(label_num)\n",
    "\n",
    "    # Stack the images for all directories\n",
    "    images = np.array(images)\n",
    "\n",
    "    # Convert labels to numpy array\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "  \n",
    "\n",
    "X0,Y0 = preprocess_images(y1, label_num = 0)\n",
    "X1,Y1 = preprocess_images(y2, label_num = 1)\n",
    "X2,Y2 = preprocess_images(y3, label_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5285a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1, X2), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1, Y2), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "# Now the shuffled data is assigned to the same variable names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780fd9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5092, 5, 28, 28, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0993d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 5, 28, 28,   0           []                               \n",
      "                                3)]                                                               \n",
      "                                                                                                  \n",
      " patch_encoder_2 (PatchEncoder)  (None, 5, 32)       11064       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 5, 32)       64          ['patch_encoder_2[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 5, 32)       25184       ['layer_normalization_26[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 5, 32)        0           ['multi_head_attention_12[0][0]',\n",
      "                                                                  'patch_encoder_2[0][0]',        \n",
      "                                                                  'lstm_12[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 5, 32)       64          ['add_24[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 5, 32)        1056        ['layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 5, 32)        0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 5, 32)        0           ['dropout_14[0][0]',             \n",
      "                                                                  'add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 5, 32)       64          ['add_25[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 5, 32)       25184       ['layer_normalization_28[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 5, 32)        0           ['multi_head_attention_13[0][0]',\n",
      "                                                                  'add_25[0][0]',                 \n",
      "                                                                  'lstm_13[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 5, 32)       64          ['add_26[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 5, 32)        1056        ['layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 5, 32)        0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 5, 32)        0           ['dropout_15[0][0]',             \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 5, 32)       64          ['add_27[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 5, 32)       25184       ['layer_normalization_30[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_14 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 5, 32)        0           ['multi_head_attention_14[0][0]',\n",
      "                                                                  'add_27[0][0]',                 \n",
      "                                                                  'lstm_14[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 5, 32)       64          ['add_28[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 5, 32)        1056        ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 5, 32)        0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 5, 32)        0           ['dropout_16[0][0]',             \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 5, 32)       64          ['add_29[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 5, 32)       25184       ['layer_normalization_32[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 5, 32)        0           ['multi_head_attention_15[0][0]',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'add_29[0][0]',                 \n",
      "                                                                  'lstm_15[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 5, 32)       64          ['add_30[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 5, 32)        1056        ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 5, 32)        0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 5, 32)        0           ['dropout_17[0][0]',             \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 5, 32)       64          ['add_31[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 5, 32)       25184       ['layer_normalization_34[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_16 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 5, 32)        0           ['multi_head_attention_16[0][0]',\n",
      "                                                                  'add_31[0][0]',                 \n",
      "                                                                  'lstm_16[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 5, 32)       64          ['add_32[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 5, 32)        1056        ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 5, 32)        0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 5, 32)        0           ['dropout_18[0][0]',             \n",
      "                                                                  'add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 5, 32)       64          ['add_33[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 5, 32)       25184       ['layer_normalization_36[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_17 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 5, 32)        0           ['multi_head_attention_17[0][0]',\n",
      "                                                                  'add_33[0][0]',                 \n",
      "                                                                  'lstm_17[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 5, 32)       64          ['add_34[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 5, 32)        1056        ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 5, 32)        0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 5, 32)        0           ['dropout_19[0][0]',             \n",
      "                                                                  'add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 5, 32)       64          ['add_35[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 32)          0           ['layer_normalization_38[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 32)           0           ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 3)            99          ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 219,355\n",
      "Trainable params: 219,355\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "DATASET_NAME = \"organmnist3d\"\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = ( 5, 28, 28, 3 )\n",
    "NUM_CLASSES = 2\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 60\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (4, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 32\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "from tensorflow.keras import layers\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super(PatchEncoder, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(2, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\": self.projection_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded \n",
    "from keras.layers import Input, TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import layers, models\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "inputs = layers.Input(shape=(5, 28, 28, 3))\n",
    "\n",
    "# Encoding patches\n",
    "encoded_patches = PatchEncoder(5, 32)(inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    # Layer normalization and multi-head attention\n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    attention_output = layers.MultiHeadAttention(num_heads=6, key_dim=32, dropout=0.1)(x1, x1)\n",
    "\n",
    "    # Adding an LSTM layer with dropout\n",
    "    lstm_output = LSTM(32, return_sequences=True, dropout=0.2)(x1)  # Larger dropout added here\n",
    "\n",
    "    # Skip connection\n",
    "    x2 = layers.Add()([attention_output, encoded_patches, lstm_output])\n",
    "\n",
    "    # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "    x3 = layers.Dense(units=32, activation=tf.nn.gelu)(x3)\n",
    "\n",
    "    # Adding a dropout layer after MLP\n",
    "    x3 = Dropout(0.9)(x3)  # Dropout added here\n",
    "\n",
    "    # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "# Layer normalization and global average pooling\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "# Adding a dropout layer before the final dense layer\n",
    "representation = Dropout(0.9)(representation)  # Dropout added here\n",
    "\n",
    "# Output layer\n",
    "outputs = layers.Dense(units=3, activation=\"softmax\")(representation)\n",
    "\n",
    "# Model definition\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b29b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [ 0.40464151  2.02202786 29.30516432]\n"
     ]
    }
   ],
   "source": [
    "class_weights = np.zeros(3)\n",
    "\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "total_samples = np.sum(counts)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    class_weights[label] = total_samples / (len(unique_labels) * counts[i])\n",
    "\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82635e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "167/167 [==============================] - 36s 96ms/step - loss: 0.1794 - accuracy: 0.9430 - val_loss: 0.2167 - val_accuracy: 0.9393\n",
      "Epoch 2/50\n",
      "167/167 [==============================] - 9s 55ms/step - loss: 0.1625 - accuracy: 0.9453 - val_loss: 0.2336 - val_accuracy: 0.9275\n",
      "Epoch 3/50\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.1599 - accuracy: 0.9492 - val_loss: 0.2233 - val_accuracy: 0.9359\n",
      "Epoch 4/50\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 0.2628 - accuracy: 0.9132 - val_loss: 0.2035 - val_accuracy: 0.9309\n",
      "Epoch 5/50\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.2252 - accuracy: 0.9226 - val_loss: 0.2510 - val_accuracy: 0.9275\n",
      "Epoch 6/50\n",
      "167/167 [==============================] - 14s 84ms/step - loss: 0.1840 - accuracy: 0.9391 - val_loss: 0.2554 - val_accuracy: 0.9275\n",
      "Epoch 7/50\n",
      "167/167 [==============================] - 11s 65ms/step - loss: 0.1717 - accuracy: 0.9425 - val_loss: 0.2403 - val_accuracy: 0.9325\n",
      "Epoch 8/50\n",
      "167/167 [==============================] - 14s 85ms/step - loss: 0.1530 - accuracy: 0.9501 - val_loss: 0.2496 - val_accuracy: 0.9410\n",
      "Epoch 9/50\n",
      "167/167 [==============================] - 10s 59ms/step - loss: 0.1396 - accuracy: 0.9554 - val_loss: 0.2441 - val_accuracy: 0.9342\n",
      "Epoch 10/50\n",
      "167/167 [==============================] - 10s 59ms/step - loss: 0.1335 - accuracy: 0.9578 - val_loss: 0.2641 - val_accuracy: 0.9427\n",
      "Epoch 11/50\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 0.1632 - accuracy: 0.9487 - val_loss: 0.2278 - val_accuracy: 0.9325\n",
      "Epoch 12/50\n",
      "167/167 [==============================] - 11s 66ms/step - loss: 0.2059 - accuracy: 0.9290 - val_loss: 0.2433 - val_accuracy: 0.9359\n",
      "Epoch 13/50\n",
      "167/167 [==============================] - 10s 61ms/step - loss: 0.1527 - accuracy: 0.9494 - val_loss: 0.2585 - val_accuracy: 0.9427\n",
      "Epoch 14/50\n",
      "167/167 [==============================] - 11s 67ms/step - loss: 0.1428 - accuracy: 0.9573 - val_loss: 0.2650 - val_accuracy: 0.9410\n",
      "Epoch 15/50\n",
      "167/167 [==============================] - 12s 73ms/step - loss: 0.2732 - accuracy: 0.9076 - val_loss: 0.3107 - val_accuracy: 0.8836\n",
      "Epoch 16/50\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 0.2919 - accuracy: 0.8915 - val_loss: 0.2250 - val_accuracy: 0.9325\n",
      "Epoch 17/50\n",
      "167/167 [==============================] - 12s 72ms/step - loss: 0.2076 - accuracy: 0.9308 - val_loss: 0.2152 - val_accuracy: 0.9292\n",
      "Epoch 18/50\n",
      "167/167 [==============================] - 11s 66ms/step - loss: 0.1766 - accuracy: 0.9415 - val_loss: 0.2238 - val_accuracy: 0.9359\n",
      "Epoch 19/50\n",
      "167/167 [==============================] - 14s 82ms/step - loss: 0.1544 - accuracy: 0.9477 - val_loss: 0.2464 - val_accuracy: 0.9427\n",
      "Epoch 20/50\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.1433 - accuracy: 0.9546 - val_loss: 0.2584 - val_accuracy: 0.9460\n",
      "Epoch 21/50\n",
      "167/167 [==============================] - 12s 71ms/step - loss: 0.1783 - accuracy: 0.9415 - val_loss: 0.2240 - val_accuracy: 0.9393\n",
      "Epoch 22/50\n",
      "167/167 [==============================] - 12s 73ms/step - loss: 0.1499 - accuracy: 0.9520 - val_loss: 0.2612 - val_accuracy: 0.9376\n",
      "Epoch 23/50\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 0.1447 - accuracy: 0.9531 - val_loss: 0.2430 - val_accuracy: 0.9494\n",
      "Epoch 24/50\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 0.1446 - accuracy: 0.9556 - val_loss: 0.3266 - val_accuracy: 0.9376\n",
      "Epoch 25/50\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 0.1402 - accuracy: 0.9614 - val_loss: 0.2898 - val_accuracy: 0.9292\n",
      "Epoch 26/50\n",
      "167/167 [==============================] - 13s 78ms/step - loss: 0.1241 - accuracy: 0.9612 - val_loss: 0.3290 - val_accuracy: 0.9410\n",
      "Epoch 27/50\n",
      "167/167 [==============================] - 12s 70ms/step - loss: 0.1280 - accuracy: 0.9578 - val_loss: 0.2620 - val_accuracy: 0.9376\n",
      "Epoch 28/50\n",
      "167/167 [==============================] - 14s 81ms/step - loss: 0.1183 - accuracy: 0.9627 - val_loss: 0.4416 - val_accuracy: 0.9292\n",
      "Epoch 29/50\n",
      "167/167 [==============================] - 12s 74ms/step - loss: 0.1372 - accuracy: 0.9537 - val_loss: 0.2499 - val_accuracy: 0.9393\n",
      "Epoch 30/50\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.1140 - accuracy: 0.9629 - val_loss: 0.3328 - val_accuracy: 0.9427\n",
      "Epoch 31/50\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 0.1212 - accuracy: 0.9629 - val_loss: 0.2819 - val_accuracy: 0.9528\n",
      "Epoch 32/50\n",
      "167/167 [==============================] - 12s 74ms/step - loss: 0.1206 - accuracy: 0.9631 - val_loss: 0.3183 - val_accuracy: 0.9393\n",
      "Epoch 33/50\n",
      "167/167 [==============================] - 13s 78ms/step - loss: 0.1455 - accuracy: 0.9554 - val_loss: 0.2963 - val_accuracy: 0.9376\n",
      "Epoch 34/50\n",
      "167/167 [==============================] - 13s 75ms/step - loss: 0.1047 - accuracy: 0.9657 - val_loss: 0.2951 - val_accuracy: 0.9342\n",
      "Epoch 35/50\n",
      "167/167 [==============================] - 14s 82ms/step - loss: 0.1071 - accuracy: 0.9665 - val_loss: 0.3211 - val_accuracy: 0.9292\n",
      "Epoch 36/50\n",
      "167/167 [==============================] - 12s 75ms/step - loss: 0.1128 - accuracy: 0.9638 - val_loss: 0.4253 - val_accuracy: 0.9258\n",
      "Epoch 37/50\n",
      "167/167 [==============================] - 14s 82ms/step - loss: 0.1280 - accuracy: 0.9610 - val_loss: 0.2722 - val_accuracy: 0.9427\n",
      "Epoch 38/50\n",
      "167/167 [==============================] - 12s 71ms/step - loss: 0.1009 - accuracy: 0.9668 - val_loss: 0.3217 - val_accuracy: 0.9444\n",
      "Epoch 39/50\n",
      "167/167 [==============================] - 10s 59ms/step - loss: 0.1219 - accuracy: 0.9633 - val_loss: 0.2781 - val_accuracy: 0.9376\n",
      "Epoch 40/50\n",
      "167/167 [==============================] - 11s 65ms/step - loss: 0.1069 - accuracy: 0.9653 - val_loss: 0.3615 - val_accuracy: 0.9393\n",
      "Epoch 41/50\n",
      "167/167 [==============================] - 11s 65ms/step - loss: 0.0959 - accuracy: 0.9713 - val_loss: 0.3994 - val_accuracy: 0.9309\n",
      "Epoch 42/50\n",
      "167/167 [==============================] - 11s 65ms/step - loss: 0.0937 - accuracy: 0.9693 - val_loss: 0.4464 - val_accuracy: 0.9292\n",
      "Epoch 43/50\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 0.1091 - accuracy: 0.9635 - val_loss: 0.3055 - val_accuracy: 0.9410\n",
      "Epoch 44/50\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.1041 - accuracy: 0.9663 - val_loss: 0.3469 - val_accuracy: 0.9376\n",
      "Epoch 45/50\n",
      "167/167 [==============================] - 11s 66ms/step - loss: 0.1044 - accuracy: 0.9674 - val_loss: 0.3642 - val_accuracy: 0.9410\n",
      "Epoch 46/50\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.1047 - accuracy: 0.9676 - val_loss: 0.3475 - val_accuracy: 0.9410\n",
      "Epoch 47/50\n",
      "167/167 [==============================] - 13s 78ms/step - loss: 0.0949 - accuracy: 0.9719 - val_loss: 0.3907 - val_accuracy: 0.9427\n",
      "Epoch 48/50\n",
      "167/167 [==============================] - 12s 72ms/step - loss: 0.0999 - accuracy: 0.9676 - val_loss: 0.3688 - val_accuracy: 0.9410\n",
      "Epoch 49/50\n",
      "167/167 [==============================] - 12s 72ms/step - loss: 0.1076 - accuracy: 0.9668 - val_loss: 0.4121 - val_accuracy: 0.9359\n",
      "Epoch 50/50\n",
      "167/167 [==============================] - 13s 80ms/step - loss: 0.1580 - accuracy: 0.9473 - val_loss: 0.2116 - val_accuracy: 0.9309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127c26798e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "class_weights = [ 0.5 , 2.2, 4]\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef0261d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming you have a Keras model named \"model\"\n",
    "model.save(r\"E:\\five_frame_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f8435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ec798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8dcc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020644e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609545e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8bbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a3a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18223eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a71e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5a6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc4a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff64890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
