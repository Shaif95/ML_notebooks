{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896f6083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 256\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "hidden_units = 256\n",
    "projection_units = 128\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463d11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4944a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "trn1='D:/data/invasive-aquatic-species-data/noninvasive/*/'\n",
    "trn2='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Ostracod Image1/*/'\n",
    "trn3='D:/data/invasive-aquatic-species-data/invasive/*/'\n",
    "\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)\n",
    "tr3= glob(trn3)\n",
    "\n",
    "trn11='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers/*/'\n",
    "trn33='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Zebra Pediveliger Image1a/*/'\n",
    "tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "#trn111='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/NonVeligers/Images_001/*/'\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "#tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "#tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "trn11='D:/data/Veligers/Preserved Zebra Ped 1 To Baylor/Preserved Zebra Ped 1 To Baylor/Sorted Images/Not/*/'\n",
    "trn33='D:/data/Veligers/Preserved Zebra Ped 1 To Baylor/Preserved Zebra Ped 1 To Baylor/Sorted Images/Pedi-Zebra Veligers/*/'\n",
    "tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "trn111='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/NonVeligers/Images_001/*/'\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "#trn11='D:/data/Veligers/Preserved Zebra Ped 1a To Baylor/Preserved Zebra Ped 1a To Baylor/Sorted Images/Not/*/'\n",
    "trn33='D:/data/Veligers/Preserved Zebra Ped 1a To Baylor/Preserved Zebra Ped 1a To Baylor/Sorted Images/Preserved Zebra Ped 1a/*/'\n",
    "#tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "#tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "trn111='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/NonVeligers/Images_001/*/'\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "trnl1='D:/data/Ostracod/Ostracod Day 2 Image12 Short To Baylor/Ostracod Day 2 Image12 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl2='D:/data/Ostracod/Ostracods Day 2 Image1 To Baylor/Ostracods Day 2 Image1 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl3='D:/data/Ostracod/Ostracods Day 2 Image2 To Baylor/Ostracods Day 2 Image2 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl4='D:/data/Ostracod/Ostracods Day 2 Image3 To Baylor/Ostracods Day 2 Image3 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl5='D:/data/Ostracod/Ostracods Day 2 Image12 To Baylor/Ostracods Day 2 Image12 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl6='D:/data/Ostracod/Preserved Ostracods 1 To Baylor/Preserved Ostracods 1 To Baylor/Sorted Images/Preserve Ostracods/*/'\n",
    "trnl7='D:/data/Ostracod/Preserved Ostracods 1a To Baylor/Preserved Ostracods 1a To Baylor/Sorted Images/Preserved Ostracods 1a/*/'\n",
    "\n",
    "trl1= glob(trnl1)\n",
    "trl2= glob(trnl2)\n",
    "trl3= glob(trnl3)\n",
    "trl4= glob(trnl4)\n",
    "trl5= glob(trnl5)\n",
    "trl6= glob(trnl6)\n",
    "trl7= glob(trnl7)\n",
    "\n",
    "\n",
    "tr2.extend(trl1)\n",
    "tr2.extend(trl2)\n",
    "tr2.extend(trl3)\n",
    "tr2.extend(trl4)\n",
    "tr2.extend(trl5)\n",
    "tr2.extend(trl6)\n",
    "tr2.extend(trl7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d6e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac0d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4879610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4797 104 1282 6183\n"
     ]
    }
   ],
   "source": [
    "print(len(tr1),len(tr2),len(tr3),(len(tr1)+len(tr2)+len(tr3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66852ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "tr1 = shuffle(tr1)\n",
    "tr2 = shuffle(tr2)\n",
    "tr3 = shuffle(tr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca8b263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "897.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_index_noninv = np.round( len(tr1)* .6  )\n",
    "tran_index_osc = np.round( len(tr2)* .7  )\n",
    "tran_index_inv = np.round( len(tr3)* .7  )\n",
    "tran_index_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329a5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2500239",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "for i in tr1[:(int) (tran_index_noninv)]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(0)\n",
    "\n",
    "\n",
    "for i in tr2[:(int)(tran_index_osc)]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(1)\n",
    "        \n",
    "for i in tr3[:(int)(tran_index_inv)]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(2)\n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = tf.image.resize_with_crop_or_pad(tf.keras.preprocessing.image.img_to_array(a), 30, 30)\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(30,30,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f87b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),30,30,3))\n",
    "# One hot vector representation of labels\n",
    "Y_train = to_categorical (label)\n",
    "\n",
    "X_train,Y_train = shuffle(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccd8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b8ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "for i in tr1[(int) (tran_index_noninv) + 1 :]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(0)\n",
    "\n",
    "\n",
    "for i in tr2[(int)(tran_index_osc) + 1 :]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(1)\n",
    "        \n",
    "for i in tr3[(int)(tran_index_inv) + 1 :]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(2)\n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = tf.image.resize_with_crop_or_pad(tf.keras.preprocessing.image.img_to_array(a), 30, 30)\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(30,30,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deff7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),30,30,3))\n",
    "# One hot vector representation of labels\n",
    "Y_test = to_categorical(label)\n",
    "\n",
    "X_test,Y_test = shuffle(X_test , Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fb79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e3ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,603\n",
      "Trainable params: 122,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(30, 30, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.Flatten()) \n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(10))\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ace01100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142352"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a425a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08afc384",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2564\\1619001012.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Create a dataset for the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m120000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m120000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Shuffle, batch, and repeat the dataset for training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    779\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m     \"\"\"\n\u001b[1;32m--> 781\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4659\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4660\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4661\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4662\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4663\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    127\u001b[0m           \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m           normalized_components.append(\n\u001b[1;32m--> 129\u001b[1;33m               ops.convert_to_tensor(t, name=\"component_%d\" % i, dtype=dtype))\n\u001b[0m\u001b[0;32m    130\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpack_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1620\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1621\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1623\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "#The hardcoded number is for train/val split\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create a dataset for the training data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train[:120000], Y_train[:120000].astype('float32')))\n",
    "\n",
    "# Shuffle, batch, and repeat the dataset for training\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Create a dataset for the validation/test data\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_train[120000:], Y_train[120000:].astype('float32')))\n",
    "\n",
    "# Batch the dataset for validation/test\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# Now, you can use the `train_dataset` and `val_dataset` to train and validate your Keras model.\n",
    "\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=([get_f1]))\n",
    "model.fit(train_dataset,  \n",
    "          validation_data=val_dataset,  \n",
    "          epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0f7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "669cb3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2784/2784 [==============================] - 39s 10ms/step - loss: 0.3013 - get_f1: 0.8727 - val_loss: 0.2668 - val_get_f1: 0.8878\n",
      "Epoch 2/50\n",
      "2784/2784 [==============================] - 28s 10ms/step - loss: 0.2302 - get_f1: 0.9053 - val_loss: 0.2118 - val_get_f1: 0.9148\n",
      "Epoch 3/50\n",
      "2784/2784 [==============================] - 29s 10ms/step - loss: 0.2020 - get_f1: 0.9179 - val_loss: 0.1918 - val_get_f1: 0.9237\n",
      "Epoch 4/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.1847 - get_f1: 0.9257 - val_loss: 0.2162 - val_get_f1: 0.9151\n",
      "Epoch 5/50\n",
      "2784/2784 [==============================] - 26s 9ms/step - loss: 0.1692 - get_f1: 0.9315 - val_loss: 0.1976 - val_get_f1: 0.9240\n",
      "Epoch 6/50\n",
      "2784/2784 [==============================] - 26s 9ms/step - loss: 0.1562 - get_f1: 0.9372 - val_loss: 0.1818 - val_get_f1: 0.9274\n",
      "Epoch 7/50\n",
      "2784/2784 [==============================] - 31s 11ms/step - loss: 0.1433 - get_f1: 0.9435 - val_loss: 0.1720 - val_get_f1: 0.9313\n",
      "Epoch 8/50\n",
      "2784/2784 [==============================] - 33s 12ms/step - loss: 0.1344 - get_f1: 0.9463 - val_loss: 0.1667 - val_get_f1: 0.9346\n",
      "Epoch 9/50\n",
      "2784/2784 [==============================] - 29s 11ms/step - loss: 0.1260 - get_f1: 0.9507 - val_loss: 0.1657 - val_get_f1: 0.9353\n",
      "Epoch 10/50\n",
      "2784/2784 [==============================] - 28s 10ms/step - loss: 0.1188 - get_f1: 0.9531 - val_loss: 0.1627 - val_get_f1: 0.9362\n",
      "Epoch 11/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.1108 - get_f1: 0.9563 - val_loss: 0.1607 - val_get_f1: 0.9405\n",
      "Epoch 12/50\n",
      "2784/2784 [==============================] - 28s 10ms/step - loss: 0.1049 - get_f1: 0.9593 - val_loss: 0.1719 - val_get_f1: 0.9362\n",
      "Epoch 13/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.0981 - get_f1: 0.9617 - val_loss: 0.1742 - val_get_f1: 0.9392\n",
      "Epoch 14/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.0945 - get_f1: 0.9630 - val_loss: 0.1605 - val_get_f1: 0.9391\n",
      "Epoch 15/50\n",
      "2784/2784 [==============================] - 26s 10ms/step - loss: 0.0883 - get_f1: 0.9659 - val_loss: 0.1617 - val_get_f1: 0.9443\n",
      "Epoch 16/50\n",
      "2784/2784 [==============================] - 26s 10ms/step - loss: 0.0849 - get_f1: 0.9670 - val_loss: 0.1673 - val_get_f1: 0.9423\n",
      "Epoch 17/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.0808 - get_f1: 0.9688 - val_loss: 0.1727 - val_get_f1: 0.9406\n",
      "Epoch 18/50\n",
      "2784/2784 [==============================] - 26s 9ms/step - loss: 0.0758 - get_f1: 0.9711 - val_loss: 0.1641 - val_get_f1: 0.9458\n",
      "Epoch 19/50\n",
      "2784/2784 [==============================] - 26s 9ms/step - loss: 0.0717 - get_f1: 0.9721 - val_loss: 0.2012 - val_get_f1: 0.9382\n",
      "Epoch 20/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.0691 - get_f1: 0.9736 - val_loss: 0.1648 - val_get_f1: 0.9458\n",
      "Epoch 21/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.0652 - get_f1: 0.9749 - val_loss: 0.1761 - val_get_f1: 0.9457\n",
      "Epoch 22/50\n",
      "2784/2784 [==============================] - 26s 9ms/step - loss: 0.0624 - get_f1: 0.9756 - val_loss: 0.1856 - val_get_f1: 0.9449\n",
      "Epoch 23/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.0595 - get_f1: 0.9771 - val_loss: 0.1808 - val_get_f1: 0.9473\n",
      "Epoch 24/50\n",
      "2784/2784 [==============================] - 27s 10ms/step - loss: 0.0570 - get_f1: 0.9783 - val_loss: 0.1819 - val_get_f1: 0.9460\n",
      "Epoch 25/50\n",
      "2784/2784 [==============================] - 28s 10ms/step - loss: 0.0540 - get_f1: 0.9793 - val_loss: 0.1971 - val_get_f1: 0.9465\n",
      "Epoch 26/50\n",
      "2784/2784 [==============================] - 28s 10ms/step - loss: 0.0530 - get_f1: 0.9802 - val_loss: 0.2035 - val_get_f1: 0.9472\n",
      "Epoch 27/50\n",
      "2784/2784 [==============================] - 28s 10ms/step - loss: 0.0503 - get_f1: 0.9810 - val_loss: 0.1910 - val_get_f1: 0.9454\n",
      "Epoch 28/50\n",
      "2784/2784 [==============================] - 28s 10ms/step - loss: 0.0487 - get_f1: 0.9816 - val_loss: 0.1912 - val_get_f1: 0.9454\n",
      "Epoch 29/50\n",
      "2784/2784 [==============================] - 28s 10ms/step - loss: 0.0462 - get_f1: 0.9823 - val_loss: 0.1854 - val_get_f1: 0.9456\n",
      "Epoch 30/50\n",
      "2784/2784 [==============================] - 46s 17ms/step - loss: 0.0457 - get_f1: 0.9824 - val_loss: 0.2233 - val_get_f1: 0.9490\n",
      "Epoch 31/50\n",
      "2784/2784 [==============================] - 75s 27ms/step - loss: 0.0442 - get_f1: 0.9834 - val_loss: 0.2026 - val_get_f1: 0.9448\n",
      "Epoch 32/50\n",
      "2784/2784 [==============================] - 81s 29ms/step - loss: 0.0411 - get_f1: 0.9846 - val_loss: 0.2399 - val_get_f1: 0.9453\n",
      "Epoch 33/50\n",
      "2784/2784 [==============================] - 78s 28ms/step - loss: 0.0400 - get_f1: 0.9847 - val_loss: 0.2166 - val_get_f1: 0.9497\n",
      "Epoch 34/50\n",
      "2784/2784 [==============================] - 78s 28ms/step - loss: 0.0394 - get_f1: 0.9850 - val_loss: 0.2147 - val_get_f1: 0.9499\n",
      "Epoch 35/50\n",
      "2784/2784 [==============================] - 85s 31ms/step - loss: 0.0388 - get_f1: 0.9859 - val_loss: 0.2134 - val_get_f1: 0.9484\n",
      "Epoch 36/50\n",
      "2784/2784 [==============================] - 79s 28ms/step - loss: 0.0371 - get_f1: 0.9863 - val_loss: 0.2117 - val_get_f1: 0.9480\n",
      "Epoch 37/50\n",
      "2784/2784 [==============================] - 72s 26ms/step - loss: 0.0357 - get_f1: 0.9864 - val_loss: 0.2190 - val_get_f1: 0.9492\n",
      "Epoch 38/50\n",
      "2784/2784 [==============================] - 78s 28ms/step - loss: 0.0340 - get_f1: 0.9868 - val_loss: 0.2184 - val_get_f1: 0.9473\n",
      "Epoch 39/50\n",
      "2784/2784 [==============================] - 81s 29ms/step - loss: 0.0341 - get_f1: 0.9875 - val_loss: 0.2202 - val_get_f1: 0.9496\n",
      "Epoch 40/50\n",
      "2784/2784 [==============================] - 84s 30ms/step - loss: 0.0320 - get_f1: 0.9886 - val_loss: 0.2200 - val_get_f1: 0.9498\n",
      "Epoch 41/50\n",
      "2784/2784 [==============================] - 93s 34ms/step - loss: 0.0303 - get_f1: 0.9881 - val_loss: 0.2507 - val_get_f1: 0.9490\n",
      "Epoch 42/50\n",
      "2784/2784 [==============================] - 84s 30ms/step - loss: 0.0320 - get_f1: 0.9883 - val_loss: 0.2505 - val_get_f1: 0.9479\n",
      "Epoch 43/50\n",
      "2784/2784 [==============================] - 82s 30ms/step - loss: 0.0307 - get_f1: 0.9888 - val_loss: 0.2368 - val_get_f1: 0.9493\n",
      "Epoch 44/50\n",
      "2784/2784 [==============================] - 85s 30ms/step - loss: 0.0293 - get_f1: 0.9893 - val_loss: 0.2508 - val_get_f1: 0.9477\n",
      "Epoch 45/50\n",
      "2784/2784 [==============================] - 78s 28ms/step - loss: 0.0279 - get_f1: 0.9900 - val_loss: 0.2460 - val_get_f1: 0.9513\n",
      "Epoch 46/50\n",
      "2784/2784 [==============================] - 76s 27ms/step - loss: 0.0274 - get_f1: 0.9901 - val_loss: 0.2509 - val_get_f1: 0.9461\n",
      "Epoch 47/50\n",
      "2784/2784 [==============================] - 78s 28ms/step - loss: 0.0270 - get_f1: 0.9902 - val_loss: 0.2591 - val_get_f1: 0.9483\n",
      "Epoch 48/50\n",
      "2784/2784 [==============================] - 84s 30ms/step - loss: 0.0275 - get_f1: 0.9898 - val_loss: 0.2737 - val_get_f1: 0.9478\n",
      "Epoch 49/50\n",
      "2784/2784 [==============================] - 80s 29ms/step - loss: 0.0268 - get_f1: 0.9905 - val_loss: 0.2802 - val_get_f1: 0.9495\n",
      "Epoch 50/50\n",
      "2784/2784 [==============================] - 83s 30ms/step - loss: 0.0254 - get_f1: 0.9909 - val_loss: 0.2736 - val_get_f1: 0.9505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220f24c5ee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=([get_f1]))\n",
    "model.fit( np.array(X_train) , np.array(Y_train).astype('float32') , epochs=50, batch_size=32, validation_split = .3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc470258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef9d973",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,3,30,30] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_5471762]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6464\\3622679004.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mte_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,3,30,30] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/conv2d/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_5471762]"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "te_df = model.predict(np.array(X_test),batch_size=32)\n",
    "y_pred = np.argmax(te_df, axis=1)\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "# plot confusion matrix as heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ca5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db503db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "#model.save('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "256059c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 score for class 1\n",
    "f1_class1 = f1_score(y_true, y_pred, labels=[0], average='macro')\n",
    "print(\"F1 score for class 1: {:.2f}%\".format(f1_class1 * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c206aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bbb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523d86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b90fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8c80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea8e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d007b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9dd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e2f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455bf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757452db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d38ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f0077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c27d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
