{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896f6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4944a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "trn1='D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers/*/'\n",
    "trn2='D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Ostracod Image1/*/'\n",
    "trn3='D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Zebra Pediveliger Image1a/*/'\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)\n",
    "tr3= glob(trn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d329a5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_003\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_005\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_007\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_041\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_048\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_051\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_052\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_053\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_054\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_055\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_056\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_057\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_058\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_059\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_060\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_061\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_064\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_086\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_088\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_089\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_091\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_092\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_106\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_113\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_116\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_122\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_125\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_126\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_128\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_129\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_139\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_140\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_151\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_152\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_154\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_155\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_156\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_157\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_158\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_160\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_161\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_162\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_163\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_165\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_166\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_179\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_180\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_181\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_182\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_183\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_184\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_185\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_186\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_187\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_189\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_190\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_195\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_196\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_197\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_198\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_206\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_207\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_208\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_209\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_210\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_211\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_250\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_251\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_252\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_253\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_254\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_255\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_256\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_257\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_258\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_259\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_260\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_261\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_262\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_263\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_264\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_265\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_266\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_267\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_268\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_269\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_270\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_272\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_273\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_274\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_282\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_283\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_284\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_285\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_286\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_287\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_288\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_289\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_290\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_291\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_293\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_294\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_295\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_296\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_297\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_298\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_299\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_300\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_301\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_302\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_303\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_304\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_306\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_307\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_308\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_309\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_310\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_311\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_312\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_313\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_314\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_315\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_316\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_317\\\\',\n",
       " 'D:/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers\\\\Object_354\\\\']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2500239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_index_inv = np.round( len(tr1)* .8  )\n",
    "tran_index_noninv = np.round( len(tr2)* .8  )\n",
    "tran_index_osc = np.round( len(tr3)* .8  )\n",
    "tran_index_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87b8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02b8ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "for i in tr1[:(int) (tran_index_inv)]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(0)\n",
    "\n",
    "\n",
    "for i in tr2[:(int)(tran_index_noninv)]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(1)\n",
    "        \n",
    "for i in tr3[:(int)(tran_index_osc)]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(2)\n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((40, 40))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(40,40,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deff7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),40,40,3))\n",
    "# One hot vector representation of labels\n",
    "Y_train = to_categorical(label)\n",
    "\n",
    "X_train,Y_train = shuffle(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fb79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60e3ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "for i in tr1[(int) (tran_index_inv) + 1 :]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(0)\n",
    "\n",
    "\n",
    "for i in tr2[ (int)(tran_index_noninv) + 1:]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(1)\n",
    "        \n",
    "for i in tr3[ (int)(tran_index_osc) + 1:]:\n",
    "    for j in glob(i+'/*'):\n",
    "        data.append(j)\n",
    "        label.append(2)\n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((40, 40))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(40,40,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a0f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),40,40,3))\n",
    "# One hot vector representation of labels\n",
    "Y_test = to_categorical(label)\n",
    "\n",
    "X_test,Y_test = shuffle(X_test , Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9db503db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2745, 40, 40, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256059c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c206aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 38, 38, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 19, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 17, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                147520    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,523\n",
      "Trainable params: 204,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(40, 40, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3),))\n",
    "model.add(layers.Flatten()) \n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(10))\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71bbb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3523d86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "251/251 [==============================] - 9s 32ms/step - loss: 0.4202 - accuracy: 0.8329 - val_loss: 0.1982 - val_accuracy: 0.9246\n",
      "Epoch 2/20\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.1716 - accuracy: 0.9381 - val_loss: 0.1300 - val_accuracy: 0.9552\n",
      "Epoch 3/20\n",
      "251/251 [==============================] - 9s 36ms/step - loss: 0.1183 - accuracy: 0.9593 - val_loss: 0.1032 - val_accuracy: 0.9622\n",
      "Epoch 4/20\n",
      "251/251 [==============================] - 10s 42ms/step - loss: 0.0958 - accuracy: 0.9671 - val_loss: 0.1809 - val_accuracy: 0.9290\n",
      "Epoch 5/20\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.1078 - accuracy: 0.9663 - val_loss: 0.2470 - val_accuracy: 0.9063\n",
      "Epoch 6/20\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.0826 - accuracy: 0.9709 - val_loss: 0.0976 - val_accuracy: 0.9656\n",
      "Epoch 7/20\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.0719 - accuracy: 0.9740 - val_loss: 0.0646 - val_accuracy: 0.9779\n",
      "Epoch 8/20\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 0.0772 - val_accuracy: 0.9747\n",
      "Epoch 9/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0610 - accuracy: 0.9790 - val_loss: 0.0698 - val_accuracy: 0.9776\n",
      "Epoch 10/20\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.0620 - accuracy: 0.9794 - val_loss: 0.0791 - val_accuracy: 0.9779\n",
      "Epoch 11/20\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.0587 - accuracy: 0.9804 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
      "Epoch 12/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0626 - accuracy: 0.9794 - val_loss: 0.0673 - val_accuracy: 0.9785\n",
      "Epoch 13/20\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.0407 - accuracy: 0.9864 - val_loss: 0.0904 - val_accuracy: 0.9697\n",
      "Epoch 14/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 0.0699 - val_accuracy: 0.9761\n",
      "Epoch 15/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0419 - accuracy: 0.9864 - val_loss: 0.0919 - val_accuracy: 0.9741\n",
      "Epoch 16/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0437 - accuracy: 0.9842 - val_loss: 0.0768 - val_accuracy: 0.9758\n",
      "Epoch 17/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0376 - accuracy: 0.9864 - val_loss: 0.0598 - val_accuracy: 0.9805\n",
      "Epoch 18/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0309 - accuracy: 0.9894 - val_loss: 0.0636 - val_accuracy: 0.9831\n",
      "Epoch 19/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0511 - accuracy: 0.9804 - val_loss: 0.0589 - val_accuracy: 0.9822\n",
      "Epoch 20/20\n",
      "251/251 [==============================] - 10s 38ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.1050 - val_accuracy: 0.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29190919ee0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=('accuracy'))\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_split = .3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b90fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ad8c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 7ms/step - loss: 0.2503 - accuracy: 0.9406\n",
      "Test score: 0.2502859830856323\n",
      "Test accuracy: 0.9406192898750305\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, Y_test,\n",
    "                            batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea8e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e2f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455bf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757452db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d38ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f0077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c27d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
