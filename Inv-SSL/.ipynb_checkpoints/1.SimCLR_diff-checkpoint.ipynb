{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae33427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import cv2_\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import tensorflow as tf  # framework\n",
    "from tensorflow import keras  # for tf.keras\n",
    "import tensorflow_addons as tfa  # LAMB optimizer and gaussian_blur_2d function\n",
    "import numpy as np  # np.random.random\n",
    "import matplotlib.pyplot as plt  # graphs\n",
    "import datetime  # tensorboard logs naming\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 512\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "hidden_units = 512\n",
    "projection_units = 256\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3812210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boo\n",
      "directory_paths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_23968\\3742525301.py:37: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((32, 32), Image.ANTIALIAS)  # Resize to 16x16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def list_lowest_level_subdirectories(directory_path):\n",
    "    print(\"boo\")\n",
    "    lowest_level_subdirectories = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for dir in dirs:\n",
    "            dir_path = os.path.join(root, dir)\n",
    "            # Check if the current directory doesn't contain any subdirectories\n",
    "            if not any(os.path.isdir(os.path.join(dir_path, sub_dir)) for sub_dir in os.listdir(dir_path)):\n",
    "                lowest_level_subdirectories.append(dir_path)\n",
    "    #print(lowest_level_subdirectories)\n",
    "    return lowest_level_subdirectories\n",
    "\n",
    "def collect_images_and_lengths(directory_paths):\n",
    "    \n",
    "    print(\"directory_paths\")\n",
    "    images_list = []\n",
    "    lengths_list = []\n",
    "    train_features = []\n",
    "    q = 0\n",
    "    for directory_path in directory_paths:\n",
    "        #print(directory_path)\n",
    "        q = q + 1\n",
    "        if(q==30):\n",
    "            #print(q)\n",
    "            break\n",
    "        image_paths = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "        image = 0\n",
    "\n",
    "        for image_path in image_paths:\n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    # Check if the image is not in RGB mode\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    img = img.resize((32, 32), Image.ANTIALIAS)  # Resize to 16x16\n",
    "                    img = np.array(img).astype('float32') / 255.0  # Convert to float and normalize\n",
    "                    images_list.append(img)\n",
    "                    if(image == 0 ):\n",
    "                        train_features.append(img)\n",
    "                    image= image + 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading or converting image '{image_path}': {e}\")\n",
    "        lengths_list.append((image))\n",
    "        \n",
    "    return images_list, lengths_list\n",
    "\n",
    "\n",
    "# Specify the directory path\n",
    "start_directory = r'E:\\invasive-aquatic-species-data'\n",
    "\n",
    "# Get a list of lowest-level subdirectories\n",
    "lowest_level_subdirectories = list_lowest_level_subdirectories(start_directory)\n",
    "\n",
    "# Collect images and lengths for subdirectories\n",
    "images_list, lengths_list = collect_images_and_lengths(lowest_level_subdirectories)\n",
    "\n",
    "a = np.sum(lengths_list)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "# Width and height of image\n",
    "IMAGE_SIZE = 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3dc20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cda2541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 2, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "import random\n",
    "\n",
    "\n",
    "# Function to calculate LBP features\n",
    "def get_lbp(img, r=1, pts=8):\n",
    "    if len(img.shape) == 3:\n",
    "        img = rgb2gray(img)\n",
    "    \n",
    "    # Convert the image to integer type to avoid the warning\n",
    "    img = (img * 255).astype('uint8')\n",
    "    \n",
    "    lbp = local_binary_pattern(img, pts, r, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=256, range=(0, 256))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return hist\n",
    "\n",
    "# Function to pick a similar image based on LBP feature distances\n",
    "def pick_similar_image(idx, lst):\n",
    "    ref_img = lst[idx]   \n",
    "    ref_lbp = get_lbp(ref_img)\n",
    "\n",
    "    dist = []\n",
    "    \n",
    "    # Compare the reference image to each image in the list\n",
    "    for img in lst:\n",
    "        lbp_feat = get_lbp(img)\n",
    "        # Use Chi-Square distance to compare\n",
    "        dist_val = 0.5 * np.sum(((ref_lbp - lbp_feat) ** 2) / (ref_lbp + lbp_feat + 1e-10))  # Chi-Square distance\n",
    "        dist.append(dist_val)\n",
    "\n",
    "    # Find the indices of the three largest distances\n",
    "    top_3_idx = np.argsort(dist)[-3:]  # Get the last 3 indices (largest distances)\n",
    "    \n",
    "    # Pick one of the top 3 randomly\n",
    "    selected_idx = random.choice(top_3_idx)\n",
    "    \n",
    "    # Return the image corresponding to the randomly selected index\n",
    "    return lst[selected_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d3576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " resnet50 (Functional)          (None, 1, 1, 2048)   23587712    ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['resnet50[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['resnet50[1][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          262272      ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          262272      ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          16512       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,145,280\n",
      "Trainable params: 557,568\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "def create_simclr_model(input_shape=(32, 32, 3)):\n",
    "    # Input layers for the two augmented images\n",
    "    inputs_1 = layers.Input(shape=input_shape)\n",
    "    inputs_2 = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Shared base model with ResNet50\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    # Pass both inputs through the same base model\n",
    "    features_1 = base_model(inputs_1)\n",
    "    features_2 = base_model(inputs_2)\n",
    "\n",
    "    # Global average pooling\n",
    "    pooled_features_1 = layers.GlobalAveragePooling2D()(features_1)\n",
    "    pooled_features_2 = layers.GlobalAveragePooling2D()(features_2)\n",
    "\n",
    "    # Projection head\n",
    "    projection_1 = layers.Dense(128, activation='relu')(pooled_features_1)\n",
    "    projection_1 = layers.Dense(128)(projection_1)\n",
    "    \n",
    "    projection_2 = layers.Dense(128, activation='relu')(pooled_features_2)\n",
    "    projection_2 = layers.Dense(128)(projection_2)\n",
    "\n",
    "    # Final SimCLR model\n",
    "    simclr_model = Model(inputs=[inputs_1, inputs_2], outputs=[projection_1, projection_2])\n",
    "\n",
    "    return simclr_model\n",
    "\n",
    "# Create the SimCLR model\n",
    "simclr_model = create_simclr_model()\n",
    "simclr_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c262e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(projection_1, projection_2, temperature=0.1):\n",
    "    # Normalize the projections\n",
    "    projection_1 = tf.math.l2_normalize(projection_1, axis=1)\n",
    "    projection_2 = tf.math.l2_normalize(projection_2, axis=1)\n",
    "    \n",
    "    # Concatenate both projections\n",
    "    projections = tf.concat([projection_1, projection_2], axis=0)\n",
    "    \n",
    "    # Compute the similarity matrix\n",
    "    similarity_matrix = tf.matmul(projections, projections, transpose_b=True)\n",
    "    \n",
    "    # Create the labels for contrastive loss\n",
    "    batch_size = tf.shape(projection_1)[0]\n",
    "    labels = tf.concat([tf.range(batch_size), tf.range(batch_size)], axis=0)\n",
    "    \n",
    "    # Temperature scaling\n",
    "    logits = similarity_matrix / temperature\n",
    "    \n",
    "    # Compute contrastive loss\n",
    "    contrastive_labels = tf.one_hot(labels, depth=2*batch_size)\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(contrastive_labels, logits)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Custom training step to use the contrastive loss\n",
    "@tf.function\n",
    "def train_step(images_1, images_2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        projection_1, projection_2 = simclr_model([images_1, images_2], training=True)\n",
    "        loss = contrastive_loss(projection_1, projection_2)\n",
    "    \n",
    "    gradients = tape.gradient(loss, simclr_model.trainable_variables)\n",
    "    simclr_model.optimizer.apply_gradients(zip(gradients, simclr_model.trainable_variables))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da764610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.773989677429199\n",
      "Epoch 2, Loss: 2.7723021507263184\n",
      "Epoch 3, Loss: 2.771940231323242\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Function to create the SimCLR dataset with batching\n",
    "def create_simclr_dataset(images_list, lengths_list, batch_size=BATCH_SIZE):\n",
    "    dataset = []\n",
    "\n",
    "    # Same logic as before, just grouping into pairs\n",
    "    for i in range(0, len(lengths_list)):\n",
    "        a = int(np.sum(lengths_list[:i]))  # Start index for the current object\n",
    "        b = a + lengths_list[i]  # End index for the current object\n",
    "        \n",
    "        lst = images_list[a:b]  # List of images for the current object\n",
    "\n",
    "        index = 0\n",
    "        for k in lst:\n",
    "            pairs = []\n",
    "            # Use pick_similar_image to get another view (image) of the same object\n",
    "            augment = pick_similar_image(index, lst)\n",
    "            pairs.append(k)       # First image (original view)\n",
    "            pairs.append(augment) # Second image (similar view based on LBP)\n",
    "            dataset.append(pairs)\n",
    "            index += 1\n",
    "\n",
    "    # Convert dataset to a TensorFlow Dataset object\n",
    "    a1 = [pair[0] for pair in dataset]\n",
    "    a2 = [pair[1] for pair in dataset]\n",
    "\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((a1, a2))\n",
    "    tf_dataset = tf_dataset.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return tf_dataset\n",
    "\n",
    "# Create the dataset\n",
    "simclr_dataset = create_simclr_dataset(images_list, lengths_list)\n",
    "\n",
    "# Model training\n",
    "@tf.function\n",
    "def train_step(images_1, images_2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        projection_1, projection_2 = simclr_model([images_1, images_2], training=True)\n",
    "        loss = contrastive_loss(projection_1, projection_2)\n",
    "    \n",
    "    gradients = tape.gradient(loss, simclr_model.trainable_variables)\n",
    "    simclr_model.optimizer.apply_gradients(zip(gradients, simclr_model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Set up optimizer\n",
    "simclr_model.optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "    for images_1, images_2 in simclr_dataset:\n",
    "        loss = train_step(images_1, images_2)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34576065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.771742105484009\n",
      "Epoch 2, Loss: 2.769824266433716\n",
      "Epoch 3, Loss: 2.752725124359131\n",
      "Epoch 4, Loss: 2.821380615234375\n",
      "Epoch 5, Loss: 2.8326148986816406\n",
      "Epoch 6, Loss: 2.7805018424987793\n",
      "Epoch 7, Loss: 2.6052680015563965\n",
      "Epoch 8, Loss: 2.616990089416504\n",
      "Epoch 9, Loss: 2.428842067718506\n",
      "Epoch 10, Loss: 2.6639046669006348\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):  # Adjust the number of epochs as needed\n",
    "    for images_1, images_2 in simclr_dataset:\n",
    "        loss = train_step(images_1, images_2)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262666a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1496a198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the SimCLR model (before projection head for fine-tuning)\n",
    "simclr_model.save('simclr_model.h5')  # Save the entire SimCLR model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb72b326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87f297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
