{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import cv2_\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import tensorflow as tf  # framework\n",
    "from tensorflow import keras  # for tf.keras\n",
    "import tensorflow_addons as tfa  # LAMB optimizer and gaussian_blur_2d function\n",
    "import numpy as np  # np.random.random\n",
    "import matplotlib.pyplot as plt  # graphs\n",
    "import datetime  # tensorboard logs naming\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 512\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "hidden_units = 512\n",
    "projection_units = 256\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4dfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8e92fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_8020\\3436569470.py:37: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((32, 32), Image.ANTIALIAS)  # Resize to 16x16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def list_lowest_level_subdirectories(directory_path):\n",
    "    lowest_level_subdirectories = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for dir in dirs:\n",
    "            dir_path = os.path.join(root, dir)\n",
    "            # Check if the current directory doesn't contain any subdirectories\n",
    "            if not any(os.path.isdir(os.path.join(dir_path, sub_dir)) for sub_dir in os.listdir(dir_path)):\n",
    "                lowest_level_subdirectories.append(dir_path)\n",
    "\n",
    "    return lowest_level_subdirectories\n",
    "\n",
    "def collect_images_and_lengths(directory_paths):\n",
    "    images_list = []\n",
    "    lengths_list = []\n",
    "    train_features = []\n",
    "    q = 0\n",
    "    for directory_path in directory_paths:\n",
    "        q = q +1\n",
    "        print(q)\n",
    "        if(q==30):\n",
    "            break\n",
    "        image_paths = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "        image = 0\n",
    "\n",
    "        for image_path in image_paths:\n",
    "            try:\n",
    "                with Image.open(image_path) as img:\n",
    "                    # Check if the image is not in RGB mode\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    img = img.resize((32, 32), Image.ANTIALIAS)  # Resize to 16x16\n",
    "                    img = np.array(img).astype('float32') / 255.0  # Convert to float and normalize\n",
    "                    images_list.append(img)\n",
    "                    if(image == 0 ):\n",
    "                        train_features.append(img)\n",
    "                    image= image + 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading or converting image '{image_path}': {e}\")\n",
    "        lengths_list.append((image))\n",
    "        \n",
    "    return images_list, lengths_list\n",
    "\n",
    "# Specify the directory path\n",
    "start_directory = r'E:\\invasive-aquatic-species-data'\n",
    "\n",
    "# Get a list of lowest-level subdirectories\n",
    "lowest_level_subdirectories = list_lowest_level_subdirectories(start_directory)\n",
    "\n",
    "# Collect images and lengths for subdirectories\n",
    "images_list, lengths_list = collect_images_and_lengths(lowest_level_subdirectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e068de83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55037c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.sum(lengths_list)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b154664",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "# Width and height of image\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23774f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabe2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "936c3082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 2, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = []\n",
    "\n",
    "for i in range(0,len(lengths_list)):\n",
    "    a = int(np.sum(lengths_list[:i])) #0,  27, 65, 95\n",
    "    \n",
    "    b = a+lengths_list[i]    # 27, 65, 95\n",
    "    lst = images_list[a:b]\n",
    "    \n",
    "    #print(np.shape(lst))\n",
    "    \n",
    "    for k in lst:\n",
    "        pairs = []\n",
    "        augment = random.choice(lst)\n",
    "        pairs.append(k)\n",
    "        pairs.append(augment)\n",
    "        dataset.append(pairs)\n",
    "        \n",
    "print(np.shape(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46ec392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class BTDatasetCreator:\n",
    "    def __init__(self, seed: int = 1024):\n",
    "        self.seed = seed\n",
    "\n",
    "    def split_pairs(self, ds: list) -> tf.data.Dataset:\n",
    "        # Split pairs into a1 and a2\n",
    "        a1 = [pair[0] for pair in ds]\n",
    "        a2 = [pair[1] for pair in ds]\n",
    "\n",
    "        return (tf.data.Dataset.from_tensor_slices((a1, a2))\n",
    "                .shuffle(1000, seed=self.seed)\n",
    "                .batch(BATCH_SIZE, drop_remainder=True)\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "    def __call__(self, ds: list) -> tf.data.Dataset:\n",
    "        return self.split_pairs(ds)\n",
    "\n",
    "bt_creator = BTDatasetCreator()\n",
    "augment_versions = bt_creator(dataset)\n",
    "\n",
    "\n",
    "sample_augment_versions = iter(augment_versions)\n",
    "\n",
    "\n",
    "def plot_values(batch: tuple):\n",
    "    fig, axs = plt.subplots(3, 3)\n",
    "    fig1, axs1 = plt.subplots(3, 3)\n",
    "\n",
    "    fig.suptitle(\"Augmentation 1\")\n",
    "    fig1.suptitle(\"Augmentation 2\")\n",
    "\n",
    "    a1, a2 = batch\n",
    "\n",
    "    # plots images on both tables\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # CHANGE(add / 255)\n",
    "            axs[i][j].imshow(a1[3 * i + j])\n",
    "            axs[i][j].axis(\"off\")\n",
    "            axs1[i][j].imshow(a2[3 * i + j])\n",
    "            axs1[i][j].axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eea59887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BarlowLoss(keras.losses.Loss):\n",
    "\n",
    "\n",
    "    def __init__(self, batch_size: int):\n",
    "\n",
    "        super().__init__()\n",
    "        self.lambda_amt = 5e-3\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def get_off_diag(self, c: tf.Tensor) -> tf.Tensor:\n",
    "   \n",
    "        zero_diag = tf.zeros(c.shape[-1])\n",
    "        return tf.linalg.set_diag(c, zero_diag)\n",
    "\n",
    "    def cross_corr_matrix_loss(self, c: tf.Tensor) -> tf.Tensor:\n",
    "     \n",
    "        # subtracts diagonals by one and squares them(first part)\n",
    "        c_diff = tf.pow(tf.linalg.diag_part(c) - 1, 2)\n",
    "\n",
    "        # takes off diagonal, squares it, multiplies with lambda(second part)\n",
    "        off_diag = tf.pow(self.get_off_diag(c), 2) * self.lambda_amt\n",
    "\n",
    "        # sum first and second parts together\n",
    "        loss = tf.reduce_sum(c_diff) + tf.reduce_sum(off_diag)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def normalize(self, output: tf.Tensor) -> tf.Tensor:\n",
    "    \n",
    "\n",
    "        return (output - tf.reduce_mean(output, axis=0)) / tf.math.reduce_std(\n",
    "            output, axis=0\n",
    "        )\n",
    "\n",
    "    def cross_corr_matrix(self, z_a_norm: tf.Tensor, z_b_norm: tf.Tensor) -> tf.Tensor:\n",
    "        \n",
    "        return (tf.transpose(z_a_norm) @ z_b_norm) / self.batch_size\n",
    "\n",
    "    def call(self, z_a: tf.Tensor, z_b: tf.Tensor) -> tf.Tensor:\n",
    "        \n",
    "        z_a_norm, z_b_norm = self.normalize(z_a), self.normalize(z_b)\n",
    "        c = self.cross_corr_matrix(z_a_norm, z_b_norm)\n",
    "        loss = self.cross_corr_matrix_loss(c)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "865a26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "\n",
    "class ResNet34:\n",
    "\n",
    "    def __call__(self, shape=(32, 32, 3)):\n",
    "        \n",
    "        inputs = Input(shape=shape)\n",
    "        base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=shape, pooling=\"avg\")\n",
    "        x = base_model(inputs)\n",
    "        output = Dense(2048)(x)\n",
    "        new_model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "        return new_model\n",
    "\n",
    "resnet = ResNet34()()\n",
    "#resnet.summary()\n",
    "\n",
    "def build_twin() -> keras.Model:\n",
    "\n",
    "\n",
    "    # number of dense neurons in the projector\n",
    "    n_dense_neurons = 5000\n",
    "\n",
    "    # encoder network\n",
    "    resnet = ResNet34()()\n",
    "    last_layer = resnet.layers[-1].output\n",
    "\n",
    "    # intermediate layers of the projector network\n",
    "    n_layers = 2\n",
    "    for i in range(n_layers):\n",
    "        dense = tf.keras.layers.Dense(n_dense_neurons, name=f\"projector_dense_{i}\")\n",
    "        if i == 0:\n",
    "            x = dense(last_layer)\n",
    "        else:\n",
    "            x = dense(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=f\"projector_bn_{i}\")(x)\n",
    "        x = tf.keras.layers.ReLU(name=f\"projector_relu_{i}\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(n_dense_neurons, name=f\"projector_dense_{n_layers}\")(x)\n",
    "\n",
    "    model = keras.Model(resnet.input, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "class BarlowModel(keras.Model):\n",
    "   \n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = build_twin()\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "    def train_step(self, batch: tf.Tensor) -> tf.Tensor:\n",
    "       \n",
    "        # get the two augmentations from the batch\n",
    "        y_a, y_b = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # get two versions of predictions\n",
    "            z_a, z_b = self.model(y_a, training=True), self.model(y_b, training=True)\n",
    "            loss = self.loss(z_a, z_b)\n",
    "\n",
    "        grads_model = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(grads_model, self.model.trainable_variables))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ac8a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "726395e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "174/174 [==============================] - 33s 70ms/step - loss: 49386.6445\n",
      "Epoch 2/2\n",
      "174/174 [==============================] - 13s 74ms/step - loss: 53185.6602\n"
     ]
    }
   ],
   "source": [
    "bm = BarlowModel()\n",
    "loss = BarlowLoss(BATCH_SIZE)\n",
    "\n",
    "bm.compile(optimizer='Adam', loss=loss)\n",
    "\n",
    "history = bm.fit(augment_versions, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d2951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5ae6345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\invasive-aquatic-species-data\\inv\\invasive\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_004\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_005\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_009\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_010\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_016\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_019\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_023\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_033\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_052\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_065\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_076\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_084\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_086\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1002\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1004\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_8020\\2580716688.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((32, 32), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1009\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_101\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1010\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1014\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1015\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1027\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1044\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1049\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1052\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1080\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1082\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1091\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1096\n",
      "E:\\invasive-aquatic-species-data\\inv\\invasive\\Object_1105\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_003\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_006\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_007\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_008\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_011\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_012\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_013\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_015\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_017\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_018\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_020\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_021\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_022\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_024\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_025\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_026\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_027\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_028\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_029\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_030\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_031\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_032\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_034\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_035\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_036\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_037\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_039\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_040\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_041\n",
      "E:\\invasive-aquatic-species-data\\inv\\noninvasive\\Object_042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def list_subdirectories(directory_path):\n",
    "    try:\n",
    "        subdirectories = [f.path for f in os.scandir(directory_path) if f.is_dir()]\n",
    "        return subdirectories\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def list_all_subdirectories_with_images(parent_directory):\n",
    "    subdirectories = list_subdirectories(parent_directory)\n",
    "    XT = []  # List to store all images\n",
    "    YT = []  # List to store labels\n",
    "    YT_count = []\n",
    "    #print(subdirectories)\n",
    "    \n",
    "    label= 0\n",
    "    length_list = []\n",
    "    for s in subdirectories:\n",
    "        print(s)\n",
    "        q = 0\n",
    "        sub = [f.path for f in os.scandir(s) if f.is_dir()]\n",
    "        #print(sub)\n",
    "        for f in sub:\n",
    "            \n",
    "            print(f)\n",
    "            q = q +1\n",
    "            if(q==30):\n",
    "                break\n",
    "                \n",
    "            count = 0\n",
    "            for img_path in os.listdir(f):\n",
    "            \n",
    "                if img_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                    img = Image.open(os.path.join(f, img_path))\n",
    "                    if img.mode != 'RGB':\n",
    "                        img = img.convert('RGB')\n",
    "                    img = img.resize((32, 32), Image.ANTIALIAS)\n",
    "                    img = np.array(img).astype('float32') / 255.0\n",
    "                    XT.append(img)\n",
    "                    count = count + 1\n",
    "                    YT.append(label)\n",
    "                #print(np.shape(lst))\n",
    "            length_list.append(count)\n",
    "            YT_count.append(label)\n",
    "        label=label+1    \n",
    "    \n",
    "    return XT, YT, YT_count, length_list\n",
    "\n",
    "# Example usage:\n",
    "directory_path = r'E:\\invasive-aquatic-species-data\\inv'\n",
    "images_list, YT, YT_count, lengths_list = list_all_subdirectories_with_images(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86d7dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "combined_data = list(zip(images_list, YT))\n",
    "random.shuffle(combined_data)\n",
    "images_list, YT = zip(*combined_data)\n",
    "\n",
    "yt = to_categorical(YT)\n",
    "ytc = to_categorical(YT_count)\n",
    "\n",
    "k = int(.7 * len(lengths_list))\n",
    "\n",
    "num_test_samples = np.sum(lengths_list[k:])\n",
    "X_test = images_list[:num_test_samples]\n",
    "Y_test = yt[:num_test_samples]\n",
    "X_train = images_list[num_test_samples:]\n",
    "Y_train = yt[num_test_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e2e7ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "24/24 [==============================] - 15s 228ms/step - loss: 15.5078 - accuracy: 0.5315 - val_loss: 12830686.0000 - val_accuracy: 0.4332\n",
      "Epoch 2/4\n",
      "24/24 [==============================] - 1s 61ms/step - loss: 3.4224 - accuracy: 0.5477 - val_loss: 572676.0625 - val_accuracy: 0.4332\n",
      "Epoch 3/4\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 8.0905 - accuracy: 0.5154 - val_loss: 21.2279 - val_accuracy: 0.4332\n",
      "Epoch 4/4\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 11.9549 - accuracy: 0.5128 - val_loss: 63.4214 - val_accuracy: 0.4332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c32f48340>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D\n",
    "model = bm.model\n",
    "model.layers[0].trainable = False\n",
    "x = model.layers[-1].output \n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "new_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.fit(np.array(X_train).astype('float32'),Y_train, batch_size=32, epochs=4, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0a2c5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.484375\n",
      "Balanced Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = new_model.predict(np.array(X_test).astype('float32'))\n",
    "accuracy = accuracy_score(np.argmax(Y_test,axis = 1),np.argmax(predictions,axis = 1))\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "ground_truth_labels = np.argmax(Y_test, axis=1)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "balanced_accuracy = balanced_accuracy_score(ground_truth_labels, predicted_labels)\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95a32c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45528b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a5e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b388cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb154f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "26a12583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f54924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99488fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00585a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e5fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3cc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396bdae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
