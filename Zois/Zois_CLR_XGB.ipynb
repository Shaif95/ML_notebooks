{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a033e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 256\n",
    "LATENT_DIM = 1024\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "hidden_units = 1024\n",
    "projection_units = 512\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff0cb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "trn1='E:/zois-data/jpg/train/*/'\n",
    "trn2='E:/zois-data/jpg/test/*/'\n",
    "\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "992db864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_11028\\2940079136.py:1: DeprecationWarning: Please use `convolve` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import convolve\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.filters import convolve\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "limit = []\n",
    "l = 0\n",
    "\n",
    "for i in tr1:\n",
    "    s = 0\n",
    "    y = glob(i+'/*')\n",
    "    for j in range(0,len(y)):\n",
    "        \n",
    "        if(y[j][-4:] == 'data'):\n",
    "            continue\n",
    "            \n",
    "        data.append(y[j])\n",
    "        label.append(l)\n",
    "        s = s + 1\n",
    "        \n",
    "    limit.append(s)\n",
    "    l=l+1\n",
    "\n",
    "\n",
    "#kk = []\n",
    "l=0\n",
    "s=0\n",
    "te_label = []\n",
    "te_data = []\n",
    "\n",
    "for i in tr2:\n",
    "    s = 0\n",
    "    y = glob(i+'/*')\n",
    "    for j in range(0,len(y)):\n",
    "        \n",
    "        if(y[j][-4:] == 'data'):\n",
    "            continue\n",
    "            \n",
    "        te_data.append(y[j])\n",
    "        te_label.append(l)\n",
    "        s = s + 1\n",
    "        \n",
    "        if(s>limit[l]-1):\n",
    "            break\n",
    "    l=l+1\n",
    "    #kk.append(s)\n",
    "\n",
    "    \n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i]).convert(\"L\")\n",
    "    b = a.resize((32, 32))\n",
    "    image_rgb = Image.merge(\"RGB\", (b, b, b))\n",
    "    c = np.array(image_rgb)\n",
    "    imgdata.append(c.reshape(32,32,3))\n",
    "    \n",
    "te_imgdata=[]\n",
    "for i in range(len(te_data)):\n",
    "    a = Image.open(data[i]).convert(\"L\")\n",
    "    b = a.resize((32, 32))\n",
    "    image_rgb = Image.merge(\"RGB\", (b, b, b))\n",
    "    c = np.array(image_rgb)\n",
    "    te_imgdata.append(c.reshape(32,32,3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13c7ce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2489, 32, 32, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac3b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4331d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),32,32,3))\n",
    "# One hot vector representation of labels\n",
    "Y_train = np.array(label)\n",
    "\n",
    "X_train,Y_train = shuffle(X_train,Y_train)\n",
    "\n",
    "idata = np.array(te_imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),32,32,3))\n",
    "# One hot vector representation of labels\n",
    "Y_test = np.array(te_label)\n",
    "\n",
    "X_test,Y_test = shuffle(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941ce58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "132a1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"vertical\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.02),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fec58e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_101 (InputLayer)      [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential_19 (Sequential)  (None, 32, 32, 3)         7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_classes = 7\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "def create_encoder():\n",
    "    resnet = tf.keras.applications.ResNet50V2( include_top=False, weights=\"imagenet\", input_shape=input_shape, pooling=\"avg\" )\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = resnet(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "56b4dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "\n",
    "        logits = tf.divide( tf.matmul(  \n",
    "            feature_vectors_normalized, tf.transpose(feature_vectors_normalized)),self.temperature,)\n",
    "        \n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0a1ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar-encoder_with_projection-head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_104 (InputLayer)      [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " cifar10-encoder (Functional  (None, 2048)             23564807  \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 512)               1049088   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,613,895\n",
      "Trainable params: 24,568,448\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "39/39 [==============================] - 35s 281ms/step - loss: 9.4127\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 11s 284ms/step - loss: 5.1578\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 12s 296ms/step - loss: 3.7932\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 10s 265ms/step - loss: 3.4498\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 11s 278ms/step - loss: 3.2489\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 11s 271ms/step - loss: 3.1549\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 11s 275ms/step - loss: 3.0754\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 10s 261ms/step - loss: 3.0006\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 2.9589\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 10s 265ms/step - loss: 2.9193\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 10s 267ms/step - loss: 2.9045\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 11s 278ms/step - loss: 2.8511\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 14s 364ms/step - loss: 2.8260\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 15s 382ms/step - loss: 2.7944\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 11s 283ms/step - loss: 2.8259\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 11s 281ms/step - loss: 2.8151\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 11s 274ms/step - loss: 2.7711\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 2.7562\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 2.7273\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 10s 269ms/step - loss: 2.7560\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 2.7306\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 2.7647\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 10s 266ms/step - loss: 2.7731\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 11s 275ms/step - loss: 2.7324\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 10s 268ms/step - loss: 2.7124\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 10s 257ms/step - loss: 2.7133\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 10s 262ms/step - loss: 2.6847\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 10s 260ms/step - loss: 2.6855\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 2.6721\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 10s 257ms/step - loss: 2.6647\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 10s 265ms/step - loss: 2.6667\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 2.6976\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 2.6625\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 10s 260ms/step - loss: 2.6539\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 10s 256ms/step - loss: 2.6529\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 2.6565\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 2.6393\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 10s 258ms/step - loss: 2.6554\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 2.6439\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 10s 255ms/step - loss: 2.6128\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 11s 295ms/step - loss: 2.6304\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 10s 266ms/step - loss: 2.6059\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 10s 259ms/step - loss: 2.6404\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 10s 257ms/step - loss: 2.6422\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 2.6059\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 10s 269ms/step - loss: 2.6374\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 10s 265ms/step - loss: 2.6179\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 11s 277ms/step - loss: 2.6028\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 2.5965\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 10s 254ms/step - loss: 2.6098\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "32d2b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - 20s 103ms/step - loss: 0.6710 - sparse_categorical_accuracy: 0.8513\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 7s 95ms/step - loss: 0.1834 - sparse_categorical_accuracy: 0.9823\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 8s 97ms/step - loss: 0.1423 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 8s 97ms/step - loss: 0.0945 - sparse_categorical_accuracy: 0.9867\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 7s 89ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9811\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9831\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0928 - sparse_categorical_accuracy: 0.9843\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 7s 86ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9847\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0837 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9839\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 7s 87ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9827\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 7s 90ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9867\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 7s 87ms/step - loss: 0.0627 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - 7s 87ms/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - 7s 90ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9867\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9843\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - 8s 97ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - 8s 96ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - 7s 95ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9871\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - 8s 97ms/step - loss: 0.0494 - sparse_categorical_accuracy: 0.9871: 3s - loss: 0.04\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - 8s 97ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - 7s 95ms/step - loss: 0.0448 - sparse_categorical_accuracy: 0.9900\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - 8s 103ms/step - loss: 0.0384 - sparse_categorical_accuracy: 0.9916\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - 10s 129ms/step - loss: 0.0434 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - 8s 101ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9855 4s - loss\n",
      "Epoch 29/50\n",
      "78/78 [==============================] - 7s 93ms/step - loss: 0.0427 - sparse_categorical_accuracy: 0.9904\n",
      "Epoch 30/50\n",
      "78/78 [==============================] - 7s 92ms/step - loss: 0.0466 - sparse_categorical_accuracy: 0.9904\n",
      "Epoch 31/50\n",
      "78/78 [==============================] - 7s 92ms/step - loss: 0.0447 - sparse_categorical_accuracy: 0.9883: 0s - loss: 0.0423 - sparse_categorical_accura\n",
      "Epoch 32/50\n",
      "78/78 [==============================] - 7s 86ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9892: 2s - loss: 0.0420 - sparse_categorical_accuracy: 0.990 - ETA: 2s - loss: 0.0413 - sparse_cat\n",
      "Epoch 33/50\n",
      "78/78 [==============================] - 7s 88ms/step - loss: 0.0467 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 34/50\n",
      "78/78 [==============================] - 8s 101ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 35/50\n",
      "78/78 [==============================] - 10s 127ms/step - loss: 0.0494 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 36/50\n",
      "78/78 [==============================] - 10s 124ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 37/50\n",
      "78/78 [==============================] - 10s 131ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 38/50\n",
      "78/78 [==============================] - 12s 157ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 39/50\n",
      "78/78 [==============================] - 9s 117ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 40/50\n",
      "78/78 [==============================] - 9s 112ms/step - loss: 0.0449 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 41/50\n",
      "78/78 [==============================] - 8s 106ms/step - loss: 0.0466 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 42/50\n",
      "78/78 [==============================] - 9s 109ms/step - loss: 0.0371 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 43/50\n",
      "78/78 [==============================] - 7s 95ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9900\n",
      "Epoch 44/50\n",
      "78/78 [==============================] - 8s 97ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9867\n",
      "Epoch 45/50\n",
      "78/78 [==============================] - 7s 89ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9867\n",
      "Epoch 46/50\n",
      "78/78 [==============================] - 7s 95ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 47/50\n",
      "78/78 [==============================] - 7s 89ms/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9883\n",
      "Epoch 48/50\n",
      "78/78 [==============================] - 7s 91ms/step - loss: 0.0389 - sparse_categorical_accuracy: 0.9904\n",
      "Epoch 49/50\n",
      "78/78 [==============================] - 7s 94ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9879\n",
      "Epoch 50/50\n",
      "78/78 [==============================] - 8s 97ms/step - loss: 0.0392 - sparse_categorical_accuracy: 0.9892\n",
      "72/72 [==============================] - 9s 78ms/step - loss: 9.9681 - sparse_categorical_accuracy: 0.5946\n",
      "Test accuracy: 59.46%\n"
     ]
    }
   ],
   "source": [
    "classifier = create_classifier(encoder, trainable=False) \n",
    "\n",
    "history = classifier.fit(x=X_train, y=Y_train, batch_size=32, epochs=50) \n",
    "\n",
    "accuracy = classifier.evaluate(X_test, Y_test)[1] \n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf4784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d2a65466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5980735551663747\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your data: X_train, Y_train, X_test, Y_test (omitted for brevity)\n",
    "\n",
    "# Encode the data\n",
    "X_train_embeddings = encoder.predict(X_train)  # Assuming encoder is your pre-trained encoder model\n",
    "X_test_embeddings = encoder.predict(X_test)\n",
    "\n",
    "# Create and train an XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train_embeddings, Y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "Y_pred = xgb_model.predict(X_test_embeddings)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ab734e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2284, 2048)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bf57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb143cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4943431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08efaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160fceff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76aa775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c38c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2eed1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe168a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf0b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a138259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de18ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
