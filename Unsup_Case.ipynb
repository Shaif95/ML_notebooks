{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c816a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [10:01<00:00, 31.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2872, 32, 32, 3)\n",
      "Y_train shape: (2872,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"G:\\datasets\\Underwater_Image\\WHOI\\archive\\dataset_pm\\training\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf13620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:30<00:00,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29009, 32, 32, 3)\n",
      "Y_train shape: (29009,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"E:\\imbcifar\\train\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b609b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602c030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFrames: 100%|██████████████████████████████████████████| 4/4 [00:56<00:00, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "file_paths = [\n",
    "    r\"E:\\imagenet\\lbpfeature1.csv\",\n",
    "    r\"E:\\imagenet\\lbpfeature2.csv\",\n",
    "    r\"E:\\imagenet\\lbpfeature3.csv\",\n",
    "    r\"E:\\imagenet\\lbpfeature4.csv\"\n",
    "]\n",
    "\n",
    "# Load the CSV files into Dask DataFrames and immediately drop rows with NaN values\n",
    "dfs = [dd.read_csv(file_path).dropna() for file_path in file_paths]\n",
    "\n",
    "# Function to get random indexes and retrieve the full rows\n",
    "def get_random_rows(df, n=250000):\n",
    "    # Convert the Dask DataFrame to a Pandas DataFrame after dropping NaNs\n",
    "    pandas_df = df.compute()\n",
    "    \n",
    "    # Get the total number of rows in the DataFrame\n",
    "    total_rows = len(pandas_df)\n",
    "    \n",
    "    # If there are fewer rows than n, use the total number of rows instead\n",
    "    n = min(total_rows, n)\n",
    "    \n",
    "    # Generate random indexes\n",
    "    random_indexes = np.random.choice(total_rows, n, replace=False)\n",
    "    \n",
    "    # Retrieve the full rows for these random indexes and split on tabs\n",
    "    random_rows = [\n",
    "        [item for sublist in (str(cell).split('\\t') for cell in row) for item in sublist]\n",
    "        for row in pandas_df.iloc[random_indexes].values\n",
    "    ]\n",
    "    \n",
    "    return random_rows\n",
    "\n",
    "# Initialize an empty list to store all rows\n",
    "all_random_rows = []\n",
    "\n",
    "# Get the rows from each DataFrame\n",
    "for df in tqdm(dfs, desc=\"Processing DataFrames\"):\n",
    "    rows = get_random_rows(df)\n",
    "    all_random_rows.extend(rows)\n",
    "\n",
    "# Print the total number of rows collected\n",
    "print(len(all_random_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cfa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27963558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994940, 256)\n"
     ]
    }
   ],
   "source": [
    "# Remove the first and last items from each element in all_random_rows\n",
    "new_all_random_rows = [row[1:-1] for row in all_random_rows]\n",
    "print(np.shape(new_all_random_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59381467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9caf10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the cluster centers: (1000, 256)\n",
      "Cluster centers have been saved to 'cluster_centers.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Assuming new_all_random_rows has been populated as described\n",
    "\n",
    "# Convert new_all_random_rows to a NumPy array\n",
    "data = np.array(new_all_random_rows)\n",
    "\n",
    "batch_size = 25000\n",
    "max_iter = 100\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = MiniBatchKMeans(n_clusters=1000, batch_size=batch_size, max_iter=max_iter, random_state=42)\n",
    "kmeans.fit(data)\n",
    "\n",
    "# Store the cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Print the shape of the cluster centers\n",
    "print(f\"Shape of the cluster centers: {centers.shape}\")\n",
    "\n",
    "# Save the cluster centers to a pickle file\n",
    "with open('cluster_centers.pkl', 'wb') as file:\n",
    "    pickle.dump(centers, file)\n",
    "\n",
    "print(\"Cluster centers have been saved to 'cluster_centers.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cd015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bba5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92419d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306f205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10d8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                     | 0/50000 [00:00<?, ?it/s]C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\skimage\\feature\\texture.py:353: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████| 50000/50000 [01:21<00:00, 612.55it/s]\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from tqdm import tqdm\n",
    "\n",
    "# LBP parameters\n",
    "radius = 3\n",
    "n_points = 8 * radius  # Total number of points\n",
    "METHOD = 'uniform'\n",
    "num_bins = 256  # Number of bins for the histogram\n",
    "\n",
    "def extract_features(image, target_size=(32, 32)):\n",
    "    # Process the image\n",
    "    image_resized = resize(image, target_size, anti_aliasing=True)\n",
    "    image_gray = rgb2gray(image_resized)\n",
    "    lbp = local_binary_pattern(image_gray, n_points, radius, METHOD)\n",
    "    hist, _ = np.histogram(lbp, density=True, bins=num_bins, range=(0, num_bins))\n",
    "    return hist\n",
    "\n",
    "def process_images(images):\n",
    "    features = []\n",
    "    \n",
    "    for image in tqdm(images):\n",
    "        try:\n",
    "            hist = extract_features(image)\n",
    "            features.append(hist)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process an image: {e}\")\n",
    "    return features\n",
    "\n",
    "# Example usage, assuming x_train is already loaded with numpy arrays of images\n",
    "features = process_images(x_train)\n",
    "\n",
    "# Clustering with MiniBatchKMeans\n",
    "n_clusters = 400\n",
    "batch_size = 100\n",
    "max_iter = 100\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, max_iter=max_iter)\n",
    "kmeans.fit(np.array(features))\n",
    "ct = kmeans.cluster_centers_.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b9d0753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4179a7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 400/400 [00:08<00:00, 48.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the distance array: (400, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize a list to store the distances\n",
    "tot_dist = []\n",
    "\n",
    "# Calculate L2 distances\n",
    "for i in tqdm(range(len(ct))):\n",
    "    distances = []\n",
    "    for j in range(len(centers)):\n",
    "        distance = np.linalg.norm(ct[i] - centers[j])\n",
    "        distances.append(distance)\n",
    "    tot_dist.append(distances)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "tot_dist = np.array(tot_dist)\n",
    "\n",
    "# Print the shape of the resulting array\n",
    "print(f\"Shape of the distance array: {tot_dist.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3ca2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01589f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1000/1000 [00:22<00:00, 44.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost = 1364.0356541084543\n",
      "\n",
      "Cluster 280 assigned to Class 0. Cost: 3.8959321753766325\n",
      "Cluster 2 assigned to Class 3. Cost: 2.986787980180775\n",
      "Cluster 93 assigned to Class 5. Cost: 3.4249302979573133\n",
      "Cluster 160 assigned to Class 11. Cost: 3.4083469260901853\n",
      "Cluster 307 assigned to Class 12. Cost: 3.3835023439833534\n",
      "Cluster 208 assigned to Class 15. Cost: 2.7702192819836338\n",
      "Cluster 15 assigned to Class 18. Cost: 3.48376051501223\n",
      "Cluster 156 assigned to Class 20. Cost: 3.371691266129736\n",
      "Cluster 252 assigned to Class 22. Cost: 3.4763524878423926\n",
      "Cluster 251 assigned to Class 23. Cost: 2.9865940658701566\n",
      "Cluster 327 assigned to Class 24. Cost: 3.5321905771257915\n",
      "Cluster 92 assigned to Class 29. Cost: 3.5080448162892486\n",
      "Cluster 66 assigned to Class 30. Cost: 3.433456745300317\n",
      "Cluster 261 assigned to Class 32. Cost: 3.5223143456787374\n",
      "Cluster 178 assigned to Class 34. Cost: 2.9672819396136645\n",
      "Cluster 88 assigned to Class 38. Cost: 2.926131048399946\n",
      "Cluster 162 assigned to Class 39. Cost: 3.740926636123498\n",
      "Cluster 356 assigned to Class 41. Cost: 3.119980130844913\n",
      "Cluster 100 assigned to Class 42. Cost: 3.6377786763401287\n",
      "Cluster 281 assigned to Class 49. Cost: 3.1680852306288556\n",
      "Cluster 161 assigned to Class 50. Cost: 3.8140729057237714\n",
      "Cluster 172 assigned to Class 53. Cost: 2.937900052847379\n",
      "Cluster 165 assigned to Class 55. Cost: 3.349856367360654\n",
      "Cluster 39 assigned to Class 58. Cost: 3.7762356213678157\n",
      "Cluster 86 assigned to Class 62. Cost: 3.5227225483452065\n",
      "Cluster 260 assigned to Class 68. Cost: 3.073748141687534\n",
      "Cluster 176 assigned to Class 71. Cost: 3.4295735013316984\n",
      "Cluster 271 assigned to Class 72. Cost: 3.487253806814151\n",
      "Cluster 234 assigned to Class 77. Cost: 3.8021855258812396\n",
      "Cluster 129 assigned to Class 78. Cost: 3.1390177139515663\n",
      "Cluster 17 assigned to Class 82. Cost: 3.410085819549933\n",
      "Cluster 112 assigned to Class 88. Cost: 3.6779418699987763\n",
      "Cluster 54 assigned to Class 90. Cost: 3.045327086947117\n",
      "Cluster 296 assigned to Class 92. Cost: 3.5910074485382117\n",
      "Cluster 127 assigned to Class 94. Cost: 3.07748575458866\n",
      "Cluster 168 assigned to Class 95. Cost: 3.46842437008423\n",
      "Cluster 236 assigned to Class 96. Cost: 3.515994133510285\n",
      "Cluster 390 assigned to Class 98. Cost: 3.113678263091615\n",
      "Cluster 341 assigned to Class 101. Cost: 3.1086731457689303\n",
      "Cluster 201 assigned to Class 102. Cost: 3.236354053544805\n",
      "Cluster 76 assigned to Class 103. Cost: 2.592270648881357\n",
      "Cluster 392 assigned to Class 107. Cost: 2.8112108671822056\n",
      "Cluster 292 assigned to Class 109. Cost: 3.4920566766827075\n",
      "Cluster 309 assigned to Class 112. Cost: 3.7973261743223503\n",
      "Cluster 287 assigned to Class 114. Cost: 3.471928790766433\n",
      "Cluster 38 assigned to Class 116. Cost: 3.7784929992930865\n",
      "Cluster 320 assigned to Class 120. Cost: 3.5774802547799496\n",
      "Cluster 158 assigned to Class 122. Cost: 3.1973580377386215\n",
      "Cluster 253 assigned to Class 123. Cost: 3.51853027131883\n",
      "Cluster 365 assigned to Class 126. Cost: 3.1927837795950076\n",
      "Cluster 372 assigned to Class 127. Cost: 3.6968105233150097\n",
      "Cluster 215 assigned to Class 132. Cost: 3.4528446132914805\n",
      "Cluster 247 assigned to Class 135. Cost: 3.5300359694177774\n",
      "Cluster 291 assigned to Class 138. Cost: 3.43987343539835\n",
      "Cluster 106 assigned to Class 143. Cost: 3.7048612679557866\n",
      "Cluster 154 assigned to Class 144. Cost: 3.780864108189759\n",
      "Cluster 49 assigned to Class 145. Cost: 3.5399679577635257\n",
      "Cluster 233 assigned to Class 146. Cost: 3.073521505500095\n",
      "Cluster 343 assigned to Class 147. Cost: 3.366063071261308\n",
      "Cluster 210 assigned to Class 150. Cost: 3.894166777745962\n",
      "Cluster 99 assigned to Class 151. Cost: 2.7676976162318736\n",
      "Cluster 71 assigned to Class 156. Cost: 3.8426267246297368\n",
      "Cluster 302 assigned to Class 157. Cost: 3.6905847505871905\n",
      "Cluster 130 assigned to Class 162. Cost: 3.499516729636312\n",
      "Cluster 186 assigned to Class 163. Cost: 3.4632008151235105\n",
      "Cluster 318 assigned to Class 164. Cost: 3.593792942740437\n",
      "Cluster 140 assigned to Class 168. Cost: 3.3073258448847787\n",
      "Cluster 91 assigned to Class 170. Cost: 3.646279344786704\n",
      "Cluster 194 assigned to Class 172. Cost: 3.8805402641297437\n",
      "Cluster 322 assigned to Class 176. Cost: 3.263254227982088\n",
      "Cluster 153 assigned to Class 178. Cost: 2.8784100194108126\n",
      "Cluster 237 assigned to Class 180. Cost: 3.77100909664127\n",
      "Cluster 202 assigned to Class 183. Cost: 3.4259934378896104\n",
      "Cluster 68 assigned to Class 184. Cost: 2.7672593178117966\n",
      "Cluster 214 assigned to Class 186. Cost: 3.737166315214108\n",
      "Cluster 222 assigned to Class 193. Cost: 3.721997871026698\n",
      "Cluster 11 assigned to Class 194. Cost: 2.824925566935365\n",
      "Cluster 7 assigned to Class 196. Cost: 2.9656104498792124\n",
      "Cluster 67 assigned to Class 198. Cost: 3.721302662340975\n",
      "Cluster 359 assigned to Class 202. Cost: 3.777223139346333\n",
      "Cluster 121 assigned to Class 203. Cost: 2.7735727567242705\n",
      "Cluster 41 assigned to Class 207. Cost: 3.0266783887998687\n",
      "Cluster 94 assigned to Class 211. Cost: 3.242844605896829\n",
      "Cluster 355 assigned to Class 215. Cost: 3.5809306095881834\n",
      "Cluster 230 assigned to Class 216. Cost: 3.0636954615951337\n",
      "Cluster 328 assigned to Class 218. Cost: 3.2797662326912174\n",
      "Cluster 173 assigned to Class 222. Cost: 3.469681833117651\n",
      "Cluster 56 assigned to Class 224. Cost: 3.091445200054024\n",
      "Cluster 382 assigned to Class 226. Cost: 3.1405999858719884\n",
      "Cluster 243 assigned to Class 234. Cost: 3.8702990188812016\n",
      "Cluster 133 assigned to Class 236. Cost: 3.7290121620916006\n",
      "Cluster 29 assigned to Class 239. Cost: 3.2602405242917296\n",
      "Cluster 312 assigned to Class 240. Cost: 3.807352402545698\n",
      "Cluster 274 assigned to Class 242. Cost: 3.4232275187865944\n",
      "Cluster 145 assigned to Class 250. Cost: 2.958240329231601\n",
      "Cluster 381 assigned to Class 251. Cost: 3.776866983883274\n",
      "Cluster 235 assigned to Class 252. Cost: 3.39983993292135\n",
      "Cluster 331 assigned to Class 253. Cost: 3.2412734509283125\n",
      "Cluster 338 assigned to Class 256. Cost: 3.9105578056566284\n",
      "Cluster 310 assigned to Class 257. Cost: 3.028851167017827\n",
      "Cluster 45 assigned to Class 258. Cost: 3.523345619691604\n",
      "Cluster 142 assigned to Class 259. Cost: 3.5149282672588362\n",
      "Cluster 242 assigned to Class 263. Cost: 3.4921313595654113\n",
      "Cluster 371 assigned to Class 264. Cost: 3.602093793687427\n",
      "Cluster 148 assigned to Class 268. Cost: 3.7274843979319834\n",
      "Cluster 62 assigned to Class 274. Cost: 2.8690428135454042\n",
      "Cluster 30 assigned to Class 275. Cost: 3.2939228927357744\n",
      "Cluster 79 assigned to Class 280. Cost: 3.5135945327949343\n",
      "Cluster 190 assigned to Class 284. Cost: 3.4517542672455006\n",
      "Cluster 239 assigned to Class 297. Cost: 3.6647031837566173\n",
      "Cluster 293 assigned to Class 299. Cost: 3.058673401620495\n",
      "Cluster 323 assigned to Class 301. Cost: 3.1294723037297167\n",
      "Cluster 18 assigned to Class 303. Cost: 3.158800219501823\n",
      "Cluster 350 assigned to Class 310. Cost: 2.883209207687793\n",
      "Cluster 377 assigned to Class 313. Cost: 2.7325869316016824\n",
      "Cluster 363 assigned to Class 314. Cost: 3.4269725239856563\n",
      "Cluster 78 assigned to Class 315. Cost: 3.862436912997496\n",
      "Cluster 378 assigned to Class 319. Cost: 3.2568195133909876\n",
      "Cluster 32 assigned to Class 320. Cost: 3.6369614394452805\n",
      "Cluster 131 assigned to Class 322. Cost: 3.5789917233449624\n",
      "Cluster 36 assigned to Class 323. Cost: 2.8716659649585323\n",
      "Cluster 351 assigned to Class 326. Cost: 3.32503707470192\n",
      "Cluster 383 assigned to Class 327. Cost: 3.7185467721352503\n",
      "Cluster 102 assigned to Class 333. Cost: 3.059428297816744\n",
      "Cluster 246 assigned to Class 334. Cost: 3.52113099576953\n",
      "Cluster 332 assigned to Class 335. Cost: 3.4695837740822646\n",
      "Cluster 60 assigned to Class 336. Cost: 3.297417152925924\n",
      "Cluster 174 assigned to Class 338. Cost: 3.681091954442342\n",
      "Cluster 366 assigned to Class 340. Cost: 3.7307764113552775\n",
      "Cluster 74 assigned to Class 341. Cost: 3.582503931670196\n",
      "Cluster 282 assigned to Class 343. Cost: 3.7589901316575105\n",
      "Cluster 266 assigned to Class 344. Cost: 3.7949021714705014\n",
      "Cluster 87 assigned to Class 346. Cost: 3.132843519255101\n",
      "Cluster 275 assigned to Class 348. Cost: 3.669646598930085\n",
      "Cluster 51 assigned to Class 351. Cost: 3.714473731752667\n",
      "Cluster 248 assigned to Class 352. Cost: 3.8667147691103283\n",
      "Cluster 225 assigned to Class 354. Cost: 2.743212666987743\n",
      "Cluster 124 assigned to Class 358. Cost: 3.645304946632685\n",
      "Cluster 169 assigned to Class 362. Cost: 3.543157694262723\n",
      "Cluster 185 assigned to Class 364. Cost: 3.5747178527721784\n",
      "Cluster 326 assigned to Class 365. Cost: 3.8941954818515514\n",
      "Cluster 98 assigned to Class 369. Cost: 3.2867906427610776\n",
      "Cluster 364 assigned to Class 370. Cost: 3.0699979028386988\n",
      "Cluster 206 assigned to Class 371. Cost: 3.63781303143873\n",
      "Cluster 339 assigned to Class 376. Cost: 3.841800993047423\n",
      "Cluster 170 assigned to Class 377. Cost: 3.815472700444245\n",
      "Cluster 81 assigned to Class 381. Cost: 3.6420531348060496\n",
      "Cluster 306 assigned to Class 384. Cost: 3.637677367890738\n",
      "Cluster 166 assigned to Class 387. Cost: 3.189814852770104\n",
      "Cluster 164 assigned to Class 388. Cost: 3.8031765834243965\n",
      "Cluster 196 assigned to Class 389. Cost: 3.2333151853003543\n",
      "Cluster 34 assigned to Class 393. Cost: 3.109356707361763\n",
      "Cluster 374 assigned to Class 395. Cost: 2.9440179392921197\n",
      "Cluster 128 assigned to Class 398. Cost: 3.314133920232763\n",
      "Cluster 77 assigned to Class 403. Cost: 3.0612065812867977\n",
      "Cluster 203 assigned to Class 405. Cost: 2.831953747061655\n",
      "Cluster 223 assigned to Class 410. Cost: 3.5901284157247106\n",
      "Cluster 20 assigned to Class 411. Cost: 3.0275783803579803\n",
      "Cluster 52 assigned to Class 412. Cost: 2.8415809189387637\n",
      "Cluster 73 assigned to Class 413. Cost: 3.7667422356961517\n",
      "Cluster 308 assigned to Class 424. Cost: 3.296686794798833\n",
      "Cluster 46 assigned to Class 426. Cost: 3.2091853254431464\n",
      "Cluster 224 assigned to Class 429. Cost: 3.4236293204426236\n",
      "Cluster 360 assigned to Class 431. Cost: 3.3997922937348846\n",
      "Cluster 324 assigned to Class 434. Cost: 3.7730998660817963\n",
      "Cluster 370 assigned to Class 442. Cost: 3.863186375761647\n",
      "Cluster 353 assigned to Class 443. Cost: 3.7021476658397314\n",
      "Cluster 379 assigned to Class 444. Cost: 3.65037936374026\n",
      "Cluster 110 assigned to Class 446. Cost: 3.605785290157765\n",
      "Cluster 150 assigned to Class 450. Cost: 2.8070219066119626\n",
      "Cluster 303 assigned to Class 453. Cost: 3.8191629424790223\n",
      "Cluster 358 assigned to Class 456. Cost: 2.9764110990723274\n",
      "Cluster 53 assigned to Class 457. Cost: 3.245500333619952\n",
      "Cluster 182 assigned to Class 459. Cost: 3.5181452131022284\n",
      "Cluster 139 assigned to Class 461. Cost: 3.742256001267276\n",
      "Cluster 155 assigned to Class 465. Cost: 3.7413030791529067\n",
      "Cluster 61 assigned to Class 469. Cost: 3.049920526544572\n",
      "Cluster 189 assigned to Class 470. Cost: 3.485819352750722\n",
      "Cluster 227 assigned to Class 475. Cost: 3.2413048658958403\n",
      "Cluster 19 assigned to Class 476. Cost: 3.1980345793249776\n",
      "Cluster 325 assigned to Class 479. Cost: 3.3889700413672066\n",
      "Cluster 114 assigned to Class 481. Cost: 3.3366852099941973\n",
      "Cluster 115 assigned to Class 482. Cost: 3.541507392641494\n",
      "Cluster 104 assigned to Class 484. Cost: 3.695237429894653\n",
      "Cluster 262 assigned to Class 485. Cost: 3.8637505255650195\n",
      "Cluster 219 assigned to Class 487. Cost: 3.640613616329658\n",
      "Cluster 37 assigned to Class 490. Cost: 3.8405717494131766\n",
      "Cluster 304 assigned to Class 491. Cost: 3.1014971668332403\n",
      "Cluster 283 assigned to Class 493. Cost: 3.3365142075739085\n",
      "Cluster 97 assigned to Class 497. Cost: 3.386657427905659\n",
      "Cluster 31 assigned to Class 498. Cost: 3.3027146002474836\n",
      "Cluster 205 assigned to Class 499. Cost: 3.651097403273598\n",
      "Cluster 397 assigned to Class 501. Cost: 3.6888345471265485\n",
      "Cluster 369 assigned to Class 503. Cost: 3.8856671674264756\n",
      "Cluster 107 assigned to Class 504. Cost: 3.6729216149698054\n",
      "Cluster 389 assigned to Class 508. Cost: 3.4608391910331013\n",
      "Cluster 319 assigned to Class 509. Cost: 3.4721661091399567\n",
      "Cluster 263 assigned to Class 510. Cost: 2.7886171379066074\n",
      "Cluster 285 assigned to Class 514. Cost: 3.665537603568778\n",
      "Cluster 138 assigned to Class 516. Cost: 3.444353161337241\n",
      "Cluster 277 assigned to Class 517. Cost: 3.718759241270321\n",
      "Cluster 315 assigned to Class 518. Cost: 3.0297555493925494\n",
      "Cluster 229 assigned to Class 521. Cost: 3.362934756899766\n",
      "Cluster 337 assigned to Class 531. Cost: 3.381745651115052\n",
      "Cluster 300 assigned to Class 533. Cost: 3.484296409447409\n",
      "Cluster 119 assigned to Class 539. Cost: 3.0769946188203834\n",
      "Cluster 146 assigned to Class 541. Cost: 3.2657340665875085\n",
      "Cluster 204 assigned to Class 548. Cost: 2.9191308561807836\n",
      "Cluster 136 assigned to Class 549. Cost: 3.861516299202161\n",
      "Cluster 258 assigned to Class 550. Cost: 3.6114002316625924\n",
      "Cluster 42 assigned to Class 551. Cost: 3.397910532024108\n",
      "Cluster 216 assigned to Class 557. Cost: 3.5304312287412527\n",
      "Cluster 179 assigned to Class 564. Cost: 3.331803700341724\n",
      "Cluster 21 assigned to Class 565. Cost: 3.643210196994989\n",
      "Cluster 301 assigned to Class 569. Cost: 3.1696675856633654\n",
      "Cluster 57 assigned to Class 572. Cost: 3.0906527675524567\n",
      "Cluster 147 assigned to Class 575. Cost: 3.737166354275709\n",
      "Cluster 191 assigned to Class 577. Cost: 3.633990260060764\n",
      "Cluster 368 assigned to Class 581. Cost: 3.2534300874451376\n",
      "Cluster 256 assigned to Class 583. Cost: 3.406819015308312\n",
      "Cluster 109 assigned to Class 585. Cost: 3.521531151755851\n",
      "Cluster 241 assigned to Class 587. Cost: 3.185938022220033\n",
      "Cluster 334 assigned to Class 590. Cost: 3.782062597691384\n",
      "Cluster 135 assigned to Class 594. Cost: 3.2957572526215055\n",
      "Cluster 23 assigned to Class 596. Cost: 3.8688375582823706\n",
      "Cluster 259 assigned to Class 597. Cost: 3.4142675852924347\n",
      "Cluster 361 assigned to Class 601. Cost: 3.582367369354795\n",
      "Cluster 65 assigned to Class 602. Cost: 2.726267440387487\n",
      "Cluster 340 assigned to Class 605. Cost: 3.2943991247683355\n",
      "Cluster 380 assigned to Class 608. Cost: 3.122206348771196\n",
      "Cluster 311 assigned to Class 616. Cost: 3.878730351269534\n",
      "Cluster 69 assigned to Class 617. Cost: 2.9264098071717446\n",
      "Cluster 44 assigned to Class 618. Cost: 2.6076510498958823\n",
      "Cluster 240 assigned to Class 622. Cost: 3.4189396833751897\n",
      "Cluster 348 assigned to Class 625. Cost: 3.7316463005337424\n",
      "Cluster 70 assigned to Class 629. Cost: 2.944187959804006\n",
      "Cluster 197 assigned to Class 630. Cost: 3.588720581605786\n",
      "Cluster 250 assigned to Class 632. Cost: 3.8971397587744874\n",
      "Cluster 269 assigned to Class 637. Cost: 2.821142828905965\n",
      "Cluster 335 assigned to Class 639. Cost: 3.7541246664016303\n",
      "Cluster 27 assigned to Class 640. Cost: 3.231236220550128\n",
      "Cluster 244 assigned to Class 643. Cost: 2.957795307908591\n",
      "Cluster 362 assigned to Class 645. Cost: 3.28685890534337\n",
      "Cluster 35 assigned to Class 646. Cost: 3.8777869357200765\n",
      "Cluster 373 assigned to Class 647. Cost: 3.2039525446188324\n",
      "Cluster 59 assigned to Class 648. Cost: 3.6278999457698013\n",
      "Cluster 184 assigned to Class 649. Cost: 3.342377408546081\n",
      "Cluster 3 assigned to Class 650. Cost: 3.5599362698983508\n",
      "Cluster 28 assigned to Class 653. Cost: 3.2729649857093723\n",
      "Cluster 352 assigned to Class 656. Cost: 3.732235277352277\n",
      "Cluster 116 assigned to Class 657. Cost: 3.689138022923038\n",
      "Cluster 375 assigned to Class 660. Cost: 3.3602020918327895\n",
      "Cluster 143 assigned to Class 663. Cost: 3.2809038609066397\n",
      "Cluster 137 assigned to Class 669. Cost: 3.698466573429879\n",
      "Cluster 217 assigned to Class 671. Cost: 3.3604785631325127\n",
      "Cluster 195 assigned to Class 672. Cost: 3.6817024985526148\n",
      "Cluster 167 assigned to Class 673. Cost: 3.274640949716577\n",
      "Cluster 231 assigned to Class 678. Cost: 3.0714069340639667\n",
      "Cluster 149 assigned to Class 681. Cost: 3.225616812116102\n",
      "Cluster 290 assigned to Class 686. Cost: 3.81713462696418\n",
      "Cluster 26 assigned to Class 687. Cost: 3.508273464436423\n",
      "Cluster 177 assigned to Class 690. Cost: 3.465205250955384\n",
      "Cluster 159 assigned to Class 693. Cost: 3.4353605904664026\n",
      "Cluster 286 assigned to Class 696. Cost: 3.6966112057242944\n",
      "Cluster 209 assigned to Class 697. Cost: 3.4713795342952296\n",
      "Cluster 333 assigned to Class 699. Cost: 3.755629712071782\n",
      "Cluster 313 assigned to Class 703. Cost: 3.0838599852041204\n",
      "Cluster 299 assigned to Class 706. Cost: 3.8561688731268644\n",
      "Cluster 265 assigned to Class 708. Cost: 3.3365825456570763\n",
      "Cluster 101 assigned to Class 709. Cost: 3.1766013655165777\n",
      "Cluster 5 assigned to Class 711. Cost: 3.499192682904416\n",
      "Cluster 122 assigned to Class 714. Cost: 3.7562300601040346\n",
      "Cluster 72 assigned to Class 717. Cost: 3.472621283029727\n",
      "Cluster 132 assigned to Class 718. Cost: 3.651523703127021\n",
      "Cluster 123 assigned to Class 720. Cost: 3.539718973011766\n",
      "Cluster 346 assigned to Class 731. Cost: 2.978506856478562\n",
      "Cluster 297 assigned to Class 733. Cost: 3.719728277177642\n",
      "Cluster 25 assigned to Class 734. Cost: 3.5638564832418167\n",
      "Cluster 367 assigned to Class 735. Cost: 3.372595945881431\n",
      "Cluster 1 assigned to Class 736. Cost: 3.141031171281896\n",
      "Cluster 388 assigned to Class 739. Cost: 3.3987228810708734\n",
      "Cluster 257 assigned to Class 740. Cost: 3.6429870935355972\n",
      "Cluster 384 assigned to Class 743. Cost: 3.8718835977360446\n",
      "Cluster 273 assigned to Class 745. Cost: 3.8306222340395357\n",
      "Cluster 85 assigned to Class 746. Cost: 3.7335693320392442\n",
      "Cluster 188 assigned to Class 748. Cost: 3.71361727848471\n",
      "Cluster 105 assigned to Class 751. Cost: 3.5256281533142646\n",
      "Cluster 13 assigned to Class 753. Cost: 3.7200766954405196\n",
      "Cluster 267 assigned to Class 756. Cost: 3.5972377535778497\n",
      "Cluster 192 assigned to Class 760. Cost: 2.8989272195490767\n",
      "Cluster 151 assigned to Class 761. Cost: 3.138169341174918\n",
      "Cluster 75 assigned to Class 765. Cost: 3.744710579595219\n",
      "Cluster 22 assigned to Class 766. Cost: 3.4098602276364587\n",
      "Cluster 163 assigned to Class 767. Cost: 3.7501473849148943\n",
      "Cluster 144 assigned to Class 769. Cost: 3.0393156230518423\n",
      "Cluster 152 assigned to Class 770. Cost: 3.6786947156307193\n",
      "Cluster 89 assigned to Class 772. Cost: 3.854310659961251\n",
      "Cluster 221 assigned to Class 773. Cost: 3.324480366819481\n",
      "Cluster 298 assigned to Class 774. Cost: 3.2869533423641024\n",
      "Cluster 113 assigned to Class 775. Cost: 3.6153477286962823\n",
      "Cluster 187 assigned to Class 776. Cost: 3.6654587346238907\n",
      "Cluster 103 assigned to Class 780. Cost: 3.818667108830745\n",
      "Cluster 272 assigned to Class 781. Cost: 3.2498973486489673\n",
      "Cluster 245 assigned to Class 784. Cost: 3.4554135160250867\n",
      "Cluster 213 assigned to Class 786. Cost: 3.155578633637333\n",
      "Cluster 305 assigned to Class 787. Cost: 3.8273702007250336\n",
      "Cluster 48 assigned to Class 788. Cost: 2.857135692960862\n",
      "Cluster 284 assigned to Class 789. Cost: 3.704645515967189\n",
      "Cluster 175 assigned to Class 790. Cost: 2.9384845386526384\n",
      "Cluster 249 assigned to Class 793. Cost: 3.4689347359635385\n",
      "Cluster 238 assigned to Class 794. Cost: 3.8488382677326953\n",
      "Cluster 295 assigned to Class 795. Cost: 2.9384191585016377\n",
      "Cluster 226 assigned to Class 799. Cost: 3.832718031431812\n",
      "Cluster 385 assigned to Class 806. Cost: 3.4795589887871934\n",
      "Cluster 344 assigned to Class 810. Cost: 3.6802545587224134\n",
      "Cluster 108 assigned to Class 816. Cost: 3.427095514198647\n",
      "Cluster 317 assigned to Class 819. Cost: 3.255213389665691\n",
      "Cluster 111 assigned to Class 820. Cost: 3.1639081156195688\n",
      "Cluster 4 assigned to Class 824. Cost: 3.8566602489611634\n",
      "Cluster 357 assigned to Class 826. Cost: 3.3781737037306265\n",
      "Cluster 171 assigned to Class 827. Cost: 2.9848469804180935\n",
      "Cluster 212 assigned to Class 828. Cost: 3.8217777146254206\n",
      "Cluster 199 assigned to Class 829. Cost: 3.659001449190859\n",
      "Cluster 321 assigned to Class 832. Cost: 3.7648022260462692\n",
      "Cluster 193 assigned to Class 833. Cost: 3.6636178286431615\n",
      "Cluster 387 assigned to Class 834. Cost: 2.7177361365012622\n",
      "Cluster 126 assigned to Class 835. Cost: 2.875328310587457\n",
      "Cluster 200 assigned to Class 837. Cost: 3.6630261986883648\n",
      "Cluster 82 assigned to Class 840. Cost: 3.8294317885599645\n",
      "Cluster 9 assigned to Class 841. Cost: 3.0197180339703857\n",
      "Cluster 47 assigned to Class 843. Cost: 2.994804314967365\n",
      "Cluster 6 assigned to Class 846. Cost: 3.032944733986709\n",
      "Cluster 289 assigned to Class 850. Cost: 3.8182145757405945\n",
      "Cluster 276 assigned to Class 851. Cost: 3.2046195762014427\n",
      "Cluster 84 assigned to Class 852. Cost: 2.995389262587519\n",
      "Cluster 0 assigned to Class 854. Cost: 3.343939298995067\n",
      "Cluster 254 assigned to Class 855. Cost: 3.590938242327705\n",
      "Cluster 157 assigned to Class 858. Cost: 2.623455000865165\n",
      "Cluster 207 assigned to Class 861. Cost: 3.3937678695962337\n",
      "Cluster 386 assigned to Class 864. Cost: 3.5893477258440947\n",
      "Cluster 40 assigned to Class 866. Cost: 3.2791822452184007\n",
      "Cluster 83 assigned to Class 867. Cost: 3.8773822600283174\n",
      "Cluster 120 assigned to Class 868. Cost: 3.4398359287575135\n",
      "Cluster 33 assigned to Class 870. Cost: 2.8411903623477333\n",
      "Cluster 8 assigned to Class 871. Cost: 3.2573923900202617\n",
      "Cluster 395 assigned to Class 873. Cost: 3.1111760612807284\n",
      "Cluster 218 assigned to Class 876. Cost: 3.1554536279912115\n",
      "Cluster 118 assigned to Class 880. Cost: 3.5439951124544606\n",
      "Cluster 396 assigned to Class 881. Cost: 3.1177382255932438\n",
      "Cluster 354 assigned to Class 887. Cost: 3.392692174579061\n",
      "Cluster 288 assigned to Class 891. Cost: 3.301670036779365\n",
      "Cluster 398 assigned to Class 892. Cost: 3.3887249795856635\n",
      "Cluster 316 assigned to Class 895. Cost: 3.4474529876675777\n",
      "Cluster 141 assigned to Class 896. Cost: 3.344950069929591\n",
      "Cluster 14 assigned to Class 897. Cost: 3.236439803958471\n",
      "Cluster 43 assigned to Class 901. Cost: 3.4193994281443256\n",
      "Cluster 211 assigned to Class 903. Cost: 3.895126694837856\n",
      "Cluster 270 assigned to Class 905. Cost: 3.538365869139629\n",
      "Cluster 279 assigned to Class 906. Cost: 3.1394795257610646\n",
      "Cluster 294 assigned to Class 907. Cost: 3.7544626520137667\n",
      "Cluster 391 assigned to Class 910. Cost: 3.6864066799123227\n",
      "Cluster 63 assigned to Class 913. Cost: 3.189964388423033\n",
      "Cluster 198 assigned to Class 916. Cost: 3.5208209667516273\n",
      "Cluster 125 assigned to Class 921. Cost: 3.8150590131646145\n",
      "Cluster 24 assigned to Class 922. Cost: 3.0931750546299615\n",
      "Cluster 228 assigned to Class 924. Cost: 2.9596971923809883\n",
      "Cluster 55 assigned to Class 925. Cost: 3.526135171205407\n",
      "Cluster 134 assigned to Class 926. Cost: 2.939717913390572\n",
      "Cluster 96 assigned to Class 929. Cost: 3.497286464605906\n",
      "Cluster 330 assigned to Class 932. Cost: 2.9931028699085935\n",
      "Cluster 50 assigned to Class 933. Cost: 3.7789477167861842\n",
      "Cluster 314 assigned to Class 935. Cost: 2.940664004858579\n",
      "Cluster 255 assigned to Class 938. Cost: 2.7260034639607427\n",
      "Cluster 232 assigned to Class 939. Cost: 3.642696705061225\n",
      "Cluster 80 assigned to Class 943. Cost: 3.5372554897462205\n",
      "Cluster 10 assigned to Class 947. Cost: 3.7796117941921157\n",
      "Cluster 90 assigned to Class 952. Cost: 3.167621148551398\n",
      "Cluster 399 assigned to Class 955. Cost: 3.0239445719266933\n",
      "Cluster 117 assigned to Class 956. Cost: 3.328310787445917\n",
      "Cluster 349 assigned to Class 957. Cost: 3.353607098653707\n",
      "Cluster 264 assigned to Class 958. Cost: 3.3045340567587242\n",
      "Cluster 347 assigned to Class 959. Cost: 3.166713282045396\n",
      "Cluster 278 assigned to Class 960. Cost: 3.249761263668176\n",
      "Cluster 183 assigned to Class 962. Cost: 3.621607224727507\n",
      "Cluster 329 assigned to Class 968. Cost: 3.7910597084506463\n",
      "Cluster 336 assigned to Class 969. Cost: 3.6617016862407343\n",
      "Cluster 58 assigned to Class 973. Cost: 3.371033931634899\n",
      "Cluster 393 assigned to Class 974. Cost: 3.0330099801185777\n",
      "Cluster 268 assigned to Class 983. Cost: 3.459165550349892\n",
      "Cluster 16 assigned to Class 984. Cost: 3.739734912304235\n",
      "Cluster 220 assigned to Class 986. Cost: 3.8000740712298673\n",
      "Cluster 180 assigned to Class 988. Cost: 3.0837245842846155\n",
      "Cluster 345 assigned to Class 989. Cost: 3.8789268370246743\n",
      "Cluster 64 assigned to Class 990. Cost: 3.239591775638206\n",
      "Cluster 12 assigned to Class 992. Cost: 3.3362157038861575\n",
      "Cluster 95 assigned to Class 993. Cost: 3.3035483941145665\n",
      "Cluster 181 assigned to Class 994. Cost: 3.1343343571833064\n",
      "Cluster 342 assigned to Class 995. Cost: 3.069598004682559\n",
      "Cluster 376 assigned to Class 996. Cost: 3.5846075787031633\n",
      "Cluster 394 assigned to Class 997. Cost: 3.1746964507707225\n"
     ]
    }
   ],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "dist_list =  np.transpose(tot_dist, (1, 0))\n",
    "from tqdm import tqdm\n",
    "\n",
    "costs = dist_list\n",
    "\n",
    "num_workers = len(costs)\n",
    "num_tasks = len(costs[0])\n",
    "# Create the mip solver with the SCIP backend.\n",
    "solver = pywraplp.Solver.CreateSolver(\"SCIP\")\n",
    "\n",
    "# x[i, j] is an array of 0-1 variables, which will be 1\n",
    "# if worker i is assigned to task j.\n",
    "x = {}\n",
    "for i in range(num_workers):\n",
    "    for j in range(num_tasks):\n",
    "        x[i, j] = solver.IntVar(0, 1, \"\")\n",
    "        \n",
    "# Each worker is assigned to at most 1 task.\n",
    "for i in range(num_workers):\n",
    "    solver.Add(solver.Sum([x[i, j] for j in range(num_tasks)]) <= 1)\n",
    "\n",
    "# Each task is assigned to exactly one worker.\n",
    "for j in range(num_tasks):\n",
    "    solver.Add(solver.Sum([x[i, j] for i in range(num_workers)]) == 1)\n",
    "    \n",
    "objective_terms = []\n",
    "for i in tqdm(range(num_workers)):\n",
    "    for j in range(num_tasks):\n",
    "        objective_terms.append(costs[i][j] * x[i, j])\n",
    "solver.Minimize(solver.Sum(objective_terms))\n",
    "\n",
    "status = solver.Solve()\n",
    "\n",
    "sol_indexes = []\n",
    "if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "    print(f\"Total cost = {solver.Objective().Value()}\\n\")\n",
    "    for i in range(num_workers):\n",
    "        for j in range(num_tasks):\n",
    "            # Test if x[i,j] is 1 (with tolerance for floating point arithmetic).\n",
    "            if x[i, j].solution_value() > 0.1:\n",
    "                print(f\"Cluster {j} assigned to Class {i}.\" + f\" Cost: {costs[i][j]}\")\n",
    "                sol_indexes.append(i)\n",
    "else:\n",
    "    print(\"No solution found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e8b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sol_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c015e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes have been saved to 'cvfinal.pkl'.\n"
     ]
    }
   ],
   "source": [
    "with open('cvfinal.pkl', 'wb') as file:\n",
    "    pickle.dump(sol_indexes, file)\n",
    "\n",
    "print(\"Indexes have been saved to 'cvfinal.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118f0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6783421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.6200830936431885 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1575fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\distributed\\node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 58656 instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\contextlib.py:120: UserWarning: Creating scratch directories is taking a surprisingly long time. (5.65s) This is often due to running workers on a network file system. Consider specifying a local-directory to point workers to write scratch data to a local disk.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFrames:   0%|                                                  | 0/4 [00:00<?, ?it/s]\n",
      "Processing chunks:   0%|                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Processing DataFrames:  25%|██████████▎                              | 1/4 [06:15<18:46, 375.55s/it]\u001b[A\n",
      "Processing chunks:   0%|                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Processing DataFrames:  50%|████████████████████▌                    | 2/4 [19:39<20:55, 627.73s/it]\u001b[A\n",
      "Processing chunks:   0%|                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Processing DataFrames:  75%|██████████████████████████████▊          | 3/4 [35:56<13:07, 787.14s/it]\u001b[A\n",
      "Processing chunks:   0%|                                                      | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Processing DataFrames: 100%|█████████████████████████████████████████| 4/4 [56:57<00:00, 854.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 3418.967207431793 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from dask.distributed import Client\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "\n",
    "# Initialize Dask client\n",
    "client = Client()\n",
    "\n",
    "def compute_closest_indexes(chunk, centers, index_set):\n",
    "    result_list = []\n",
    "    print(\"Centers shape:\", np.shape(centers))\n",
    "    # Convert the DataFrame to a list of lists and handle tab-separated values\n",
    "    chunk_list = [row[0].split('\\t') for row in chunk.values.tolist()]\n",
    "    print(\"Chunk DataFrame as list after splitting tabs:\\n\", chunk_list)\n",
    "\n",
    "    for idx, row in enumerate(chunk_list):\n",
    "        # Remove the first and last element from each row and convert the rest to float\n",
    "        features = np.array(row[1:-1], dtype=float).reshape(1, -1)  # Skipping the first element (file path) and the last element\n",
    "        print(\"Processed features array:\", features)  # Print features for debugging\n",
    "\n",
    "        # Compute the Euclidean distance to each center\n",
    "        distances = cdist(features, centers, metric='euclidean')\n",
    "        closest_center_idx = np.argmin(distances)\n",
    "        \n",
    "        # Append results if closest center is in the index set\n",
    "        if closest_center_idx in index_set:\n",
    "            result_list.append((closest_center_idx, row[1]))  # row[1] should still be the ID or similar\n",
    "\n",
    "    return result_list\n",
    "\n",
    "# Function to process elements of all DataFrames\n",
    "def process_elements(dfs, centers, index_set, max_len_per_index=500):\n",
    "    result_list = []\n",
    "    index_count = {idx: 0 for idx in index_set}\n",
    "    delayed_results = []\n",
    "    print(len(result_list))\n",
    "    for df in tqdm(dfs, desc=\"Processing DataFrames\"):\n",
    "        # Iterate over chunks of the DataFrame\n",
    "        for chunk in tqdm(df.to_delayed(), desc=\"Processing chunks\", leave=False):\n",
    "            # Process each chunk in parallel\n",
    "            delayed_result = dask.delayed(compute_closest_indexes)(chunk, centers, index_set)\n",
    "            delayed_results.append(delayed_result)\n",
    "\n",
    "        # Compute and collect results\n",
    "        if delayed_results:\n",
    "            chunk_results = dask.compute(*delayed_results)\n",
    "            for chunk_result in chunk_results:\n",
    "                for closest_center_idx, row_1 in chunk_result:\n",
    "                    if index_count[closest_center_idx] < max_len_per_index:\n",
    "                        result_list.append(row_1)\n",
    "                        index_count[closest_center_idx] += 1\n",
    "                        if index_count[closest_center_idx] >= max_len_per_index:\n",
    "                            index_set.remove(closest_center_idx)\n",
    "                        if all(count >= max_len_per_index for count in index_count.values()):\n",
    "                            return result_list\n",
    "\n",
    "    return result_list\n",
    "\n",
    "# Measure the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the pickle files\n",
    "with open(\"D:/ML_notebooks/cvfinal.pkl\", 'rb') as file:\n",
    "    index = pickle.load(file)\n",
    "with open(\"D:/ML_notebooks/cluster_centers.pkl\", 'rb') as file:\n",
    "    centers = pickle.load(file)\n",
    "\n",
    "# Convert index to a set for faster lookup\n",
    "index_set = set(index)\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "file_paths = [\n",
    "    r\"E:\\imagenet\\lbpfeature1.csv\",\n",
    "    r\"E:\\imagenet\\lbpfeature2.csv\",\n",
    "    r\"E:\\imagenet\\lbpfeature3.csv\",\n",
    "    r\"E:\\imagenet\\lbpfeature4.csv\"\n",
    "]\n",
    "\n",
    "# Load the CSV files into Dask DataFrames\n",
    "dfs = [dd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Call the function to process elements of each DataFrame\n",
    "result_list = process_elements(dfs, centers, index_set)\n",
    "\n",
    "# Save the result_list in a pickle file\n",
    "#with open(\"cifar_images.pkl\", \"wb\") as file:\n",
    "#    pickle.dump(result_list, file)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the execution time\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90056f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1d18729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197367\n"
     ]
    }
   ],
   "source": [
    "print(len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c9cd4-a50e-4b6c-b298-a8d179d3c77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9c450d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers shape: (1000, 256)\n",
      "Chunk DataFrame as list after splitting tabs:\n",
      " [['D:/data/imagenet\\\\n01440764\\\\n01440764_10027.JPEG', '0.5673076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.21153846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.22115384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2980769230769231', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.33653846153846156', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.4326923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.5096153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.4423076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.41346153846153844', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3557692307692308', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.36538461538461536', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.23076923076923078', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.22115384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.08653846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.16346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.11538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3942307692307692', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '3.25', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', ''], ['D:/data/imagenet\\\\n01440764\\\\n01440764_10029.JPEG', '0.6538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.375', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3269230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.08653846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.21153846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.27884615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.34615384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.33653846153846156', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3269230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.125', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.038461538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.04807692307692308', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.04807692307692308', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.07692307692307693', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.125', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.34615384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '4.605769230769231', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', ''], ['D:/data/imagenet\\\\n01440764\\\\n01440764_10040.JPEG', '0.4519230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.27884615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.20192307692307693', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.38461538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.375', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3076923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2403846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3173076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3942307692307692', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.23076923076923078', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.28846153846153844', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3269230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2692307692307692', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.4326923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.22115384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.22115384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.11538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.16346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3942307692307692', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '3.451923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', ''], ['D:/data/imagenet\\\\n01440764\\\\n01440764_10042.JPEG', '0.4519230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.5480769230769231', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3269230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2980769230769231', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.11538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0673076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.125', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.33653846153846156', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3942307692307692', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.47115384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3173076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.16346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.375', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '3.9615384615384617', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', ''], ['D:/data/imagenet\\\\n01440764\\\\n01440764_10043.JPEG', '0.6057692307692307', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3076923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2692307692307692', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.22115384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.23076923076923078', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.28846153846153844', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.4807692307692308', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.40384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.40384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3942307692307692', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.36538461538461536', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3076923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.20192307692307693', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.11538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.038461538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.125', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.4326923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '3.326923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', ''], ['D:/data/imagenet\\\\n01440764\\\\n01440764_10048.JPEG', '0.8173076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.40384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.34615384615384615', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.17307692307692307', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.27884615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2980769230769231', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.23076923076923078', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.125', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.08653846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0673076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.07692307692307693', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.057692307692307696', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.08653846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.23076923076923078', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.20192307692307693', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.40384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '4.355769230769231', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', ''], ['D:/data/imagenet\\\\n01440764\\\\n01440764_10066.JPEG', '0.8173076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.36538461538461536', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2403846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.17307692307692307', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.16346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.08653846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.09615384615384616', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.08653846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.23076923076923078', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.21153846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.16346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.23076923076923078', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.33653846153846156', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '4.778846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', ''], ['D:/data/imagenet\\\\n01440764\\\\n01440764_10074.JPEG', '0.5673076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3173076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.27884615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.27884615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.15384615384615385', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.17307692307692307', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.36538461538461536', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3269230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3076923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3269230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.21153846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2403846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.125', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.11538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.08653846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.08653846153846154', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.2980769230769231', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '4.125', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', ''], ['D:/data/imagenet\\\\n01440764\\\\n01440764_1009.JPEG', '0.9423076923076923', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.3942307692307692', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.28846153846153844', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.25961538461538464', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.20192307692307693', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.18269230769230768', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.19230769230769232', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.11538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.11538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.11538461538461539', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.10576923076923077', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.028846153846153848', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.16346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.057692307692307696', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.07692307692307693', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.07692307692307693', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.125', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.1346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.16346153846153846', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.14423076923076922', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.4519230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '4.894230769230769', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '']]\n",
      "Processed features array: [[0.56730769 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.21153846 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18269231 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.22115385\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25961538 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25       0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.29807692\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33653846 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.43269231 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.50961538 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.44230769 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.41346154 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.35576923 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.36538462 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.23076923\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22115385 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09615385 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08653846\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.10576923 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13461538 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10576923 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09615385 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16346154 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.11538462 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.39423077 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  3.25       0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Processed features array: [[0.65384615 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.375      0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.32692308 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.13461538\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25961538 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08653846 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.19230769\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.21153846 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27884615 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.19230769 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.19230769 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34615385 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33653846 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.32692308 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.09615385\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.125      0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03846154 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04807692\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.04807692 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09615385 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.07692308 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14423077 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18269231 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.125      0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.34615385 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  4.60576923 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Processed features array: [[0.45192308 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.27884615 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20192308 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.38461538\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.375      0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.30769231 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.24038462\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31730769 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.39423077 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23076923 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.28846154 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32692308 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.26923077 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.43269231 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.22115385\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.15384615 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.22115385 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.15384615\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.09615385 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11538462 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09615385 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13461538 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16346154 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14423077 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.39423077 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  3.45192308 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Processed features array: [[0.45192308 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.54807692 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25961538 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32692308\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.29807692 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19230769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.11538462\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06730769 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.125      0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.13461538 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18269231 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.33653846 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.39423077 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.47115385 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.19230769\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.31730769 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15384615 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.13461538\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.16346154 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09615385 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10576923 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18269231 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10576923 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.15384615 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.375      0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  3.96153846 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed features array: [[0.60576923 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.30769231 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26923077 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18269231\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22115385 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23076923 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.28846154\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.48076923 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40384615 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.40384615 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.39423077 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.36538462 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25961538 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30769231 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20192308\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.15384615 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11538462 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.09615385\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.03846154 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09615385 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10576923 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25       0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.125      0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18269231 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.43269231 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  3.32692308 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Processed features array: [[0.81730769 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.40384615 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.25961538 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.34615385\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25961538 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18269231 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.15384615\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17307692 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19230769 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.27884615 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29807692 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18269231 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.13461538 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.23076923 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.08653846 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.06730769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.07692308\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05769231 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08653846 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10576923 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13461538 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23076923 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.20192308 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.40384615 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  4.35576923 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Processed features array: [[0.81730769 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.36538462 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24038462 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.17307692\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25961538 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13461538 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16346154\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13461538 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08653846 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18269231 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.15384615 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.09615385 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14423077 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14423077 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08653846\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.15384615 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14423077 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.15384615\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.15384615 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23076923 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.21153846 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10576923 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16346154 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23076923 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33653846 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  4.77884615 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Processed features array: [[0.56730769 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.31730769 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27884615 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.27884615\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.15384615 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.17307692 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.25\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.36538462 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32692308 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.30769231 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.32692308 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25961538 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.21153846 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.24038462 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.19230769\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.18269231 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.125      0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.11538462\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.08653846 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.14423077 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10576923 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08653846 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14423077 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18269231 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29807692 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  4.125      0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Processed features array: [[0.94230769 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.39423077 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.28846154 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.19230769\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25961538 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20192308 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.18269231\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.19230769 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11538462 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.13461538 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11538462 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.11538462 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14423077 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10576923 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.02884615\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.16346154 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.05769231 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.07692308\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.07692308 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.125      0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.13461538 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14423077 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16346154 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14423077 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.45192308 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  4.89423077 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "Results: [(770, '0.5673076923076923'), (733, '0.4519230769230769'), (215, '0.6057692307692307')]\n"
     ]
    }
   ],
   "source": [
    "def compute_closest_indexes(chunk, centers, index_set):\n",
    "    result_list = []\n",
    "    print(\"Centers shape:\", np.shape(centers))\n",
    "    # Convert the DataFrame to a list of lists and handle tab-separated values\n",
    "    chunk_list = [row[0].split('\\t') for row in chunk.values.tolist()]\n",
    "    print(\"Chunk DataFrame as list after splitting tabs:\\n\", chunk_list)\n",
    "\n",
    "    for idx, row in enumerate(chunk_list):\n",
    "        # Remove the first and last element from each row and convert the rest to float\n",
    "        features = np.array(row[1:-1], dtype=float).reshape(1, -1)  # Skipping the first element (file path) and the last element\n",
    "        print(\"Processed features array:\", features)  # Print features for debugging\n",
    "\n",
    "        # Compute the Euclidean distance to each center\n",
    "        distances = cdist(features, centers, metric='euclidean')\n",
    "        closest_center_idx = np.argmin(distances)\n",
    "        \n",
    "        # Append results if closest center is in the index set\n",
    "        if closest_center_idx in index_set:\n",
    "            result_list.append((closest_center_idx, row[1]))  # row[1] should still be the ID or similar\n",
    "\n",
    "    return result_list\n",
    "\n",
    "# Assuming 'df', 'centers', and 'index_set' are defined and initialized appropriately\n",
    "chunk = df.iloc[1:10]  # Get a subset of the DataFrame\n",
    "results = compute_closest_indexes(chunk, centers, index_set)\n",
    "print(\"Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b42cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25ea22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ffbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c8433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe875fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f43ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
