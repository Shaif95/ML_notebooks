{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c816a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602c030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFrames: 100%|████████████████████████████████████████████████████████████| 4/4 [18:31<00:00, 277.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "file_paths = [\n",
    "    \"G:/image_features.csv\",\n",
    "    \"G:/image_features1.csv\",\n",
    "    \"G:/image_features2.csv\",\n",
    "    \"G:/image_features3.csv\"\n",
    "]\n",
    "\n",
    "# Load the CSV files into Dask DataFrames\n",
    "dfs = [dd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Function to get 25,000 random indexes and retrieve the full rows\n",
    "def get_random_rows(df, n=25000):\n",
    "    # Convert the Dask DataFrame to a Pandas DataFrame\n",
    "    pandas_df = df.compute()\n",
    "    \n",
    "    # Get the total number of rows in the DataFrame\n",
    "    total_rows = len(pandas_df)\n",
    "    \n",
    "    # Generate 25,000 random indexes\n",
    "    random_indexes = np.random.choice(total_rows, n, replace=False)\n",
    "    \n",
    "    # Retrieve the full rows for these random indexes\n",
    "    random_rows = pandas_df.iloc[random_indexes].values.tolist()\n",
    "    \n",
    "    return random_rows\n",
    "\n",
    "# Initialize an empty list to store all rows\n",
    "all_random_rows = []\n",
    "\n",
    "# Get the rows from each DataFrame\n",
    "for df in tqdm(dfs, desc=\"Processing DataFrames\"):\n",
    "    rows = get_random_rows(df)\n",
    "    all_random_rows.extend(rows)\n",
    "\n",
    "# Print the total number of rows collected\n",
    "print(len(all_random_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cfa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59381467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the first two items from each element in all_random_rows\n",
    "new_all_random_rows = [row[2:] for row in all_random_rows]\n",
    "np.shape(new_all_random_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9caf10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the cluster centers: (1000, 2048)\n",
      "Cluster centers have been saved to 'cluster_centers.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Assuming new_all_random_rows has been populated as described\n",
    "\n",
    "# Convert new_all_random_rows to a NumPy array\n",
    "data = np.array(new_all_random_rows)\n",
    "\n",
    "batch_size = 10000\n",
    "max_iter = 100\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = MiniBatchKMeans(n_clusters=1000, batch_size=batch_size, max_iter=max_iter, random_state=42)\n",
    "kmeans.fit(data)\n",
    "\n",
    "# Store the cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Print the shape of the cluster centers\n",
    "print(f\"Shape of the cluster centers: {centers.shape}\")\n",
    "\n",
    "# Save the cluster centers to a pickle file\n",
    "with open('cluster_centers.pkl', 'wb') as file:\n",
    "    pickle.dump(centers, file)\n",
    "\n",
    "print(\"Cluster centers have been saved to 'cluster_centers.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cd015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bba5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10d8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "import glob\n",
    "\n",
    "target_size = (32, 32)  # Change the values as per your requirement\n",
    "# Load the pre-trained ResNet50 model with modified input shape\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(target_size[0], target_size[1], 3))\n",
    "\n",
    "ft = model.predict(np.array(x_train).astype(\"float32\"))\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "n_clusters = 400\n",
    "batch_size = 100\n",
    "max_iter = 100\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, max_iter=max_iter)\n",
    "kmeans.fit(ft)\n",
    "# Retrieve the cluster centers\n",
    "ct = kmeans.cluster_centers_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9d0753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4179a7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [00:47<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the distance array: (400, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize a list to store the distances\n",
    "tot_dist = []\n",
    "\n",
    "# Calculate L2 distances\n",
    "for i in tqdm(range(len(ct))):\n",
    "    distances = []\n",
    "    for j in range(len(centers)):\n",
    "        distance = np.linalg.norm(ct[i] - centers[j])\n",
    "        distances.append(distance)\n",
    "    tot_dist.append(distances)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "tot_dist = np.array(tot_dist)\n",
    "\n",
    "# Print the shape of the resulting array\n",
    "print(f\"Shape of the distance array: {tot_dist.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3ca2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01589f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:35<00:00, 27.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost = 34849.1477692988\n",
      "\n",
      "Cluster 258 assigned to Class 1. Cost: 72.4741963365812\n",
      "Cluster 156 assigned to Class 3. Cost: 94.81770189599621\n",
      "Cluster 38 assigned to Class 4. Cost: 67.62513828161217\n",
      "Cluster 18 assigned to Class 5. Cost: 99.71419070540072\n",
      "Cluster 250 assigned to Class 7. Cost: 77.56734502728682\n",
      "Cluster 379 assigned to Class 9. Cost: 85.95481599334808\n",
      "Cluster 131 assigned to Class 10. Cost: 96.82082589561405\n",
      "Cluster 81 assigned to Class 11. Cost: 83.23474367071579\n",
      "Cluster 330 assigned to Class 12. Cost: 89.85992665338985\n",
      "Cluster 342 assigned to Class 13. Cost: 97.68242741567232\n",
      "Cluster 273 assigned to Class 15. Cost: 92.18520593956254\n",
      "Cluster 187 assigned to Class 17. Cost: 70.95434333418568\n",
      "Cluster 11 assigned to Class 18. Cost: 73.40117176791223\n",
      "Cluster 200 assigned to Class 20. Cost: 88.25364549060023\n",
      "Cluster 88 assigned to Class 21. Cost: 92.76846237132023\n",
      "Cluster 225 assigned to Class 27. Cost: 79.01357612185525\n",
      "Cluster 284 assigned to Class 28. Cost: 97.61617572909618\n",
      "Cluster 74 assigned to Class 30. Cost: 91.97421482333023\n",
      "Cluster 236 assigned to Class 33. Cost: 88.5600872772352\n",
      "Cluster 183 assigned to Class 35. Cost: 85.83646315921595\n",
      "Cluster 323 assigned to Class 39. Cost: 96.24732100602729\n",
      "Cluster 367 assigned to Class 40. Cost: 93.09608172798478\n",
      "Cluster 391 assigned to Class 41. Cost: 99.02623823567728\n",
      "Cluster 178 assigned to Class 44. Cost: 99.19885850827083\n",
      "Cluster 85 assigned to Class 45. Cost: 84.88672708418385\n",
      "Cluster 133 assigned to Class 50. Cost: 72.72700960297229\n",
      "Cluster 69 assigned to Class 55. Cost: 72.9601695627377\n",
      "Cluster 224 assigned to Class 56. Cost: 98.98455162102992\n",
      "Cluster 48 assigned to Class 58. Cost: 86.06085256869363\n",
      "Cluster 275 assigned to Class 59. Cost: 94.98936105392697\n",
      "Cluster 116 assigned to Class 60. Cost: 89.73114491417113\n",
      "Cluster 138 assigned to Class 64. Cost: 69.57292325571531\n",
      "Cluster 263 assigned to Class 69. Cost: 72.16059277913202\n",
      "Cluster 346 assigned to Class 70. Cost: 91.43829853224247\n",
      "Cluster 293 assigned to Class 71. Cost: 90.73108902453835\n",
      "Cluster 168 assigned to Class 72. Cost: 85.77920075716682\n",
      "Cluster 180 assigned to Class 76. Cost: 93.63571031107986\n",
      "Cluster 360 assigned to Class 84. Cost: 85.78098102515328\n",
      "Cluster 57 assigned to Class 86. Cost: 81.00258891424896\n",
      "Cluster 394 assigned to Class 89. Cost: 92.74845497163308\n",
      "Cluster 354 assigned to Class 93. Cost: 73.19710089399086\n",
      "Cluster 45 assigned to Class 94. Cost: 95.85252248764421\n",
      "Cluster 318 assigned to Class 95. Cost: 94.89012240806872\n",
      "Cluster 311 assigned to Class 96. Cost: 95.66910796794541\n",
      "Cluster 160 assigned to Class 98. Cost: 80.79117165769959\n",
      "Cluster 51 assigned to Class 99. Cost: 97.44713516752111\n",
      "Cluster 52 assigned to Class 101. Cost: 90.64964425193895\n",
      "Cluster 334 assigned to Class 102. Cost: 75.25067022061891\n",
      "Cluster 353 assigned to Class 103. Cost: 94.50292713554454\n",
      "Cluster 186 assigned to Class 104. Cost: 93.71144214049842\n",
      "Cluster 207 assigned to Class 105. Cost: 94.96200957531167\n",
      "Cluster 12 assigned to Class 106. Cost: 87.40094690465794\n",
      "Cluster 239 assigned to Class 110. Cost: 82.73310162831054\n",
      "Cluster 55 assigned to Class 111. Cost: 65.73016092979529\n",
      "Cluster 60 assigned to Class 112. Cost: 87.07112495690231\n",
      "Cluster 67 assigned to Class 113. Cost: 88.17727741789426\n",
      "Cluster 264 assigned to Class 117. Cost: 88.28579626727797\n",
      "Cluster 6 assigned to Class 118. Cost: 90.42239486672509\n",
      "Cluster 1 assigned to Class 120. Cost: 93.93527015250592\n",
      "Cluster 84 assigned to Class 121. Cost: 80.61541345843641\n",
      "Cluster 65 assigned to Class 124. Cost: 94.2380712347805\n",
      "Cluster 338 assigned to Class 133. Cost: 71.09972459769588\n",
      "Cluster 130 assigned to Class 135. Cost: 84.13713150352706\n",
      "Cluster 14 assigned to Class 138. Cost: 87.79095722836688\n",
      "Cluster 176 assigned to Class 140. Cost: 85.82594352935567\n",
      "Cluster 212 assigned to Class 141. Cost: 89.44502974152985\n",
      "Cluster 350 assigned to Class 144. Cost: 82.88733596469089\n",
      "Cluster 237 assigned to Class 145. Cost: 83.62681814522378\n",
      "Cluster 220 assigned to Class 146. Cost: 80.0227634694113\n",
      "Cluster 177 assigned to Class 148. Cost: 85.34120458445783\n",
      "Cluster 390 assigned to Class 151. Cost: 99.8980311948196\n",
      "Cluster 387 assigned to Class 153. Cost: 88.49623884229176\n",
      "Cluster 125 assigned to Class 154. Cost: 80.74826460713282\n",
      "Cluster 351 assigned to Class 156. Cost: 74.73764380004089\n",
      "Cluster 358 assigned to Class 157. Cost: 100.34357722137409\n",
      "Cluster 159 assigned to Class 159. Cost: 93.81978176562059\n",
      "Cluster 112 assigned to Class 164. Cost: 92.38974624784512\n",
      "Cluster 170 assigned to Class 165. Cost: 89.13160579900648\n",
      "Cluster 395 assigned to Class 167. Cost: 95.74554372978467\n",
      "Cluster 271 assigned to Class 168. Cost: 83.18207858507382\n",
      "Cluster 154 assigned to Class 170. Cost: 90.76991590277133\n",
      "Cluster 260 assigned to Class 173. Cost: 91.18081794442655\n",
      "Cluster 291 assigned to Class 175. Cost: 83.5896282594465\n",
      "Cluster 364 assigned to Class 176. Cost: 83.99601931659079\n",
      "Cluster 202 assigned to Class 178. Cost: 94.87036934920667\n",
      "Cluster 5 assigned to Class 179. Cost: 88.61642495984556\n",
      "Cluster 92 assigned to Class 180. Cost: 82.59581929394406\n",
      "Cluster 106 assigned to Class 185. Cost: 82.73559596624045\n",
      "Cluster 174 assigned to Class 191. Cost: 88.95192999381948\n",
      "Cluster 136 assigned to Class 192. Cost: 85.02023895360014\n",
      "Cluster 193 assigned to Class 193. Cost: 95.13954818993705\n",
      "Cluster 149 assigned to Class 195. Cost: 96.14747978749782\n",
      "Cluster 369 assigned to Class 196. Cost: 99.98776502544321\n",
      "Cluster 24 assigned to Class 198. Cost: 87.25322899710261\n",
      "Cluster 73 assigned to Class 206. Cost: 70.15261835308529\n",
      "Cluster 134 assigned to Class 207. Cost: 95.33830613289858\n",
      "Cluster 352 assigned to Class 208. Cost: 84.622620127945\n",
      "Cluster 270 assigned to Class 209. Cost: 92.58620483576823\n",
      "Cluster 115 assigned to Class 216. Cost: 85.47074719379118\n",
      "Cluster 251 assigned to Class 217. Cost: 96.975180584636\n",
      "Cluster 56 assigned to Class 222. Cost: 94.32289728399076\n",
      "Cluster 328 assigned to Class 223. Cost: 75.61149728299034\n",
      "Cluster 49 assigned to Class 226. Cost: 95.25168638093791\n",
      "Cluster 374 assigned to Class 231. Cost: 68.56013741568971\n",
      "Cluster 64 assigned to Class 236. Cost: 82.8510497147847\n",
      "Cluster 319 assigned to Class 239. Cost: 77.92813613146502\n",
      "Cluster 252 assigned to Class 240. Cost: 94.96252332208309\n",
      "Cluster 259 assigned to Class 241. Cost: 89.24968685558403\n",
      "Cluster 123 assigned to Class 243. Cost: 74.8353822401355\n",
      "Cluster 29 assigned to Class 245. Cost: 83.07700078881231\n",
      "Cluster 66 assigned to Class 246. Cost: 54.53621651630326\n",
      "Cluster 10 assigned to Class 249. Cost: 94.62543832994896\n",
      "Cluster 392 assigned to Class 250. Cost: 89.56979499548015\n",
      "Cluster 34 assigned to Class 254. Cost: 79.62347037881516\n",
      "Cluster 70 assigned to Class 261. Cost: 93.34805521523145\n",
      "Cluster 143 assigned to Class 262. Cost: 78.8526308808646\n",
      "Cluster 141 assigned to Class 264. Cost: 67.64913664928089\n",
      "Cluster 33 assigned to Class 268. Cost: 80.37059392712655\n",
      "Cluster 279 assigned to Class 276. Cost: 93.03421559386787\n",
      "Cluster 341 assigned to Class 278. Cost: 97.35163476792684\n",
      "Cluster 257 assigned to Class 279. Cost: 80.44686231007728\n",
      "Cluster 226 assigned to Class 280. Cost: 84.50475611793352\n",
      "Cluster 71 assigned to Class 284. Cost: 85.41580530856497\n",
      "Cluster 376 assigned to Class 285. Cost: 81.11572634129813\n",
      "Cluster 386 assigned to Class 286. Cost: 99.06990445408313\n",
      "Cluster 266 assigned to Class 292. Cost: 72.83338852815885\n",
      "Cluster 292 assigned to Class 294. Cost: 97.46574165780167\n",
      "Cluster 348 assigned to Class 295. Cost: 72.37858328237431\n",
      "Cluster 345 assigned to Class 299. Cost: 82.47517385667082\n",
      "Cluster 321 assigned to Class 300. Cost: 89.00860358481887\n",
      "Cluster 217 assigned to Class 301. Cost: 97.19668525651706\n",
      "Cluster 336 assigned to Class 306. Cost: 79.71534627007651\n",
      "Cluster 35 assigned to Class 310. Cost: 76.50250462928824\n",
      "Cluster 362 assigned to Class 314. Cost: 87.72987821651381\n",
      "Cluster 142 assigned to Class 315. Cost: 81.99289728230666\n",
      "Cluster 268 assigned to Class 316. Cost: 97.69603454645747\n",
      "Cluster 190 assigned to Class 317. Cost: 91.98071812267892\n",
      "Cluster 105 assigned to Class 318. Cost: 96.67487051216888\n",
      "Cluster 185 assigned to Class 320. Cost: 96.97285109300935\n",
      "Cluster 244 assigned to Class 321. Cost: 95.35447058807635\n",
      "Cluster 299 assigned to Class 323. Cost: 94.88352866853181\n",
      "Cluster 399 assigned to Class 325. Cost: 82.8043282794731\n",
      "Cluster 98 assigned to Class 331. Cost: 82.81550987286273\n",
      "Cluster 210 assigned to Class 332. Cost: 93.97136498710593\n",
      "Cluster 121 assigned to Class 333. Cost: 98.06894281939402\n",
      "Cluster 144 assigned to Class 336. Cost: 93.14883923712432\n",
      "Cluster 393 assigned to Class 337. Cost: 73.61301578431657\n",
      "Cluster 265 assigned to Class 340. Cost: 85.79310291245748\n",
      "Cluster 227 assigned to Class 344. Cost: 70.41418682058895\n",
      "Cluster 306 assigned to Class 348. Cost: 92.47177510220129\n",
      "Cluster 317 assigned to Class 357. Cost: 95.56892754491346\n",
      "Cluster 262 assigned to Class 361. Cost: 84.95388715493182\n",
      "Cluster 39 assigned to Class 364. Cost: 93.80219905882767\n",
      "Cluster 37 assigned to Class 367. Cost: 95.88519043742852\n",
      "Cluster 58 assigned to Class 368. Cost: 88.99204547144814\n",
      "Cluster 101 assigned to Class 369. Cost: 95.48344728450687\n",
      "Cluster 296 assigned to Class 371. Cost: 98.4611924444902\n",
      "Cluster 302 assigned to Class 372. Cost: 89.79714228421119\n",
      "Cluster 261 assigned to Class 373. Cost: 86.19127490152299\n",
      "Cluster 124 assigned to Class 374. Cost: 98.96085471602251\n",
      "Cluster 167 assigned to Class 376. Cost: 84.6063677528735\n",
      "Cluster 366 assigned to Class 377. Cost: 94.34903557478961\n",
      "Cluster 324 assigned to Class 381. Cost: 78.86950929314182\n",
      "Cluster 117 assigned to Class 382. Cost: 94.39561254432613\n",
      "Cluster 151 assigned to Class 383. Cost: 98.26575855760593\n",
      "Cluster 21 assigned to Class 384. Cost: 69.37049947485616\n",
      "Cluster 249 assigned to Class 385. Cost: 97.43880661440262\n",
      "Cluster 137 assigned to Class 390. Cost: 84.44665089306635\n",
      "Cluster 42 assigned to Class 392. Cost: 94.38476729891025\n",
      "Cluster 103 assigned to Class 393. Cost: 86.51807879263346\n",
      "Cluster 370 assigned to Class 396. Cost: 76.44925131211644\n",
      "Cluster 128 assigned to Class 397. Cost: 94.57544645857561\n",
      "Cluster 274 assigned to Class 398. Cost: 76.8396132266191\n",
      "Cluster 315 assigned to Class 399. Cost: 95.45247480881326\n",
      "Cluster 140 assigned to Class 400. Cost: 85.60186473100755\n",
      "Cluster 198 assigned to Class 403. Cost: 93.55625616144474\n",
      "Cluster 175 assigned to Class 406. Cost: 93.3179072198184\n",
      "Cluster 8 assigned to Class 409. Cost: 92.22253576739563\n",
      "Cluster 295 assigned to Class 411. Cost: 83.0247637646084\n",
      "Cluster 229 assigned to Class 412. Cost: 89.4420184957662\n",
      "Cluster 203 assigned to Class 418. Cost: 93.84656361013374\n",
      "Cluster 359 assigned to Class 419. Cost: 84.53454480369105\n",
      "Cluster 161 assigned to Class 421. Cost: 97.01290721441475\n",
      "Cluster 223 assigned to Class 425. Cost: 87.71808180676568\n",
      "Cluster 139 assigned to Class 427. Cost: 84.13299583406645\n",
      "Cluster 25 assigned to Class 428. Cost: 89.5421274830088\n",
      "Cluster 163 assigned to Class 429. Cost: 84.9682597655802\n",
      "Cluster 329 assigned to Class 431. Cost: 80.13345169615702\n",
      "Cluster 381 assigned to Class 435. Cost: 83.39591728833274\n",
      "Cluster 314 assigned to Class 437. Cost: 82.41111192287508\n",
      "Cluster 300 assigned to Class 439. Cost: 87.31309112201133\n",
      "Cluster 209 assigned to Class 443. Cost: 87.86687244358838\n",
      "Cluster 372 assigned to Class 446. Cost: 92.40579221752475\n",
      "Cluster 298 assigned to Class 449. Cost: 89.79352622354008\n",
      "Cluster 181 assigned to Class 452. Cost: 71.88363329999369\n",
      "Cluster 219 assigned to Class 454. Cost: 77.48361631136586\n",
      "Cluster 331 assigned to Class 456. Cost: 88.70115499646776\n",
      "Cluster 166 assigned to Class 461. Cost: 84.14578155245222\n",
      "Cluster 32 assigned to Class 462. Cost: 66.4281415769662\n",
      "Cluster 27 assigned to Class 463. Cost: 75.40930681671057\n",
      "Cluster 150 assigned to Class 466. Cost: 97.76023929029841\n",
      "Cluster 254 assigned to Class 471. Cost: 85.80597471696399\n",
      "Cluster 213 assigned to Class 475. Cost: 90.31731631988451\n",
      "Cluster 222 assigned to Class 479. Cost: 96.5794755391771\n",
      "Cluster 332 assigned to Class 480. Cost: 98.21190313559175\n",
      "Cluster 234 assigned to Class 481. Cost: 90.81954224231258\n",
      "Cluster 241 assigned to Class 483. Cost: 82.17129989974316\n",
      "Cluster 40 assigned to Class 485. Cost: 79.48149188360271\n",
      "Cluster 86 assigned to Class 486. Cost: 97.01581943086397\n",
      "Cluster 233 assigned to Class 487. Cost: 84.02242703377065\n",
      "Cluster 72 assigned to Class 489. Cost: 93.00481715684477\n",
      "Cluster 194 assigned to Class 493. Cost: 71.32539353627418\n",
      "Cluster 289 assigned to Class 498. Cost: 79.75881229338367\n",
      "Cluster 146 assigned to Class 501. Cost: 92.87348417834441\n",
      "Cluster 211 assigned to Class 504. Cost: 57.96581565762238\n",
      "Cluster 272 assigned to Class 506. Cost: 94.12264490754252\n",
      "Cluster 91 assigned to Class 514. Cost: 89.11792196391639\n",
      "Cluster 349 assigned to Class 517. Cost: 77.53555255852432\n",
      "Cluster 238 assigned to Class 518. Cost: 85.83251913238358\n",
      "Cluster 206 assigned to Class 520. Cost: 99.01329825730957\n",
      "Cluster 188 assigned to Class 522. Cost: 92.85690839432962\n",
      "Cluster 201 assigned to Class 532. Cost: 95.27730511399474\n",
      "Cluster 309 assigned to Class 533. Cost: 94.30041096792155\n",
      "Cluster 285 assigned to Class 534. Cost: 84.82833459565539\n",
      "Cluster 246 assigned to Class 536. Cost: 76.2985956387811\n",
      "Cluster 179 assigned to Class 537. Cost: 90.83807140497416\n",
      "Cluster 153 assigned to Class 540. Cost: 83.55181302194998\n",
      "Cluster 373 assigned to Class 541. Cost: 87.77953519859452\n",
      "Cluster 313 assigned to Class 542. Cost: 73.60564060181818\n",
      "Cluster 247 assigned to Class 543. Cost: 98.29547499322375\n",
      "Cluster 169 assigned to Class 547. Cost: 98.23808731067895\n",
      "Cluster 303 assigned to Class 548. Cost: 83.19033562602097\n",
      "Cluster 196 assigned to Class 551. Cost: 88.38996400687253\n",
      "Cluster 347 assigned to Class 553. Cost: 92.07220000159649\n",
      "Cluster 325 assigned to Class 554. Cost: 91.46603696898397\n",
      "Cluster 218 assigned to Class 560. Cost: 91.83165562296908\n",
      "Cluster 93 assigned to Class 562. Cost: 83.8809164381185\n",
      "Cluster 281 assigned to Class 566. Cost: 98.70756095765529\n",
      "Cluster 19 assigned to Class 567. Cost: 82.2465232586478\n",
      "Cluster 397 assigned to Class 570. Cost: 98.63187221660745\n",
      "Cluster 113 assigned to Class 571. Cost: 91.02924333011579\n",
      "Cluster 320 assigned to Class 574. Cost: 83.30510089918928\n",
      "Cluster 119 assigned to Class 575. Cost: 75.22150387982629\n",
      "Cluster 307 assigned to Class 577. Cost: 87.7153820690007\n",
      "Cluster 230 assigned to Class 579. Cost: 87.72230952666601\n",
      "Cluster 248 assigned to Class 580. Cost: 79.69062406565988\n",
      "Cluster 344 assigned to Class 582. Cost: 96.94821672098819\n",
      "Cluster 182 assigned to Class 586. Cost: 83.27498737889441\n",
      "Cluster 304 assigned to Class 591. Cost: 95.26110599899376\n",
      "Cluster 61 assigned to Class 596. Cost: 91.36385304747779\n",
      "Cluster 127 assigned to Class 597. Cost: 98.21113608160334\n",
      "Cluster 382 assigned to Class 600. Cost: 94.57485647398919\n",
      "Cluster 78 assigned to Class 603. Cost: 85.88980872534981\n",
      "Cluster 383 assigned to Class 604. Cost: 83.9341559734849\n",
      "Cluster 63 assigned to Class 606. Cost: 86.2471598241072\n",
      "Cluster 283 assigned to Class 609. Cost: 82.68323749527859\n",
      "Cluster 0 assigned to Class 611. Cost: 91.44685179497482\n",
      "Cluster 282 assigned to Class 613. Cost: 88.2842769396436\n",
      "Cluster 148 assigned to Class 614. Cost: 73.96023419683164\n",
      "Cluster 30 assigned to Class 622. Cost: 97.55893161380796\n",
      "Cluster 3 assigned to Class 627. Cost: 77.03925426879826\n",
      "Cluster 135 assigned to Class 632. Cost: 92.72966376606324\n",
      "Cluster 375 assigned to Class 638. Cost: 91.09131473983348\n",
      "Cluster 322 assigned to Class 640. Cost: 64.71746935611206\n",
      "Cluster 90 assigned to Class 642. Cost: 74.45259276271966\n",
      "Cluster 232 assigned to Class 645. Cost: 81.26512482884955\n",
      "Cluster 171 assigned to Class 651. Cost: 62.84753165470565\n",
      "Cluster 41 assigned to Class 652. Cost: 80.09460518093648\n",
      "Cluster 108 assigned to Class 653. Cost: 83.86003014418287\n",
      "Cluster 339 assigned to Class 657. Cost: 91.00342181920982\n",
      "Cluster 76 assigned to Class 660. Cost: 75.89473148168483\n",
      "Cluster 343 assigned to Class 662. Cost: 87.82412223574106\n",
      "Cluster 102 assigned to Class 664. Cost: 85.60645230843596\n",
      "Cluster 195 assigned to Class 666. Cost: 75.99613221672135\n",
      "Cluster 109 assigned to Class 667. Cost: 89.7657640174311\n",
      "Cluster 9 assigned to Class 668. Cost: 71.98309881400608\n",
      "Cluster 385 assigned to Class 673. Cost: 99.31147421917399\n",
      "Cluster 356 assigned to Class 682. Cost: 96.11429041993199\n",
      "Cluster 4 assigned to Class 684. Cost: 97.3341563064644\n",
      "Cluster 79 assigned to Class 685. Cost: 83.46055784608791\n",
      "Cluster 361 assigned to Class 686. Cost: 95.10934958018251\n",
      "Cluster 384 assigned to Class 687. Cost: 93.02451442263826\n",
      "Cluster 301 assigned to Class 694. Cost: 98.228514720991\n",
      "Cluster 162 assigned to Class 697. Cost: 85.54304679175902\n",
      "Cluster 129 assigned to Class 699. Cost: 91.18640034828007\n",
      "Cluster 54 assigned to Class 701. Cost: 75.61803994995938\n",
      "Cluster 50 assigned to Class 705. Cost: 75.95801098435876\n",
      "Cluster 297 assigned to Class 711. Cost: 83.28888679046185\n",
      "Cluster 267 assigned to Class 712. Cost: 84.33863951877498\n",
      "Cluster 276 assigned to Class 716. Cost: 83.94048897840548\n",
      "Cluster 47 assigned to Class 717. Cost: 95.66843347091519\n",
      "Cluster 310 assigned to Class 719. Cost: 84.63964279696853\n",
      "Cluster 164 assigned to Class 721. Cost: 87.48894839656354\n",
      "Cluster 256 assigned to Class 726. Cost: 97.20733220182339\n",
      "Cluster 152 assigned to Class 729. Cost: 86.22318696367037\n",
      "Cluster 118 assigned to Class 731. Cost: 93.48481596076132\n",
      "Cluster 255 assigned to Class 732. Cost: 92.93170326260136\n",
      "Cluster 368 assigned to Class 737. Cost: 97.74344163591746\n",
      "Cluster 173 assigned to Class 739. Cost: 67.15304699885077\n",
      "Cluster 240 assigned to Class 740. Cost: 96.09943914408161\n",
      "Cluster 365 assigned to Class 744. Cost: 76.21876660379205\n",
      "Cluster 83 assigned to Class 747. Cost: 84.05114247705403\n",
      "Cluster 380 assigned to Class 752. Cost: 83.44886904180596\n",
      "Cluster 104 assigned to Class 753. Cost: 95.30417168900969\n",
      "Cluster 189 assigned to Class 754. Cost: 95.26446331251982\n",
      "Cluster 87 assigned to Class 755. Cost: 81.12563345348683\n",
      "Cluster 243 assigned to Class 757. Cost: 81.29614775608131\n",
      "Cluster 17 assigned to Class 759. Cost: 92.19833069651281\n",
      "Cluster 16 assigned to Class 760. Cost: 91.30345350707795\n",
      "Cluster 228 assigned to Class 767. Cost: 88.84485118088885\n",
      "Cluster 288 assigned to Class 770. Cost: 89.23026661725781\n",
      "Cluster 316 assigned to Class 772. Cost: 85.31698866491406\n",
      "Cluster 290 assigned to Class 779. Cost: 77.58741666044872\n",
      "Cluster 80 assigned to Class 782. Cost: 71.22746970473042\n",
      "Cluster 355 assigned to Class 783. Cost: 79.9198293463393\n",
      "Cluster 96 assigned to Class 784. Cost: 88.24053517503923\n",
      "Cluster 205 assigned to Class 786. Cost: 98.48738893165235\n",
      "Cluster 107 assigned to Class 790. Cost: 87.49975925605952\n",
      "Cluster 22 assigned to Class 791. Cost: 97.59324372870455\n",
      "Cluster 46 assigned to Class 797. Cost: 89.53553608046708\n",
      "Cluster 59 assigned to Class 799. Cost: 99.39130046681237\n",
      "Cluster 77 assigned to Class 805. Cost: 98.92362701585841\n",
      "Cluster 245 assigned to Class 806. Cost: 87.9419612819326\n",
      "Cluster 287 assigned to Class 808. Cost: 82.60422155777208\n",
      "Cluster 312 assigned to Class 810. Cost: 83.76903881610158\n",
      "Cluster 28 assigned to Class 811. Cost: 98.78554136581889\n",
      "Cluster 15 assigned to Class 813. Cost: 87.34851656887346\n",
      "Cluster 95 assigned to Class 817. Cost: 73.63452334959061\n",
      "Cluster 378 assigned to Class 819. Cost: 79.06688778784827\n",
      "Cluster 75 assigned to Class 820. Cost: 77.22314880976924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 335 assigned to Class 821. Cost: 85.58309993214087\n",
      "Cluster 172 assigned to Class 823. Cost: 78.67928109897555\n",
      "Cluster 120 assigned to Class 825. Cost: 86.50832306712468\n",
      "Cluster 253 assigned to Class 832. Cost: 84.39559613267117\n",
      "Cluster 371 assigned to Class 834. Cost: 77.494028049695\n",
      "Cluster 204 assigned to Class 836. Cost: 92.86625600382851\n",
      "Cluster 13 assigned to Class 838. Cost: 86.84863031017761\n",
      "Cluster 97 assigned to Class 839. Cost: 92.93403245868637\n",
      "Cluster 122 assigned to Class 841. Cost: 90.46365333311196\n",
      "Cluster 110 assigned to Class 843. Cost: 90.08984721083553\n",
      "Cluster 157 assigned to Class 849. Cost: 85.73438771866394\n",
      "Cluster 43 assigned to Class 851. Cost: 91.87545499713255\n",
      "Cluster 99 assigned to Class 856. Cost: 84.57514705151775\n",
      "Cluster 221 assigned to Class 857. Cost: 86.84573281388926\n",
      "Cluster 215 assigned to Class 859. Cost: 84.29843899959208\n",
      "Cluster 165 assigned to Class 861. Cost: 92.67550147615391\n",
      "Cluster 308 assigned to Class 865. Cost: 99.21319958935577\n",
      "Cluster 389 assigned to Class 866. Cost: 97.49974900659214\n",
      "Cluster 7 assigned to Class 867. Cost: 98.62953942180124\n",
      "Cluster 398 assigned to Class 874. Cost: 73.0423495259009\n",
      "Cluster 192 assigned to Class 877. Cost: 67.279836406381\n",
      "Cluster 305 assigned to Class 878. Cost: 98.52704959057596\n",
      "Cluster 155 assigned to Class 881. Cost: 91.8265340863639\n",
      "Cluster 53 assigned to Class 889. Cost: 90.17933783072992\n",
      "Cluster 357 assigned to Class 893. Cost: 71.61501526540894\n",
      "Cluster 326 assigned to Class 894. Cost: 94.87977369334504\n",
      "Cluster 68 assigned to Class 897. Cost: 84.85883055537123\n",
      "Cluster 184 assigned to Class 898. Cost: 98.68272400172467\n",
      "Cluster 44 assigned to Class 899. Cost: 71.26276703417392\n",
      "Cluster 26 assigned to Class 901. Cost: 86.60986300901479\n",
      "Cluster 294 assigned to Class 909. Cost: 84.98356740970053\n",
      "Cluster 337 assigned to Class 913. Cost: 85.19366284133861\n",
      "Cluster 231 assigned to Class 914. Cost: 86.38670032280827\n",
      "Cluster 20 assigned to Class 915. Cost: 94.57937328423559\n",
      "Cluster 23 assigned to Class 919. Cost: 79.87732582842665\n",
      "Cluster 191 assigned to Class 921. Cost: 87.27989209053753\n",
      "Cluster 132 assigned to Class 924. Cost: 88.9304079082247\n",
      "Cluster 2 assigned to Class 925. Cost: 73.23097724558231\n",
      "Cluster 327 assigned to Class 928. Cost: 77.99368993685428\n",
      "Cluster 145 assigned to Class 932. Cost: 93.15607786724003\n",
      "Cluster 197 assigned to Class 933. Cost: 80.13396814852068\n",
      "Cluster 100 assigned to Class 938. Cost: 74.24455131285748\n",
      "Cluster 89 assigned to Class 940. Cost: 91.83703661458124\n",
      "Cluster 82 assigned to Class 944. Cost: 99.15987175122042\n",
      "Cluster 242 assigned to Class 946. Cost: 98.12084074736295\n",
      "Cluster 94 assigned to Class 949. Cost: 91.43565314761491\n",
      "Cluster 396 assigned to Class 951. Cost: 80.08852751701524\n",
      "Cluster 377 assigned to Class 956. Cost: 86.82492183285476\n",
      "Cluster 214 assigned to Class 957. Cost: 86.16272672579214\n",
      "Cluster 388 assigned to Class 958. Cost: 99.69317863619028\n",
      "Cluster 158 assigned to Class 960. Cost: 88.68545306360643\n",
      "Cluster 111 assigned to Class 961. Cost: 97.1868735456052\n",
      "Cluster 277 assigned to Class 963. Cost: 92.17546409937053\n",
      "Cluster 286 assigned to Class 964. Cost: 85.10329709952876\n",
      "Cluster 114 assigned to Class 967. Cost: 94.59068794955999\n",
      "Cluster 333 assigned to Class 968. Cost: 91.12593741001379\n",
      "Cluster 235 assigned to Class 972. Cost: 88.87432303594096\n",
      "Cluster 199 assigned to Class 973. Cost: 83.25781114816553\n",
      "Cluster 216 assigned to Class 978. Cost: 86.49556308390059\n",
      "Cluster 147 assigned to Class 982. Cost: 77.85765648782888\n",
      "Cluster 62 assigned to Class 986. Cost: 96.53657779442973\n",
      "Cluster 269 assigned to Class 988. Cost: 86.43632346140355\n",
      "Cluster 126 assigned to Class 989. Cost: 76.69969733974122\n",
      "Cluster 340 assigned to Class 991. Cost: 94.36950253656559\n",
      "Cluster 31 assigned to Class 992. Cost: 82.67624518791024\n",
      "Cluster 208 assigned to Class 993. Cost: 98.28783085360116\n",
      "Cluster 278 assigned to Class 994. Cost: 84.32809440666675\n",
      "Cluster 280 assigned to Class 995. Cost: 84.04947867339\n",
      "Cluster 363 assigned to Class 996. Cost: 97.74373120663643\n",
      "Cluster 36 assigned to Class 998. Cost: 86.63067641933438\n"
     ]
    }
   ],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "dist_list =  np.transpose(tot_dist, (1, 0))\n",
    "from tqdm import tqdm\n",
    "\n",
    "costs = dist_list\n",
    "\n",
    "num_workers = len(costs)\n",
    "num_tasks = len(costs[0])\n",
    "# Create the mip solver with the SCIP backend.\n",
    "solver = pywraplp.Solver.CreateSolver(\"SCIP\")\n",
    "\n",
    "# x[i, j] is an array of 0-1 variables, which will be 1\n",
    "# if worker i is assigned to task j.\n",
    "x = {}\n",
    "for i in range(num_workers):\n",
    "    for j in range(num_tasks):\n",
    "        x[i, j] = solver.IntVar(0, 1, \"\")\n",
    "        \n",
    "# Each worker is assigned to at most 1 task.\n",
    "for i in range(num_workers):\n",
    "    solver.Add(solver.Sum([x[i, j] for j in range(num_tasks)]) <= 1)\n",
    "\n",
    "# Each task is assigned to exactly one worker.\n",
    "for j in range(num_tasks):\n",
    "    solver.Add(solver.Sum([x[i, j] for i in range(num_workers)]) == 1)\n",
    "    \n",
    "objective_terms = []\n",
    "for i in tqdm(range(num_workers)):\n",
    "    for j in range(num_tasks):\n",
    "        objective_terms.append(costs[i][j] * x[i, j])\n",
    "solver.Minimize(solver.Sum(objective_terms))\n",
    "\n",
    "status = solver.Solve()\n",
    "\n",
    "sol_indexes = []\n",
    "if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "    print(f\"Total cost = {solver.Objective().Value()}\\n\")\n",
    "    for i in range(num_workers):\n",
    "        for j in range(num_tasks):\n",
    "            # Test if x[i,j] is 1 (with tolerance for floating point arithmetic).\n",
    "            if x[i, j].solution_value() > 0.1:\n",
    "                print(f\"Cluster {j} assigned to Class {i}.\" + f\" Cost: {costs[i][j]}\")\n",
    "                sol_indexes.append(i)\n",
    "else:\n",
    "    print(\"No solution found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e8b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sol_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c015e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes have been saved to 'cvfinal.pkl'.\n"
     ]
    }
   ],
   "source": [
    "with open('cvfinal.pkl', 'wb') as file:\n",
    "    pickle.dump(sol_indexes, file)\n",
    "\n",
    "print(\"Indexes have been saved to 'cvfinal.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118f0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6783421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.6200830936431885 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1575fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFrames:   0%|                                                                     | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunks:   0%|                                                                        | 0/97 [00:00<?, ?it/s]\u001b[A\n",
      "Processing chunks:  49%|██████████████████████████████▋                               | 48/97 [00:00<00:00, 462.78it/s]\u001b[A\n",
      "Processing chunks:  98%|████████████████████████████████████████████████████████████▋ | 95/97 [00:00<00:00, 451.70it/s]\u001b[A\n",
      "                                                                                                                       \u001b[AC:\\Users\\shaif\\anaconda3\\envs\\dasks\\lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 16.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Processing DataFrames:  25%|███████████████                                             | 1/4 [14:43<44:10, 883.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunks:   0%|                                                                       | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "Processing chunks:  96%|██████████████████████████████████████████████████████████▌  | 97/101 [00:00<00:00, 954.96it/s]\u001b[A\n",
      "                                                                                                                       \u001b[AC:\\Users\\shaif\\anaconda3\\envs\\dasks\\lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 16.33 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Processing DataFrames:  50%|█████████████████████████████▌                             | 2/4 [43:57<46:31, 1395.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunks:   0%|                                                                        | 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                                                       \u001b[AC:\\Users\\shaif\\anaconda3\\envs\\dasks\\lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 16.61 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Processing DataFrames:  75%|██████████████████████████████████████████▊              | 3/4 [1:19:11<28:43, 1723.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunks:   0%|                                                                        | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                                                       \u001b[AC:\\Users\\shaif\\anaconda3\\envs\\dasks\\lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 16.88 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Processing DataFrames: 100%|█████████████████████████████████████████████████████████| 4/4 [2:00:42<00:00, 1810.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 7249.91442322731 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from dask.distributed import Client\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "\n",
    "# Initialize Dask client\n",
    "client = Client()\n",
    "\n",
    "# Function to compute closest indexes\n",
    "def compute_closest_indexes(chunk, centers, index_set):\n",
    "    result_list = []\n",
    "    for idx, row in chunk.iterrows():\n",
    "        features = np.array(row[2:], dtype=float).reshape(1, -1)\n",
    "        distances = cdist(features, centers, metric='euclidean')\n",
    "        closest_center_idx = np.argmin(distances)\n",
    "        if closest_center_idx in index_set:\n",
    "            result_list.append((closest_center_idx, row[1]))\n",
    "    return result_list\n",
    "\n",
    "# Function to process elements of all DataFrames\n",
    "def process_elements(dfs, centers, index_set, max_len_per_index=500):\n",
    "    result_list = []\n",
    "    index_count = {idx: 0 for idx in index_set}\n",
    "    delayed_results = []\n",
    "\n",
    "    for df in tqdm(dfs, desc=\"Processing DataFrames\"):\n",
    "        print(len(result_list))\n",
    "        # Iterate over chunks of the DataFrame\n",
    "        for chunk in tqdm(df.to_delayed(), desc=\"Processing chunks\", leave=False):\n",
    "            # Process each chunk in parallel\n",
    "            delayed_result = dask.delayed(compute_closest_indexes)(chunk, centers, index_set)\n",
    "            delayed_results.append(delayed_result)\n",
    "\n",
    "        # Compute and collect results\n",
    "        if delayed_results:\n",
    "            chunk_results = dask.compute(*delayed_results)\n",
    "            for chunk_result in chunk_results:\n",
    "                for closest_center_idx, row_1 in chunk_result:\n",
    "                    if index_count[closest_center_idx] < max_len_per_index:\n",
    "                        result_list.append(row_1)\n",
    "                        index_count[closest_center_idx] += 1\n",
    "                        if index_count[closest_center_idx] >= max_len_per_index:\n",
    "                            index_set.remove(closest_center_idx)\n",
    "                        if all(count >= max_len_per_index for count in index_count.values()):\n",
    "                            return result_list\n",
    "\n",
    "    return result_list\n",
    "\n",
    "# Measure the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the pickle files\n",
    "with open(\"F:/ML_notebooks/cvfinal.pkl\", 'rb') as file:\n",
    "    index = pickle.load(file)\n",
    "with open(\"F:/ML_notebooks/cluster_centers.pkl\", 'rb') as file:\n",
    "    centers = pickle.load(file)\n",
    "\n",
    "# Convert index to a set for faster lookup\n",
    "index_set = set(index)\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "file_paths = [\n",
    "    \"G:/image_features.csv\",\n",
    "    \"G:/image_features1.csv\",\n",
    "    \"G:/image_features2.csv\",\n",
    "    \"G:/image_features3.csv\"\n",
    "]\n",
    "\n",
    "# Load the CSV files into Dask DataFrames\n",
    "dfs = [dd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Call the function to process elements of each DataFrame\n",
    "result_list = process_elements(dfs, centers, index_set)\n",
    "\n",
    "# Save the result_list in a pickle file\n",
    "with open(\"cifar_images.pkl\", \"wb\") as file:\n",
    "    pickle.dump(result_list, file)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the execution time\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90056f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d18729",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c9cd4-a50e-4b6c-b298-a8d179d3c77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c450d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f43ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
