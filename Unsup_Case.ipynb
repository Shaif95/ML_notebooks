{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c816a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [10:01<00:00, 31.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2872, 32, 32, 3)\n",
      "Y_train shape: (2872,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"G:\\datasets\\Underwater_Image\\WHOI\\archive\\dataset_pm\\training\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b609b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602c030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFrames: 100%|████████████████████████████████████████████████████████████| 4/4 [17:37<00:00, 264.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "file_paths = [\n",
    "    \"G:/image_features.csv\",\n",
    "    \"G:/image_features1.csv\",\n",
    "    \"G:/image_features2.csv\",\n",
    "    \"G:/image_features3.csv\"\n",
    "]\n",
    "\n",
    "# Load the CSV files into Dask DataFrames\n",
    "dfs = [dd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Function to get 25,000 random indexes and retrieve the full rows\n",
    "def get_random_rows(df, n=25000):\n",
    "    # Convert the Dask DataFrame to a Pandas DataFrame\n",
    "    pandas_df = df.compute()\n",
    "    \n",
    "    # Get the total number of rows in the DataFrame\n",
    "    total_rows = len(pandas_df)\n",
    "    \n",
    "    # Generate 25,000 random indexes\n",
    "    random_indexes = np.random.choice(total_rows, n, replace=False)\n",
    "    \n",
    "    # Retrieve the full rows for these random indexes\n",
    "    random_rows = pandas_df.iloc[random_indexes].values.tolist()\n",
    "    \n",
    "    return random_rows\n",
    "\n",
    "# Initialize an empty list to store all rows\n",
    "all_random_rows = []\n",
    "\n",
    "# Get the rows from each DataFrame\n",
    "for df in tqdm(dfs, desc=\"Processing DataFrames\"):\n",
    "    rows = get_random_rows(df)\n",
    "    all_random_rows.extend(rows)\n",
    "\n",
    "# Print the total number of rows collected\n",
    "print(len(all_random_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cfa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59381467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the first two items from each element in all_random_rows\n",
    "new_all_random_rows = [row[2:] for row in all_random_rows]\n",
    "np.shape(new_all_random_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9caf10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the cluster centers: (1000, 2048)\n",
      "Cluster centers have been saved to 'cluster_centers.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Assuming new_all_random_rows has been populated as described\n",
    "\n",
    "# Convert new_all_random_rows to a NumPy array\n",
    "data = np.array(new_all_random_rows)\n",
    "\n",
    "batch_size = 10000\n",
    "max_iter = 100\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = MiniBatchKMeans(n_clusters=1000, batch_size=batch_size, max_iter=max_iter, random_state=42)\n",
    "kmeans.fit(data)\n",
    "\n",
    "# Store the cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Print the shape of the cluster centers\n",
    "print(f\"Shape of the cluster centers: {centers.shape}\")\n",
    "\n",
    "# Save the cluster centers to a pickle file\n",
    "with open('cluster_centers.pkl', 'wb') as file:\n",
    "    pickle.dump(centers, file)\n",
    "\n",
    "print(\"Cluster centers have been saved to 'cluster_centers.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cd015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bba5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92419d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train\n",
    "y_train = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306f205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10d8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "import glob\n",
    "\n",
    "target_size = (32, 32)  # Change the values as per your requirement\n",
    "# Load the pre-trained ResNet50 model with modified input shape\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(target_size[0], target_size[1], 3))\n",
    "\n",
    "ft = model.predict(np.array(x_train).astype(\"float32\"))\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "n_clusters = 400\n",
    "batch_size = 100\n",
    "max_iter = 100\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, max_iter=max_iter)\n",
    "kmeans.fit(ft)\n",
    "# Retrieve the cluster centers\n",
    "ct = kmeans.cluster_centers_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b9d0753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4179a7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [00:48<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the distance array: (400, 1000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize a list to store the distances\n",
    "tot_dist = []\n",
    "\n",
    "# Calculate L2 distances\n",
    "for i in tqdm(range(len(ct))):\n",
    "    distances = []\n",
    "    for j in range(len(centers)):\n",
    "        distance = np.linalg.norm(ct[i] - centers[j])\n",
    "        distances.append(distance)\n",
    "    tot_dist.append(distances)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "tot_dist = np.array(tot_dist)\n",
    "\n",
    "# Print the shape of the resulting array\n",
    "print(f\"Shape of the distance array: {tot_dist.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3ca2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01589f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:36<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost = 34499.063236818794\n",
      "\n",
      "Cluster 207 assigned to Class 0. Cost: 76.2538709826466\n",
      "Cluster 89 assigned to Class 2. Cost: 68.37838189447001\n",
      "Cluster 138 assigned to Class 3. Cost: 108.39003251129522\n",
      "Cluster 383 assigned to Class 4. Cost: 85.73153563640906\n",
      "Cluster 380 assigned to Class 6. Cost: 64.08120703551813\n",
      "Cluster 353 assigned to Class 7. Cost: 79.65443986155162\n",
      "Cluster 186 assigned to Class 8. Cost: 106.65387436740725\n",
      "Cluster 341 assigned to Class 9. Cost: 120.07183631574954\n",
      "Cluster 264 assigned to Class 10. Cost: 61.80326187536922\n",
      "Cluster 181 assigned to Class 11. Cost: 83.46243017738098\n",
      "Cluster 294 assigned to Class 14. Cost: 125.25119369248732\n",
      "Cluster 224 assigned to Class 15. Cost: 74.39360031401229\n",
      "Cluster 372 assigned to Class 18. Cost: 72.00200103674577\n",
      "Cluster 266 assigned to Class 20. Cost: 68.8813390336442\n",
      "Cluster 392 assigned to Class 22. Cost: 73.77314063347103\n",
      "Cluster 370 assigned to Class 25. Cost: 71.09834486335471\n",
      "Cluster 193 assigned to Class 26. Cost: 130.39033768150253\n",
      "Cluster 140 assigned to Class 28. Cost: 89.13620755123628\n",
      "Cluster 219 assigned to Class 30. Cost: 76.7661692493852\n",
      "Cluster 319 assigned to Class 31. Cost: 86.43672572309225\n",
      "Cluster 276 assigned to Class 32. Cost: 108.26843666942446\n",
      "Cluster 289 assigned to Class 34. Cost: 95.8555992673417\n",
      "Cluster 336 assigned to Class 35. Cost: 64.44179358159823\n",
      "Cluster 324 assigned to Class 36. Cost: 73.08869548961756\n",
      "Cluster 338 assigned to Class 40. Cost: 75.72171931090018\n",
      "Cluster 398 assigned to Class 43. Cost: 68.48191665503663\n",
      "Cluster 315 assigned to Class 47. Cost: 105.70955583396821\n",
      "Cluster 211 assigned to Class 48. Cost: 70.6503260698077\n",
      "Cluster 109 assigned to Class 51. Cost: 78.79085116326155\n",
      "Cluster 189 assigned to Class 53. Cost: 90.22885535025377\n",
      "Cluster 272 assigned to Class 56. Cost: 126.93083593278685\n",
      "Cluster 4 assigned to Class 59. Cost: 100.57886378258793\n",
      "Cluster 161 assigned to Class 63. Cost: 113.77051200750513\n",
      "Cluster 64 assigned to Class 64. Cost: 85.39134699378613\n",
      "Cluster 152 assigned to Class 66. Cost: 120.1371928989416\n",
      "Cluster 221 assigned to Class 68. Cost: 80.4169310140846\n",
      "Cluster 98 assigned to Class 69. Cost: 64.29792778409939\n",
      "Cluster 225 assigned to Class 70. Cost: 70.25714419594159\n",
      "Cluster 83 assigned to Class 71. Cost: 88.45536927967873\n",
      "Cluster 23 assigned to Class 72. Cost: 64.61345515607603\n",
      "Cluster 187 assigned to Class 73. Cost: 126.16800572083113\n",
      "Cluster 11 assigned to Class 76. Cost: 55.728909328006004\n",
      "Cluster 399 assigned to Class 78. Cost: 85.9362711661285\n",
      "Cluster 78 assigned to Class 79. Cost: 76.42214301370403\n",
      "Cluster 111 assigned to Class 80. Cost: 80.89843033246291\n",
      "Cluster 13 assigned to Class 83. Cost: 103.57508012158225\n",
      "Cluster 244 assigned to Class 84. Cost: 88.59892225273732\n",
      "Cluster 254 assigned to Class 92. Cost: 74.62535925651572\n",
      "Cluster 123 assigned to Class 95. Cost: 113.5923938291547\n",
      "Cluster 241 assigned to Class 96. Cost: 107.37841308350082\n",
      "Cluster 358 assigned to Class 97. Cost: 90.67642678513776\n",
      "Cluster 240 assigned to Class 98. Cost: 64.10699507588521\n",
      "Cluster 57 assigned to Class 102. Cost: 82.10019374475256\n",
      "Cluster 246 assigned to Class 107. Cost: 70.50660827480068\n",
      "Cluster 100 assigned to Class 108. Cost: 83.22851359055636\n",
      "Cluster 124 assigned to Class 114. Cost: 79.2551426061297\n",
      "Cluster 125 assigned to Class 116. Cost: 99.93693431893317\n",
      "Cluster 155 assigned to Class 117. Cost: 90.4582375402319\n",
      "Cluster 297 assigned to Class 119. Cost: 72.12026658070424\n",
      "Cluster 9 assigned to Class 120. Cost: 82.23883811942837\n",
      "Cluster 351 assigned to Class 123. Cost: 137.8382786232004\n",
      "Cluster 234 assigned to Class 126. Cost: 59.626333186473396\n",
      "Cluster 212 assigned to Class 127. Cost: 89.99303894931553\n",
      "Cluster 88 assigned to Class 128. Cost: 126.58707569876714\n",
      "Cluster 121 assigned to Class 129. Cost: 67.86412549725829\n",
      "Cluster 60 assigned to Class 130. Cost: 78.68420423640345\n",
      "Cluster 361 assigned to Class 139. Cost: 58.94032410923841\n",
      "Cluster 296 assigned to Class 140. Cost: 77.08472822880638\n",
      "Cluster 148 assigned to Class 142. Cost: 81.47748296947516\n",
      "Cluster 82 assigned to Class 145. Cost: 69.27784685917551\n",
      "Cluster 360 assigned to Class 146. Cost: 61.85317067240914\n",
      "Cluster 191 assigned to Class 148. Cost: 84.80842200071781\n",
      "Cluster 101 assigned to Class 152. Cost: 76.56320470998514\n",
      "Cluster 134 assigned to Class 154. Cost: 57.44711471051306\n",
      "Cluster 245 assigned to Class 155. Cost: 71.78897897655403\n",
      "Cluster 28 assigned to Class 156. Cost: 67.12772269533227\n",
      "Cluster 291 assigned to Class 157. Cost: 61.39342615838435\n",
      "Cluster 227 assigned to Class 160. Cost: 68.81546316993284\n",
      "Cluster 209 assigned to Class 161. Cost: 95.4688287465733\n",
      "Cluster 26 assigned to Class 163. Cost: 130.26054655147163\n",
      "Cluster 110 assigned to Class 164. Cost: 78.29125124820254\n",
      "Cluster 274 assigned to Class 170. Cost: 59.82520197728561\n",
      "Cluster 198 assigned to Class 175. Cost: 102.21184304379742\n",
      "Cluster 347 assigned to Class 179. Cost: 74.91742824411622\n",
      "Cluster 72 assigned to Class 181. Cost: 107.13294122211296\n",
      "Cluster 176 assigned to Class 183. Cost: 72.94955192543009\n",
      "Cluster 377 assigned to Class 189. Cost: 76.11545235001782\n",
      "Cluster 185 assigned to Class 192. Cost: 90.22821025338513\n",
      "Cluster 239 assigned to Class 194. Cost: 79.4737007718654\n",
      "Cluster 42 assigned to Class 195. Cost: 90.46572430024067\n",
      "Cluster 256 assigned to Class 197. Cost: 89.93163019089594\n",
      "Cluster 379 assigned to Class 200. Cost: 96.9961716884451\n",
      "Cluster 236 assigned to Class 201. Cost: 96.58097163467706\n",
      "Cluster 166 assigned to Class 202. Cost: 50.36483282933196\n",
      "Cluster 112 assigned to Class 203. Cost: 85.00763872519411\n",
      "Cluster 25 assigned to Class 206. Cost: 59.94643711173775\n",
      "Cluster 38 assigned to Class 214. Cost: 61.5237995702083\n",
      "Cluster 243 assigned to Class 219. Cost: 83.33505008700392\n",
      "Cluster 19 assigned to Class 220. Cost: 108.6814743902438\n",
      "Cluster 203 assigned to Class 223. Cost: 73.65501661874465\n",
      "Cluster 261 assigned to Class 224. Cost: 95.91305671059143\n",
      "Cluster 46 assigned to Class 225. Cost: 97.82212834285113\n",
      "Cluster 107 assigned to Class 229. Cost: 73.12261107799445\n",
      "Cluster 280 assigned to Class 232. Cost: 84.27419556702507\n",
      "Cluster 127 assigned to Class 233. Cost: 104.13003280478809\n",
      "Cluster 200 assigned to Class 234. Cost: 86.90505998222213\n",
      "Cluster 73 assigned to Class 236. Cost: 81.3352566492566\n",
      "Cluster 149 assigned to Class 243. Cost: 88.29243654122081\n",
      "Cluster 368 assigned to Class 248. Cost: 45.02021435678833\n",
      "Cluster 295 assigned to Class 249. Cost: 76.82232557608556\n",
      "Cluster 378 assigned to Class 250. Cost: 80.09291558327337\n",
      "Cluster 228 assigned to Class 251. Cost: 54.27584613182911\n",
      "Cluster 278 assigned to Class 255. Cost: 82.37569673828993\n",
      "Cluster 290 assigned to Class 256. Cost: 91.67624743528852\n",
      "Cluster 395 assigned to Class 257. Cost: 91.93592516180043\n",
      "Cluster 116 assigned to Class 260. Cost: 101.87156694570503\n",
      "Cluster 279 assigned to Class 261. Cost: 104.61307001728628\n",
      "Cluster 90 assigned to Class 264. Cost: 71.68965248873207\n",
      "Cluster 326 assigned to Class 266. Cost: 73.1942990166795\n",
      "Cluster 97 assigned to Class 272. Cost: 61.68982172510368\n",
      "Cluster 2 assigned to Class 275. Cost: 105.30626847002267\n",
      "Cluster 77 assigned to Class 278. Cost: 132.38353560925535\n",
      "Cluster 270 assigned to Class 279. Cost: 79.82832091678836\n",
      "Cluster 47 assigned to Class 281. Cost: 93.15048884964824\n",
      "Cluster 37 assigned to Class 282. Cost: 82.75177758328599\n",
      "Cluster 277 assigned to Class 283. Cost: 80.53151619270616\n",
      "Cluster 325 assigned to Class 284. Cost: 113.45305025494045\n",
      "Cluster 39 assigned to Class 287. Cost: 72.57221960507903\n",
      "Cluster 332 assigned to Class 289. Cost: 98.70024200073681\n",
      "Cluster 105 assigned to Class 293. Cost: 101.22566968744093\n",
      "Cluster 394 assigned to Class 294. Cost: 71.43175676755965\n",
      "Cluster 312 assigned to Class 299. Cost: 61.90371639920133\n",
      "Cluster 229 assigned to Class 300. Cost: 84.98153592840588\n",
      "Cluster 374 assigned to Class 301. Cost: 100.2304743605655\n",
      "Cluster 275 assigned to Class 306. Cost: 106.69509553273465\n",
      "Cluster 385 assigned to Class 308. Cost: 104.53772318736789\n",
      "Cluster 49 assigned to Class 314. Cost: 81.7042856170263\n",
      "Cluster 41 assigned to Class 317. Cost: 68.10212977649923\n",
      "Cluster 260 assigned to Class 319. Cost: 79.72970670670905\n",
      "Cluster 349 assigned to Class 320. Cost: 91.1152488847532\n",
      "Cluster 202 assigned to Class 322. Cost: 68.86301221497142\n",
      "Cluster 27 assigned to Class 323. Cost: 73.30956383919705\n",
      "Cluster 106 assigned to Class 330. Cost: 68.42490357388827\n",
      "Cluster 18 assigned to Class 332. Cost: 116.8256881242531\n",
      "Cluster 390 assigned to Class 333. Cost: 130.68164108146053\n",
      "Cluster 79 assigned to Class 336. Cost: 120.75069896615426\n",
      "Cluster 248 assigned to Class 338. Cost: 50.22202604306483\n",
      "Cluster 314 assigned to Class 341. Cost: 76.21525014146079\n",
      "Cluster 150 assigned to Class 342. Cost: 47.52722323542154\n",
      "Cluster 217 assigned to Class 347. Cost: 75.05544107079294\n",
      "Cluster 237 assigned to Class 348. Cost: 80.39734461800003\n",
      "Cluster 306 assigned to Class 351. Cost: 74.70489088527036\n",
      "Cluster 192 assigned to Class 354. Cost: 89.98079267573549\n",
      "Cluster 223 assigned to Class 360. Cost: 87.25753141860865\n",
      "Cluster 375 assigned to Class 363. Cost: 86.3524849769842\n",
      "Cluster 343 assigned to Class 364. Cost: 43.00168693998531\n",
      "Cluster 396 assigned to Class 366. Cost: 96.30068080171836\n",
      "Cluster 308 assigned to Class 368. Cost: 96.5694990417191\n",
      "Cluster 300 assigned to Class 373. Cost: 83.5092731253672\n",
      "Cluster 40 assigned to Class 376. Cost: 89.2941208818671\n",
      "Cluster 164 assigned to Class 389. Cost: 107.73114758953416\n",
      "Cluster 29 assigned to Class 392. Cost: 72.61456012295712\n",
      "Cluster 352 assigned to Class 399. Cost: 84.03404407912558\n",
      "Cluster 273 assigned to Class 400. Cost: 78.41636837543676\n",
      "Cluster 174 assigned to Class 402. Cost: 74.87497773103031\n",
      "Cluster 389 assigned to Class 403. Cost: 89.68621930311869\n",
      "Cluster 67 assigned to Class 405. Cost: 78.9395437423894\n",
      "Cluster 56 assigned to Class 411. Cost: 72.94273370627464\n",
      "Cluster 269 assigned to Class 415. Cost: 72.30348152222946\n",
      "Cluster 128 assigned to Class 417. Cost: 76.1865487324416\n",
      "Cluster 104 assigned to Class 424. Cost: 69.3856392083594\n",
      "Cluster 299 assigned to Class 425. Cost: 86.35526968560562\n",
      "Cluster 271 assigned to Class 427. Cost: 78.21742214004485\n",
      "Cluster 388 assigned to Class 428. Cost: 114.36125058771457\n",
      "Cluster 160 assigned to Class 430. Cost: 117.29659002130589\n",
      "Cluster 172 assigned to Class 433. Cost: 74.88057987422225\n",
      "Cluster 340 assigned to Class 435. Cost: 89.70601642173547\n",
      "Cluster 180 assigned to Class 436. Cost: 64.88951490092249\n",
      "Cluster 103 assigned to Class 437. Cost: 122.78234029228604\n",
      "Cluster 328 assigned to Class 438. Cost: 88.09993369933377\n",
      "Cluster 354 assigned to Class 440. Cost: 142.9093881448749\n",
      "Cluster 52 assigned to Class 441. Cost: 72.41508812643268\n",
      "Cluster 305 assigned to Class 442. Cost: 94.8603206440807\n",
      "Cluster 307 assigned to Class 443. Cost: 95.99095077616631\n",
      "Cluster 158 assigned to Class 446. Cost: 84.70589311165715\n",
      "Cluster 76 assigned to Class 447. Cost: 92.39401209557737\n",
      "Cluster 168 assigned to Class 451. Cost: 61.46197078828086\n",
      "Cluster 216 assigned to Class 453. Cost: 91.41380346515702\n",
      "Cluster 5 assigned to Class 454. Cost: 107.324993364539\n",
      "Cluster 163 assigned to Class 455. Cost: 93.83093149350954\n",
      "Cluster 184 assigned to Class 457. Cost: 138.77491893320888\n",
      "Cluster 316 assigned to Class 467. Cost: 77.1917875529623\n",
      "Cluster 3 assigned to Class 468. Cost: 81.17661522568525\n",
      "Cluster 329 assigned to Class 470. Cost: 92.00854643975504\n",
      "Cluster 257 assigned to Class 473. Cost: 115.71136108080903\n",
      "Cluster 14 assigned to Class 474. Cost: 136.84662291471653\n",
      "Cluster 81 assigned to Class 475. Cost: 68.9559332045125\n",
      "Cluster 369 assigned to Class 476. Cost: 100.8216895118512\n",
      "Cluster 323 assigned to Class 480. Cost: 56.835462635209744\n",
      "Cluster 284 assigned to Class 481. Cost: 76.60792608772736\n",
      "Cluster 259 assigned to Class 484. Cost: 82.69421275034045\n",
      "Cluster 195 assigned to Class 485. Cost: 64.19520672358662\n",
      "Cluster 335 assigned to Class 490. Cost: 84.03038388977619\n",
      "Cluster 356 assigned to Class 491. Cost: 86.87506691782485\n",
      "Cluster 135 assigned to Class 492. Cost: 118.81134380586327\n",
      "Cluster 201 assigned to Class 493. Cost: 59.978038245184315\n",
      "Cluster 249 assigned to Class 497. Cost: 91.59646192442905\n",
      "Cluster 61 assigned to Class 498. Cost: 35.68165076427573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 310 assigned to Class 501. Cost: 71.01298105259106\n",
      "Cluster 59 assigned to Class 503. Cost: 63.803379247241146\n",
      "Cluster 359 assigned to Class 504. Cost: 98.88817638845299\n",
      "Cluster 204 assigned to Class 506. Cost: 75.90018674293437\n",
      "Cluster 170 assigned to Class 509. Cost: 52.323697294270175\n",
      "Cluster 43 assigned to Class 515. Cost: 89.41555829996861\n",
      "Cluster 327 assigned to Class 516. Cost: 129.06720997346855\n",
      "Cluster 339 assigned to Class 517. Cost: 108.87850240386669\n",
      "Cluster 363 assigned to Class 518. Cost: 71.19549037647978\n",
      "Cluster 303 assigned to Class 520. Cost: 83.84148186023478\n",
      "Cluster 142 assigned to Class 522. Cost: 129.26309555049846\n",
      "Cluster 253 assigned to Class 523. Cost: 127.73637570331523\n",
      "Cluster 74 assigned to Class 526. Cost: 63.547483303057696\n",
      "Cluster 220 assigned to Class 529. Cost: 69.89537883323419\n",
      "Cluster 34 assigned to Class 533. Cost: 111.16264165354632\n",
      "Cluster 122 assigned to Class 535. Cost: 81.6892184341848\n",
      "Cluster 337 assigned to Class 536. Cost: 81.37012745573793\n",
      "Cluster 113 assigned to Class 539. Cost: 109.59424801940385\n",
      "Cluster 96 assigned to Class 546. Cost: 147.49891123233283\n",
      "Cluster 130 assigned to Class 551. Cost: 130.17960489636235\n",
      "Cluster 35 assigned to Class 552. Cost: 72.24052476610086\n",
      "Cluster 196 assigned to Class 553. Cost: 87.4739781887843\n",
      "Cluster 145 assigned to Class 556. Cost: 112.95934234817251\n",
      "Cluster 8 assigned to Class 557. Cost: 99.10258751368212\n",
      "Cluster 117 assigned to Class 558. Cost: 66.61143351915297\n",
      "Cluster 171 assigned to Class 559. Cost: 117.59506442548066\n",
      "Cluster 173 assigned to Class 560. Cost: 86.92565221250685\n",
      "Cluster 66 assigned to Class 564. Cost: 145.8407222021814\n",
      "Cluster 94 assigned to Class 566. Cost: 78.42093717457317\n",
      "Cluster 268 assigned to Class 571. Cost: 64.45260719823898\n",
      "Cluster 147 assigned to Class 572. Cost: 70.39141933667575\n",
      "Cluster 75 assigned to Class 575. Cost: 83.05309495706267\n",
      "Cluster 45 assigned to Class 578. Cost: 60.43210690523044\n",
      "Cluster 391 assigned to Class 579. Cost: 79.27229992175201\n",
      "Cluster 21 assigned to Class 580. Cost: 65.4348657514536\n",
      "Cluster 16 assigned to Class 581. Cost: 91.22695616635042\n",
      "Cluster 373 assigned to Class 584. Cost: 97.06072255885263\n",
      "Cluster 251 assigned to Class 585. Cost: 63.46673952001911\n",
      "Cluster 58 assigned to Class 586. Cost: 107.02871483157766\n",
      "Cluster 133 assigned to Class 587. Cost: 60.799444318240795\n",
      "Cluster 208 assigned to Class 588. Cost: 84.57539207105378\n",
      "Cluster 199 assigned to Class 589. Cost: 113.22459275707708\n",
      "Cluster 129 assigned to Class 591. Cost: 56.896734142575276\n",
      "Cluster 258 assigned to Class 593. Cost: 77.98512252482791\n",
      "Cluster 393 assigned to Class 595. Cost: 71.17942711811038\n",
      "Cluster 334 assigned to Class 596. Cost: 105.01996618166064\n",
      "Cluster 281 assigned to Class 598. Cost: 84.05384443225886\n",
      "Cluster 7 assigned to Class 599. Cost: 92.98482973640205\n",
      "Cluster 321 assigned to Class 603. Cost: 109.80416169880215\n",
      "Cluster 157 assigned to Class 607. Cost: 127.25317140251278\n",
      "Cluster 53 assigned to Class 610. Cost: 111.04310173817562\n",
      "Cluster 114 assigned to Class 612. Cost: 83.42891168403138\n",
      "Cluster 190 assigned to Class 617. Cost: 66.60897838684456\n",
      "Cluster 218 assigned to Class 618. Cost: 74.53757488697639\n",
      "Cluster 215 assigned to Class 622. Cost: 84.77948216271655\n",
      "Cluster 115 assigned to Class 629. Cost: 96.02457656770396\n",
      "Cluster 355 assigned to Class 637. Cost: 77.11691678249828\n",
      "Cluster 247 assigned to Class 639. Cost: 58.7395003519418\n",
      "Cluster 153 assigned to Class 640. Cost: 82.10196990625795\n",
      "Cluster 141 assigned to Class 645. Cost: 43.48441470959045\n",
      "Cluster 177 assigned to Class 646. Cost: 46.91829588997514\n",
      "Cluster 24 assigned to Class 648. Cost: 77.46508991113451\n",
      "Cluster 146 assigned to Class 653. Cost: 83.57059942277878\n",
      "Cluster 50 assigned to Class 654. Cost: 113.54651546648014\n",
      "Cluster 15 assigned to Class 662. Cost: 130.4089978426102\n",
      "Cluster 231 assigned to Class 663. Cost: 68.74755004725631\n",
      "Cluster 0 assigned to Class 665. Cost: 74.13640720029078\n",
      "Cluster 10 assigned to Class 668. Cost: 96.9763591327326\n",
      "Cluster 85 assigned to Class 670. Cost: 131.10548946739954\n",
      "Cluster 330 assigned to Class 672. Cost: 103.90552696158117\n",
      "Cluster 36 assigned to Class 674. Cost: 121.43736617534859\n",
      "Cluster 65 assigned to Class 675. Cost: 91.06386387435697\n",
      "Cluster 345 assigned to Class 679. Cost: 82.69398989647362\n",
      "Cluster 55 assigned to Class 681. Cost: 57.25049228734024\n",
      "Cluster 301 assigned to Class 686. Cost: 86.5110132068837\n",
      "Cluster 311 assigned to Class 689. Cost: 53.87481323130829\n",
      "Cluster 48 assigned to Class 691. Cost: 101.8680231112127\n",
      "Cluster 33 assigned to Class 692. Cost: 118.54107654018675\n",
      "Cluster 182 assigned to Class 694. Cost: 77.98719445153861\n",
      "Cluster 309 assigned to Class 698. Cost: 80.85782438562705\n",
      "Cluster 317 assigned to Class 700. Cost: 48.84466460837641\n",
      "Cluster 63 assigned to Class 706. Cost: 74.12703027022269\n",
      "Cluster 93 assigned to Class 707. Cost: 93.27890693384016\n",
      "Cluster 71 assigned to Class 709. Cost: 119.25785012369779\n",
      "Cluster 387 assigned to Class 713. Cost: 112.46363414434825\n",
      "Cluster 30 assigned to Class 714. Cost: 99.29776198713955\n",
      "Cluster 397 assigned to Class 718. Cost: 138.04472596148346\n",
      "Cluster 137 assigned to Class 723. Cost: 95.89152131730793\n",
      "Cluster 175 assigned to Class 725. Cost: 83.53009198500523\n",
      "Cluster 210 assigned to Class 736. Cost: 87.0902150002916\n",
      "Cluster 350 assigned to Class 737. Cost: 103.13797848450506\n",
      "Cluster 320 assigned to Class 738. Cost: 72.6824393596841\n",
      "Cluster 44 assigned to Class 740. Cost: 76.23340947865029\n",
      "Cluster 206 assigned to Class 745. Cost: 75.29896934853187\n",
      "Cluster 162 assigned to Class 746. Cost: 50.16223174127832\n",
      "Cluster 250 assigned to Class 748. Cost: 38.35579461191933\n",
      "Cluster 222 assigned to Class 749. Cost: 73.78849567309888\n",
      "Cluster 91 assigned to Class 751. Cost: 59.73855935661743\n",
      "Cluster 108 assigned to Class 753. Cost: 139.87478652883362\n",
      "Cluster 286 assigned to Class 754. Cost: 84.46996552016773\n",
      "Cluster 188 assigned to Class 756. Cost: 116.6258583608337\n",
      "Cluster 362 assigned to Class 757. Cost: 98.37708343940791\n",
      "Cluster 364 assigned to Class 759. Cost: 80.41021350019996\n",
      "Cluster 357 assigned to Class 763. Cost: 72.82533081436976\n",
      "Cluster 156 assigned to Class 764. Cost: 74.65984084584525\n",
      "Cluster 213 assigned to Class 765. Cost: 111.40626990376359\n",
      "Cluster 255 assigned to Class 768. Cost: 62.47448786425232\n",
      "Cluster 386 assigned to Class 771. Cost: 70.87038335241078\n",
      "Cluster 382 assigned to Class 777. Cost: 79.17743770708061\n",
      "Cluster 167 assigned to Class 778. Cost: 90.962628598641\n",
      "Cluster 87 assigned to Class 785. Cost: 70.44034308434993\n",
      "Cluster 313 assigned to Class 788. Cost: 98.36901739450941\n",
      "Cluster 285 assigned to Class 789. Cost: 86.98169401956783\n",
      "Cluster 151 assigned to Class 793. Cost: 71.68760458221522\n",
      "Cluster 267 assigned to Class 794. Cost: 75.42856173674127\n",
      "Cluster 322 assigned to Class 797. Cost: 58.28518681374563\n",
      "Cluster 139 assigned to Class 798. Cost: 53.30507327265523\n",
      "Cluster 165 assigned to Class 799. Cost: 70.88690775516797\n",
      "Cluster 143 assigned to Class 802. Cost: 115.97654909756551\n",
      "Cluster 298 assigned to Class 806. Cost: 55.76045144833657\n",
      "Cluster 333 assigned to Class 809. Cost: 123.03840651083951\n",
      "Cluster 86 assigned to Class 811. Cost: 66.17911519469207\n",
      "Cluster 54 assigned to Class 813. Cost: 83.80686435712933\n",
      "Cluster 331 assigned to Class 815. Cost: 78.12552547557235\n",
      "Cluster 126 assigned to Class 819. Cost: 75.67462313357436\n",
      "Cluster 183 assigned to Class 822. Cost: 113.20142324223885\n",
      "Cluster 99 assigned to Class 824. Cost: 76.89062941905145\n",
      "Cluster 132 assigned to Class 825. Cost: 126.5109306835768\n",
      "Cluster 304 assigned to Class 828. Cost: 31.47024966241476\n",
      "Cluster 342 assigned to Class 831. Cost: 80.41958319645121\n",
      "Cluster 102 assigned to Class 833. Cost: 80.63257882794663\n",
      "Cluster 12 assigned to Class 837. Cost: 108.37043694852872\n",
      "Cluster 263 assigned to Class 839. Cost: 75.90550982792313\n",
      "Cluster 205 assigned to Class 840. Cost: 69.48329432538576\n",
      "Cluster 118 assigned to Class 845. Cost: 59.79142395457023\n",
      "Cluster 381 assigned to Class 847. Cost: 79.41865617938069\n",
      "Cluster 51 assigned to Class 849. Cost: 73.72763735134701\n",
      "Cluster 95 assigned to Class 851. Cost: 107.10690225733644\n",
      "Cluster 119 assigned to Class 853. Cost: 68.7871732999784\n",
      "Cluster 226 assigned to Class 856. Cost: 61.53261124164629\n",
      "Cluster 69 assigned to Class 859. Cost: 74.93661495233617\n",
      "Cluster 136 assigned to Class 862. Cost: 92.96602692285231\n",
      "Cluster 288 assigned to Class 864. Cost: 89.92046499373885\n",
      "Cluster 31 assigned to Class 866. Cost: 85.05334601968411\n",
      "Cluster 344 assigned to Class 867. Cost: 70.23314661213351\n",
      "Cluster 194 assigned to Class 869. Cost: 100.63729001138202\n",
      "Cluster 287 assigned to Class 872. Cost: 72.33094076300296\n",
      "Cluster 230 assigned to Class 873. Cost: 64.26241851318174\n",
      "Cluster 214 assigned to Class 874. Cost: 128.20719890420546\n",
      "Cluster 62 assigned to Class 875. Cost: 86.3191561709561\n",
      "Cluster 318 assigned to Class 881. Cost: 96.94323728980126\n",
      "Cluster 233 assigned to Class 882. Cost: 79.5759719175841\n",
      "Cluster 169 assigned to Class 888. Cost: 82.95450223925431\n",
      "Cluster 20 assigned to Class 890. Cost: 61.08112896735555\n",
      "Cluster 262 assigned to Class 893. Cost: 66.11666611791365\n",
      "Cluster 371 assigned to Class 899. Cost: 92.14181385028428\n",
      "Cluster 6 assigned to Class 902. Cost: 146.84061165397475\n",
      "Cluster 84 assigned to Class 905. Cost: 60.449207389876975\n",
      "Cluster 92 assigned to Class 910. Cost: 95.5005430248132\n",
      "Cluster 197 assigned to Class 911. Cost: 85.78539035680186\n",
      "Cluster 144 assigned to Class 918. Cost: 94.53279985260069\n",
      "Cluster 376 assigned to Class 919. Cost: 81.18352768713608\n",
      "Cluster 293 assigned to Class 920. Cost: 94.50573191679602\n",
      "Cluster 302 assigned to Class 923. Cost: 63.42781844449981\n",
      "Cluster 348 assigned to Class 926. Cost: 75.34832987003891\n",
      "Cluster 154 assigned to Class 931. Cost: 123.08390471645778\n",
      "Cluster 265 assigned to Class 936. Cost: 104.27188153550946\n",
      "Cluster 366 assigned to Class 938. Cost: 67.08561993894224\n",
      "Cluster 283 assigned to Class 944. Cost: 97.7091694407468\n",
      "Cluster 384 assigned to Class 950. Cost: 60.97706331601987\n",
      "Cluster 1 assigned to Class 953. Cost: 71.94503276589862\n",
      "Cluster 70 assigned to Class 957. Cost: 85.75280289226063\n",
      "Cluster 282 assigned to Class 959. Cost: 76.28226906676362\n",
      "Cluster 178 assigned to Class 961. Cost: 53.89144363677833\n",
      "Cluster 232 assigned to Class 962. Cost: 90.42587262750769\n",
      "Cluster 346 assigned to Class 966. Cost: 98.63554310323255\n",
      "Cluster 22 assigned to Class 967. Cost: 109.52829276919806\n",
      "Cluster 365 assigned to Class 970. Cost: 104.53985222571032\n",
      "Cluster 367 assigned to Class 972. Cost: 139.0244144425593\n",
      "Cluster 32 assigned to Class 974. Cost: 72.23560431198666\n",
      "Cluster 179 assigned to Class 975. Cost: 76.80177428237339\n",
      "Cluster 131 assigned to Class 976. Cost: 96.64054939808115\n",
      "Cluster 292 assigned to Class 977. Cost: 102.85067382243241\n",
      "Cluster 120 assigned to Class 979. Cost: 86.79625677589004\n",
      "Cluster 80 assigned to Class 980. Cost: 114.18349306469689\n",
      "Cluster 68 assigned to Class 987. Cost: 92.17802746415894\n",
      "Cluster 242 assigned to Class 990. Cost: 83.7828528874362\n",
      "Cluster 252 assigned to Class 991. Cost: 134.17335171035836\n",
      "Cluster 159 assigned to Class 992. Cost: 77.42971864866982\n",
      "Cluster 17 assigned to Class 996. Cost: 110.14391342827005\n",
      "Cluster 235 assigned to Class 998. Cost: 66.67328253046794\n",
      "Cluster 238 assigned to Class 999. Cost: 85.23141443508368\n"
     ]
    }
   ],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "dist_list =  np.transpose(tot_dist, (1, 0))\n",
    "from tqdm import tqdm\n",
    "\n",
    "costs = dist_list\n",
    "\n",
    "num_workers = len(costs)\n",
    "num_tasks = len(costs[0])\n",
    "# Create the mip solver with the SCIP backend.\n",
    "solver = pywraplp.Solver.CreateSolver(\"SCIP\")\n",
    "\n",
    "# x[i, j] is an array of 0-1 variables, which will be 1\n",
    "# if worker i is assigned to task j.\n",
    "x = {}\n",
    "for i in range(num_workers):\n",
    "    for j in range(num_tasks):\n",
    "        x[i, j] = solver.IntVar(0, 1, \"\")\n",
    "        \n",
    "# Each worker is assigned to at most 1 task.\n",
    "for i in range(num_workers):\n",
    "    solver.Add(solver.Sum([x[i, j] for j in range(num_tasks)]) <= 1)\n",
    "\n",
    "# Each task is assigned to exactly one worker.\n",
    "for j in range(num_tasks):\n",
    "    solver.Add(solver.Sum([x[i, j] for i in range(num_workers)]) == 1)\n",
    "    \n",
    "objective_terms = []\n",
    "for i in tqdm(range(num_workers)):\n",
    "    for j in range(num_tasks):\n",
    "        objective_terms.append(costs[i][j] * x[i, j])\n",
    "solver.Minimize(solver.Sum(objective_terms))\n",
    "\n",
    "status = solver.Solve()\n",
    "\n",
    "sol_indexes = []\n",
    "if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "    print(f\"Total cost = {solver.Objective().Value()}\\n\")\n",
    "    for i in range(num_workers):\n",
    "        for j in range(num_tasks):\n",
    "            # Test if x[i,j] is 1 (with tolerance for floating point arithmetic).\n",
    "            if x[i, j].solution_value() > 0.1:\n",
    "                print(f\"Cluster {j} assigned to Class {i}.\" + f\" Cost: {costs[i][j]}\")\n",
    "                sol_indexes.append(i)\n",
    "else:\n",
    "    print(\"No solution found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e8b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sol_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c015e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes have been saved to 'cvfinal.pkl'.\n"
     ]
    }
   ],
   "source": [
    "with open('cvfinal.pkl', 'wb') as file:\n",
    "    pickle.dump(sol_indexes, file)\n",
    "\n",
    "print(\"Indexes have been saved to 'cvfinal.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118f0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6783421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.6200830936431885 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1575fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DataFrames:   0%|                                                           | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunks:   0%|                                                              | 0/97 [00:00<?, ?it/s]\u001b[A\n",
      "Processing chunks:  95%|█████████████████████████████████████████████████▎  | 92/97 [00:00<00:00, 903.52it/s]\u001b[A\n",
      "                                                                                                             \u001b[AC:\\Users\\shaif\\anaconda3\\envs\\dasks\\lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 16.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Processing DataFrames:  25%|████████████▌                                     | 1/4 [12:51<38:35, 771.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunks:   0%|                                                             | 0/101 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                                             \u001b[AC:\\Users\\shaif\\anaconda3\\envs\\dasks\\lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 16.35 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Processing DataFrames:  50%|████████████████████████▌                        | 2/4 [42:04<44:57, 1348.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunks:   0%|                                                              | 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                                             \u001b[AC:\\Users\\shaif\\anaconda3\\envs\\dasks\\lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 16.63 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Processing DataFrames:  75%|███████████████████████████████████▎           | 3/4 [1:16:42<28:01, 1681.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunks:   0%|                                                              | 0/43 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                                             \u001b[AC:\\Users\\shaif\\anaconda3\\envs\\dasks\\lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 16.90 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Processing DataFrames: 100%|███████████████████████████████████████████████| 4/4 [1:56:28<00:00, 1747.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 7000.50746011734 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from dask.distributed import Client\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "\n",
    "# Initialize Dask client\n",
    "client = Client()\n",
    "\n",
    "# Function to compute closest indexes\n",
    "def compute_closest_indexes(chunk, centers, index_set):\n",
    "    result_list = []\n",
    "    for idx, row in chunk.iterrows():\n",
    "        features = np.array(row[2:], dtype=float).reshape(1, -1)\n",
    "        distances = cdist(features, centers, metric='euclidean')\n",
    "        closest_center_idx = np.argmin(distances)\n",
    "        if closest_center_idx in index_set:\n",
    "            result_list.append((closest_center_idx, row[1]))\n",
    "    return result_list\n",
    "\n",
    "# Function to process elements of all DataFrames\n",
    "def process_elements(dfs, centers, index_set, max_len_per_index=500):\n",
    "    result_list = []\n",
    "    index_count = {idx: 0 for idx in index_set}\n",
    "    delayed_results = []\n",
    "\n",
    "    for df in tqdm(dfs, desc=\"Processing DataFrames\"):\n",
    "        print(len(result_list))\n",
    "        # Iterate over chunks of the DataFrame\n",
    "        for chunk in tqdm(df.to_delayed(), desc=\"Processing chunks\", leave=False):\n",
    "            # Process each chunk in parallel\n",
    "            delayed_result = dask.delayed(compute_closest_indexes)(chunk, centers, index_set)\n",
    "            delayed_results.append(delayed_result)\n",
    "\n",
    "        # Compute and collect results\n",
    "        if delayed_results:\n",
    "            chunk_results = dask.compute(*delayed_results)\n",
    "            for chunk_result in chunk_results:\n",
    "                for closest_center_idx, row_1 in chunk_result:\n",
    "                    if index_count[closest_center_idx] < max_len_per_index:\n",
    "                        result_list.append(row_1)\n",
    "                        index_count[closest_center_idx] += 1\n",
    "                        if index_count[closest_center_idx] >= max_len_per_index:\n",
    "                            index_set.remove(closest_center_idx)\n",
    "                        if all(count >= max_len_per_index for count in index_count.values()):\n",
    "                            return result_list\n",
    "\n",
    "    return result_list\n",
    "\n",
    "# Measure the execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the pickle files\n",
    "with open(\"F:/ML_notebooks/cvfinal.pkl\", 'rb') as file:\n",
    "    index = pickle.load(file)\n",
    "with open(\"F:/ML_notebooks/cluster_centers.pkl\", 'rb') as file:\n",
    "    centers = pickle.load(file)\n",
    "\n",
    "# Convert index to a set for faster lookup\n",
    "index_set = set(index)\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "file_paths = [\n",
    "    \"G:/image_features.csv\",\n",
    "    \"G:/image_features1.csv\",\n",
    "    \"G:/image_features2.csv\",\n",
    "    \"G:/image_features3.csv\"\n",
    "]\n",
    "\n",
    "# Load the CSV files into Dask DataFrames\n",
    "dfs = [dd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Call the function to process elements of each DataFrame\n",
    "result_list = process_elements(dfs, centers, index_set)\n",
    "\n",
    "# Save the result_list in a pickle file\n",
    "with open(\"cifar_images.pkl\", \"wb\") as file:\n",
    "    pickle.dump(result_list, file)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the execution time\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90056f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1d18729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196705\n"
     ]
    }
   ],
   "source": [
    "print(len(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c9cd4-a50e-4b6c-b298-a8d179d3c77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c450d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f43ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
