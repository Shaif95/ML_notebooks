{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379e3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e329042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1020, 32, 32, 3)\n",
      "Y_train shape: (1020,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the Flowers102 dataset using TensorFlow Datasets\n",
    "dataset_name = 'oxford_flowers102'\n",
    "(ds_train, ds_test, ds_validation), info = tfds.load(\n",
    "    name=dataset_name,\n",
    "    split=['train', 'test', 'validation'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# Normalize the pixel values between 0 and 1 and resize the images (adjust as needed)\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (32, 32))  # Resize images to a common size (you can adjust this)\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(preprocess_image)\n",
    "ds_test = ds_test.map(preprocess_image)\n",
    "\n",
    "# Batch and prefetch the datasets\n",
    "batch_size = 32\n",
    "ds_train = ds_train.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Extract the data as NumPy arrays\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for images, labels in ds_train:\n",
    "    for image, label in zip(images, labels):\n",
    "        x_train.append(image.numpy())\n",
    "        y_train.append(label.numpy())\n",
    "\n",
    "for images, labels in ds_test:\n",
    "    for image, label in zip(images, labels):\n",
    "        x_test.append(image.numpy())\n",
    "        y_test.append(label.numpy())\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Now you have x_train, y_train, x_test, and y_test with the Flowers102 dataset\n",
    "\n",
    "# Now you have x_train, y_train, x_test, and y_test with the Flowers102 dataset\n",
    "\n",
    "print(f'X_train shape: {x_train.shape}')\n",
    "print(f'Y_train shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37702c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ce9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc75184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_16216\\1555111213.py:18: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((32, 32), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_and_process_images(base_dir):\n",
    "    images = []\n",
    "    # Iterate through all subdirectories\n",
    "    for subdir, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            try:\n",
    "                # Open the image\n",
    "                with Image.open(filepath) as img:\n",
    "                    # Convert to RGB\n",
    "                    img = img.convert('RGB')\n",
    "                    # Resize to 32x32\n",
    "                    img = img.resize((32, 32), Image.ANTIALIAS)\n",
    "                    # Convert to numpy array and scale\n",
    "                    img_array = np.asarray(img, dtype=np.float32) / 255\n",
    "                    images.append(img_array)\n",
    "            except IOError:\n",
    "                # Handle the case where the file could not be opened as an image\n",
    "                print(f\"Cannot open {file} as an image.\")\n",
    "                \n",
    "    return images\n",
    "\n",
    "base_dir = r\"D:\\datasets\\Underwater_Image\\WHOI\\archive\\dataset_pm\\training\"\n",
    "X_train = read_and_process_images(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (11276, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the paths to your dataset folders\n",
    "train_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\train_and_validation_sets\\train_and_validation_sets\"\n",
    "test_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\test_set\\test_set\"\n",
    "\n",
    "# Initialize empty lists for X_train, Y_train, X_test, and Y_test\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# Initialize an empty list to store categorical labels\n",
    "categorical_labels = []\n",
    "\n",
    "# Define a function to read and preprocess images\n",
    "def process_images(folder_path, label, is_train_set=True):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".bmp\"):  # Check if it's a file and ends with .bmp\n",
    "            # Open and resize the image to (32, 32, 3)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((32, 32))\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "            # Convert image data to a NumPy array\n",
    "            img_array = np.array(img).astype('float32')  # Convert to float\n",
    "            \n",
    "            # Normalize the image data (optional)\n",
    "            img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "            \n",
    "            # Append the image data to the appropriate list\n",
    "            if is_train_set:\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(label)  # Append the numerical label\n",
    "            else:\n",
    "                X_test.append(img_array)\n",
    "                Y_test.append(label)  # Append the numerical label\n",
    "            \n",
    "            # Append the label for categorical encoding\n",
    "            categorical_labels.append(label)  # Append the numerical label\n",
    "\n",
    "# List the folders inside the training dataset directory\n",
    "train_folders = os.listdir(train_dataset_dir)\n",
    "\n",
    "# Create a label encoder for categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through the training folders and process images\n",
    "for label, folder_name in enumerate(train_folders):\n",
    "    folder_path = os.path.join(train_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label)\n",
    "\n",
    "# List the folders inside the test dataset directory\n",
    "test_folders = os.listdir(test_dataset_dir)\n",
    "\n",
    "# Loop through the test folders and process images\n",
    "for label, folder_name in enumerate(test_folders):\n",
    "    folder_path = os.path.join(test_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label, is_train_set=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "x_train = np.concatenate((X_train, X_test), axis=0)\n",
    "# Check the shape of X_train, Y_train_categorical, X_test, and Y_test_categorical\n",
    "print(\"Shape of X_train:\", np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5d638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e60f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c549f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "import glob\n",
    "\n",
    "target_size = (32, 32)  # Change the values as per your requirement\n",
    "# Load the pre-trained ResNet50 model with modified input shape\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(target_size[0], target_size[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c9ee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 0</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 2038</th>\n",
       "      <th>Feature 2039</th>\n",
       "      <th>Feature 2040</th>\n",
       "      <th>Feature 2041</th>\n",
       "      <th>Feature 2042</th>\n",
       "      <th>Feature 2043</th>\n",
       "      <th>Feature 2044</th>\n",
       "      <th>Feature 2045</th>\n",
       "      <th>Feature 2046</th>\n",
       "      <th>Feature 2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.016108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 0  Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Feature 6  Feature 7  Feature 8  Feature 9  ...  Feature 2038  \\\n",
       "0        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "\n",
       "   Feature 2039  Feature 2040  Feature 2041  Feature 2042  Feature 2043  \\\n",
       "0           0.0      0.037739           0.0           0.0           0.0   \n",
       "\n",
       "   Feature 2044  Feature 2045  Feature 2046  Feature 2047  \n",
       "0           0.0      3.016108           0.0           0.0  \n",
       "\n",
       "[1 rows x 2048 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Define the file path\n",
    "file_path = r\"F:\\21k_avg_feature.csv\"\n",
    "# Read the tab-separated CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path, delimiter='\\t')\n",
    "columns_to_drop = [df.columns[0], df.columns[-1]]\n",
    "data = df.drop(columns_to_drop, axis=1)\n",
    "# Display the head of the DataFrame\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06649222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4357, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6afbd946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424d8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "ft = model.predict(np.array(X_train).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61ee04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\shaif\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1902: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 5120 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "n_clusters = 15\n",
    "batch_size = 100\n",
    "max_iter = 100\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, max_iter=max_iter)\n",
    "kmeans.fit(ft)\n",
    "# Retrieve the cluster centers\n",
    "ct = kmeans.cluster_centers_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "400c3f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 15/15 [00:33<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 10450)\n",
      "(15, 10450)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "combo_list = []  # Initialize combo_list\n",
    "tot_dist = []\n",
    "# Iterate over ft\n",
    "for i in tqdm(range(len(ct))):\n",
    "    distances = []\n",
    "\n",
    "    # Calculate distances for each row in data\n",
    "    for index, row in data.iterrows():\n",
    "        row_array = row.to_numpy()  # Convert row to numpy array\n",
    "        distance = np.linalg.norm(ct[i] - row_array)  # Calculate Euclidean distance\n",
    "        distances.append(distance)\n",
    "\n",
    "    tot_dist.append(distances)\n",
    "print(np.shape(tot_dist))\n",
    "#new_shape = (1000, 30)\n",
    "#re_dist = np.transpose(tot_dist, (1, 0))\n",
    "re_dist = tot_dist\n",
    "print(np.shape(re_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ba3d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo list saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the list to a file in the D: drive\n",
    "file_path = r\"F:\\dist_list.pickle\"  # r prefix is used for raw string to avoid escape characters\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(re_dist, file)\n",
    "\n",
    "print(\"Combo list saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1af5e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43511453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee431086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo list loaded successfully.\n",
      "[299, 547, 579, 1189, 1497, 4061, 4249, 6106, 6274, 6288, 7592, 7606, 9092, 9106, 9749]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Loading the list from the pickle file\n",
    "file_path = r\"F:\\index_list.pickle\"  # Update the file path if necessary\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    index_list = pickle.load(file)\n",
    "\n",
    "print(\"Combo list loaded successfully.\")\n",
    "print(index_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba86a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Directory', 'Feature 0', 'Feature 1', 'Feature 2', 'Feature 3',\n",
       "       'Feature 4', 'Feature 5', 'Feature 6', 'Feature 7', 'Feature 8',\n",
       "       ...\n",
       "       'Feature 2039', 'Feature 2040', 'Feature 2041', 'Feature 2042',\n",
       "       'Feature 2043', 'Feature 2044', 'Feature 2045', 'Feature 2046',\n",
       "       'Feature 2047', 'Unnamed: 2049'],\n",
       "      dtype='object', length=2050)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ede097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = df.loc[index_list, ['Directory']].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89170a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3dc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f11d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo list saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the list to a file in the D: drive\n",
    "file_path = r\"F:\\combo_list.pickle\"  # r prefix is used for raw string to avoid escape characters\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(selected_data, file)\n",
    "\n",
    "print(\"Combo list saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebce419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo list loaded successfully.\n",
      "['F:/imagenet21k_resized/imagenet21k_train\\\\n01488038\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01596608\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01608814\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01340014\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01596608\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n00449796\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01488038\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01953361\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n02038466\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n02044178\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01943899\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01953361\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01943899\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01953361\\\\'\n",
      " 'F:/imagenet21k_resized/imagenet21k_train\\\\n01488038\\\\']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Loading the list from the pickle file\n",
    "file_path = r\"F:\\combo_list.pickle\"  # Update the file path if necessary\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_combo_list = pickle.load(file)\n",
    "\n",
    "print(\"Combo list loaded successfully.\")\n",
    "print(loaded_combo_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12fe31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b7ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6bd347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fba0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ec790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87186a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc427dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a762d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d5acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571ec63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd7ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25eec36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0f1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e5a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54915b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
