{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379e3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e329042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29009, 32, 32, 3)\n",
      "Y_train shape: (29009,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"E:\\imbcifar\\train\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37702c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ce9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc75184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_16216\\1555111213.py:18: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((32, 32), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n",
      "Cannot open desktop.ini as an image.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def read_and_process_images(base_dir):\n",
    "    images = []\n",
    "    # Iterate through all subdirectories\n",
    "    for subdir, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            try:\n",
    "                # Open the image\n",
    "                with Image.open(filepath) as img:\n",
    "                    # Convert to RGB\n",
    "                    img = img.convert('RGB')\n",
    "                    # Resize to 32x32\n",
    "                    img = img.resize((32, 32), Image.ANTIALIAS)\n",
    "                    # Convert to numpy array and scale\n",
    "                    img_array = np.asarray(img, dtype=np.float32) / 255\n",
    "                    images.append(img_array)\n",
    "            except IOError:\n",
    "                # Handle the case where the file could not be opened as an image\n",
    "                print(f\"Cannot open {file} as an image.\")\n",
    "                \n",
    "    return images\n",
    "\n",
    "base_dir = r\"D:\\datasets\\Underwater_Image\\WHOI\\archive\\dataset_pm\\training\"\n",
    "X_train = read_and_process_images(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (11276, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the paths to your dataset folders\n",
    "train_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\train_and_validation_sets\\train_and_validation_sets\"\n",
    "test_dataset_dir = r\"D:\\datasets\\Underwater_Image\\LIMUC (Labeled Images for Ulcerative Colitis)\\test_set\\test_set\"\n",
    "\n",
    "# Initialize empty lists for X_train, Y_train, X_test, and Y_test\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# Initialize an empty list to store categorical labels\n",
    "categorical_labels = []\n",
    "\n",
    "# Define a function to read and preprocess images\n",
    "def process_images(folder_path, label, is_train_set=True):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".bmp\"):  # Check if it's a file and ends with .bmp\n",
    "            # Open and resize the image to (32, 32, 3)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((32, 32))\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "            # Convert image data to a NumPy array\n",
    "            img_array = np.array(img).astype('float32')  # Convert to float\n",
    "            \n",
    "            # Normalize the image data (optional)\n",
    "            img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "            \n",
    "            # Append the image data to the appropriate list\n",
    "            if is_train_set:\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(label)  # Append the numerical label\n",
    "            else:\n",
    "                X_test.append(img_array)\n",
    "                Y_test.append(label)  # Append the numerical label\n",
    "            \n",
    "            # Append the label for categorical encoding\n",
    "            categorical_labels.append(label)  # Append the numerical label\n",
    "\n",
    "# List the folders inside the training dataset directory\n",
    "train_folders = os.listdir(train_dataset_dir)\n",
    "\n",
    "# Create a label encoder for categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through the training folders and process images\n",
    "for label, folder_name in enumerate(train_folders):\n",
    "    folder_path = os.path.join(train_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label)\n",
    "\n",
    "# List the folders inside the test dataset directory\n",
    "test_folders = os.listdir(test_dataset_dir)\n",
    "\n",
    "# Loop through the test folders and process images\n",
    "for label, folder_name in enumerate(test_folders):\n",
    "    folder_path = os.path.join(test_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label, is_train_set=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "x_train = np.concatenate((X_train, X_test), axis=0)\n",
    "# Check the shape of X_train, Y_train_categorical, X_test, and Y_test_categorical\n",
    "print(\"Shape of X_train:\", np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5d638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████████▍                                  | 11/19 [03:50<04:22, 32.87s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r\"G:\\datasets\\Underwater_Image\\WHOI\\archive\\dataset_pm\\training\"\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for class_folder in tqdm(sorted(os.listdir(directory_path))):\n",
    "    class_path = os.path.join(directory_path, class_folder)\n",
    "    \n",
    "    for image_file in os.listdir(class_path):\n",
    "        if image_file.endswith('.png'):\n",
    "            image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((32, 32))\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "            X_train.append(img_array)\n",
    "            Y_train.append(class_label)\n",
    "            \n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c5bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\shaif\\tensorflow_datasets\\i_naturalist2018\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00500178337097168,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Dl Completed...",
       "rate": null,
       "total": 0,
       "unit": " url",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca5533831cf42139ceb2e7471d2c527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0030159950256347656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Dl Size...",
       "rate": null,
       "total": 0,
       "unit": " MiB",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f570be85164909bb2a5f3a40081943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005003690719604492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Extraction completed...",
       "rate": null,
       "total": 0,
       "unit": " file",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083ae7e6171a4ccf9f8f9398eda7732b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the iNaturalist dataset\n",
    "dataset_name = 'i_naturalist2018'\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    dataset_name,\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,  # Get the (image, label) pairs\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# Function to preprocess images and labels\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (32, 32))\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.one_hot(label, depth=ds_info.features['label'].num_classes)  # One-hot encode labels\n",
    "    return image, label\n",
    "\n",
    "# Preprocess train and test datasets\n",
    "ds_train = ds_train.map(preprocess).batch(32).shuffle(buffer_size=1000)\n",
    "ds_test = ds_test.map(preprocess).batch(32)\n",
    "\n",
    "# Convert the TensorFlow dataset to numpy arrays for x_train and y_train\n",
    "def dataset_to_numpy(ds):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_batch, label_batch in ds:\n",
    "        images.append(image_batch.numpy())\n",
    "        labels.append(label_batch.numpy())\n",
    "    return np.concatenate(images), np.concatenate(labels)\n",
    "\n",
    "# Convert train and test datasets\n",
    "x_train, y_train = dataset_to_numpy(ds_train)\n",
    "x_test, y_test = dataset_to_numpy(ds_test)\n",
    "\n",
    "# Verify shapes\n",
    "print(f'x_train shape: {x_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'x_test shape: {x_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c494d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297644b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e60f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c549f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "import glob\n",
    "\n",
    "target_size = (32, 32)  # Change the values as per your requirement\n",
    "# Load the pre-trained ResNet50 model with modified input shape\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(target_size[0], target_size[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c9ee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 0</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 2038</th>\n",
       "      <th>Feature 2039</th>\n",
       "      <th>Feature 2040</th>\n",
       "      <th>Feature 2041</th>\n",
       "      <th>Feature 2042</th>\n",
       "      <th>Feature 2043</th>\n",
       "      <th>Feature 2044</th>\n",
       "      <th>Feature 2045</th>\n",
       "      <th>Feature 2046</th>\n",
       "      <th>Feature 2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.285227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 0  Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Feature 6  Feature 7  Feature 8  Feature 9  ...  Feature 2038  \\\n",
       "0        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "\n",
       "   Feature 2039  Feature 2040  Feature 2041  Feature 2042  Feature 2043  \\\n",
       "0           0.0      0.009121           0.0           0.0           0.0   \n",
       "\n",
       "   Feature 2044  Feature 2045  Feature 2046  Feature 2047  \n",
       "0           0.0      3.285227           0.0           0.0  \n",
       "\n",
       "[1 rows x 2048 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Define the file path\n",
    "file_path = r\"D:\\feature.csv\"\n",
    "# Read the tab-separated CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path, delimiter='\\t')\n",
    "columns_to_drop = [df.columns[0], df.columns[-1]]\n",
    "data = df.drop(columns_to_drop, axis=1)\n",
    "# Display the head of the DataFrame\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06649222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4357, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6afbd946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "424d8e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "ft = model.predict(np.array(X_train).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e61ee04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "n_clusters = 400\n",
    "batch_size = 100\n",
    "max_iter = 100\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, max_iter=max_iter)\n",
    "kmeans.fit(ft)\n",
    "# Retrieve the cluster centers\n",
    "ct = kmeans.cluster_centers_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "400c3f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [01:00<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1000)\n",
      "(400, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "combo_list = []  # Initialize combo_list\n",
    "tot_dist = []\n",
    "# Iterate over ft\n",
    "for i in tqdm(range(len(ct))):\n",
    "    distances = []\n",
    "\n",
    "    # Calculate distances for each row in data\n",
    "    for index, row in data.iterrows():\n",
    "        row_array = row.to_numpy()  # Convert row to numpy array\n",
    "        distance = np.linalg.norm(ct[i] - row_array)  # Calculate Euclidean distance\n",
    "        distances.append(distance)\n",
    "\n",
    "    tot_dist.append(distances)\n",
    "print(np.shape(tot_dist))\n",
    "#new_shape = (1000, 30)\n",
    "#re_dist = np.transpose(tot_dist, (1, 0))\n",
    "re_dist = tot_dist\n",
    "print(np.shape(re_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5ba3d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo list saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the list to a file in the D: drive\n",
    "file_path = r\"D:\\dist_list.pickle\"  # r prefix is used for raw string to avoid escape characters\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(re_dist, file)\n",
    "\n",
    "print(\"Combo list saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1af5e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mindex_list\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'index_list' is not defined"
     ]
    }
   ],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43511453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee431086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo list loaded successfully.\n",
      "[1, 2, 3, 4, 5, 6, 11, 14, 18, 20, 21, 22, 23, 24, 27, 29, 31, 33, 34, 41, 42, 45, 47, 49, 50, 58, 65, 66, 70, 72, 73, 74, 75, 76, 78, 81, 83, 85, 86, 93, 96, 98, 102, 103, 105, 107, 108, 109, 115, 116, 117, 123, 127, 128, 129, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 147, 149, 152, 153, 156, 157, 165, 166, 167, 179, 181, 183, 188, 190, 195, 197, 204, 205, 206, 214, 215, 216, 217, 221, 223, 224, 229, 232, 234, 238, 239, 240, 241, 244, 247, 252, 256, 257, 259, 272, 274, 276, 277, 278, 280, 288, 291, 293, 297, 299, 302, 305, 306, 317, 318, 320, 321, 322, 324, 325, 326, 330, 331, 332, 342, 343, 344, 346, 351, 352, 353, 362, 363, 368, 369, 373, 375, 378, 379, 384, 386, 388, 393, 397, 399, 400, 403, 404, 405, 406, 408, 409, 411, 413, 414, 417, 424, 426, 432, 435, 436, 438, 442, 447, 449, 451, 453, 457, 458, 460, 465, 466, 468, 470, 472, 474, 475, 479, 484, 493, 495, 498, 500, 509, 510, 511, 512, 518, 520, 525, 527, 528, 531, 533, 535, 536, 538, 539, 540, 541, 542, 547, 550, 551, 553, 554, 555, 556, 562, 563, 564, 565, 567, 568, 570, 575, 578, 579, 581, 584, 585, 586, 590, 592, 593, 595, 597, 598, 600, 605, 607, 610, 614, 624, 625, 627, 628, 630, 632, 633, 635, 636, 639, 640, 643, 646, 648, 649, 650, 654, 657, 660, 664, 666, 667, 668, 669, 671, 675, 676, 678, 686, 688, 689, 690, 694, 695, 698, 701, 705, 707, 710, 717, 718, 724, 726, 727, 728, 730, 732, 734, 741, 743, 746, 747, 750, 751, 754, 757, 759, 762, 764, 768, 771, 773, 779, 780, 781, 782, 785, 789, 791, 794, 796, 798, 799, 800, 802, 803, 808, 809, 812, 814, 815, 817, 818, 820, 821, 823, 824, 825, 826, 827, 829, 831, 834, 836, 837, 841, 847, 851, 852, 853, 854, 856, 858, 863, 864, 866, 867, 869, 871, 874, 877, 884, 886, 891, 893, 894, 895, 902, 903, 904, 905, 906, 908, 912, 913, 914, 915, 916, 922, 923, 925, 928, 933, 935, 941, 946, 958, 959, 960, 961, 964, 965, 967, 969, 970, 972, 973, 974, 975, 976, 977, 978, 979, 980, 982, 983, 984, 985, 986, 992, 995]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Loading the list from the pickle file\n",
    "file_path = r\"D:\\index_list.pickle\"  # Update the file path if necessary\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    index_list = pickle.load(file)\n",
    "\n",
    "print(\"Combo list loaded successfully.\")\n",
    "print(index_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba86a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Directory', 'Feature 0', 'Feature 1', 'Feature 2', 'Feature 3',\n",
       "       'Feature 4', 'Feature 5', 'Feature 6', 'Feature 7', 'Feature 8',\n",
       "       ...\n",
       "       'Feature 2039', 'Feature 2040', 'Feature 2041', 'Feature 2042',\n",
       "       'Feature 2043', 'Feature 2044', 'Feature 2045', 'Feature 2046',\n",
       "       'Feature 2047', 'Unnamed: 2049'],\n",
       "      dtype='object', length=2050)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ede097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = df.loc[index_list, ['Name']].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89170a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3dc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5f11d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo list saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the list to a file in the D: drive\n",
    "file_path = r\"D:\\combo_list.pickle\"  # r prefix is used for raw string to avoid escape characters\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(selected_data, file)\n",
    "\n",
    "print(\"Combo list saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebce419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combo list loaded successfully.\n",
      "['D:/data/imagenet\\\\n01443537\\\\' 'D:/data/imagenet\\\\n01484850\\\\'\n",
      " 'D:/data/imagenet\\\\n01491361\\\\' 'D:/data/imagenet\\\\n01494475\\\\'\n",
      " 'D:/data/imagenet\\\\n01496331\\\\' 'D:/data/imagenet\\\\n01498041\\\\'\n",
      " 'D:/data/imagenet\\\\n01531178\\\\' 'D:/data/imagenet\\\\n01537544\\\\'\n",
      " 'D:/data/imagenet\\\\n01582220\\\\' 'D:/data/imagenet\\\\n01601694\\\\'\n",
      " 'D:/data/imagenet\\\\n01608432\\\\' 'D:/data/imagenet\\\\n01614925\\\\'\n",
      " 'D:/data/imagenet\\\\n01616318\\\\' 'D:/data/imagenet\\\\n01622779\\\\'\n",
      " 'D:/data/imagenet\\\\n01631663\\\\' 'D:/data/imagenet\\\\n01632777\\\\'\n",
      " 'D:/data/imagenet\\\\n01644373\\\\' 'D:/data/imagenet\\\\n01664065\\\\'\n",
      " 'D:/data/imagenet\\\\n01665541\\\\' 'D:/data/imagenet\\\\n01685808\\\\'\n",
      " 'D:/data/imagenet\\\\n01687978\\\\' 'D:/data/imagenet\\\\n01692333\\\\'\n",
      " 'D:/data/imagenet\\\\n01694178\\\\' 'D:/data/imagenet\\\\n01697457\\\\'\n",
      " 'D:/data/imagenet\\\\n01698640\\\\' 'D:/data/imagenet\\\\n01737021\\\\'\n",
      " 'D:/data/imagenet\\\\n01751748\\\\' 'D:/data/imagenet\\\\n01753488\\\\'\n",
      " 'D:/data/imagenet\\\\n01770081\\\\' 'D:/data/imagenet\\\\n01773157\\\\'\n",
      " 'D:/data/imagenet\\\\n01773549\\\\' 'D:/data/imagenet\\\\n01773797\\\\'\n",
      " 'D:/data/imagenet\\\\n01774384\\\\' 'D:/data/imagenet\\\\n01774750\\\\'\n",
      " 'D:/data/imagenet\\\\n01776313\\\\' 'D:/data/imagenet\\\\n01796340\\\\'\n",
      " 'D:/data/imagenet\\\\n01798484\\\\' 'D:/data/imagenet\\\\n01806567\\\\'\n",
      " 'D:/data/imagenet\\\\n01807496\\\\' 'D:/data/imagenet\\\\n01829413\\\\'\n",
      " 'D:/data/imagenet\\\\n01843383\\\\' 'D:/data/imagenet\\\\n01855032\\\\'\n",
      " 'D:/data/imagenet\\\\n01872401\\\\' 'D:/data/imagenet\\\\n01873310\\\\'\n",
      " 'D:/data/imagenet\\\\n01882714\\\\' 'D:/data/imagenet\\\\n01910747\\\\'\n",
      " 'D:/data/imagenet\\\\n01914609\\\\' 'D:/data/imagenet\\\\n01917289\\\\'\n",
      " 'D:/data/imagenet\\\\n01950731\\\\' 'D:/data/imagenet\\\\n01955084\\\\'\n",
      " 'D:/data/imagenet\\\\n01968897\\\\' 'D:/data/imagenet\\\\n01984695\\\\'\n",
      " 'D:/data/imagenet\\\\n02002556\\\\' 'D:/data/imagenet\\\\n02002724\\\\'\n",
      " 'D:/data/imagenet\\\\n02006656\\\\' 'D:/data/imagenet\\\\n02009229\\\\'\n",
      " 'D:/data/imagenet\\\\n02009912\\\\' 'D:/data/imagenet\\\\n02011460\\\\'\n",
      " 'D:/data/imagenet\\\\n02017213\\\\' 'D:/data/imagenet\\\\n02018207\\\\'\n",
      " 'D:/data/imagenet\\\\n02018795\\\\' 'D:/data/imagenet\\\\n02025239\\\\'\n",
      " 'D:/data/imagenet\\\\n02027492\\\\' 'D:/data/imagenet\\\\n02028035\\\\'\n",
      " 'D:/data/imagenet\\\\n02033041\\\\' 'D:/data/imagenet\\\\n02037110\\\\'\n",
      " 'D:/data/imagenet\\\\n02066245\\\\' 'D:/data/imagenet\\\\n02074367\\\\'\n",
      " 'D:/data/imagenet\\\\n02085782\\\\' 'D:/data/imagenet\\\\n02085936\\\\'\n",
      " 'D:/data/imagenet\\\\n02086646\\\\' 'D:/data/imagenet\\\\n02086910\\\\'\n",
      " 'D:/data/imagenet\\\\n02089078\\\\' 'D:/data/imagenet\\\\n02089867\\\\'\n",
      " 'D:/data/imagenet\\\\n02089973\\\\' 'D:/data/imagenet\\\\n02093256\\\\'\n",
      " 'D:/data/imagenet\\\\n02093647\\\\' 'D:/data/imagenet\\\\n02093859\\\\'\n",
      " 'D:/data/imagenet\\\\n02095314\\\\' 'D:/data/imagenet\\\\n02095889\\\\'\n",
      " 'D:/data/imagenet\\\\n02096585\\\\' 'D:/data/imagenet\\\\n02097130\\\\'\n",
      " 'D:/data/imagenet\\\\n02098413\\\\' 'D:/data/imagenet\\\\n02099267\\\\'\n",
      " 'D:/data/imagenet\\\\n02099429\\\\' 'D:/data/imagenet\\\\n02101006\\\\'\n",
      " 'D:/data/imagenet\\\\n02101388\\\\' 'D:/data/imagenet\\\\n02101556\\\\'\n",
      " 'D:/data/imagenet\\\\n02102040\\\\' 'D:/data/imagenet\\\\n02102973\\\\'\n",
      " 'D:/data/imagenet\\\\n02104365\\\\' 'D:/data/imagenet\\\\n02105056\\\\'\n",
      " 'D:/data/imagenet\\\\n02105641\\\\' 'D:/data/imagenet\\\\n02106166\\\\'\n",
      " 'D:/data/imagenet\\\\n02106550\\\\' 'D:/data/imagenet\\\\n02107574\\\\'\n",
      " 'D:/data/imagenet\\\\n02107683\\\\' 'D:/data/imagenet\\\\n02107908\\\\'\n",
      " 'D:/data/imagenet\\\\n02108000\\\\' 'D:/data/imagenet\\\\n02108551\\\\'\n",
      " 'D:/data/imagenet\\\\n02109525\\\\' 'D:/data/imagenet\\\\n02110627\\\\'\n",
      " 'D:/data/imagenet\\\\n02111277\\\\' 'D:/data/imagenet\\\\n02111500\\\\'\n",
      " 'D:/data/imagenet\\\\n02112018\\\\' 'D:/data/imagenet\\\\n02114855\\\\'\n",
      " 'D:/data/imagenet\\\\n02115913\\\\' 'D:/data/imagenet\\\\n02117135\\\\'\n",
      " 'D:/data/imagenet\\\\n02119022\\\\' 'D:/data/imagenet\\\\n02119789\\\\'\n",
      " 'D:/data/imagenet\\\\n02120505\\\\' 'D:/data/imagenet\\\\n02128385\\\\'\n",
      " 'D:/data/imagenet\\\\n02129165\\\\' 'D:/data/imagenet\\\\n02130308\\\\'\n",
      " 'D:/data/imagenet\\\\n02134418\\\\' 'D:/data/imagenet\\\\n02138441\\\\'\n",
      " 'D:/data/imagenet\\\\n02167151\\\\' 'D:/data/imagenet\\\\n02172182\\\\'\n",
      " 'D:/data/imagenet\\\\n02174001\\\\' 'D:/data/imagenet\\\\n02259212\\\\'\n",
      " 'D:/data/imagenet\\\\n02264363\\\\' 'D:/data/imagenet\\\\n02268853\\\\'\n",
      " 'D:/data/imagenet\\\\n02276258\\\\' 'D:/data/imagenet\\\\n02277742\\\\'\n",
      " 'D:/data/imagenet\\\\n02280649\\\\' 'D:/data/imagenet\\\\n02281406\\\\'\n",
      " 'D:/data/imagenet\\\\n02281787\\\\' 'D:/data/imagenet\\\\n02325366\\\\'\n",
      " 'D:/data/imagenet\\\\n02326432\\\\' 'D:/data/imagenet\\\\n02328150\\\\'\n",
      " 'D:/data/imagenet\\\\n02396427\\\\' 'D:/data/imagenet\\\\n02397096\\\\'\n",
      " 'D:/data/imagenet\\\\n02398521\\\\' 'D:/data/imagenet\\\\n02408429\\\\'\n",
      " 'D:/data/imagenet\\\\n02422106\\\\' 'D:/data/imagenet\\\\n02422699\\\\'\n",
      " 'D:/data/imagenet\\\\n02423022\\\\' 'D:/data/imagenet\\\\n02447366\\\\'\n",
      " 'D:/data/imagenet\\\\n02454379\\\\' 'D:/data/imagenet\\\\n02483362\\\\'\n",
      " 'D:/data/imagenet\\\\n02483708\\\\' 'D:/data/imagenet\\\\n02487347\\\\'\n",
      " 'D:/data/imagenet\\\\n02488702\\\\' 'D:/data/imagenet\\\\n02492035\\\\'\n",
      " 'D:/data/imagenet\\\\n02492660\\\\' 'D:/data/imagenet\\\\n02500267\\\\'\n",
      " 'D:/data/imagenet\\\\n02504458\\\\' 'D:/data/imagenet\\\\n02510455\\\\'\n",
      " 'D:/data/imagenet\\\\n02607072\\\\' 'D:/data/imagenet\\\\n02655020\\\\'\n",
      " 'D:/data/imagenet\\\\n02667093\\\\' 'D:/data/imagenet\\\\n02669723\\\\'\n",
      " 'D:/data/imagenet\\\\n02687172\\\\' 'D:/data/imagenet\\\\n02690373\\\\'\n",
      " 'D:/data/imagenet\\\\n02692877\\\\' 'D:/data/imagenet\\\\n02699494\\\\'\n",
      " 'D:/data/imagenet\\\\n02704792\\\\' 'D:/data/imagenet\\\\n02708093\\\\'\n",
      " 'D:/data/imagenet\\\\n02730930\\\\' 'D:/data/imagenet\\\\n02749479\\\\'\n",
      " 'D:/data/imagenet\\\\n02769748\\\\' 'D:/data/imagenet\\\\n02782093\\\\'\n",
      " 'D:/data/imagenet\\\\n02791270\\\\' 'D:/data/imagenet\\\\n02794156\\\\'\n",
      " 'D:/data/imagenet\\\\n02804610\\\\' 'D:/data/imagenet\\\\n02808440\\\\'\n",
      " 'D:/data/imagenet\\\\n02814533\\\\' 'D:/data/imagenet\\\\n02815834\\\\'\n",
      " 'D:/data/imagenet\\\\n02825657\\\\' 'D:/data/imagenet\\\\n02841315\\\\'\n",
      " 'D:/data/imagenet\\\\n02859443\\\\' 'D:/data/imagenet\\\\n02865351\\\\'\n",
      " 'D:/data/imagenet\\\\n02870880\\\\' 'D:/data/imagenet\\\\n02883205\\\\'\n",
      " 'D:/data/imagenet\\\\n02892201\\\\' 'D:/data/imagenet\\\\n02894605\\\\'\n",
      " 'D:/data/imagenet\\\\n02916936\\\\' 'D:/data/imagenet\\\\n02917067\\\\'\n",
      " 'D:/data/imagenet\\\\n02930766\\\\' 'D:/data/imagenet\\\\n02948072\\\\'\n",
      " 'D:/data/imagenet\\\\n02951358\\\\' 'D:/data/imagenet\\\\n02963159\\\\'\n",
      " 'D:/data/imagenet\\\\n02965783\\\\' 'D:/data/imagenet\\\\n02974003\\\\'\n",
      " 'D:/data/imagenet\\\\n02981792\\\\' 'D:/data/imagenet\\\\n03016953\\\\'\n",
      " 'D:/data/imagenet\\\\n03018349\\\\' 'D:/data/imagenet\\\\n03032252\\\\'\n",
      " 'D:/data/imagenet\\\\n03042490\\\\' 'D:/data/imagenet\\\\n03089624\\\\'\n",
      " 'D:/data/imagenet\\\\n03095699\\\\' 'D:/data/imagenet\\\\n03100240\\\\'\n",
      " 'D:/data/imagenet\\\\n03109150\\\\' 'D:/data/imagenet\\\\n03127747\\\\'\n",
      " 'D:/data/imagenet\\\\n03131574\\\\' 'D:/data/imagenet\\\\n03160309\\\\'\n",
      " 'D:/data/imagenet\\\\n03180011\\\\' 'D:/data/imagenet\\\\n03187595\\\\'\n",
      " 'D:/data/imagenet\\\\n03197337\\\\' 'D:/data/imagenet\\\\n03207743\\\\'\n",
      " 'D:/data/imagenet\\\\n03208938\\\\' 'D:/data/imagenet\\\\n03216828\\\\'\n",
      " 'D:/data/imagenet\\\\n03220513\\\\' 'D:/data/imagenet\\\\n03223299\\\\'\n",
      " 'D:/data/imagenet\\\\n03240683\\\\' 'D:/data/imagenet\\\\n03249569\\\\'\n",
      " 'D:/data/imagenet\\\\n03250847\\\\' 'D:/data/imagenet\\\\n03272562\\\\'\n",
      " 'D:/data/imagenet\\\\n03297495\\\\' 'D:/data/imagenet\\\\n03314780\\\\'\n",
      " 'D:/data/imagenet\\\\n03337140\\\\' 'D:/data/imagenet\\\\n03344393\\\\'\n",
      " 'D:/data/imagenet\\\\n03345487\\\\' 'D:/data/imagenet\\\\n03347037\\\\'\n",
      " 'D:/data/imagenet\\\\n03388043\\\\' 'D:/data/imagenet\\\\n03388183\\\\'\n",
      " 'D:/data/imagenet\\\\n03388549\\\\' 'D:/data/imagenet\\\\n03393912\\\\'\n",
      " 'D:/data/imagenet\\\\n03400231\\\\' 'D:/data/imagenet\\\\n03404251\\\\'\n",
      " 'D:/data/imagenet\\\\n03424325\\\\' 'D:/data/imagenet\\\\n03445924\\\\'\n",
      " 'D:/data/imagenet\\\\n03450230\\\\' 'D:/data/imagenet\\\\n03452741\\\\'\n",
      " 'D:/data/imagenet\\\\n03459775\\\\' 'D:/data/imagenet\\\\n03476684\\\\'\n",
      " 'D:/data/imagenet\\\\n03476991\\\\' 'D:/data/imagenet\\\\n03478589\\\\'\n",
      " 'D:/data/imagenet\\\\n03485407\\\\' 'D:/data/imagenet\\\\n03492542\\\\'\n",
      " 'D:/data/imagenet\\\\n03494278\\\\' 'D:/data/imagenet\\\\n03496892\\\\'\n",
      " 'D:/data/imagenet\\\\n03527444\\\\' 'D:/data/imagenet\\\\n03529860\\\\'\n",
      " 'D:/data/imagenet\\\\n03532672\\\\' 'D:/data/imagenet\\\\n03584254\\\\'\n",
      " 'D:/data/imagenet\\\\n03590841\\\\' 'D:/data/imagenet\\\\n03595614\\\\'\n",
      " 'D:/data/imagenet\\\\n03617480\\\\' 'D:/data/imagenet\\\\n03661043\\\\'\n",
      " 'D:/data/imagenet\\\\n03662601\\\\' 'D:/data/imagenet\\\\n03670208\\\\'\n",
      " 'D:/data/imagenet\\\\n03673027\\\\' 'D:/data/imagenet\\\\n03680355\\\\'\n",
      " 'D:/data/imagenet\\\\n03691459\\\\' 'D:/data/imagenet\\\\n03692522\\\\'\n",
      " 'D:/data/imagenet\\\\n03706229\\\\' 'D:/data/imagenet\\\\n03709823\\\\'\n",
      " 'D:/data/imagenet\\\\n03710721\\\\' 'D:/data/imagenet\\\\n03717622\\\\'\n",
      " 'D:/data/imagenet\\\\n03724870\\\\' 'D:/data/imagenet\\\\n03733281\\\\'\n",
      " 'D:/data/imagenet\\\\n03742115\\\\' 'D:/data/imagenet\\\\n03743016\\\\'\n",
      " 'D:/data/imagenet\\\\n03759954\\\\' 'D:/data/imagenet\\\\n03769881\\\\'\n",
      " 'D:/data/imagenet\\\\n03773504\\\\' 'D:/data/imagenet\\\\n03776460\\\\'\n",
      " 'D:/data/imagenet\\\\n03782006\\\\' 'D:/data/imagenet\\\\n03786901\\\\'\n",
      " 'D:/data/imagenet\\\\n03787032\\\\' 'D:/data/imagenet\\\\n03788195\\\\'\n",
      " 'D:/data/imagenet\\\\n03788365\\\\' 'D:/data/imagenet\\\\n03792782\\\\'\n",
      " 'D:/data/imagenet\\\\n03796401\\\\' 'D:/data/imagenet\\\\n03803284\\\\'\n",
      " 'D:/data/imagenet\\\\n03814639\\\\' 'D:/data/imagenet\\\\n03843555\\\\'\n",
      " 'D:/data/imagenet\\\\n03857828\\\\' 'D:/data/imagenet\\\\n03866082\\\\'\n",
      " 'D:/data/imagenet\\\\n03868242\\\\' 'D:/data/imagenet\\\\n03874293\\\\'\n",
      " 'D:/data/imagenet\\\\n03874599\\\\' 'D:/data/imagenet\\\\n03877845\\\\'\n",
      " 'D:/data/imagenet\\\\n03888257\\\\' 'D:/data/imagenet\\\\n03895866\\\\'\n",
      " 'D:/data/imagenet\\\\n03902125\\\\' 'D:/data/imagenet\\\\n03908714\\\\'\n",
      " 'D:/data/imagenet\\\\n03930630\\\\' 'D:/data/imagenet\\\\n03933933\\\\'\n",
      " 'D:/data/imagenet\\\\n03947888\\\\' 'D:/data/imagenet\\\\n03954731\\\\'\n",
      " 'D:/data/imagenet\\\\n03956157\\\\' 'D:/data/imagenet\\\\n03958227\\\\'\n",
      " 'D:/data/imagenet\\\\n03967562\\\\' 'D:/data/imagenet\\\\n03976467\\\\'\n",
      " 'D:/data/imagenet\\\\n03977966\\\\' 'D:/data/imagenet\\\\n03998194\\\\'\n",
      " 'D:/data/imagenet\\\\n04005630\\\\' 'D:/data/imagenet\\\\n04019541\\\\'\n",
      " 'D:/data/imagenet\\\\n04023962\\\\' 'D:/data/imagenet\\\\n04033995\\\\'\n",
      " 'D:/data/imagenet\\\\n04037443\\\\' 'D:/data/imagenet\\\\n04041544\\\\'\n",
      " 'D:/data/imagenet\\\\n04065272\\\\' 'D:/data/imagenet\\\\n04069434\\\\'\n",
      " 'D:/data/imagenet\\\\n04081281\\\\' 'D:/data/imagenet\\\\n04090263\\\\'\n",
      " 'D:/data/imagenet\\\\n04118538\\\\' 'D:/data/imagenet\\\\n04125021\\\\'\n",
      " 'D:/data/imagenet\\\\n04131690\\\\' 'D:/data/imagenet\\\\n04146614\\\\'\n",
      " 'D:/data/imagenet\\\\n04147183\\\\' 'D:/data/imagenet\\\\n04149813\\\\'\n",
      " 'D:/data/imagenet\\\\n04152593\\\\' 'D:/data/imagenet\\\\n04162706\\\\'\n",
      " 'D:/data/imagenet\\\\n04201297\\\\' 'D:/data/imagenet\\\\n04204347\\\\'\n",
      " 'D:/data/imagenet\\\\n04209239\\\\' 'D:/data/imagenet\\\\n04229816\\\\'\n",
      " 'D:/data/imagenet\\\\n04238763\\\\' 'D:/data/imagenet\\\\n04239074\\\\'\n",
      " 'D:/data/imagenet\\\\n04243546\\\\' 'D:/data/imagenet\\\\n04252077\\\\'\n",
      " 'D:/data/imagenet\\\\n04252225\\\\' 'D:/data/imagenet\\\\n04259630\\\\'\n",
      " 'D:/data/imagenet\\\\n04263257\\\\' 'D:/data/imagenet\\\\n04266014\\\\'\n",
      " 'D:/data/imagenet\\\\n04273569\\\\' 'D:/data/imagenet\\\\n04275548\\\\'\n",
      " 'D:/data/imagenet\\\\n04285008\\\\' 'D:/data/imagenet\\\\n04286575\\\\'\n",
      " 'D:/data/imagenet\\\\n04310018\\\\' 'D:/data/imagenet\\\\n04311004\\\\'\n",
      " 'D:/data/imagenet\\\\n04317175\\\\' 'D:/data/imagenet\\\\n04325704\\\\'\n",
      " 'D:/data/imagenet\\\\n04326547\\\\' 'D:/data/imagenet\\\\n04328186\\\\'\n",
      " 'D:/data/imagenet\\\\n04330267\\\\' 'D:/data/imagenet\\\\n04335435\\\\'\n",
      " 'D:/data/imagenet\\\\n04344873\\\\' 'D:/data/imagenet\\\\n04350905\\\\'\n",
      " 'D:/data/imagenet\\\\n04355933\\\\' 'D:/data/imagenet\\\\n04356056\\\\'\n",
      " 'D:/data/imagenet\\\\n04370456\\\\' 'D:/data/imagenet\\\\n04389033\\\\'\n",
      " 'D:/data/imagenet\\\\n04404412\\\\' 'D:/data/imagenet\\\\n04409515\\\\'\n",
      " 'D:/data/imagenet\\\\n04417672\\\\' 'D:/data/imagenet\\\\n04418357\\\\'\n",
      " 'D:/data/imagenet\\\\n04428191\\\\' 'D:/data/imagenet\\\\n04435653\\\\'\n",
      " 'D:/data/imagenet\\\\n04458633\\\\' 'D:/data/imagenet\\\\n04461696\\\\'\n",
      " 'D:/data/imagenet\\\\n04465501\\\\' 'D:/data/imagenet\\\\n04467665\\\\'\n",
      " 'D:/data/imagenet\\\\n04479046\\\\' 'D:/data/imagenet\\\\n04483307\\\\'\n",
      " 'D:/data/imagenet\\\\n04487081\\\\' 'D:/data/imagenet\\\\n04501370\\\\'\n",
      " 'D:/data/imagenet\\\\n04523525\\\\' 'D:/data/imagenet\\\\n04525305\\\\'\n",
      " 'D:/data/imagenet\\\\n04542943\\\\' 'D:/data/imagenet\\\\n04548362\\\\'\n",
      " 'D:/data/imagenet\\\\n04550184\\\\' 'D:/data/imagenet\\\\n04552348\\\\'\n",
      " 'D:/data/imagenet\\\\n04579432\\\\' 'D:/data/imagenet\\\\n04584207\\\\'\n",
      " 'D:/data/imagenet\\\\n04589890\\\\' 'D:/data/imagenet\\\\n04590129\\\\'\n",
      " 'D:/data/imagenet\\\\n04591157\\\\' 'D:/data/imagenet\\\\n04592741\\\\'\n",
      " 'D:/data/imagenet\\\\n04604644\\\\' 'D:/data/imagenet\\\\n04606251\\\\'\n",
      " 'D:/data/imagenet\\\\n04612504\\\\' 'D:/data/imagenet\\\\n04613696\\\\'\n",
      " 'D:/data/imagenet\\\\n06359193\\\\' 'D:/data/imagenet\\\\n07565083\\\\'\n",
      " 'D:/data/imagenet\\\\n07579787\\\\' 'D:/data/imagenet\\\\n07584110\\\\'\n",
      " 'D:/data/imagenet\\\\n07614500\\\\' 'D:/data/imagenet\\\\n07697313\\\\'\n",
      " 'D:/data/imagenet\\\\n07711569\\\\' 'D:/data/imagenet\\\\n07717410\\\\'\n",
      " 'D:/data/imagenet\\\\n07730033\\\\' 'D:/data/imagenet\\\\n07802026\\\\'\n",
      " 'D:/data/imagenet\\\\n07831146\\\\' 'D:/data/imagenet\\\\n07836838\\\\'\n",
      " 'D:/data/imagenet\\\\n07860988\\\\' 'D:/data/imagenet\\\\n07875152\\\\'\n",
      " 'D:/data/imagenet\\\\n07880968\\\\' 'D:/data/imagenet\\\\n07920052\\\\'\n",
      " 'D:/data/imagenet\\\\n07932039\\\\' 'D:/data/imagenet\\\\n09193705\\\\'\n",
      " 'D:/data/imagenet\\\\n09246464\\\\' 'D:/data/imagenet\\\\n09256479\\\\'\n",
      " 'D:/data/imagenet\\\\n09288635\\\\' 'D:/data/imagenet\\\\n09332890\\\\'\n",
      " 'D:/data/imagenet\\\\n09399592\\\\' 'D:/data/imagenet\\\\n09421951\\\\'\n",
      " 'D:/data/imagenet\\\\n09428293\\\\' 'D:/data/imagenet\\\\n09468604\\\\'\n",
      " 'D:/data/imagenet\\\\n09472597\\\\' 'D:/data/imagenet\\\\n10148035\\\\'\n",
      " 'D:/data/imagenet\\\\n10565667\\\\' 'D:/data/imagenet\\\\n11879895\\\\'\n",
      " 'D:/data/imagenet\\\\n11939491\\\\' 'D:/data/imagenet\\\\n12057211\\\\'\n",
      " 'D:/data/imagenet\\\\n12998815\\\\' 'D:/data/imagenet\\\\n13044778\\\\']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Loading the list from the pickle file\n",
    "file_path = r\"D:\\combo_list.pickle\"  # Update the file path if necessary\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_combo_list = pickle.load(file)\n",
    "\n",
    "print(\"Combo list loaded successfully.\")\n",
    "print(loaded_combo_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12fe31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b7ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6bd347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fba0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ec790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87186a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc427dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a762d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d5acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571ec63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96fd7ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: F:\\D-Video\\Python\n",
      "File is readable: F:\\D-Video\\Python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = r\"F:\\D-Video\\Python\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"File exists: {file_path}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {file_path}\")\n",
    "\n",
    "# Check if the file is readable\n",
    "if os.access(file_path, os.R_OK):\n",
    "    print(f\"File is readable: {file_path}\")\n",
    "else:\n",
    "    print(f\"File is not readable: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25eec36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0f1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e5a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54915b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
