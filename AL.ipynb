{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cbe26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab52343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 512\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "hidden_units = 512\n",
    "projection_units = 256\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05\n",
    "\n",
    "import glob\n",
    "\n",
    "# Invasive category\n",
    "invasive_dirs = [\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\Veligers',\n",
    "    r'D:\\VeligerData\\invasive',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Pedi-Zebra Veligers',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1a To Baylor\\Preserved Zebra Ped 1a To Baylor\\Sorted Images\\Preserved Zebra Ped 1a',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Zebra Pediveliger Image1a\\Zebra Pediveligers',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Umbonal',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Zebra D-Hinge',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal'\n",
    "]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\NonVeligers\\Images_001',\n",
    "    r'D:\\VeligerData\\noninvasive',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image2 To Baylor\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image12 To Baylor_3\\Ostracods Day 2 Image12 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Not Veligers\\O1',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Not'\n",
    "]\n",
    "\n",
    "\n",
    "#invasive_dirs = [r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal']\n",
    "#non_invasive_dirs = [r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not']\n",
    "\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3114ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\VeligerData\\\\USGS Labled Zebra\\\\USGS Labled Zebra\\\\Baylor Preserved Zebra Umbo 1 Image1\\\\Baylor Preserved Zebra Umbo 1 Image1\\\\Sorted Images\\\\Umbonal']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invasive_subdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ef8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n",
    "\n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c50cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(32, 32)):\n",
    "    # List to store image files\n",
    "    image_files = []\n",
    "    # List to store labels\n",
    "    labels = []\n",
    "\n",
    "    # Retrieve image files and create labels for each directory in y1\n",
    "    for directory in y1:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    # Add the file path to the image_files list\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                    # Add the label to the labels list\n",
    "                    \n",
    "\n",
    "    # List to store preprocessed images\n",
    "    images = []\n",
    "\n",
    "    # Preprocess each image\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            # Read the image using PIL\n",
    "            image = Image.open(file)\n",
    "            # Resize the image using tf.image.resize_with_crop_or_pad()\n",
    "            image = tf.image.resize_with_crop_or_pad(\n",
    "                tf.keras.preprocessing.image.img_to_array(image),\n",
    "                target_size[0],\n",
    "                target_size[1]\n",
    "            )\n",
    "            # Normalize the image pixels for ML training\n",
    "            image = image / 255.0\n",
    "            # Add the preprocessed image to the images list\n",
    "            images.append(image)\n",
    "            labels.append(label_num)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "    # Convert the images and labels lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61753676",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0,Y0 = preprocess_images(y1, label_num = 0)\n",
    "X1,Y1 = preprocess_images(y2, label_num = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceadfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adc90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc704243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "#train_labels_categorical = train_labels\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming you have the original train_images and train_labels_categorical\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.2, random_state=42)\n",
    "X_train, x_unlab, Y_train, y_unlab = train_test_split( X_train, Y_train, test_size=.9993, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28b6aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 143023\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train),len(y_unlab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1d3beea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178904 42055 136849\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels),np.count_nonzero(train_labels == 1),np.count_nonzero(train_labels == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "051c54d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_random_images(X_train, Y_train, label0_count=5, label1_count=5):\n",
    "    label0_indices = np.where(Y_train == 0)[0]\n",
    "    label1_indices = np.where(Y_train == 1)[0]\n",
    "\n",
    "    selected_label0_indices = np.random.choice(label0_indices, label0_count, replace=False)\n",
    "    selected_label1_indices = np.random.choice(label1_indices, label1_count, replace=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    for i, idx in enumerate(selected_label0_indices):\n",
    "        plt.subplot(2, label0_count, i + 1)\n",
    "        plt.imshow(X_train[idx])\n",
    "        plt.axis('off')\n",
    "\n",
    "    for i, idx in enumerate(selected_label1_indices):\n",
    "        plt.subplot(2, label1_count, label0_count + i + 1)\n",
    "        plt.imshow(X_train[idx])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d3aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8329988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c7d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def test(model, X_test, Y_test):\n",
    "    print(\"\\n--------------------------------------\\n\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Convert one-hot encoded predictions to class labels.\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    Y_test_classes = Y_test.argmax(axis=1)\n",
    "\n",
    "    # Calculate the F1 score.\n",
    "    f1 = f1_score(Y_test_classes, y_pred_classes, average='weighted')\n",
    "    \n",
    "    # Calculate the F1 score for class label 1.\n",
    "    class_label = 1\n",
    "    f1_class_label_1 = f1_score(Y_test_classes, y_pred_classes, labels=[class_label], average=None)\n",
    "    \n",
    "    balanced_acc = balanced_accuracy_score(Y_test_classes, y_pred_classes)\n",
    "    print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "    print(\"F1 score for class label 1:\", f1_class_label_1[0])\n",
    "    print(\"F1 score on test data:\", f1)\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "def train(model,X_train, Y_train, epoch):\n",
    "    \n",
    "    print(f\"Starting to train with {len(Y_train)} samples\")\n",
    "\n",
    "    history = model.fit(X_train, Y_train, batch_size = 128, epochs=epoch,validation_split=.20)\n",
    "\n",
    "    return model\n",
    "\n",
    "def print_acc(model, X_test, Y_test):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    # Convert one-hot encoded predictions to class labels.\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    Y_test_classes = Y_test\n",
    "\n",
    "    # Calculate the F1 score.\n",
    "    f1 = f1_score(Y_test_classes, y_pred_classes, average='weighted')\n",
    "    \n",
    "    # Calculate the F1 score for class label 1.\n",
    "    class_label = 1\n",
    "    f1_class_label_1 = f1_score(Y_test_classes, y_pred_classes, labels=[class_label], average=None)\n",
    "    \n",
    "    balanced_acc = balanced_accuracy_score(Y_test_classes, y_pred_classes)\n",
    "    print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "    print(\"F1 score for class label 1:\", f1_class_label_1[0])\n",
    "    print(\"F1 score on test data:\", f1)\n",
    "    print(\"-\" * 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592332d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c514f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee15786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "num_classes = 2\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "    # Add custom top layers\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bc3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92ef04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_epoch = 10\n",
    "ct_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"............................................Random Sample...................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd742dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd16bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train with 100 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.6973 - accuracy: 0.7375 - val_loss: 0.7329 - val_accuracy: 0.6000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.1104 - accuracy: 0.8000 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6797 - accuracy: 0.8000 - val_loss: 1.0235 - val_accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6742 - accuracy: 0.8750 - val_loss: 2.0282 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3762 - accuracy: 0.9500 - val_loss: 3.5376 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2392 - accuracy: 0.9750 - val_loss: 5.3618 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1435 - accuracy: 0.9750 - val_loss: 7.4083 - val_accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0816 - accuracy: 0.9875 - val_loss: 9.4109 - val_accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 11.1647 - val_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0196 - accuracy: 0.9875 - val_loss: 12.7948 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6636582201127257\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 110 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 11s 11s/step - loss: 1.0567 - accuracy: 0.9773 - val_loss: 9.9923 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1716 - accuracy: 0.9659 - val_loss: 12.3693 - val_accuracy: 0.8636\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0575 - accuracy: 0.9886 - val_loss: 17.3328 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 24.3808 - val_accuracy: 0.8636\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 35.0569 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 6.8835e-04 - accuracy: 1.0000 - val_loss: 45.9206 - val_accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.8142e-04 - accuracy: 1.0000 - val_loss: 58.2154 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.5401e-04 - accuracy: 1.0000 - val_loss: 72.5414 - val_accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.5091e-04 - accuracy: 1.0000 - val_loss: 87.4965 - val_accuracy: 0.8636\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 8.6089e-05 - accuracy: 1.0000 - val_loss: 103.3717 - val_accuracy: 0.8636\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6636582201127257\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 120 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1497 - accuracy: 0.9792 - val_loss: 856.5794 - val_accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3118 - accuracy: 0.9583 - val_loss: 979.2148 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1104 - accuracy: 0.9896 - val_loss: 1309.9458 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0965 - accuracy: 0.9583 - val_loss: 2112.2092 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3978 - accuracy: 0.9375 - val_loss: 3166.3145 - val_accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0700 - accuracy: 0.9896 - val_loss: 4053.5676 - val_accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0395 - accuracy: 0.9896 - val_loss: 5347.1938 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0176 - accuracy: 0.9896 - val_loss: 6677.2251 - val_accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0100 - accuracy: 0.9896 - val_loss: 7960.5425 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 8994.0869 - val_accuracy: 0.8750\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6636582201127257\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 130 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 2373.7615 - val_accuracy: 0.8462\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3174 - accuracy: 0.9712 - val_loss: 3109.4185 - val_accuracy: 0.8462\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5395 - accuracy: 0.8942 - val_loss: 2772.2410 - val_accuracy: 0.8462\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1617 - accuracy: 0.9519 - val_loss: 2831.6184 - val_accuracy: 0.8462\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0634 - accuracy: 0.9712 - val_loss: 3162.0769 - val_accuracy: 0.8462\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0386 - accuracy: 0.9712 - val_loss: 3592.9338 - val_accuracy: 0.8462\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0273 - accuracy: 0.9808 - val_loss: 4281.7964 - val_accuracy: 0.8462\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0229 - accuracy: 0.9904 - val_loss: 5169.8184 - val_accuracy: 0.8462\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 6159.9355 - val_accuracy: 0.8462\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 7061.3462 - val_accuracy: 0.8462\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6636582201127257\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 140 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0217 - accuracy: 0.9911 - val_loss: 8119.1650 - val_accuracy: 0.8929\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3114 - accuracy: 0.9286 - val_loss: 9196.2832 - val_accuracy: 0.8929\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.1932 - accuracy: 0.8839 - val_loss: 5454.2710 - val_accuracy: 0.8929\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0759 - accuracy: 0.9554 - val_loss: 4477.2896 - val_accuracy: 0.8929\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 4022.1726 - val_accuracy: 0.8929\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 4137.7861 - val_accuracy: 0.8929\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4191.8799 - val_accuracy: 0.8929\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4107.1074 - val_accuracy: 0.8929\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 8.0793e-04 - accuracy: 1.0000 - val_loss: 3667.4238 - val_accuracy: 0.8929\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.7379e-04 - accuracy: 1.0000 - val_loss: 3269.5535 - val_accuracy: 0.8929\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6636582201127257\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 150 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 1710.2006 - val_accuracy: 0.9333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.2186 - accuracy: 0.9417 - val_loss: 2464.9126 - val_accuracy: 0.9333\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0583 - accuracy: 0.9917 - val_loss: 2532.9575 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0204 - accuracy: 0.9917 - val_loss: 3095.7839 - val_accuracy: 0.9333\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2946.7449 - val_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2959.9133 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3102.4219 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3330.5161 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.1323e-04 - accuracy: 1.0000 - val_loss: 3547.8010 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 2.8449e-04 - accuracy: 1.0000 - val_loss: 3699.4692 - val_accuracy: 0.9333\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6636582201127257\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 160 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.0118 - accuracy: 0.9922 - val_loss: 7024.4805 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.3762 - accuracy: 0.8984 - val_loss: 21841.8730 - val_accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6782 - accuracy: 0.9609 - val_loss: 31925.5352 - val_accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1099 - accuracy: 0.9688 - val_loss: 38545.9336 - val_accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1431 - accuracy: 0.9531 - val_loss: 46084.1328 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1491 - accuracy: 0.9609 - val_loss: 51578.5820 - val_accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1161 - accuracy: 0.9766 - val_loss: 52874.1484 - val_accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0856 - accuracy: 0.9844 - val_loss: 52239.6328 - val_accuracy: 0.9062\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0571 - accuracy: 0.9844 - val_loss: 54724.4258 - val_accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 57035.6914 - val_accuracy: 0.9062\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6636582201127257\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 170 samples\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.1876 - accuracy: 0.9559 - val_loss: 225658.5469 - val_accuracy: 0.8529\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.4087 - accuracy: 0.9265 - val_loss: 200557.4219 - val_accuracy: 0.8529\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.8897 - accuracy: 0.8529 - val_loss: 201828.9219 - val_accuracy: 0.8529\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.3091 - accuracy: 0.9118 - val_loss: 158549.2969 - val_accuracy: 0.8529\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 3.7495 - accuracy: 0.9338 - val_loss: 35437.1562 - val_accuracy: 0.8529\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1861 - accuracy: 0.9265 - val_loss: 3454.3389 - val_accuracy: 0.8529\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.1715 - accuracy: 0.9559 - val_loss: 4517.0171 - val_accuracy: 0.1471\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.3874 - accuracy: 0.8824 - val_loss: 838.3635 - val_accuracy: 0.8529\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.5151 - accuracy: 0.8529 - val_loss: 2557.9497 - val_accuracy: 0.8529\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.5936 - accuracy: 0.8162 - val_loss: 5073.8276 - val_accuracy: 0.8529\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.4993792448696414\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6631912481154125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 180 samples\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 2s/step - loss: 0.4333 - accuracy: 0.8264 - val_loss: 10150.1006 - val_accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.3661 - accuracy: 0.9306 - val_loss: 3444.3108 - val_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.3155 - accuracy: 0.9444 - val_loss: 4216.0898 - val_accuracy: 0.5556\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.1625 - accuracy: 0.9583 - val_loss: 5922.4575 - val_accuracy: 0.5833\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.8926 - accuracy: 0.9653 - val_loss: 3021.3210 - val_accuracy: 0.8056\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4777 - accuracy: 0.9306 - val_loss: 996.9871 - val_accuracy: 0.8611\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3947 - accuracy: 0.9236 - val_loss: 149.7678 - val_accuracy: 0.7778\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2365 - accuracy: 0.9514 - val_loss: 39.6915 - val_accuracy: 0.6111\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.3471 - accuracy: 0.9306 - val_loss: 28.0297 - val_accuracy: 0.5833\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2985 - accuracy: 0.9583 - val_loss: 16.2997 - val_accuracy: 0.5556\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.32595565473061605\n",
      "F1 score for class label 1: 0.045440806045340044\n",
      "F1 score on test data: 0.4955943704612336\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 190 samples\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.3013 - accuracy: 0.9474 - val_loss: 10.0080 - val_accuracy: 0.5263\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.5799 - accuracy: 0.9145 - val_loss: 3.0796 - val_accuracy: 0.4474\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.2298 - accuracy: 0.9013 - val_loss: 8.2274 - val_accuracy: 0.6842\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.1901 - accuracy: 0.9145 - val_loss: 61.6617 - val_accuracy: 0.7105\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.1492 - accuracy: 0.9605 - val_loss: 138.3691 - val_accuracy: 0.2632\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.0909 - accuracy: 0.9868 - val_loss: 194.7851 - val_accuracy: 0.2368\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0772 - accuracy: 0.9803 - val_loss: 240.9913 - val_accuracy: 0.3684\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.0521 - accuracy: 0.9868 - val_loss: 219.4131 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.1170 - accuracy: 0.9737 - val_loss: 217.4534 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0483 - accuracy: 0.9803 - val_loss: 265.1801 - val_accuracy: 0.5000\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.30799845040659535\n",
      "F1 score for class label 1: 0.02616337128020771\n",
      "F1 score on test data: 0.48184513749331054\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "Starting to train with 200 samples\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 2s/step - loss: 0.0474 - accuracy: 0.9875 - val_loss: 398.4272 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6233 - accuracy: 0.9625 - val_loss: 86.3829 - val_accuracy: 0.3750\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.5362 - accuracy: 0.9375 - val_loss: 10.1139 - val_accuracy: 0.4750\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.1751 - accuracy: 0.9438 - val_loss: 28.4210 - val_accuracy: 0.5250\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.3185 - accuracy: 0.8875 - val_loss: 112.1983 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2081 - accuracy: 0.9250 - val_loss: 259.2613 - val_accuracy: 0.6250\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.1503 - accuracy: 0.9750 - val_loss: 356.0274 - val_accuracy: 0.7250\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0933 - accuracy: 0.9875 - val_loss: 366.0769 - val_accuracy: 0.7250\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0551 - accuracy: 0.9875 - val_loss: 301.4079 - val_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0428 - accuracy: 0.9750 - val_loss: 204.4186 - val_accuracy: 0.7750\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.4911630136507844\n",
      "F1 score for class label 1: 0.271969696969697\n",
      "F1 score on test data: 0.595881577831489\n",
      "----------------------------------------------------------------------------------------------------\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "def train_active_learning_models(\n",
    "    model,\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    x_unlab,\n",
    "    y_unlab,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    num_iterations=5):\n",
    "    \n",
    "    test(model, X_test, Y_test)\n",
    "    \n",
    "    d = 100/num_iterations\n",
    "    l = len(y_unlab)\n",
    "    x = 10\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "\n",
    "        model = tf.keras.models.load_model('saved_model/my_model')\n",
    "        \n",
    "        l = len(y_unlab)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        print(\"Iteration : \")\n",
    "        \n",
    "        print(iteration)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "         \n",
    "        #generate random number and substract from all numbers\n",
    "        rnd = random.sample(range(0, len(x_unlab)), x)\n",
    "        all_indices = list(range(1, l))\n",
    "        main_list = list(set(all_indices) - set(rnd))\n",
    "        \n",
    "        #add those index to from unlablled set to training set\n",
    "        img_list = ([x_unlab[i] for i in rnd])\n",
    "        new_lab = img_list\n",
    "        arr = np.concatenate((X_train, new_lab))\n",
    "        X_train = arr\n",
    "\n",
    "        #check labels in the set and add to training data\n",
    "        new_y = y_unlab[rnd]\n",
    "        arr = np.concatenate((Y_train, new_y))\n",
    "        Y_train = arr\n",
    "        ploty = np.argmax(new_y,axis = 1)\n",
    "        #create the new unlabelled set\n",
    "        x_unlab = ([x_unlab[i] for i in main_list])\n",
    "\n",
    "        #create the new unlabelled label set\n",
    "        y_unlab = y_unlab[main_list]\n",
    "        \n",
    "        \n",
    "        #train on data\n",
    "        model = train(model,X_train, Y_train, ct_epoch)   #10\n",
    "        \n",
    "        #test for final time\n",
    "        test(model, X_test, Y_test)\n",
    "\n",
    "        model.save('saved_model/my_model')\n",
    "\n",
    "        del model\n",
    "\n",
    "model = create_model()\n",
    "    \n",
    "model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=\"Adam\",\n",
    "        metrics='accuracy'   )\n",
    "    \n",
    "model = train(model,X_train, Y_train, st_epoch)  #50\n",
    "\n",
    "model.save('saved_model/my_model')\n",
    "\n",
    "active_learning_model = train_active_learning_models(model,X_train, Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e77ed486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f47e99ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbc3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeec797",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"............................................Entropy...................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe5a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "#train_labels_categorical = train_labels\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming you have the original train_images and train_labels_categorical\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.2, random_state=42)\n",
    "X_train, x_unlab, Y_train, y_unlab = train_test_split( X_train, Y_train, test_size=.9993, random_state=42 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ec3d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = X_train\n",
    "YT= Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4041c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2429c643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 9s 380ms/step - loss: 0.8370 - accuracy: 0.8100\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.5490 - accuracy: 0.8100\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4513 - accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.3109 - accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2632 - accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2250 - accuracy: 0.9300\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4508 - accuracy: 0.8800\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.4254 - accuracy: 0.8900\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3890 - accuracy: 0.8600\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5562 - accuracy: 0.8900\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 0\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 7s 317ms/step - loss: 0.4576 - accuracy: 0.8545\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5214 - accuracy: 0.8273\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.3861 - accuracy: 0.8273\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3614 - accuracy: 0.8273\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3376 - accuracy: 0.8455\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3239 - accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3554 - accuracy: 0.8909\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2964 - accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2378 - accuracy: 0.9182\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2239 - accuracy: 0.9091\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 1\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 90ms/step - loss: 0.6215 - accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.3250 - accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7392 - accuracy: 0.8917\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.2674 - accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2074 - accuracy: 0.9250\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.1943 - accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.3407 - accuracy: 0.8583\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.1335 - accuracy: 0.9250\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.1569 - accuracy: 0.9250\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.1303 - accuracy: 0.9333\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.4318723992185571\n",
      "F1 score for class label 1: 0.003255738238645613\n",
      "F1 score on test data: 0.606099212867846\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 2\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 7s 345ms/step - loss: 0.5715 - accuracy: 0.8692\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5134 - accuracy: 0.8308\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4381 - accuracy: 0.8538\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4195 - accuracy: 0.8538\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3676 - accuracy: 0.8538\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3968 - accuracy: 0.8538\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7104 - accuracy: 0.8769\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.4450 - accuracy: 0.8692\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.8931 - accuracy: 0.8385\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4718 - accuracy: 0.8308\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 3\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 7s 309ms/step - loss: 0.4552 - accuracy: 0.8429\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3638 - accuracy: 0.8714\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2334 - accuracy: 0.8786\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3617 - accuracy: 0.8500\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4882 - accuracy: 0.8714\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2043 - accuracy: 0.9429\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.1439 - accuracy: 0.9643\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0959 - accuracy: 0.9429\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.1309 - accuracy: 0.9714\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.1960 - accuracy: 0.9500\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5092445385840831\n",
      "F1 score for class label 1: 0.15607130844265052\n",
      "F1 score on test data: 0.6716226780415189\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 4\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 6s 186ms/step - loss: 0.3684 - accuracy: 0.9067\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.6005 - accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3262 - accuracy: 0.8467\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2389 - accuracy: 0.8667\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2298 - accuracy: 0.8733\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.1712 - accuracy: 0.9200\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.1308 - accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.1528 - accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.1168 - accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.1231 - accuracy: 0.9533\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.49975158293808336\n",
      "F1 score for class label 1: 0.00047036688617121356\n",
      "F1 score on test data: 0.6602157290577758\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 5\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 5s 48ms/step - loss: 1.2267 - accuracy: 0.9125\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4425 - accuracy: 0.9187\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.1895 - accuracy: 0.9062\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3462 - accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4535 - accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2450 - accuracy: 0.9438\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.1972 - accuracy: 0.9438\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.1523 - accuracy: 0.9563\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.1315 - accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2780 - accuracy: 0.9250\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5000040012935775\n",
      "F1 score for class label 1: 0.00023568230025925057\n",
      "F1 score on test data: 0.6603829753266057\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 6\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 6s 258ms/step - loss: 1.2208 - accuracy: 0.8765\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.3942 - accuracy: 0.9118\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.2901 - accuracy: 0.8882\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.2478 - accuracy: 0.8882\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2209 - accuracy: 0.9118\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.3149 - accuracy: 0.9412\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.3693 - accuracy: 0.9588\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.4178 - accuracy: 0.9235\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.2832 - accuracy: 0.9235\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1826 - accuracy: 0.9471\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 7\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 7s 170ms/step - loss: 1.2047 - accuracy: 0.9167\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5438 - accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.3140 - accuracy: 0.8722\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2961 - accuracy: 0.8944\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.2122 - accuracy: 0.9111\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1700 - accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1502 - accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.2323 - accuracy: 0.9389\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.1605 - accuracy: 0.9278\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.2264 - accuracy: 0.9278\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.452677627225394\n",
      "F1 score for class label 1: 0.1021059349074665\n",
      "F1 score on test data: 0.6190106690726136\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 8\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 7s 179ms/step - loss: 1.6891 - accuracy: 0.8947\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.3840 - accuracy: 0.9211\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.3494 - accuracy: 0.9421\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.2514 - accuracy: 0.9211\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.2183 - accuracy: 0.9211\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.1536 - accuracy: 0.9474\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1293 - accuracy: 0.9632\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.2790 - accuracy: 0.9316\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.2457 - accuracy: 0.9368\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1799 - accuracy: 0.9316\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.475418377890872\n",
      "F1 score for class label 1: 0.04843721440321696\n",
      "F1 score on test data: 0.6433864140928752\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 9\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 7s 112ms/step - loss: 0.5859 - accuracy: 0.9050\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.2149 - accuracy: 0.9400\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 1.3611 - accuracy: 0.9550\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.2118 - accuracy: 0.9550\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.2982 - accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.2316 - accuracy: 0.8950\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.1921 - accuracy: 0.9050\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.1865 - accuracy: 0.9100\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.5798 - accuracy: 0.9250\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.2254 - accuracy: 0.9300\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.7092506599370423\n",
      "F1 score for class label 1: 0.5174147886012294\n",
      "F1 score on test data: 0.5841690070906369\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "###ENTROPY###\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "def create_classifier(input_shape=(32, 32, 3)):\n",
    "    base_model = ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=input_shape, pooling=\"avg\")\n",
    "    x = base_model.output\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    classifier = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier()\n",
    "classifier.fit(X_train, Y_train, epochs=st_epoch)  # 50\n",
    "classifier.save('saved_model/my_model')\n",
    "test(classifier, X_test, Y_test)\n",
    "num_iterations = 10\n",
    "num_queries = 10\n",
    "x_train_unlabeled = x_unlab\n",
    "y_train_unlabeled = y_unlab\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    print(\"\\n Iteration\",iteration)\n",
    "    print(\"\\n\")\n",
    "    # Compute entropy for each sample\n",
    "    classifier = tf.keras.models.load_model('saved_model/my_model')\n",
    "    probabilities = classifier.predict(x_train_unlabeled)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-9), axis=1)\n",
    "    \n",
    "    # Select samples with highest entropy\n",
    "    query_indices = np.argsort(entropy)[-num_queries:]\n",
    "    x_query = x_train_unlabeled[query_indices]\n",
    "    y_query = y_train_unlabeled[query_indices]\n",
    "    \n",
    "    # Remove queried samples from the unlabeled pool\n",
    "    x_train_unlabeled = np.delete(x_train_unlabeled, query_indices, axis=0)\n",
    "    y_train_unlabeled = np.delete(y_train_unlabeled, query_indices, axis=0)\n",
    "    \n",
    "    # Add queried samples to the training dataset\n",
    "    X_train = np.concatenate([X_train, x_query], axis=0)\n",
    "    Y_train = np.concatenate([Y_train, y_query], axis=0)\n",
    "    \n",
    "    # Train the classifier on the updated training dataset\n",
    "    classifier.fit(X_train, Y_train, epochs=ct_epoch)    #10\n",
    "    \n",
    "    test(classifier, X_test, Y_test)\n",
    "    del classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"............................................Confidence...................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264838f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5927b864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 7s 74ms/step - loss: 0.7859 - accuracy: 0.7000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.3778 - accuracy: 0.8700\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2803 - accuracy: 0.9200\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2634 - accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.1760 - accuracy: 0.9400\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.4577 - accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7546 - accuracy: 0.8800\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.5157 - accuracy: 0.8800\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.5479 - accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.4318 - accuracy: 0.9100\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 0\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 74ms/step - loss: 0.5862 - accuracy: 0.8909\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 1.6170 - accuracy: 0.8545\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.7187 - accuracy: 0.8909\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.4966 - accuracy: 0.8545\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5543 - accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.4605 - accuracy: 0.8818\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.4195 - accuracy: 0.8364\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.3890 - accuracy: 0.9091\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.3695 - accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.5648 - accuracy: 0.9091\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 1\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 5s 97ms/step - loss: 1.2321 - accuracy: 0.8667\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.4122 - accuracy: 0.8500\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.3769 - accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2985 - accuracy: 0.8833\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.1950 - accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2288 - accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2667 - accuracy: 0.8833\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.3321 - accuracy: 0.9000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.4505 - accuracy: 0.9250\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.2607 - accuracy: 0.9250\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 2\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 8s 64ms/step - loss: 1.4343 - accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8334 - accuracy: 0.8308\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8117 - accuracy: 0.8308\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4673 - accuracy: 0.8462\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.5409 - accuracy: 0.8231\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.4981 - accuracy: 0.8385\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3950 - accuracy: 0.8692\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4024 - accuracy: 0.8308\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.3715 - accuracy: 0.8308\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.5117 - accuracy: 0.8231\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5252219975115712\n",
      "F1 score for class label 1: 0.3944880400869812\n",
      "F1 score on test data: 0.18834183635803184\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 3\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 6s 73ms/step - loss: 1.0773 - accuracy: 0.8143\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.4223 - accuracy: 0.8357\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4285 - accuracy: 0.8286\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5352 - accuracy: 0.8357\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3843 - accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3118 - accuracy: 0.8643\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.5045 - accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.4976 - accuracy: 0.8429\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 0.3625 - accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.3479 - accuracy: 0.8429\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.6370434542382742\n",
      "F1 score for class label 1: 0.4380140115747792\n",
      "F1 score on test data: 0.7704154492179425\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 4\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 6s 58ms/step - loss: 1.3261 - accuracy: 0.7933\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9526 - accuracy: 0.7867\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5715 - accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4410 - accuracy: 0.8133\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.4172 - accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3657 - accuracy: 0.8267\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3179 - accuracy: 0.8800\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.2439 - accuracy: 0.8867\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.2589 - accuracy: 0.8933\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.1840 - accuracy: 0.9200\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.49983515879702556\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6602342943943255\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 5\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 7s 57ms/step - loss: 1.2355 - accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.7685 - accuracy: 0.8188\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.6399 - accuracy: 0.7937\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.5047 - accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.5293 - accuracy: 0.8188\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.4463 - accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3866 - accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.3830 - accuracy: 0.8250\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.3432 - accuracy: 0.8188\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3203 - accuracy: 0.8313\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5255653205929267\n",
      "F1 score for class label 1: 0.39565674255691774\n",
      "F1 score on test data: 0.16961645003460105\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 6\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 7s 94ms/step - loss: 1.0819 - accuracy: 0.8235\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.8247 - accuracy: 0.8235\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.4261 - accuracy: 0.8294\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.7028 - accuracy: 0.7882\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 58ms/step - loss: 0.5301 - accuracy: 0.8059\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.4534 - accuracy: 0.8235\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.4563 - accuracy: 0.8059\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.5203 - accuracy: 0.8294\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.3925 - accuracy: 0.8529\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.4936 - accuracy: 0.8353\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 7\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 8s 99ms/step - loss: 0.7448 - accuracy: 0.8611\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.5607 - accuracy: 0.8222\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.5589 - accuracy: 0.8278\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.7678 - accuracy: 0.8222\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.7780 - accuracy: 0.8056\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.5048 - accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.4556 - accuracy: 0.7944\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.5872 - accuracy: 0.8333\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.4290 - accuracy: 0.8278\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.3609 - accuracy: 0.8444\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.502630696132921\n",
      "F1 score for class label 1: 0.3843306460769842\n",
      "F1 score on test data: 0.10263678781561286\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 8\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 6s 47ms/step - loss: 1.1219 - accuracy: 0.8368\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.5080 - accuracy: 0.8158\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.3805 - accuracy: 0.7895\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.4472 - accuracy: 0.8526\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.2823 - accuracy: 0.8789\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.2784 - accuracy: 0.8737\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 0.2126 - accuracy: 0.9105\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.5083 - accuracy: 0.9105\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.3378 - accuracy: 0.8789\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.2835 - accuracy: 0.9263\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5016951880801892\n",
      "F1 score for class label 1: 0.007045561296383278\n",
      "F1 score on test data: 0.66228728802225\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 9\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 6s 62ms/step - loss: 0.5321 - accuracy: 0.7850\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 0.5584 - accuracy: 0.8350\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.4169 - accuracy: 0.8600\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.3878 - accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.3547 - accuracy: 0.8600\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.3575 - accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.3407 - accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.2734 - accuracy: 0.8950\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 57ms/step - loss: 0.2709 - accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.2319 - accuracy: 0.9050\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.4609179296552982\n",
      "F1 score for class label 1: 0.032303370786516857\n",
      "F1 score on test data: 0.6308217217418866\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train = XT\n",
    "Y_train = YT\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def create_classifier(input_shape=(32, 32, 3), num_classes=2):\n",
    "    base_model = ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=input_shape, pooling=\"avg\")\n",
    "    x = base_model.output\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    classifier = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier()\n",
    "classifier.fit(X_train, Y_train, epochs=st_epoch)  # 50\n",
    "classifier.save('saved_model/my_model')\n",
    "test(classifier, X_test, Y_test)\n",
    "num_iterations = 10\n",
    "num_queries = 10\n",
    "x_train_unlabeled = x_unlab\n",
    "y_train_unlabeled = y_unlab\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    print(\"\\n Iteration\",iteration)\n",
    "    print(\"\\n\")\n",
    "    # Compute confidence for each sample\n",
    "    classifier = tf.keras.models.load_model('saved_model/my_model')\n",
    "    probabilities = classifier.predict(x_train_unlabeled)\n",
    "    confidence = np.max(probabilities, axis=1)\n",
    "\n",
    "    # Select samples with lowest confidence\n",
    "    query_indices = np.argsort(confidence)[:num_queries]\n",
    "    x_query = x_train_unlabeled[query_indices]\n",
    "    y_query = y_train_unlabeled[query_indices]\n",
    "\n",
    "    # Remove queried samples from the unlabeled pool\n",
    "    x_train_unlabeled = np.delete(x_train_unlabeled, query_indices, axis=0)\n",
    "    y_train_unlabeled = np.delete(y_train_unlabeled, query_indices, axis=0)\n",
    "\n",
    "    # Add queried samples to the training dataset\n",
    "    X_train = np.concatenate([X_train, x_query], axis=0)\n",
    "    Y_train = np.concatenate([Y_train, y_query], axis=0)\n",
    "\n",
    "    # Train the classifier on the updated training dataset\n",
    "    classifier.fit(X_train, Y_train, epochs=ct_epoch)\n",
    "    \n",
    "    test(classifier, X_test, Y_test)\n",
    "    del classifier \n",
    "\n",
    "X_train = XT\n",
    "Y_train = YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e99bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"............................................Coreset...................................\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163425d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c56c8342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 7s 70ms/step - loss: 0.6839 - accuracy: 0.6700\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.8596 - accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4683 - accuracy: 0.8300\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.7938 - accuracy: 0.8400\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.4919 - accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4968 - accuracy: 0.8500\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.5058 - accuracy: 0.8700\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4510 - accuracy: 0.9100\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5409 - accuracy: 0.8600\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.4820 - accuracy: 0.8500\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 0\n",
      "\n",
      "\n",
      "(143023, 3072)\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 7s 63ms/step - loss: 0.4287 - accuracy: 0.8455\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.3408 - accuracy: 0.8727\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3386 - accuracy: 0.8091\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.2389 - accuracy: 0.8727\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3117 - accuracy: 0.8909\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.2978 - accuracy: 0.9091\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 2.3542 - accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.3108 - accuracy: 0.8636\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3066 - accuracy: 0.9091\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2425 - accuracy: 0.9182\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 1\n",
      "\n",
      "\n",
      "(143013, 3072)\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 8s 48ms/step - loss: 0.6644 - accuracy: 0.8667\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.4076 - accuracy: 0.9000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4593 - accuracy: 0.8917\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3242 - accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.3643 - accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2596 - accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2368 - accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2593 - accuracy: 0.8833\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1884 - accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.1428 - accuracy: 0.9250\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.4492490368758957\n",
      "F1 score for class label 1: 0.06409468183215494\n",
      "F1 score on test data: 0.6194529384792856\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 2\n",
      "\n",
      "\n",
      "(143003, 3072)\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 5s 51ms/step - loss: 0.5948 - accuracy: 0.8615\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.3652 - accuracy: 0.8692\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 1.0706 - accuracy: 0.8615\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.9389 - accuracy: 0.8385\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.5873 - accuracy: 0.8462\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.5033 - accuracy: 0.8615\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4653 - accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4033 - accuracy: 0.8923\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.6673 - accuracy: 0.8769\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.3733 - accuracy: 0.8846\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.3832546370557803\n",
      "F1 score on test data: 0.09085173224636339\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 3\n",
      "\n",
      "\n",
      "(142993, 3072)\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 6s 65ms/step - loss: 0.6141 - accuracy: 0.8429\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.8802 - accuracy: 0.8429\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.5938 - accuracy: 0.8143\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4249 - accuracy: 0.8429\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3959 - accuracy: 0.8643\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.3364 - accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.2989 - accuracy: 0.9143\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2319 - accuracy: 0.9357\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2254 - accuracy: 0.9357\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.2222 - accuracy: 0.9143\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.41742321634230395\n",
      "F1 score for class label 1: 0.28551305998713905\n",
      "F1 score on test data: 0.37305661134940865\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 4\n",
      "\n",
      "\n",
      "(142983, 3072)\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 6s 55ms/step - loss: 0.8496 - accuracy: 0.8533\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.1887 - accuracy: 0.8667\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.5192 - accuracy: 0.8067\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.4858 - accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4742 - accuracy: 0.8267\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4619 - accuracy: 0.8267\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4544 - accuracy: 0.8267\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4267 - accuracy: 0.8267\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4197 - accuracy: 0.8267\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.4126 - accuracy: 0.8267\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 5\n",
      "\n",
      "\n",
      "(142973, 3072)\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 7s 63ms/step - loss: 0.5638 - accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5682 - accuracy: 0.8813\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4255 - accuracy: 0.8875\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2563 - accuracy: 0.9187\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.2069 - accuracy: 0.9438\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.2619 - accuracy: 0.9250\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2395 - accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.1810 - accuracy: 0.9187\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.1512 - accuracy: 0.9563\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2395 - accuracy: 0.9312\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 6\n",
      "\n",
      "\n",
      "(142963, 3072)\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 6s 59ms/step - loss: 0.4721 - accuracy: 0.8176\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.4838 - accuracy: 0.8765\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 1.9765 - accuracy: 0.9059\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.3114 - accuracy: 0.8941\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2880 - accuracy: 0.8941\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.2200 - accuracy: 0.9176\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.2475 - accuracy: 0.9118\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.2339 - accuracy: 0.9353\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2278 - accuracy: 0.9118\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.3292 - accuracy: 0.8824\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5104852570189577\n",
      "F1 score for class label 1: 0.04549091324722825\n",
      "F1 score on test data: 0.672296660601598\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 7\n",
      "\n",
      "\n",
      "(142953, 3072)\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 5s 52ms/step - loss: 0.8246 - accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.4268 - accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.3645 - accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.3378 - accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 86ms/step - loss: 0.3099 - accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.2779 - accuracy: 0.9056\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.2965 - accuracy: 0.9222\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3482 - accuracy: 0.8444\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.3937 - accuracy: 0.8389\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.3769 - accuracy: 0.8389\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5\n",
      "F1 score for class label 1: 0.0\n",
      "F1 score on test data: 0.6603578031772476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 8\n",
      "\n",
      "\n",
      "(142943, 3072)\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 6s 86ms/step - loss: 0.5323 - accuracy: 0.8737\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.3718 - accuracy: 0.8789\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.3702 - accuracy: 0.9105\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.2088 - accuracy: 0.9316\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1694 - accuracy: 0.9474\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.5036 - accuracy: 0.9053\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.3069 - accuracy: 0.8421\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.2841 - accuracy: 0.8737\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.2580 - accuracy: 0.8842\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.1965 - accuracy: 0.9053\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5006605503003889\n",
      "F1 score for class label 1: 0.02276825969341749\n",
      "F1 score on test data: 0.6628288878495567\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " Iteration 9\n",
      "\n",
      "\n",
      "(142933, 3072)\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 6s 56ms/step - loss: 0.3945 - accuracy: 0.8750\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.3725 - accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 54ms/step - loss: 0.2270 - accuracy: 0.9300\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.1647 - accuracy: 0.9450\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.1388 - accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.1953 - accuracy: 0.9400\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.1753 - accuracy: 0.9300\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 0.2183 - accuracy: 0.9300\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.1548 - accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 0.1809 - accuracy: 0.9550\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Balanced Accuracy: 0.5220973024941409\n",
      "F1 score for class label 1: 0.14528122020972356\n",
      "F1 score on test data: 0.685377723454296\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Define the k-Center Greedy Algorithm for Coreset Selection\n",
    "def k_center_greedy(data, k):\n",
    "    data = data.reshape(len(data),3072)\n",
    "    print(data.shape)\n",
    "    num_samples, num_features = data.shape\n",
    "    selected_indices = [np.random.randint(num_samples)]  # Start with a randomly selected sample\n",
    "    distances = pairwise_distances(data, data[selected_indices[0]].reshape(1, -1)).flatten()\n",
    "\n",
    "    for _ in range(1, k):\n",
    "        new_index = np.argmax(distances)\n",
    "        selected_indices.append(new_index)\n",
    "        distances = np.minimum(distances, pairwise_distances(data, data[new_index].reshape(1, -1)).flatten())\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "classifier = create_classifier()\n",
    "classifier.fit(X_train, Y_train, epochs=st_epoch)  # 50\n",
    "classifier.save('saved_model/my_model')\n",
    "test(classifier, X_test, Y_test)\n",
    "num_iterations = 10\n",
    "num_queries = 10\n",
    "x_train_unlabeled = x_unlab\n",
    "y_train_unlabeled = y_unlab\n",
    "\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    print(\"\\n Iteration\", iteration)\n",
    "    print(\"\\n\")\n",
    "    classifier = tf.keras.models.load_model('saved_model/my_model')\n",
    "    # Use k-Center Greedy Algorithm for Coreset Selection\n",
    "    coreset_indices = k_center_greedy(x_train_unlabeled, num_queries)\n",
    "    x_query = x_train_unlabeled[coreset_indices]\n",
    "    y_query = y_train_unlabeled[coreset_indices]\n",
    "\n",
    "    # Remove queried samples from the unlabeled pool\n",
    "    x_train_unlabeled = np.delete(x_train_unlabeled, coreset_indices, axis=0)\n",
    "    y_train_unlabeled = np.delete(y_train_unlabeled, coreset_indices, axis=0)\n",
    "\n",
    "    # Add queried samples to the training dataset\n",
    "    X_train = np.concatenate([X_train, x_query], axis=0)\n",
    "    Y_train = np.concatenate([Y_train, y_query], axis=0)\n",
    "\n",
    "    # Train the classifier on the updated training dataset\n",
    "    classifier.fit(X_train, Y_train, epochs=ct_epoch)\n",
    "    \n",
    "    # Test the classifier on the test dataset\n",
    "    test(classifier, X_test, Y_test)\n",
    "    del classifier\n",
    "\n",
    "X_train = XT\n",
    "Y_train = YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55f357cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1431"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98687870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..........................Initial Samples....................\n",
      "\n",
      "100 143023\n",
      "\n",
      "..........................Initial Samples....................\n",
      "\n",
      "............................................Our Method...................................\n",
      "Model: \"cifar10-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, None, None, 3)     7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564,807\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,447\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 55s 55s/step - loss: 12.7462\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 12.5985\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 12.3590\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 12.5822\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 12.1610\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 12.0929\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 11.6943\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 12.0885\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 11.4862\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 11.1448\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 4s 56ms/step - loss: 1.9933 - sparse_categorical_accuracy: 0.7300\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.5561 - sparse_categorical_accuracy: 0.6700\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.2637 - sparse_categorical_accuracy: 0.6700\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1442 - sparse_categorical_accuracy: 0.6400\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1903 - sparse_categorical_accuracy: 0.5800\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0309 - sparse_categorical_accuracy: 0.6700\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9754 - sparse_categorical_accuracy: 0.7400\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0868 - sparse_categorical_accuracy: 0.6300\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.1969 - sparse_categorical_accuracy: 0.5900\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0565 - sparse_categorical_accuracy: 0.6900\n",
      "1119/1119 [==============================] - 25s 22ms/step - loss: 0.5509 - sparse_categorical_accuracy: 0.7869\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "(143023, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 11.7372\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10.9071\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.6006\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10.2272\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 11.3052\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.6107\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 10.5980\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 9.4664\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 9.8217\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.7326\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.7368 - sparse_categorical_accuracy: 0.6455\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.9657 - sparse_categorical_accuracy: 0.6909\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7786 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0682 - sparse_categorical_accuracy: 0.6455\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7394 - sparse_categorical_accuracy: 0.7455\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6873 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6449 - sparse_categorical_accuracy: 0.7545\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6152 - sparse_categorical_accuracy: 0.7091\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6738 - sparse_categorical_accuracy: 0.7273\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6082 - sparse_categorical_accuracy: 0.7091\n",
      "Balanced Accuracy: 0.6869898034536661\n",
      "F1 score for class label 1: 0.5337584130357775\n",
      "F1 score on test data: 0.8010719277756116\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "(143012, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 9.3409\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7471\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10.4349\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 8.9177\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 9.3123\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 9.1648\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 8.9187\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.7403\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.4156\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 9.4422\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.7826 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9541 - sparse_categorical_accuracy: 0.7167\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.6278 - sparse_categorical_accuracy: 0.7583\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.6481 - sparse_categorical_accuracy: 0.6833\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7295 - sparse_categorical_accuracy: 0.6833\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5802 - sparse_categorical_accuracy: 0.7333\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6957 - sparse_categorical_accuracy: 0.7333\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5738 - sparse_categorical_accuracy: 0.7333\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6959 - sparse_categorical_accuracy: 0.7167\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7062 - sparse_categorical_accuracy: 0.6750\n",
      "Balanced Accuracy: 0.7220033875063177\n",
      "F1 score for class label 1: 0.5900625205659756\n",
      "F1 score on test data: 0.817657772027116\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "(143001, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 9.4337\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 7.0900\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 6.7833\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.8995\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 7.7607\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step - loss: 7.4517\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 8.5768\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 8.4707\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.4447\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.2054\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.7538\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6513 - sparse_categorical_accuracy: 0.7846\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6532 - sparse_categorical_accuracy: 0.7769\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6344 - sparse_categorical_accuracy: 0.7615\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5429 - sparse_categorical_accuracy: 0.7769\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.7462\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5910 - sparse_categorical_accuracy: 0.7615\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6744 - sparse_categorical_accuracy: 0.7692\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4548 - sparse_categorical_accuracy: 0.8077\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5429 - sparse_categorical_accuracy: 0.7538\n",
      "Balanced Accuracy: 0.7314772739071564\n",
      "F1 score for class label 1: 0.6007169360417585\n",
      "F1 score on test data: 0.8175097027908653\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "(142990, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 6.1124\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.0586\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.0537\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.4482\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.8184\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.3629\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.6399\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.2580\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 6.1461\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.3118\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5190 - sparse_categorical_accuracy: 0.7929\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.4480 - sparse_categorical_accuracy: 0.8214\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4804 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4285 - sparse_categorical_accuracy: 0.8643\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4658 - sparse_categorical_accuracy: 0.8214\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4848 - sparse_categorical_accuracy: 0.7714\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4586 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4249 - sparse_categorical_accuracy: 0.7929\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.8214\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5556 - sparse_categorical_accuracy: 0.7857\n",
      "Balanced Accuracy: 0.7272631258223927\n",
      "F1 score for class label 1: 0.6027954946397069\n",
      "F1 score on test data: 0.8264041151636202\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "(142979, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 5.4512\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 7.0676\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.9005\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 6.8525\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 5.7143\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.6261\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 6.4736\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 6.3243\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 6.3335\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.2422\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4571 - sparse_categorical_accuracy: 0.8400\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4099 - sparse_categorical_accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4219 - sparse_categorical_accuracy: 0.7800\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4424 - sparse_categorical_accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4039 - sparse_categorical_accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3712 - sparse_categorical_accuracy: 0.8733\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4788 - sparse_categorical_accuracy: 0.8133\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4199 - sparse_categorical_accuracy: 0.8200\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4114 - sparse_categorical_accuracy: 0.8400\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4365 - sparse_categorical_accuracy: 0.8067\n",
      "Balanced Accuracy: 0.7245596645284016\n",
      "F1 score for class label 1: 0.6012971615872794\n",
      "F1 score on test data: 0.8284104363749845\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "(142968, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 5.6411\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.1857\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 5.1569\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.6251\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 6.1043\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.1540\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 5.1592\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 5.3972\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.8931\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 5.1529\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 3s 40ms/step - loss: 0.4119 - sparse_categorical_accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3662 - sparse_categorical_accuracy: 0.8687\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4811 - sparse_categorical_accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3735 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3796 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4166 - sparse_categorical_accuracy: 0.8562\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4260 - sparse_categorical_accuracy: 0.8375\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3812 - sparse_categorical_accuracy: 0.8188\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3229 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3765 - sparse_categorical_accuracy: 0.8562\n",
      "Balanced Accuracy: 0.7340111144460761\n",
      "F1 score for class label 1: 0.6169977924944813\n",
      "F1 score on test data: 0.8341658878918408\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "(142957, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 5.3142\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.7816\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.1453\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 5.7151\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 5.0921\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.6744\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.1456\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 5.0728\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.2355\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 5.0843\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3153 - sparse_categorical_accuracy: 0.8706\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.3088 - sparse_categorical_accuracy: 0.8941\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.3343 - sparse_categorical_accuracy: 0.8471\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3384 - sparse_categorical_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.4430 - sparse_categorical_accuracy: 0.8529\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3839 - sparse_categorical_accuracy: 0.8529\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.3295 - sparse_categorical_accuracy: 0.8824\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3783 - sparse_categorical_accuracy: 0.8471\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3685 - sparse_categorical_accuracy: 0.8647\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.3573 - sparse_categorical_accuracy: 0.8529\n",
      "Balanced Accuracy: 0.7524708359129435\n",
      "F1 score for class label 1: 0.6402181676514512\n",
      "F1 score on test data: 0.838693756774624\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "(142946, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 5.6016\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.1455\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.5982\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 5.2384\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.5620\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.5185\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 5.0778\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 5.0780\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 5.4060\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 5.0661\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.2872 - sparse_categorical_accuracy: 0.8944\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2922 - sparse_categorical_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2864 - sparse_categorical_accuracy: 0.8889\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2879 - sparse_categorical_accuracy: 0.8889\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3358 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2856 - sparse_categorical_accuracy: 0.8833\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2923 - sparse_categorical_accuracy: 0.8889\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.3142 - sparse_categorical_accuracy: 0.8722\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2807 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3018 - sparse_categorical_accuracy: 0.8833\n",
      "Balanced Accuracy: 0.7657222520670948\n",
      "F1 score for class label 1: 0.6576172738177916\n",
      "F1 score on test data: 0.8438879927143205\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "(142935, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.2468\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.1196\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.4425\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 5.0839\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.0724\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 5.4211\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.3803\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 5.0424\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 5.1727\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5.3631\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 0.2882 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2557 - sparse_categorical_accuracy: 0.9158\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2620 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.3309 - sparse_categorical_accuracy: 0.8579\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 0.2126 - sparse_categorical_accuracy: 0.9263\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2805 - sparse_categorical_accuracy: 0.8789\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.2905 - sparse_categorical_accuracy: 0.8895\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 93ms/step - loss: 0.2257 - sparse_categorical_accuracy: 0.9211\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2491 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3124 - sparse_categorical_accuracy: 0.9000\n",
      "Balanced Accuracy: 0.7787478234726631\n",
      "F1 score for class label 1: 0.6673798062637428\n",
      "F1 score on test data: 0.8424784930700574\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "10\n",
      "\n",
      "\n",
      "\n",
      "(142924, 2048)\n",
      "\n",
      "\n",
      "Annotated in each iter : \n",
      "10\n",
      "(10,)\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.2044\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.0977\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 5.0904\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 5.1505\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.3823\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.1923\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 5.0833\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.2954\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 5.2955\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.1536\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 85ms/step - loss: 0.2311 - sparse_categorical_accuracy: 0.9200\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.2905 - sparse_categorical_accuracy: 0.8900\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.2456 - sparse_categorical_accuracy: 0.9200\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.2527 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2852 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2298 - sparse_categorical_accuracy: 0.9050\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2432 - sparse_categorical_accuracy: 0.9150\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.2387 - sparse_categorical_accuracy: 0.9100\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2942 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.8900\n",
      "Balanced Accuracy: 0.7858038511319553\n",
      "F1 score for class label 1: 0.6739509473439499\n",
      "F1 score on test data: 0.8433312084885557\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.7868980765342712\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "#train_labels_categorical = to_categorical(train_labels)\n",
    "train_labels_categorical = train_labels\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, x_unlab, Y_train, y_unlab = train_test_split( X_train, Y_train, test_size=.9993, random_state=42 )\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "print(\"\\n..........................Initial Samples....................\\n\")\n",
    "print(len(Y_train),len(y_unlab))\n",
    "print(\"\\n..........................Initial Samples....................\\n\")\n",
    "\n",
    "\n",
    "print(\"............................................Our Method...................................\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def test(model, X_test, Y_test):\n",
    "    print(\"\\n--------------------------------------\\n\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Convert one-hot encoded predictions to class labels.\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    Y_test_classes = Y_test.argmax(axis=1)\n",
    "\n",
    "    # Calculate the F1 score.\n",
    "    f1 = f1_score(Y_test_classes, y_pred_classes, average='weighted')\n",
    "    \n",
    "    # Calculate the F1 score for class label 1.\n",
    "    class_label = 1\n",
    "    f1_class_label_1 = f1_score(Y_test_classes, y_pred_classes, labels=[class_label], average=None)\n",
    "    \n",
    "    balanced_acc = balanced_accuracy_score(Y_test_classes, y_pred_classes)\n",
    "    print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "    print(\"F1 score for class label 1:\", f1_class_label_1[0])\n",
    "    print(\"F1 score on test data:\", f1)\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "def train(model,X_train, Y_train, epoch):\n",
    "    \n",
    "    print(f\"Starting to train with {len(Y_train)} samples\")\n",
    "\n",
    "    history = model.fit(X_train, Y_train, batch_size = 128, epochs=epoch,validation_split=.20)\n",
    "\n",
    "    return model\n",
    "\n",
    "def print_acc(model, X_test, Y_test):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    # Convert one-hot encoded predictions to class labels.\n",
    "    y_pred_classes = y_pred.argmax(axis=1)\n",
    "    Y_test_classes = Y_test\n",
    "\n",
    "    # Calculate the F1 score.\n",
    "    f1 = f1_score(Y_test_classes, y_pred_classes, average='weighted')\n",
    "    \n",
    "    # Calculate the F1 score for class label 1.\n",
    "    class_label = 1\n",
    "    f1_class_label_1 = f1_score(Y_test_classes, y_pred_classes, labels=[class_label], average=None)\n",
    "    \n",
    "    balanced_acc = balanced_accuracy_score(Y_test_classes, y_pred_classes)\n",
    "    print(\"Balanced Accuracy:\", balanced_acc)\n",
    "\n",
    "    print(\"F1 score for class label 1:\", f1_class_label_1[0])\n",
    "    print(\"F1 score on test data:\", f1)\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 512\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "hidden_units = 512\n",
    "projection_units = 256\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Normalization(),\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.02),\n",
    "        layers.experimental.preprocessing.RandomWidth(0.2),\n",
    "        layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(X_train)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "def create_encoder():\n",
    "    resnet = tf.keras.applications.ResNet50V2( include_top=False, weights=\"imagenet\", input_shape=input_shape, pooling=\"avg\" )\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = resnet(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
    "    return model\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "\n",
    "        logits = tf.divide( tf.matmul(  \n",
    "            feature_vectors_normalized, tf.transpose(feature_vectors_normalized)),self.temperature,)\n",
    "        \n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_active_learning_models(encoder,classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations,num_epochs=1):\n",
    "\n",
    "    l = len(y_unlab)\n",
    "    d = int ( np.round ( l/num_iterations ) )\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        l = len(y_unlab)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        print(\"Iteration : \")\n",
    "        \n",
    "        print(iteration+1)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "  \n",
    "        x_ulb = encoder.predict(x_unlab, batch_size=128)\n",
    "        \n",
    "        print(np.shape(x_ulb))\n",
    "\n",
    "\n",
    "        nn_clusters = 2\n",
    "        \n",
    "        budget =  5\n",
    "        print(\"\\n\")\n",
    "        print(\"Annotated in each iter : \")\n",
    "        print(budget*2)\n",
    "\n",
    "    \n",
    "        kmeans = KMeans(n_clusters=nn_clusters, init='k-means++', n_init=10).fit(x_ulb)\n",
    "\n",
    "        annotate_indices = []\n",
    "        \n",
    "        \n",
    "        for i in range(nn_clusters):\n",
    "            \n",
    "            cluster_center = kmeans.cluster_centers_[i]\n",
    "            \n",
    "            cluster_indices = np.where(kmeans.labels_ == i)[0]\n",
    "            \n",
    "            distances = np.linalg.norm(x_ulb[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "            annotate = cluster_indices[np.argsort(distances,-1)[:budget]]\n",
    "            \n",
    "            pts = cluster_indices[np.argsort(distances,-1)[:1]]\n",
    "            \n",
    "            annotate_indices.extend(annotate)\n",
    "            \n",
    "\n",
    "        print(np.shape(annotate_indices))\n",
    "\n",
    "        annt = annotate_indices      \n",
    "        \n",
    "        ante = x_ulb[annt]\n",
    "        \n",
    "        all = list(range(1, l))\n",
    "        main_list = list(set(all) - set(annt))\n",
    "        \n",
    "        new_annt = x_unlab[annt]\n",
    "        arr = np.concatenate((X_train, new_annt))\n",
    "        X_train = arr\n",
    "        \n",
    "        annt_y = y_unlab[annt]\n",
    "        arr = np.concatenate((Y_train, annt_y))\n",
    "        Y_train = arr\n",
    "        \n",
    "        #create the new unlabelled set\n",
    "        x_unlab = x_unlab[main_list]\n",
    "\n",
    "        #create the new unlabelled label set\n",
    "        y_unlab = y_unlab[main_list]\n",
    "        \n",
    "        \n",
    "        history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=256, epochs=st_epoch)\n",
    "\n",
    "\n",
    "        history = classifier.fit(x=X_train, y=Y_train, batch_size=32, epochs=ct_epoch) \n",
    "\n",
    "\n",
    "        print_acc(classifier, X_test, Y_test)\n",
    "        \n",
    "        print(\"Acc : \")\n",
    "        print(\"\\n\")\n",
    "        print(accuracy)\n",
    "       \n",
    "    \n",
    "    return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "\n",
    "data_augmentation.layers[0].adapt(X_train)\n",
    "encoder = create_encoder()\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                        loss=SupervisedContrastiveLoss(temperature))\n",
    "    \n",
    "history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=256, epochs=st_epoch)\n",
    "classifier = create_classifier(encoder, trainable=False) \n",
    "history = classifier.fit(x=X_train, y=Y_train, batch_size=32, epochs=ct_epoch) \n",
    "\n",
    "try :\n",
    "  accuracy = classifier.evaluate(X_test, Y_test, batch_size=32)[1]\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "print(\"Acc : \")\n",
    "print(\"\\n\")\n",
    "print(accuracy)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "encoder, classifier,X_train,Y_train,x_unlab,y_unlab = train_active_learning_models(encoder, classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac9e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5743ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c62693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90076653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................Random Contrastive...................................\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.7780\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 12.7795\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 12.4924\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 12.5913\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 12.1592\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 11.9089\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 12.1018\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 11.6690\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 11.4424\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 11.8479\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 4s 85ms/step - loss: 1.9730 - sparse_categorical_accuracy: 0.6900\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.7464 - sparse_categorical_accuracy: 0.6800\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.6833 - sparse_categorical_accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.6120 - sparse_categorical_accuracy: 0.6100\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.3813 - sparse_categorical_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.3159 - sparse_categorical_accuracy: 0.6100\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1536 - sparse_categorical_accuracy: 0.6300\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7588 - sparse_categorical_accuracy: 0.6600\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0992 - sparse_categorical_accuracy: 0.6300\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1908 - sparse_categorical_accuracy: 0.6700\n",
      "1119/1119 [==============================] - 27s 23ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.7774\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 11.9177\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 11.2527\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 11.5744\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10.5927\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 10.4370\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 11.2986\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10.0030\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 11.0772\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 9.5583\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10.7601\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7250 - sparse_categorical_accuracy: 0.6364\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7288 - sparse_categorical_accuracy: 0.6455\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7557 - sparse_categorical_accuracy: 0.7364\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7040 - sparse_categorical_accuracy: 0.7273\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7028 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6909 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5687 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.8387 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6463 - sparse_categorical_accuracy: 0.7727\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.7544 - sparse_categorical_accuracy: 0.7091\n",
      "Balanced Accuracy: 0.6734545091900765\n",
      "F1 score for class label 1: 0.5025769789877098\n",
      "F1 score on test data: 0.781704286175572\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 9.9063\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.7464\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10.4352\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10.3050\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 10.0552\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 8.9376\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 7.9895\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.1636\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.8306\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 9.4962\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5327 - sparse_categorical_accuracy: 0.7917\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.6860 - sparse_categorical_accuracy: 0.7417\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6805 - sparse_categorical_accuracy: 0.7250\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5801 - sparse_categorical_accuracy: 0.7583\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5855 - sparse_categorical_accuracy: 0.7333\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5415 - sparse_categorical_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6567 - sparse_categorical_accuracy: 0.7250\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6016 - sparse_categorical_accuracy: 0.7417\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4899 - sparse_categorical_accuracy: 0.8167\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6405 - sparse_categorical_accuracy: 0.8083\n",
      "Balanced Accuracy: 0.678063890007793\n",
      "F1 score for class label 1: 0.510723324896763\n",
      "F1 score on test data: 0.7862890322415762\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 9.4016\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 7.9124\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 7.9203\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 7.7148\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.2470\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 7.1385\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 7.2410\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 6.6571\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.5141\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.3877\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5380 - sparse_categorical_accuracy: 0.7615\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.5358 - sparse_categorical_accuracy: 0.7385\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4609 - sparse_categorical_accuracy: 0.7308\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.5928 - sparse_categorical_accuracy: 0.7538\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5763 - sparse_categorical_accuracy: 0.8077\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5321 - sparse_categorical_accuracy: 0.7923\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4910 - sparse_categorical_accuracy: 0.8231\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4442 - sparse_categorical_accuracy: 0.7923\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6454 - sparse_categorical_accuracy: 0.7923\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4865 - sparse_categorical_accuracy: 0.7692\n",
      "Balanced Accuracy: 0.6572302319816362\n",
      "F1 score for class label 1: 0.4766944206676523\n",
      "F1 score on test data: 0.7901341814328332\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "4\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 6.6659\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 8.2408\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.8525\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 6.2831\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.6853\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.9170\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.5412\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.4135\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 7.2352\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.2998\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 0.4473 - sparse_categorical_accuracy: 0.8071\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4632 - sparse_categorical_accuracy: 0.7786\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4212 - sparse_categorical_accuracy: 0.8214\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4537 - sparse_categorical_accuracy: 0.7857\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.4928 - sparse_categorical_accuracy: 0.7929\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4466 - sparse_categorical_accuracy: 0.8357\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4915 - sparse_categorical_accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4417 - sparse_categorical_accuracy: 0.8429\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4274 - sparse_categorical_accuracy: 0.7857\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3753 - sparse_categorical_accuracy: 0.8643\n",
      "Balanced Accuracy: 0.6761827282625784\n",
      "F1 score for class label 1: 0.5156299840510367\n",
      "F1 score on test data: 0.8081343043132745\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 5.4945\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 5.5462\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 7.0599\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 5.2597\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.3531\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 6.7278\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.6762\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 6.7089\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 6.4332\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 6.3047\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3675 - sparse_categorical_accuracy: 0.8400\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3922 - sparse_categorical_accuracy: 0.8133\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3811 - sparse_categorical_accuracy: 0.8400\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4346 - sparse_categorical_accuracy: 0.8200\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3995 - sparse_categorical_accuracy: 0.8267\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3695 - sparse_categorical_accuracy: 0.8533\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3036 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3554 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.3220 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3962 - sparse_categorical_accuracy: 0.8333\n",
      "Balanced Accuracy: 0.6988713636689732\n",
      "F1 score for class label 1: 0.5601189079245873\n",
      "F1 score on test data: 0.8240662639339059\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "6\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 5.3614\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 5.2528\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 6.2673\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 6.2839\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.1889\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.9667\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 5.9188\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.9045\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 5.0950\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 5.1139\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 3s 43ms/step - loss: 0.3726 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3586 - sparse_categorical_accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3441 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3601 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3441 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3452 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3654 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3545 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.3870 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3227 - sparse_categorical_accuracy: 0.8750\n",
      "Balanced Accuracy: 0.7271882812611659\n",
      "F1 score for class label 1: 0.6095762901184005\n",
      "F1 score on test data: 0.8397967843749874\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 5.7793\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 5.1332\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 5.6934\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 5.7420\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.7428\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 5.6370\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.1108\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.1169\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.4007\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 5.1006\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3294 - sparse_categorical_accuracy: 0.8647\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3188 - sparse_categorical_accuracy: 0.8765\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.3228 - sparse_categorical_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3350 - sparse_categorical_accuracy: 0.8529\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2785 - sparse_categorical_accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2960 - sparse_categorical_accuracy: 0.8706\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3030 - sparse_categorical_accuracy: 0.8588\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2843 - sparse_categorical_accuracy: 0.8471\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3355 - sparse_categorical_accuracy: 0.8765\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3293 - sparse_categorical_accuracy: 0.8471\n",
      "Balanced Accuracy: 0.7477797038808439\n",
      "F1 score for class label 1: 0.6427645788336933\n",
      "F1 score on test data: 0.850719521734159\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 5.1256\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 5.1030\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 5.1525\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 5.1045\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 5.5428\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 5.1024\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 5.4376\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 5.3587\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 5.2992\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 5.0946\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.2844 - sparse_categorical_accuracy: 0.8778\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.2575 - sparse_categorical_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2516 - sparse_categorical_accuracy: 0.8944\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.2697 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2467 - sparse_categorical_accuracy: 0.8944\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.2414 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.2648 - sparse_categorical_accuracy: 0.8944\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.2801 - sparse_categorical_accuracy: 0.8944\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.2549 - sparse_categorical_accuracy: 0.9056\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2625 - sparse_categorical_accuracy: 0.8667\n",
      "Balanced Accuracy: 0.7560777451427031\n",
      "F1 score for class label 1: 0.6595559425337397\n",
      "F1 score on test data: 0.858341718323649\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "9\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 5.1725\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 5.1433\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 5.3626\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 5.1450\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.2731\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 5.1001\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 5.2598\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 5.1065\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 5.0857\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 5.0874\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2961 - sparse_categorical_accuracy: 0.8842\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2960 - sparse_categorical_accuracy: 0.8737\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2501 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.2368 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.2168 - sparse_categorical_accuracy: 0.9105\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2376 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2143 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2234 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.2477 - sparse_categorical_accuracy: 0.8842\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1897 - sparse_categorical_accuracy: 0.9000\n",
      "Balanced Accuracy: 0.7696429235374435\n",
      "F1 score for class label 1: 0.682565907621579\n",
      "F1 score on test data: 0.8671891458103278\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n",
      "\n",
      "\n",
      "\n",
      "Iteration : \n",
      "10\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 5.2896\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5.1379\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 5.1401\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 5.0923\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.2981\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 5.0821\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.2479\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.0899\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 5.1097\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 5.0904\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.2329 - sparse_categorical_accuracy: 0.9100\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2735 - sparse_categorical_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2654 - sparse_categorical_accuracy: 0.9100\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2359 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2199 - sparse_categorical_accuracy: 0.9050\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2354 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2217 - sparse_categorical_accuracy: 0.9200\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2063 - sparse_categorical_accuracy: 0.9200\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2532 - sparse_categorical_accuracy: 0.8850\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9300\n",
      "Balanced Accuracy: 0.7769396317882044\n",
      "F1 score for class label 1: 0.6953718297750394\n",
      "F1 score on test data: 0.8723607247513296\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Acc : \n",
      "\n",
      "\n",
      "0.777367889881134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "#train_labels_categorical = to_categorical(train_labels)\n",
    "train_labels_categorical = train_labels\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, x_unlab, Y_train, y_unlab = train_test_split( X_train, Y_train, test_size=.9993, random_state=42 )\n",
    "\n",
    "classifier = None\n",
    "encoder = None\n",
    "\n",
    "print(\"............................................Random Contrastive...................................\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_active_learning_models(encoder,classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations,num_epochs=1):\n",
    "\n",
    "    d = 100/num_iterations\n",
    "    l = len(y_unlab)\n",
    "    x = 10\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        \n",
    "        l = len(y_unlab)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        print(\"Iteration : \")\n",
    "        \n",
    "        print(iteration+1)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "  \n",
    "        rnd = random.sample(range(0, len(x_unlab)), x)\n",
    "        all_indices = list(range(1, l))\n",
    "        main_list = list(set(all_indices) - set(rnd))\n",
    "        \n",
    "        #add those index to from unlablled set to training set\n",
    "        img_list = ([x_unlab[i] for i in rnd])\n",
    "        new_lab = img_list\n",
    "        arr = np.concatenate((X_train, new_lab))\n",
    "        X_train = arr\n",
    "\n",
    "        #check labels in the set and add to training data\n",
    "        new_y = y_unlab[rnd]\n",
    "        arr = np.concatenate((Y_train, new_y))\n",
    "        Y_train = arr\n",
    "        \n",
    "        \n",
    "        #create the new unlabelled set\n",
    "        x_unlab = ([x_unlab[i] for i in main_list])\n",
    "\n",
    "        #create the new unlabelled label set\n",
    "        y_unlab = y_unlab[main_list]\n",
    "        \n",
    "        \n",
    "        history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=256, epochs=ct_epoch)\n",
    "\n",
    "\n",
    "        history = classifier.fit(x=X_train, y=Y_train, batch_size=32, epochs=ct_epoch) \n",
    "\n",
    "\n",
    "        print_acc(classifier, X_test, Y_test)\n",
    "        \n",
    "        print(\"Acc : \")\n",
    "        print(\"\\n\")\n",
    "        print(accuracy)\n",
    "       \n",
    "    \n",
    "    return encoder, classifier,X_train,Y_train,x_unlab,y_unlab \n",
    "\n",
    "data_augmentation.layers[0].adapt(X_train)\n",
    "encoder = create_encoder()\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                        loss=SupervisedContrastiveLoss(temperature))\n",
    "    \n",
    "history = encoder_with_projection_head.fit(x=X_train, y=Y_train, batch_size=256, epochs=st_epoch)\n",
    "classifier = create_classifier(encoder, trainable=False) \n",
    "history = classifier.fit(x=X_train, y=Y_train, batch_size=32, epochs=ct_epoch) \n",
    "\n",
    "try :\n",
    "  accuracy = classifier.evaluate(X_test, Y_test, batch_size=32)[1]\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "print(\"Acc : \")\n",
    "print(\"\\n\")\n",
    "print(accuracy)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "\n",
    "encoder, classifier,X_train,Y_train,x_unlab,y_unlab = train_active_learning_models(encoder, classifier,X_train,Y_train,x_unlab,y_unlab,X_test,Y_test,num_iterations=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384689a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ec256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b6cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d76e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cad60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0ecd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42735712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "675b7cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1145, 32, 32, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403c2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1de25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31083b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be88f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e2ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd07929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
