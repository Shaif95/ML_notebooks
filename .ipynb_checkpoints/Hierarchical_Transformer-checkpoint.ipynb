{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71b2a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow_addons as tfa\n",
    "import glob, random, os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a26b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train, y_train),( X_test, Y_test )= cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "X_test = X_test / 255 \n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "n_classes = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 10\n",
    "patch_size = 4  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 2\n",
    "mlp_head_units = [56, 28] \n",
    "\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split( x_train, y_train, test_size=0.2, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a086665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class ImageResizeGenerator(Sequence):\n",
    "    def __init__(self, images, labels, batch_size, image_size, shuffle=True):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_idx = index * self.batch_size\n",
    "        end_idx = (index + 1) * self.batch_size\n",
    "        batch_indices = self.indices[start_idx:end_idx]\n",
    "\n",
    "        batch_images = self.images[batch_indices]\n",
    "        batch_labels = self.labels[batch_indices]\n",
    "\n",
    "        resized_batch_images = np.array([tf.image.resize(img, (self.image_size, self.image_size)).numpy() for img in batch_images])\n",
    "\n",
    "        return resized_batch_images, batch_labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.images))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "            \n",
    "train_generator = ImageResizeGenerator(X_train,  Y_train, batch_size=16, image_size=224)\n",
    "test_generator = ImageResizeGenerator(X_val, Y_val, batch_size=16, image_size=224, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1329dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = L.Dense(units, activation = tf.nn.gelu)(x)\n",
    "        x = L.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "class Patches(L.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images,\n",
    "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
    "            strides = [1, self.patch_size, self.patch_size, 1],\n",
    "            rates = [1, 1, 1, 1],\n",
    "            padding = 'VALID',\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bd654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 32 X 32\n",
      "Patch size: 4 X 4\n",
      "Patches per image: 64\n",
      "Elements per patch: 48\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAFICAYAAADd1gwNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATsklEQVR4nO3dW5Ac1X3H8X93z+yudiWtLiWChAUmuJzkxSEVilCO44qIKynHsVPYlh0o2UbS6mKBIQTKDhdhjABDCBQCIXl1QyRyHKPYfkolPCQp7FKqnNi4nIoMKgrJMsISxpKFbnubmc5DIiKVp3//s316dhfx/Tz2f7rPmZ6Z3/bDf89J8jzPDQDQVjrZEwCAqYyQBACBkAQAgZAEAIGQBACBkAQAgZAEAIGQBACBkAQAoRb6wo/e+KSs562mrKdpSB4nsvqNDTcU1j52w4aYS1ve8v/xKDf9mm9tvKnt8WvWPO5eu9OK5mYWMj9985LEubkBvvnkjW2Pf9T7XD0Bc8udl3zrieLv3TWf07+LKqTOBL+xYU3b4x+7YZM8z7szVXyuuzasLqx93MkUc35vIbNLMx1xX19fPL83rxEwDgC8bRGSACAQkgAgEJIAIBCSACAQkgAgEJIAIAT3SXp9jl6XYUifZExfVpplpc81M8uTgD7Jkou4p2nc3Dotdn5V9NMVCeuvFQLmFjP7WtL554y85BiJ0yPojht1ti9NvPk5fZIBn22axP/2eJIEAIGQBACBkAQAgZAEAIGQBACBkAQAgZAEACGukeosXg9hq9VyrxHTbxdyfbz9JAG9rTFtnknHuwnNyncsTsTcyku8dUrdRWDjxwjBkyQACIQkAAiEJAAIhCQACIQkAAiEJAAIhCQACIQkAAjBzeRu42cFC6+WXdS2CiHzL/sevfOqeN9RCxbHLmzbQfFzC7i3rWbHru99LkGfWsmPtuYsJO197UK+UjHN2plzqp85/hg0kwNAhxGSACAQkgAgEJIAIBCSACAQkgAgEJIAICT5ZDYnAsAUx5MkAAiEJAAIhCQACIQkAAiEJAAIwasALb55UNbzqJVUwvzDE2sKax//3MaoawetAuTUn3n8s22PL75pkzxvIlYB2lUwNzN/flXwbu8z69vP7xM3f8W5rnPhgO9lqzEm67s23lxY+8SNj8tzs0z/xLLMf06pO9d46uGBtseX3rZFntdq6nuThKzA5Hx3dzy6qrD2mVs262tXsLJYkuj3sOOR5e41eJIEAIGQBACBkAQAgZAEAIGQBACBkAQAgZAEACG4TzJ1epZaFfQ0xYjdrbGK3R4n49pVjDER8yvL3W3Qm3vIjnrOroKK95RRd/og6111d4xp9eCf6Tmm92Sy3mzo87NMn29mlofsRlmgr1e/r5bz4eWtiVnAjCdJABAISQAQCEkAEAhJABAISQAQCEkAEAhJABCCG7C8drPEe0WHW/Gi+yQrfNW4z6pi3byIG+zeuwra0cq+Re+veOJMLg1ZE7GrXB+imVlXtz63x+mD7Onqdsco2SZp9bp+713OvQlokzRLW+OY0bn6+vQArZbXJ+mPkeQhb0LjSRIABEISAARCEgAEQhIABEISAARCEgAEQhIABEISAIRxtKk6i596p3d4fcyIdVPHoeQgzmlV9NnH9KP7p8b/o0Bacn4158TMqddrAe8upOG8QN80p1m8pn9i3c6ivGZmeeKsjlvAu3RXqhutX//Zq+4Yw2PHxzOlc7QaJ2U9q/fKei3rcsdImuX/UeAMniQBQCAkAUAgJAFAICQBQCAkAUAgJAFAICQBQEjyPJ+YHb4B4C2IJ0kAEAhJABAISQAQCEkAEAhJABAISQAQgtcRuvaWLbKet8rvvxvq79evKqz92c2DHR/fUzS/iZibt3f21x5bWVi79s83exePGtvMLHNe8rePDLQ9vvS2rfK8ek0v99XT7T8H1LOmrD9y97LC2ufv3SHPzbx70/I78NKGXirt/nXt791dX9ymL1zX9+757/27Pt/MDry0R9b37NldWPuTxavluXMXXCLrc2bPk3Uzs3qml1v7q7XXudfgSRIABEISAARCEgAEQhIABEISAARCEgCE4BYgt80jZru+CoS0oUyWiZhbzBj+ubH18rwGmZbTetZs+i02WcRWnqlz77xFtkbHxtwxsma59rqTuT5vyNlJ8mhAOvzsePndEnPnGS3Pdf3U8Ig7Rq1LtzmF4EkSAARCEgAEQhIABEISAARCEgAEQhIABEISAITwPkmnF+6tvuViJ3sZvWtXs2Fl+Wu443stsgFD5yXnlztLiTWdXsDhMf9zbTj9eMqQ0+aYJPraw+b38aVJuV6/42m3rL9R03MbnTHbHWPGvIXjmtPZFiy4VNaz3umyPhqwPGOj6feheniSBACBkAQAgZAEAIGQBACBkAQAgZAEAIGQBACBkAQAIbiZPFanF56dygvbeqdV0kseIfrWBZ1fdpC4m9MMuLnNpt53Wxka0c3KLedtj6b+/OpZz3im9KZTTd2E3jdT71v9zne+2x3j4Cu/GNecztbTM0PWR7393gPGqOK3xZMkAAiEJAAIhCQACIQkAAiEJAAIhCQACIQkAAhJXs2KrwBwXuJJEgAEQhIABEISAARCEgAEQhIABEISAITgpdKW3LZd1lvOclNVLGX21UcHCmvX3bIl6tppGjA/5z3s/OvlbY8vuXVbmSn9v4AuLe8VMffO2zs6Cbl3zv7YOx9pP79P37JZj+2886TW0PMys2k9ev6b1q0prN35wNP64pleruyNfFSfb2avOfd/1xeub3v8/Q/vlOf1ze2X9fzIEVk3Mzvx3y/I+u6nHyqsrV67VY/vrGAX0r2YOfd/033L3GvwJAkAAiEJAAIhCQACIQkAAiEJAAIhCQACIQkAQnCfpNfnmLp9kEEbQIZO55dkqc77StaDK3kRr5+ritXqYv7a1ZyTc9M9jiGjZyUn2N3tfEWd/suL5uteQDOz91356+OZ0jkW//F7Zb3e0y3rew8ddMd4/hfltm39wO+9R9Ybzna4R1vD7hiHZk4b15zO5vW45on+7LPE/910Z/G7ZvMkCQACIQkAAiEJAAIhCQACIQkAAiEJAAIhCQBCcBNR3elpalbRiRix5GSW654vT+6s2Wfmr6tYpO40IqZ6yTvrrTsvMLPexFl8T+gbelXWL1q4QNYvvPRSd4zp03vHNaczFn/4d2S9r0/3IZ48dswdIxn2+wGLHDqwT9YPHzog6//xg++6Y1x19e+PZ0pvuu6y+bL+k4Ovy/ru4RF3jJOJvv9SK673OvN+OGZmJX+z58wj+goAcB4jJAFAICQBQCAkAUAgJAFAICQBQCAkAUAgJAFACG4mb3mNm04veVga+xvJF5nVX5f1/v4Zst47vc8do2+mv4BrO4sWXSHr03v1x3BBv7+waXb6jXHN6WyHX9ot6xfO+E1Z/8BVH3LHeOPE8XHN6Yy507zvhP4nghOnj7hjfPu578j6H1x9VWHt6W2b5LlHf/5TWR86eUzWzcz6u5yf6Sc/1fbw1zfque3Zp+dWn6mb0c3MumZc4L6mSKOlQ6OWxv+DSmOSF7QGgPMeIQkAAiEJAAIhCQACIQkAAiEJAAIhCQBCkucVNBIBwHmKJ0kAEAhJABAISQAQCEkAEAhJABCCVwFacsffyXrSGHLqo+4YM/r0SkNPrltZWHvuhy/Lc+ddMEfW9/34FVk3Mzt24qSsL/nD97Y9vuMfn5PnnThySNYvnf8remJm9o7ZehWjy6+4srD2qT9dJM99ed9+Wb/7gfWybmZ2+eW/JesXLry47fGX9vxInnfwVb0d7iv7X9ITM7Pnv6tXQXps+1cLax/83eL7amY22tBb/TacuplZ2qO/u/+2+1/bHv/INUvleXPmt7/nZ3TNnKsnZmbNrEfWt91f/JsduH2rPLeW6me4kC2eE+caG+/9tHsNniQBQCAkAUAgJAFAICQBQCAkAUAgJAFAICQBQAjuk0ycXem6M12/ZMEsd4zLLr4wdDq/PH4+Iuv7X/gvWd+7V/dZmpk1vfWSCvokDx/QvXojzo556SldNzOb9Wvvcl9TZOHFl8j6977/n7K+4bGH3TFuve0Lsl7UJzmtS++C2Z3q+t4X9+qJmdn+Vw+6rykcv1/3MGam+whr3XoXTzOz/rm6n7HIOy77bVnP6/rejVrijtHI/dcUjp/oc1vOAmVp4i9gljhjhOBJEgAEQhIABEISAARCEgAEQhIABEISAARCEgCE4D7JWvOUrF80T69n+O6LZrljvPbjF5xXFK97+M2dO+WZPz9yVNaPHT/hjG025jRKfn7NsrbHv/3sv8jzGs2WrF8wd56emJll+TRZf9/VxbWxZLY8t2/2Qln/4R6/F/He+x+S9UUf/HDb44+u3yDP279PrwM6e56/JuIViz7ivqbIVX+0WNZfOXxc1k+P+s8p9fr0cc3pjLFM/yZbLf19boU8QkX0IXp9kN6lcwvpkxzPjNrjSRIABEISAARCEgAEQhIABEISAARCEgAEQhIABEISAITgZvLuzOnKbDZk+dl/etYd49ABvfDtTX+xprC2Z48+N613y3pW183YZmY90/QCqkVmzdHN2ElXr6zX6/643//R4XHN6WyHTurrv+ty0YluZunLL7pjnGj4jb/t/ODFn8j60OkhWV/wG3rhWTOz4dRv1i/y+qkuWR/JZsl6sztzx3B6rouvnTjPQF6jdaL/ycHMLC05txDe6CFPeF7DegieJAFAICQBQCAkAUAgJAFAICQBQCAkAUAgJAFASPK8gkYiADhP8SQJAAIhCQACIQkAAiEJAAIhCQACIQkAQvBSacvu2CrrM+r6/KOHDrhjjJzWexQ/s3N9YW3VrXpf5zxzJpj4S1Z5r9n84I1tj6+8Y5M8r+VcN28FLKflrCu1/aHlhbXlfzkoz61lTVk/dGC/HtzMRkeGZf2fdz3R9viHrr1Jnvfa4Z/K+hVXvl9PzMzyRC9VN/jgQGFtxe1PyXObznpk+s7+L2/Fsx33X9/2+LK79Ny8NdiSoOZA/f62PbC0sLbsdp0p3lJuScCm2lmmI27zvZ9xr8GTJAAIhCQACIQkAAiEJAAIhCQACIQkAAjBLUBN07vCnRgZlfW8Z7Y7RprpVgxlrHumd3FZbgW0O7Tc7eXaG3Juc+r9rXLmbmZmAe0QRcYy/dk2c92oMnv+r7pjJCW31eudM1+PnejWrkaq35uZWc0C7m8B765nzo6DiXNvzcxKL9OV6GsnzuyDnqAiFhHzvrK5+5X2x87dPRd9PEkCgEBIAoBASAKAQEgCgEBIAoBASAKAQEgCgBDcJ5k5izq1vJ6lerc/hrOskRzfaapKvEbIgHavsn9RvHflLUmVe+ugRUqde+O2q9X8PsOybZzT++c4dd1/G9Lb2ghasKy9ZtKQdW85L28ZNLOA+1/Aa01Nyndgnn2R8qd6S6FVML8qrsGTJAAIhCQACIQkAAiEJAAIhCQACIQkAAiEJAAIhCQACMHd24mzeGjqdETXaiFDlV/8NPW6Wt3G2hDlGlMTb2FSb//jKpp+hdRrVve63cM2aC7F31s5opv5/+Qx8/ceM9zpBcy/7PS8753fzd1R/j8YxE/AW1g4BE+SACAQkgAgEJIAIBCSACAQkgAgEJIAIBCSACAkeR6xuzgAnOd4kgQAgZAEAIGQBACBkAQAgZAEAIGQBAAheKm0gTu3y7q3N3RIp5H3mqceXFlYW3b7oHv9Ttv+5VVtj/tzq2I5MH3vtn9Z3bvNUcMnafxyVNvuW9H2+PI79dy8b5W/1Jr/mq3rBgprA2u3Ro/v8VZy27xuedvjK9duix47VtHczCZmfmmql1/8ypeu969R0VwA4LxESAKAQEgCgEBIAoBASAKAQEgCgEBIAoAwji1lO7+1Z0xLmTe/t/aKcJM79w7vLKrHTvXf8cmcm5n/vauiT7KsyRw7xETMr4oxeJIEAIGQBACBkAQAgZAEAIGQBACBkAQAgZAEAKGyPkmvDTGsX6l8T9NU7gmbynMzC+hPrWD6Ze/BVL93U5nXG/x2uLdVrHXKkyQACIQkAAiEJAAIhCQACIQkAAiEJAAIhCQACIQkAAjhzeROU2aSV9GRXH5x2ancGOvOzdt9Pui+RDTip971nb+lAfe+U5/PZH/ukz2+Eju3Tr83Ft0FgPMAIQkAAiEJAAIhCQACIQkAAiEJAAIhCQBCknsrcwLA2xhPkgAgEJIAIBCSACAQkgAgEJIAIASvArT6nr+R9bzZdK4QvwrQ4LqlhbUVd20NuH5nbblvoO3xFXdt0SdWsgqQtmXdqsLairWDztn6b2mSZP4EnI9/85eWtT2+8ovbnbE7v5LM4D3F37tVzvyqaB3x3uFgwb1bffdTUReu4t5uuuf6wtpn79kRfX1PlumI27B2iXsNniQBQCAkAUAgJAFAICQBQCAkAUAgJAFAICQBQAjuk/Q64VruFUI6xsp3lWWxPV0BiyGVnV3mdrp59c4u1JRF7obobpQZwb1z3uc2yTv+VTG620ZbwNngtJq5Rdxft7vWvbQ/dlrBb4cnSQAQCEkAEAhJABAISQAQCEkAEAhJABAISQAQgvskU68fyil3elPG6LTvYD+de+9cne31S9275/VJTuV754vp9YudX8ivoux3O7p3OEDMEFka158bMnTijRGAJ0kAEAhJABAISQAQCEkAEAhJABAISQAQCEkAEAhJABAqaybvZENxiInYpL6sqTw3s4D5xdYjTMS9ixkjdn5BDdFlrz0R9y7iHx3cBYsj62Y0kwNAxxGSACAQkgAgEJIAIBCSACAQkgAgEJIAICR5p1fDBYC3MJ4kAUAgJAFAICQBQCAkAUAgJAFAICQBQCAkAUAgJAFAICQBQPgfOyJqGeeG3dkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 400x400 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "image = X_train[10]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size = (image_size, image_size)\n",
    ")\n",
    "\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f'Image size: {image_size} X {image_size}')\n",
    "print(f'Patch size: {patch_size} X {patch_size}')\n",
    "print(f'Patches per image: {patches.shape[1]}')\n",
    "print(f'Elements per patch: {patches.shape[-1]}')\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31cdcdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(L.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = L.Dense(units = projection_dim)\n",
    "        self.position_embedding = L.Embedding(\n",
    "            input_dim = num_patches, output_dim = projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b57253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71bda0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_transformer():\n",
    "    inputs = L.Input(shape = (image_size, image_size, 3))\n",
    "    \n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    \n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(6):\n",
    "        \n",
    "        # Layer normalization 1.\n",
    "        x1 = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
    "        \n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = L.MultiHeadAttention(\n",
    "            num_heads = 6, key_dim = projection_dim, dropout = 0.1\n",
    "        )(x1, x1)\n",
    "        \n",
    "        # Skip connection 1.\n",
    "        x2 = L.Add()([attention_output, encoded_patches])\n",
    "        \n",
    "        # Layer normalization 2.\n",
    "        x3 = L.LayerNormalization(epsilon = 1e-6)(x2)\n",
    "        \n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units = transformer_units, dropout_rate = 0.1)\n",
    "        \n",
    "        # Skip connection 2.\n",
    "        encoded_patches = L.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = L.LayerNormalization(epsilon = 1e-6)(encoded_patches)\n",
    "    representation = L.Flatten()(representation)\n",
    "    representation = L.Dropout(0.5)(representation)\n",
    "    \n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units = mlp_head_units, dropout_rate = 0.5)\n",
    "    \n",
    "    # Classify outputs.\n",
    "    logits = L.Dense(n_classes)(features)\n",
    "    \n",
    "    # Create the model.\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = logits)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485367ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8b236c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " patches_2 (Patches)            (None, None, 48)     0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " patch_encoder_1 (PatchEncoder)  (None, 64, 64)      7232        ['patches_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 64, 64)      128         ['patch_encoder_1[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 64, 64)      99520       ['layer_normalization_13[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 64, 64)       0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'patch_encoder_1[0][0]']        \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 64, 64)      128         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 64, 128)      8320        ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 64, 128)      0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 64, 64)       8256        ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 64, 64)       0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 64, 64)       0           ['dropout_16[0][0]',             \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 64, 64)      128         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 64, 64)      99520       ['layer_normalization_15[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 64, 64)       0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 64, 64)      128         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 64, 128)      8320        ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 64, 128)      0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 64, 64)       8256        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 64, 64)       0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 64, 64)       0           ['dropout_18[0][0]',             \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 64, 64)      128         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 64, 64)      99520       ['layer_normalization_17[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 64, 64)       0           ['multi_head_attention_8[0][0]', \n",
      "                                                                  'add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 64, 64)      128         ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 64, 128)      8320        ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 64, 128)      0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 64, 64)       8256        ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 64, 64)       0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 64, 64)       0           ['dropout_20[0][0]',             \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 64, 64)      128         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 64, 64)      99520       ['layer_normalization_19[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 64, 64)       0           ['multi_head_attention_9[0][0]', \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 64, 64)      128         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 64, 128)      8320        ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 64, 128)      0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 64, 64)       8256        ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 64, 64)       0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 64, 64)       0           ['dropout_22[0][0]',             \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 64, 64)      128         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 64, 64)      99520       ['layer_normalization_21[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 64, 64)       0           ['multi_head_attention_10[0][0]',\n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 64, 64)      128         ['add_20[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 64, 128)      8320        ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 64, 128)      0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 64, 64)       8256        ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 64, 64)       0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 64, 64)       0           ['dropout_24[0][0]',             \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 64, 64)      128         ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 64, 64)      99520       ['layer_normalization_23[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 64, 64)       0           ['multi_head_attention_11[0][0]',\n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 64, 64)      128         ['add_22[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 64, 128)      8320        ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 64, 128)      0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 64, 64)       8256        ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 64, 64)       0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 64, 64)       0           ['dropout_26[0][0]',             \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 64, 64)      128         ['add_23[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 4096)         0           ['layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 4096)         0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 56)           229432      ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 56)           0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 28)           1596        ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 28)           0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 10)           290         ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 936,790\n",
      "Trainable params: 936,790\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vision_transformer()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08529ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[node model_1/patch_encoder_1/dense_16/Tensordot/MatMul\n (defined at C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\dense.py:202)\n]] [Op:__inference_train_function_13048]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_1/patch_encoder_1/dense_16/Tensordot/MatMul:\nIn[0] model_1/patch_encoder_1/dense_16/Tensordot/Reshape:\t\nIn[1] model_1/patch_encoder_1/dense_16/Tensordot/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_10344\\3109428961.py\", line 12, in <module>\n>>>     model.fit(X_train,Y_train, epochs=50, validation_split = .1)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_10344\\4198443743.py\", line 12, in call\n>>>     encoded = self.projection(patch) + self.position_embedding(positions)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\dense.py\", line 202, in call\n>>>     outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10344\\3109428961.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     ), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[node model_1/patch_encoder_1/dense_16/Tensordot/MatMul\n (defined at C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\dense.py:202)\n]] [Op:__inference_train_function_13048]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_1/patch_encoder_1/dense_16/Tensordot/MatMul:\nIn[0] model_1/patch_encoder_1/dense_16/Tensordot/Reshape:\t\nIn[1] model_1/patch_encoder_1/dense_16/Tensordot/ReadVariableOp:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_10344\\3109428961.py\", line 12, in <module>\n>>>     model.fit(X_train,Y_train, epochs=50, validation_split = .1)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_10344\\4198443743.py\", line 12, in call\n>>>     encoded = self.projection(patch) + self.position_embedding(positions)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\dense.py\", line 202, in call\n>>>     outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\n>>> "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "num_epochs = 40\n",
    "validation_split = 0.1\n",
    "weight_decay = 0.0001\n",
    "label_smoothing = 0.1\n",
    "\n",
    "model.compile(optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    ), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "model.fit(X_train,Y_train, epochs=50, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23a9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b0cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7dadbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d70a6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 32, 32, 3), (None, 102)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96947bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ebce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7408940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c25bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab591c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8cb53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54c686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f246d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
