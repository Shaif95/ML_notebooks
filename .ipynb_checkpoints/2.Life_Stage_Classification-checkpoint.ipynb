{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696d630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (49227, 32, 32, 3)\n",
      "Y_train shape: (49227,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Define the path to the directory\n",
    "directory_path = r'C:\\Users\\shaif\\Downloads\\Compressed\\Invasive_Life_Stage'\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "class_label = 0\n",
    "\n",
    "# Loop through subdirectories (classes)\n",
    "for folder in os.listdir(directory_path):\n",
    "    #print(class_folder)\n",
    "    clsp = os.path.join(directory_path,folder)  \n",
    "    for class_folder in os.listdir(clsp):\n",
    "        #print(class_folder)\n",
    "        class_path = os.path.join(clsp, class_folder)    \n",
    "        #print(class_path)\n",
    "        for image_file in os.listdir(class_path):\n",
    "            if image_file.endswith('.png'):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "            \n",
    "            # Load image, convert to RGB and resize\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                img = img.resize((32, 32))\n",
    "                img_array = np.array(img)\n",
    "            \n",
    "            # Append image and label to lists\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(class_label)\n",
    "                #print(class_label)\n",
    "    class_label = class_label + 1\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884830c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "Y_train_encoded = to_categorical(Y_train)\n",
    "indices = np.arange(len(X_train))\n",
    "np.random.shuffle(indices)\n",
    "X_train_shuffled = X_train[indices]\n",
    "Y_train_encoded_shuffled = Y_train_encoded[indices]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_shuffled, Y_train_encoded_shuffled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0102e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af25d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/100\n",
      "985/985 [==============================] - 75s 51ms/step - loss: 10.3268 - accuracy: 0.4243 - val_loss: 1.8753 - val_accuracy: 0.4828\n",
      "Epoch 2/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 1.8586 - accuracy: 0.5126 - val_loss: 1.8448 - val_accuracy: 0.5025\n",
      "Epoch 3/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 1.6875 - accuracy: 0.5755 - val_loss: 1.3346 - val_accuracy: 0.6057\n",
      "Epoch 4/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 1.2253 - accuracy: 0.6232 - val_loss: 1.0673 - val_accuracy: 0.6264\n",
      "Epoch 5/100\n",
      "985/985 [==============================] - 56s 56ms/step - loss: 1.1455 - accuracy: 0.6503 - val_loss: 236.2982 - val_accuracy: 0.4099\n",
      "Epoch 6/100\n",
      "985/985 [==============================] - 63s 64ms/step - loss: 1.5874 - accuracy: 0.6266 - val_loss: 6.8404 - val_accuracy: 0.5651\n",
      "Epoch 7/100\n",
      "985/985 [==============================] - 55s 56ms/step - loss: 1.2529 - accuracy: 0.6417 - val_loss: 1.3288 - val_accuracy: 0.6585\n",
      "Epoch 8/100\n",
      "985/985 [==============================] - 66s 67ms/step - loss: 1.0546 - accuracy: 0.6557 - val_loss: 22.3810 - val_accuracy: 0.5831\n",
      "Epoch 9/100\n",
      "985/985 [==============================] - 66s 67ms/step - loss: 1.0120 - accuracy: 0.6563 - val_loss: 17.4184 - val_accuracy: 0.6301\n",
      "Epoch 10/100\n",
      "985/985 [==============================] - 82s 83ms/step - loss: 0.9607 - accuracy: 0.6737 - val_loss: 1202.7426 - val_accuracy: 0.5982\n",
      "Epoch 11/100\n",
      "985/985 [==============================] - 88s 89ms/step - loss: 0.9297 - accuracy: 0.6865 - val_loss: 3.9608 - val_accuracy: 0.6708\n",
      "Epoch 12/100\n",
      "985/985 [==============================] - 67s 68ms/step - loss: 0.9800 - accuracy: 0.6745 - val_loss: 74.0827 - val_accuracy: 0.6548\n",
      "Epoch 13/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.8852 - accuracy: 0.6915 - val_loss: 120.6274 - val_accuracy: 0.6852\n",
      "Epoch 14/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.8316 - accuracy: 0.7104 - val_loss: 2.1911 - val_accuracy: 0.7117\n",
      "Epoch 15/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.9091 - accuracy: 0.7031 - val_loss: 407.9825 - val_accuracy: 0.6841\n",
      "Epoch 16/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.8563 - accuracy: 0.7144 - val_loss: 114.1748 - val_accuracy: 0.6873\n",
      "Epoch 17/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.8338 - accuracy: 0.7177 - val_loss: 520.0519 - val_accuracy: 0.6779\n",
      "Epoch 18/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.9855 - accuracy: 0.7003 - val_loss: 1916.1045 - val_accuracy: 0.6918\n",
      "Epoch 19/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.8519 - accuracy: 0.6994 - val_loss: 3657.5217 - val_accuracy: 0.6114\n",
      "Epoch 20/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 1.1215 - accuracy: 0.6718 - val_loss: 140.0039 - val_accuracy: 0.6833\n",
      "Epoch 21/100\n",
      "985/985 [==============================] - 51s 51ms/step - loss: 0.9657 - accuracy: 0.6570 - val_loss: 712.0416 - val_accuracy: 0.6808\n",
      "Epoch 22/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.8942 - accuracy: 0.6780 - val_loss: 133.0068 - val_accuracy: 0.6920\n",
      "Epoch 23/100\n",
      "985/985 [==============================] - 51s 52ms/step - loss: 0.8905 - accuracy: 0.6780 - val_loss: 871.5406 - val_accuracy: 0.6867\n",
      "Epoch 24/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.8456 - accuracy: 0.6981 - val_loss: 342.3998 - val_accuracy: 0.7151\n",
      "Epoch 25/100\n",
      "985/985 [==============================] - 48s 48ms/step - loss: 0.8066 - accuracy: 0.7097 - val_loss: 39.6999 - val_accuracy: 0.7301\n",
      "Epoch 26/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 1.0222 - accuracy: 0.6850 - val_loss: 9.1238 - val_accuracy: 0.7059\n",
      "Epoch 27/100\n",
      "985/985 [==============================] - 54s 54ms/step - loss: 0.8057 - accuracy: 0.7000 - val_loss: 5.4049 - val_accuracy: 0.7105\n",
      "Epoch 28/100\n",
      "985/985 [==============================] - 49s 50ms/step - loss: 0.8525 - accuracy: 0.6990 - val_loss: 131.6436 - val_accuracy: 0.6989\n",
      "Epoch 29/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.9591 - accuracy: 0.6686 - val_loss: 106.9272 - val_accuracy: 0.6829\n",
      "Epoch 30/100\n",
      "985/985 [==============================] - 55s 56ms/step - loss: 0.8244 - accuracy: 0.6936 - val_loss: 150.4655 - val_accuracy: 0.7118\n",
      "Epoch 31/100\n",
      "985/985 [==============================] - 55s 56ms/step - loss: 0.8192 - accuracy: 0.7055 - val_loss: 47.8689 - val_accuracy: 0.7146\n",
      "Epoch 32/100\n",
      "985/985 [==============================] - 51s 52ms/step - loss: 0.8633 - accuracy: 0.6940 - val_loss: 291.3799 - val_accuracy: 0.6995\n",
      "Epoch 33/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.8587 - accuracy: 0.6887 - val_loss: 77.3851 - val_accuracy: 0.7136\n",
      "Epoch 34/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.7941 - accuracy: 0.7061 - val_loss: 213.6971 - val_accuracy: 0.7145\n",
      "Epoch 35/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.8322 - accuracy: 0.7026 - val_loss: 74.7979 - val_accuracy: 0.7119\n",
      "Epoch 36/100\n",
      "985/985 [==============================] - 51s 51ms/step - loss: 0.7932 - accuracy: 0.7086 - val_loss: 43.7924 - val_accuracy: 0.7264\n",
      "Epoch 37/100\n",
      "985/985 [==============================] - 62s 63ms/step - loss: 0.7617 - accuracy: 0.7222 - val_loss: 124.6661 - val_accuracy: 0.7397\n",
      "Epoch 38/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.7709 - accuracy: 0.7174 - val_loss: 511.8695 - val_accuracy: 0.7391\n",
      "Epoch 39/100\n",
      "985/985 [==============================] - 49s 50ms/step - loss: 0.8160 - accuracy: 0.7039 - val_loss: 957.3106 - val_accuracy: 0.7253\n",
      "Epoch 40/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.7594 - accuracy: 0.7207 - val_loss: 373.7376 - val_accuracy: 0.7208\n",
      "Epoch 41/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.7986 - accuracy: 0.7148 - val_loss: 7179.8096 - val_accuracy: 0.4824\n",
      "Epoch 42/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.7799 - accuracy: 0.7113 - val_loss: 183.8387 - val_accuracy: 0.7276\n",
      "Epoch 43/100\n",
      "985/985 [==============================] - 55s 56ms/step - loss: 0.7586 - accuracy: 0.7273 - val_loss: 36.1971 - val_accuracy: 0.7498\n",
      "Epoch 44/100\n",
      "985/985 [==============================] - 61s 62ms/step - loss: 0.7392 - accuracy: 0.7354 - val_loss: 44.1185 - val_accuracy: 0.7475\n",
      "Epoch 45/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.7359 - accuracy: 0.7384 - val_loss: 40.0234 - val_accuracy: 0.7089\n",
      "Epoch 46/100\n",
      "985/985 [==============================] - 49s 50ms/step - loss: 0.7627 - accuracy: 0.7314 - val_loss: 562.1775 - val_accuracy: 0.6655\n",
      "Epoch 47/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.7552 - accuracy: 0.7333 - val_loss: 276.4670 - val_accuracy: 0.7307\n",
      "Epoch 48/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.7019 - accuracy: 0.7407 - val_loss: 0.6687 - val_accuracy: 0.7563\n",
      "Epoch 49/100\n",
      "985/985 [==============================] - 45s 45ms/step - loss: 0.7747 - accuracy: 0.7264 - val_loss: 192.5395 - val_accuracy: 0.7296\n",
      "Epoch 50/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 0.8746 - accuracy: 0.7130 - val_loss: 147.1230 - val_accuracy: 0.7222\n",
      "Epoch 51/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 0.7466 - accuracy: 0.7349 - val_loss: 1454.6486 - val_accuracy: 0.5847\n",
      "Epoch 52/100\n",
      "985/985 [==============================] - 53s 54ms/step - loss: 0.7741 - accuracy: 0.7407 - val_loss: 694.8078 - val_accuracy: 0.7420\n",
      "Epoch 53/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.6968 - accuracy: 0.7449 - val_loss: 103.4628 - val_accuracy: 0.7447\n",
      "Epoch 54/100\n",
      "985/985 [==============================] - 54s 55ms/step - loss: 0.6823 - accuracy: 0.7513 - val_loss: 53.5562 - val_accuracy: 0.7483\n",
      "Epoch 55/100\n",
      "985/985 [==============================] - 55s 56ms/step - loss: 0.6936 - accuracy: 0.7499 - val_loss: 491.0602 - val_accuracy: 0.7395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.7124 - accuracy: 0.7509 - val_loss: 3393.0269 - val_accuracy: 0.6767\n",
      "Epoch 57/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.7048 - accuracy: 0.7399 - val_loss: 526.6785 - val_accuracy: 0.7466\n",
      "Epoch 58/100\n",
      "985/985 [==============================] - 65s 66ms/step - loss: 0.6909 - accuracy: 0.7439 - val_loss: 827.2780 - val_accuracy: 0.7410\n",
      "Epoch 59/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.7014 - accuracy: 0.7430 - val_loss: 771.0168 - val_accuracy: 0.7554\n",
      "Epoch 60/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.6710 - accuracy: 0.7512 - val_loss: 811.5791 - val_accuracy: 0.7588\n",
      "Epoch 61/100\n",
      "985/985 [==============================] - 60s 60ms/step - loss: 0.6662 - accuracy: 0.7582 - val_loss: 2239.9167 - val_accuracy: 0.7603\n",
      "Epoch 62/100\n",
      "985/985 [==============================] - 63s 64ms/step - loss: 0.6308 - accuracy: 0.7663 - val_loss: 101.8772 - val_accuracy: 0.7485\n",
      "Epoch 63/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.6536 - accuracy: 0.7627 - val_loss: 930.3508 - val_accuracy: 0.7664\n",
      "Epoch 64/100\n",
      "985/985 [==============================] - 60s 61ms/step - loss: 0.6754 - accuracy: 0.7678 - val_loss: 2226.0798 - val_accuracy: 0.7730\n",
      "Epoch 65/100\n",
      "985/985 [==============================] - 58s 58ms/step - loss: 0.6771 - accuracy: 0.7596 - val_loss: 292.8352 - val_accuracy: 0.7356\n",
      "Epoch 66/100\n",
      "985/985 [==============================] - 64s 65ms/step - loss: 0.6436 - accuracy: 0.7562 - val_loss: 651.9368 - val_accuracy: 0.7448\n",
      "Epoch 67/100\n",
      "985/985 [==============================] - 56s 56ms/step - loss: 0.6770 - accuracy: 0.7633 - val_loss: 249.9748 - val_accuracy: 0.7649\n",
      "Epoch 68/100\n",
      "985/985 [==============================] - 62s 63ms/step - loss: 0.6130 - accuracy: 0.7731 - val_loss: 2514.5989 - val_accuracy: 0.7519\n",
      "Epoch 69/100\n",
      "985/985 [==============================] - 52s 52ms/step - loss: 0.6326 - accuracy: 0.7725 - val_loss: 1181.8485 - val_accuracy: 0.7734\n",
      "Epoch 70/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.6203 - accuracy: 0.7759 - val_loss: 192.3250 - val_accuracy: 0.7841\n",
      "Epoch 71/100\n",
      "985/985 [==============================] - 54s 54ms/step - loss: 0.6955 - accuracy: 0.7488 - val_loss: 5536.4155 - val_accuracy: 0.7429\n",
      "Epoch 72/100\n",
      "985/985 [==============================] - 49s 50ms/step - loss: 0.6719 - accuracy: 0.7552 - val_loss: 21000.6016 - val_accuracy: 0.7439\n",
      "Epoch 73/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.7052 - accuracy: 0.7406 - val_loss: 908.7813 - val_accuracy: 0.7262\n",
      "Epoch 74/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.6723 - accuracy: 0.7557 - val_loss: 183.4755 - val_accuracy: 0.7532\n",
      "Epoch 75/100\n",
      "985/985 [==============================] - 54s 55ms/step - loss: 0.6470 - accuracy: 0.7637 - val_loss: 1101.7183 - val_accuracy: 0.7555\n",
      "Epoch 76/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.6456 - accuracy: 0.7681 - val_loss: 41.1835 - val_accuracy: 0.7587\n",
      "Epoch 77/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.6559 - accuracy: 0.7635 - val_loss: 1001.8016 - val_accuracy: 0.7528\n",
      "Epoch 78/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.6442 - accuracy: 0.7636 - val_loss: 255.2002 - val_accuracy: 0.7535\n",
      "Epoch 79/100\n",
      "985/985 [==============================] - 43s 44ms/step - loss: 0.8103 - accuracy: 0.7501 - val_loss: 11446.6436 - val_accuracy: 0.7513\n",
      "Epoch 80/100\n",
      "985/985 [==============================] - 46s 46ms/step - loss: 1.3769 - accuracy: 0.6850 - val_loss: 1944.3451 - val_accuracy: 0.6754\n",
      "Epoch 81/100\n",
      "985/985 [==============================] - 50s 51ms/step - loss: 0.8111 - accuracy: 0.7087 - val_loss: 5271.3418 - val_accuracy: 0.6958\n",
      "Epoch 82/100\n",
      "985/985 [==============================] - 55s 56ms/step - loss: 0.7766 - accuracy: 0.7127 - val_loss: 4892.6782 - val_accuracy: 0.7118\n",
      "Epoch 83/100\n",
      "985/985 [==============================] - 54s 54ms/step - loss: 0.7461 - accuracy: 0.7226 - val_loss: 51.8747 - val_accuracy: 0.7391\n",
      "Epoch 84/100\n",
      "985/985 [==============================] - 52s 52ms/step - loss: 0.7143 - accuracy: 0.7350 - val_loss: 7775.1172 - val_accuracy: 0.7300\n",
      "Epoch 85/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.7014 - accuracy: 0.7387 - val_loss: 8863.5488 - val_accuracy: 0.7314\n",
      "Epoch 86/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.6869 - accuracy: 0.7436 - val_loss: 477.4381 - val_accuracy: 0.7423\n",
      "Epoch 87/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.6715 - accuracy: 0.7482 - val_loss: 4084.5361 - val_accuracy: 0.7239\n",
      "Epoch 88/100\n",
      "985/985 [==============================] - 62s 63ms/step - loss: 0.6668 - accuracy: 0.7540 - val_loss: 364.5786 - val_accuracy: 0.7467\n",
      "Epoch 89/100\n",
      "985/985 [==============================] - 62s 63ms/step - loss: 0.6876 - accuracy: 0.7536 - val_loss: 1035.5432 - val_accuracy: 0.7439\n",
      "Epoch 90/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.6583 - accuracy: 0.7631 - val_loss: 3816.4448 - val_accuracy: 0.7528\n",
      "Epoch 91/100\n",
      "985/985 [==============================] - 47s 47ms/step - loss: 0.6120 - accuracy: 0.7683 - val_loss: 533.5356 - val_accuracy: 0.7543\n",
      "Epoch 92/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.6487 - accuracy: 0.7662 - val_loss: 102.4475 - val_accuracy: 0.7632\n",
      "Epoch 93/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.7677 - accuracy: 0.7463 - val_loss: 9.6043 - val_accuracy: 0.7587\n",
      "Epoch 94/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.6948 - accuracy: 0.7538 - val_loss: 110.4808 - val_accuracy: 0.7629\n",
      "Epoch 95/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.6338 - accuracy: 0.7636 - val_loss: 351.9087 - val_accuracy: 0.7648\n",
      "Epoch 96/100\n",
      "985/985 [==============================] - 56s 57ms/step - loss: 0.6474 - accuracy: 0.7628 - val_loss: 1374.5182 - val_accuracy: 0.6688\n",
      "Epoch 97/100\n",
      "985/985 [==============================] - 61s 61ms/step - loss: 0.7536 - accuracy: 0.7370 - val_loss: 308.9911 - val_accuracy: 0.7329\n",
      "Epoch 98/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.6889 - accuracy: 0.7508 - val_loss: 94.9867 - val_accuracy: 0.7670\n",
      "Epoch 99/100\n",
      "985/985 [==============================] - 49s 50ms/step - loss: 0.6568 - accuracy: 0.7544 - val_loss: 569.0190 - val_accuracy: 0.7568\n",
      "Epoch 100/100\n",
      "985/985 [==============================] - 55s 56ms/step - loss: 0.6496 - accuracy: 0.7556 - val_loss: 370.0207 - val_accuracy: 0.7670\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D\n",
    "\n",
    "model_path = r\"C:\\Users\\shaif\\Downloads\\invasive_ssl.h5\"\n",
    "model = load_model(model_path)\n",
    "#model.layers[0].trainable = False\n",
    "x = model.layers[-8].output  \n",
    "output = Dense(5, activation='softmax')(x)\n",
    "new_model = keras.models.Model(inputs=model.input, outputs=output)\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, mode='max', verbose=1)\n",
    "new_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = new_model.fit(X_train, y_train, batch_size=32, epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df2a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527c8253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Balanced Accuracy: 0.5964422415682512\n",
      "Test Accuracy: 0.7594962421287833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "predictions = new_model.predict(np.array(X_test).astype('float32'))\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "balanced_accuracy = balanced_accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "print(\"Test Balanced Accuracy:\", balanced_accuracy)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e13845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ffb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc37585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "985/985 [==============================] - 55s 50ms/step - loss: 1.0012 - accuracy: 0.7235 - val_loss: 1196.4908 - val_accuracy: 0.4384\n",
      "Epoch 2/100\n",
      "985/985 [==============================] - 58s 58ms/step - loss: 0.8458 - accuracy: 0.7337 - val_loss: 0.9320 - val_accuracy: 0.6566\n",
      "Epoch 3/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.5347 - accuracy: 0.8039 - val_loss: 0.6323 - val_accuracy: 0.7695\n",
      "Epoch 4/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 0.5154 - accuracy: 0.8182 - val_loss: 1.3514 - val_accuracy: 0.6037\n",
      "Epoch 5/100\n",
      "985/985 [==============================] - 54s 55ms/step - loss: 0.5396 - accuracy: 0.8041 - val_loss: 0.5253 - val_accuracy: 0.8030\n",
      "Epoch 6/100\n",
      "985/985 [==============================] - 46s 46ms/step - loss: 0.4793 - accuracy: 0.8256 - val_loss: 2.4249 - val_accuracy: 0.6598\n",
      "Epoch 7/100\n",
      "985/985 [==============================] - 56s 56ms/step - loss: 0.5909 - accuracy: 0.7939 - val_loss: 0.6627 - val_accuracy: 0.7712\n",
      "Epoch 8/100\n",
      "985/985 [==============================] - 46s 46ms/step - loss: 0.5220 - accuracy: 0.8053 - val_loss: 2.2187 - val_accuracy: 0.6406\n",
      "Epoch 9/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.4481 - accuracy: 0.8367 - val_loss: 1.1745 - val_accuracy: 0.5525\n",
      "Epoch 10/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.4344 - accuracy: 0.8441 - val_loss: 0.4259 - val_accuracy: 0.8529\n",
      "Epoch 11/100\n",
      "985/985 [==============================] - 46s 47ms/step - loss: 0.3835 - accuracy: 0.8613 - val_loss: 2.2309 - val_accuracy: 0.3825\n",
      "Epoch 12/100\n",
      "985/985 [==============================] - 51s 51ms/step - loss: 0.3655 - accuracy: 0.8651 - val_loss: 2.6930 - val_accuracy: 0.4395\n",
      "Epoch 13/100\n",
      "985/985 [==============================] - 43s 44ms/step - loss: 0.5040 - accuracy: 0.8361 - val_loss: 1.8054 - val_accuracy: 0.4942\n",
      "Epoch 14/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.3847 - accuracy: 0.8618 - val_loss: 1.1613 - val_accuracy: 0.5835\n",
      "Epoch 15/100\n",
      "985/985 [==============================] - 48s 49ms/step - loss: 0.3388 - accuracy: 0.8773 - val_loss: 0.4782 - val_accuracy: 0.8180\n",
      "Epoch 16/100\n",
      "985/985 [==============================] - 43s 43ms/step - loss: 0.3117 - accuracy: 0.8845 - val_loss: 0.7180 - val_accuracy: 0.7719\n",
      "Epoch 17/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 0.2972 - accuracy: 0.8911 - val_loss: 0.8853 - val_accuracy: 0.6520\n",
      "Epoch 18/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.2746 - accuracy: 0.8976 - val_loss: 1.2685 - val_accuracy: 0.5982\n",
      "Epoch 19/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.2590 - accuracy: 0.9034 - val_loss: 0.5820 - val_accuracy: 0.7974\n",
      "Epoch 20/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.2488 - accuracy: 0.9094 - val_loss: 0.3071 - val_accuracy: 0.8860\n",
      "Epoch 21/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.2319 - accuracy: 0.9135 - val_loss: 0.4267 - val_accuracy: 0.8607\n",
      "Epoch 22/100\n",
      "985/985 [==============================] - 44s 45ms/step - loss: 0.2127 - accuracy: 0.9217 - val_loss: 2.1867 - val_accuracy: 0.5298\n",
      "Epoch 23/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.1989 - accuracy: 0.9269 - val_loss: 0.7112 - val_accuracy: 0.7497\n",
      "Epoch 24/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.1926 - accuracy: 0.9323 - val_loss: 0.9084 - val_accuracy: 0.8035\n",
      "Epoch 25/100\n",
      "985/985 [==============================] - 45s 45ms/step - loss: 0.2650 - accuracy: 0.9097 - val_loss: 0.3831 - val_accuracy: 0.8591\n",
      "Epoch 26/100\n",
      "985/985 [==============================] - 45s 46ms/step - loss: 0.2125 - accuracy: 0.9227 - val_loss: 0.9815 - val_accuracy: 0.7467\n",
      "Epoch 27/100\n",
      "985/985 [==============================] - 42s 42ms/step - loss: 0.1519 - accuracy: 0.9432 - val_loss: 0.5763 - val_accuracy: 0.8133\n",
      "Epoch 28/100\n",
      "985/985 [==============================] - 47s 48ms/step - loss: 0.1356 - accuracy: 0.9498 - val_loss: 0.4765 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.1256 - accuracy: 0.9534 - val_loss: 0.5658 - val_accuracy: 0.8074\n",
      "Epoch 30/100\n",
      "985/985 [==============================] - 42s 43ms/step - loss: 0.4376 - accuracy: 0.8459 - val_loss: 0.4088 - val_accuracy: 0.8539\n",
      "Epoch 31/100\n",
      "985/985 [==============================] - 48s 48ms/step - loss: 0.3390 - accuracy: 0.8804 - val_loss: 0.4156 - val_accuracy: 0.8545\n",
      "Epoch 32/100\n",
      "985/985 [==============================] - 43s 44ms/step - loss: 0.2018 - accuracy: 0.9278 - val_loss: 0.3483 - val_accuracy: 0.8831\n",
      "Epoch 33/100\n",
      "985/985 [==============================] - 44s 44ms/step - loss: 0.1424 - accuracy: 0.9481 - val_loss: 0.3749 - val_accuracy: 0.8866\n",
      "Epoch 34/100\n",
      "985/985 [==============================] - 43s 44ms/step - loss: 0.2030 - accuracy: 0.9265 - val_loss: 0.8911 - val_accuracy: 0.7918\n",
      "Epoch 35/100\n",
      "985/985 [==============================] - 41s 41ms/step - loss: 0.2460 - accuracy: 0.9221 - val_loss: 0.3260 - val_accuracy: 0.8973\n",
      "Epoch 36/100\n",
      "985/985 [==============================] - 46s 46ms/step - loss: 0.1345 - accuracy: 0.9516 - val_loss: 0.4729 - val_accuracy: 0.8466\n",
      "Epoch 37/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.1116 - accuracy: 0.9584 - val_loss: 0.4887 - val_accuracy: 0.8606\n",
      "Epoch 38/100\n",
      "985/985 [==============================] - 60s 61ms/step - loss: 0.1053 - accuracy: 0.9616 - val_loss: 0.3312 - val_accuracy: 0.8996\n",
      "Epoch 39/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.1031 - accuracy: 0.9623 - val_loss: 1.0778 - val_accuracy: 0.7069\n",
      "Epoch 40/100\n",
      "985/985 [==============================] - 55s 55ms/step - loss: 0.0958 - accuracy: 0.9643 - val_loss: 1.1777 - val_accuracy: 0.7430\n",
      "Epoch 41/100\n",
      "985/985 [==============================] - 60s 61ms/step - loss: 0.0900 - accuracy: 0.9669 - val_loss: 0.6373 - val_accuracy: 0.8172\n",
      "Epoch 42/100\n",
      "985/985 [==============================] - 58s 59ms/step - loss: 0.0895 - accuracy: 0.9673 - val_loss: 0.7052 - val_accuracy: 0.8428\n",
      "Epoch 43/100\n",
      "985/985 [==============================] - 59s 60ms/step - loss: 0.0838 - accuracy: 0.9694 - val_loss: 1.0239 - val_accuracy: 0.7959\n",
      "Epoch 44/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.1027 - accuracy: 0.9672 - val_loss: 1.5935 - val_accuracy: 0.7362\n",
      "Epoch 45/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.0724 - accuracy: 0.9753 - val_loss: 0.6646 - val_accuracy: 0.8502\n",
      "Epoch 46/100\n",
      "985/985 [==============================] - 57s 58ms/step - loss: 0.0635 - accuracy: 0.9777 - val_loss: 0.5024 - val_accuracy: 0.8803\n",
      "Epoch 47/100\n",
      "985/985 [==============================] - 58s 58ms/step - loss: 0.0686 - accuracy: 0.9750 - val_loss: 2.1208 - val_accuracy: 0.6379\n",
      "Epoch 48/100\n",
      "985/985 [==============================] - 52s 53ms/step - loss: 0.0591 - accuracy: 0.9797 - val_loss: 1.0601 - val_accuracy: 0.7823\n",
      "Epoch 49/100\n",
      "138/985 [===>..........................] - ETA: 35s - loss: 0.0343 - accuracy: 0.9900"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m ne_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mne_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(32,32,3), pooling=\"avg\")\n",
    "x =  Dense(500)(base_model.output)\n",
    "output = Dense(5, activation='softmax')(x)\n",
    "ne_model = Model(inputs=base_model.input, outputs=output)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, mode='max', verbose=1)\n",
    "ne_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = ne_model.fit(X_train, y_train, batch_size=32, epochs=100,validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388753c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d77dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7316676823075361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = ne_model.predict(np.array(X_test).astype('float32'))\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ccc94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76349b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = MobileNetV2(include_top=False, weights=None, input_shape=(32,32,3), pooling=\"avg\")\n",
    "x =  Dense(500)(base_model.output)\n",
    "output = Dense(5, activation='softmax')(x) \n",
    "new_model = Model(inputs=base_model.input, outputs=output)\n",
    "new_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "new_model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d64a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4174111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = new_model.predict(np.array(X_test).astype('float32'))\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a46cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b14ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49d284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8f928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c63c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552da65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
