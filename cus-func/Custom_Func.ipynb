{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acba090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf0822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeab214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a504b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn1='D:/Inv_Data_Imbalance/data/invasive-aquatic-species-data/invasive/*/'\n",
    "trn2='D:/Inv_Data_Imbalance/data/invasive-aquatic-species-data/noninvasive/*/'\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)\n",
    "tr1= shuffle(tr1)\n",
    "tr2= shuffle(tr2)\n",
    "\n",
    "tran_index_inv = np.round( len(tr1)* .7 )\n",
    "tran_index_noninv = np.round( len(tr2)* .7  )\n",
    "tran_index_noninv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c51980",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[:(int) (tran_index_inv)]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[:(int) (tran_index_noninv)]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[:(int) (tran_index_inv)])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr2[:(int) (tran_index_noninv)])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((15, 15))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(15,15,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),15,15,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079c6d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3062, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "train_df= []\n",
    "breath = 6\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*6+k)\n",
    "        \n",
    "        deff.append(X_train[index])\n",
    "        \n",
    "    train_df.append(deff)\n",
    "\n",
    "Y_train = to_categorical(label)\n",
    "train_df = np.array(train_df)\n",
    "train_df,Y_train = shuffle(train_df,Y_train)\n",
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d262b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[(int) (tran_index_inv) + 1 :]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[ (int)(tran_index_noninv) + 1:]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[(int) (tran_index_inv) + 1 :])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr2[ (int)(tran_index_noninv) + 1:])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((15, 15))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(15,15,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),15,15,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661c2759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "test_df= []\n",
    "breath = 6\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*6+k)\n",
    "        \n",
    "        deff.append(X_test[index])\n",
    "        \n",
    "    test_df.append(deff)\n",
    "    \n",
    "Y_test = to_categorical(label)\n",
    "test_df = np.array(test_df)\n",
    "test_df,Y_test = shuffle(test_df,Y_test)\n",
    "np.shape(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5cc97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31947b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimalRNNCell(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer=tf.keras.initializers.Ones(),\n",
    "                                      name='kernel')\n",
    "        self.recurrent_kernel = self.add_weight(\n",
    "            shape=(self.units, self.units),\n",
    "            initializer='uniform',\n",
    "            name='recurrent_kernel')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states = (6,6)):\n",
    "        prev_output = states[0]\n",
    "        h = K.dot(inputs, self.kernel)\n",
    "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
    "        return output, [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc77872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomLayer(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, output_dim,  activation=None, **kwargs): \n",
    "        \n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        super(CustomLayer, self).__init__(**kwargs) \n",
    "        \n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        w_init = tf.keras.initializers.Ones()\n",
    "        \n",
    "        self.w = tf.Variable(name=\"kernel\",   initial_value=w_init(shape=(input_shape[-1], self.output_dim),\n",
    "                 dtype='float32'),trainable=True)\n",
    "\n",
    "        b_init = tf.zeros_initializer()\n",
    "        \n",
    "        self.b = tf.Variable(name=\"bias\",initial_value=b_init(shape=(self.output_dim,), dtype='float32'),trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        return self.activation(tf.matmul(inputs, self.w) + self.b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8262812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Layer, RNN\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "    \n",
    "class CustomLSTMCell(Layer):\n",
    "    \n",
    "    def __init__(self, units, **kwargs):\n",
    "        \n",
    "        self.state_size = [units, units]\n",
    "        super(CustomLSTMCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.forget_w = self.add_weight(shape=(1, self.state_size[0], self.state_size[0] + input_shape[-1]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='forget_w')\n",
    "        \n",
    "        self.forget_b = self.add_weight(shape=(1, self.state_size[0]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='forget_b')\n",
    "\n",
    "        self.input_w1 = self.add_weight(shape=(1, self.state_size[0], self.state_size[0] + input_shape[-1]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='input_w1')\n",
    "        \n",
    "        self.input_b1 = self.add_weight(shape=(1, self.state_size[0]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='input_b1')\n",
    "        \n",
    "        self.input_w2 = self.add_weight(shape=(1, self.state_size[0], self.state_size[0] + input_shape[-1]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='input_w2')\n",
    "        \n",
    "        self.input_b2 = self.add_weight(shape=(1, self.state_size[0],),\n",
    "                                         initializer='uniform',\n",
    "                                         name='input_b2')\n",
    "\n",
    "        self.output_w = self.add_weight(shape=(1, self.state_size[0], self.state_size[0] + input_shape[-1]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='output_w')\n",
    "        \n",
    "        self.output_b = self.add_weight(shape=(1, self.state_size[0],),\n",
    "                                         initializer='uniform',\n",
    "                                         name='output_b')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def merge_with_state(self, inputs):\n",
    "        \n",
    "        self.stateH = K.concatenate([self.stateH, inputs], axis=-1)\n",
    "\n",
    "    def forget_gate(self):  \n",
    "        \n",
    "        forget = K.batch_dot(self.forget_w, self.stateH) + self.forget_b\n",
    "        \n",
    "        forget = K.sigmoid(forget)\n",
    "        \n",
    "        self.stateC = self.stateC * forget\n",
    "\n",
    "    def input_gate(self):\n",
    "        \n",
    "        candidate = K.batch_dot(self.input_w1, self.stateH) + self.input_b1\n",
    "        \n",
    "        candidate = K.tanh(candidate)\n",
    "\n",
    "        amount = K.batch_dot(self.input_w2, self.stateH) + self.input_b2\n",
    "        \n",
    "        amount = K.sigmoid(amount)\n",
    "\n",
    "        self.stateC = self.stateC + amount * candidate\n",
    "\n",
    "    def output_gate(self):\n",
    "        \n",
    "        self.stateH = K.batch_dot(self.output_w, self.stateH) + self.output_b\n",
    "        \n",
    "        self.stateH = K.sigmoid(self.stateH)\n",
    "\n",
    "        self.stateH = self.stateH * K.tanh(self.stateC)\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "\n",
    "        self.stateH = states[0]\n",
    "        \n",
    "        self.stateC = states[1]\n",
    "\n",
    "        self.merge_with_state(inputs)\n",
    "        \n",
    "        self.forget_gate()\n",
    "        \n",
    "        self.input_gate()\n",
    "        \n",
    "        self.output_gate()\n",
    "\n",
    "        return self.stateH, [self.stateH, self.stateC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2676f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 3)]         0         \n",
      "                                                                 \n",
      " rnn (RNN)                   (None, 10)                560       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 560\n",
      "Trainable params: 560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(None, 3))\n",
    "lstm = RNN(CustomLSTMCell(10))(inp)\n",
    "\n",
    "model = Model(inputs=inp, outputs=lstm)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bac82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d89f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36be08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cf3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Layer, RNN\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def tep1(x):\n",
    "    \n",
    "    a= tf.multiply(x,-15.00)\n",
    "    ex=tf.exp(a)\n",
    "    b=tf.add(ex,1.00)\n",
    "    m=tf.truediv(1.00,b)\n",
    "    \n",
    "    return m;\n",
    "\n",
    "def tep2(x):\n",
    "    \n",
    "    a= tf.multiply(x,-10.00)\n",
    "    ex=tf.exp(a)\n",
    "    b=tf.add(ex,1.00)\n",
    "    m=tf.truediv(1.00,b)\n",
    "    \n",
    "    return m;\n",
    "\n",
    "def tep3(x):\n",
    "    \n",
    "    a= tf.multiply(x,-2.00)\n",
    "    ex=tf.exp(a)\n",
    "    b=tf.add(ex,1.00)\n",
    "    m=tf.truediv(1.00,b)\n",
    "    return m;\n",
    "\n",
    "    \n",
    "class CustomLSTMCell(Layer):\n",
    "    \n",
    "    def __init__(self, units, **kwargs):\n",
    "        \n",
    "        self.state_size = [units, units]\n",
    "        super(CustomLSTMCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.forget_w = self.add_weight(shape=(1, self.state_size[0], self.state_size[0] + input_shape[-1]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='forget_w')\n",
    "        \n",
    "        self.forget_b = self.add_weight(shape=(1, self.state_size[0]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='forget_b')\n",
    "\n",
    "        self.input_w1 = self.add_weight(shape=(1, self.state_size[0], self.state_size[0] + input_shape[-1]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='input_w1')\n",
    "        \n",
    "        self.input_b1 = self.add_weight(shape=(1, self.state_size[0]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='input_b1')\n",
    "        \n",
    "        self.input_w2 = self.add_weight(shape=(1, self.state_size[0], self.state_size[0] + input_shape[-1]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='input_w2')\n",
    "        \n",
    "        self.input_b2 = self.add_weight(shape=(1, self.state_size[0],),\n",
    "                                         initializer='uniform',\n",
    "                                         name='input_b2')\n",
    "\n",
    "        self.output_w = self.add_weight(shape=(1, self.state_size[0], self.state_size[0] + input_shape[-1]),\n",
    "                                         initializer='uniform',\n",
    "                                         name='output_w')\n",
    "        \n",
    "        self.output_b = self.add_weight(shape=(1, self.state_size[0],),\n",
    "                                         initializer='uniform',\n",
    "                                         name='output_b')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def merge_with_state(self, inputs):\n",
    "        \n",
    "        self.stateH = K.concatenate([self.stateH, inputs], axis=-1)\n",
    "\n",
    "    def forget_gate(self):  \n",
    "        \n",
    "        forget = K.batch_dot(self.forget_w, self.stateH) + self.forget_b\n",
    "        \n",
    "        forget = K.sigmoid(forget)\n",
    "        \n",
    "        self.stateC = self.stateC * forget\n",
    "\n",
    "    def input_gate(self):\n",
    "        \n",
    "        candidate = K.batch_dot(self.input_w1, self.stateH) + self.input_b1\n",
    "        \n",
    "        candidate = K.tanh(candidate)\n",
    "\n",
    "        amount = K.batch_dot(self.input_w2, self.stateH) + self.input_b2\n",
    "        \n",
    "        amount = K.sigmoid(amount)\n",
    "\n",
    "        self.stateC = self.stateC + amount * candidate\n",
    "\n",
    "    def output_gate(self):\n",
    "        \n",
    "        self.stateH = K.batch_dot(self.output_w, self.stateH) + self.output_b\n",
    "        \n",
    "        self.stateH = K.sigmoid(self.stateH)\n",
    "\n",
    "        self.stateH = self.stateH * K.tanh(self.stateC)\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "\n",
    "        self.stateH = states[0]\n",
    "        \n",
    "        self.stateC = states[1]\n",
    "\n",
    "        self.merge_with_state(inputs)\n",
    "        \n",
    "        self.forget_gate()\n",
    "        \n",
    "        self.input_gate()\n",
    "        \n",
    "        self.output_gate()\n",
    "\n",
    "        return self.stateH, [self.stateH, self.stateC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc7dc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0523831a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_20 (TimeDi  (None, 6, 13, 13, 32)    896       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_21 (TimeDi  (None, 6, 11, 11, 16)    4624      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 6, 9, 9, 8)       1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_23 (TimeDi  (None, 6, 7, 7, 4)       292       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_24 (TimeDi  (None, 6, 196)           0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " rnn_2 (RNN)                 (None, 10)                8280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                352       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,670\n",
      "Trainable params: 15,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "model= models.Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'),input_shape=(6, 15, 15, 3)) )\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')) )\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')) )\n",
    "model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')) )\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()) )\n",
    "\n",
    "model.add(RNN(CustomLSTMCell(10)) )\n",
    "\n",
    "model.add(Dense(32,activation='relu') )\n",
    "#model.add(MyCustomLayer(8, input_shape = (32,),activation='relu' ) )\n",
    "model.add(Dense(2, activation='softmax') )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "model= models.Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'),input_shape=(6, 15, 15, 3)) )\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')) )\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')) )\n",
    "model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')) )\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()) )\n",
    "\n",
    "model.add(RNN(CustomLSTMCell(100)) )\n",
    "\n",
    "model.add(Dense(32,activation='relu') )\n",
    "#model.add(MyCustomLayer(8, input_shape = (32,),activation='relu' ) )\n",
    "model.add(Dense(2, activation='softmax') )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6b82757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "model= models.Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'),input_shape=(6, 15, 15, 3)))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(100,return_sequences=False,dropout=0.2)) # used 32 units\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "#model.add(CustomLayer(8, input_shape = (32,),activation='relu' ))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28803bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf326e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60360ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_63 (TimeDi  (None, 6, 13, 13, 32)    896       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_64 (TimeDi  (None, 6, 11, 11, 16)    4624      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_65 (TimeDi  (None, 6, 9, 9, 8)       1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_66 (TimeDi  (None, 6, 7, 7, 4)       292       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_67 (TimeDi  (None, 6, 196)           0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 6, 10)             8280      \n",
      "                                                                 \n",
      " Attention (SeqSelfAttention  (None, 6, 10)            101       \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 60)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                1952      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,371\n",
      "Trainable params: 17,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "model= models.Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'),input_shape=(6, 15, 15, 3)))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(10,return_sequences=True,dropout=0.2)) # used 32 units\n",
    "model.add(SeqSelfAttention(attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,name='Attention'))\n",
    "\n",
    "model.add((Flatten()))\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aa5b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "model= models.Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'),input_shape=(6, 15, 15, 3)))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(10,return_sequences=False,dropout=0.2)) # used 32 units\n",
    "\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c6df61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "77/77 [==============================] - 7s 55ms/step - loss: 0.3949 - accuracy: 0.8501 - val_loss: 0.4072 - val_accuracy: 0.8499\n",
      "Epoch 2/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.2233 - accuracy: 0.8963 - val_loss: 0.2096 - val_accuracy: 0.8956\n",
      "Epoch 3/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.1860 - accuracy: 0.9106 - val_loss: 0.2244 - val_accuracy: 0.8956\n",
      "Epoch 4/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.1708 - accuracy: 0.9183 - val_loss: 0.2732 - val_accuracy: 0.8923\n",
      "Epoch 5/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.1720 - accuracy: 0.9249 - val_loss: 0.2022 - val_accuracy: 0.9070\n",
      "Epoch 6/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.1588 - accuracy: 0.9253 - val_loss: 0.2370 - val_accuracy: 0.9054\n",
      "Epoch 7/80\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 0.1560 - accuracy: 0.9322 - val_loss: 0.2130 - val_accuracy: 0.9070\n",
      "Epoch 8/80\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.1533 - accuracy: 0.9339 - val_loss: 0.1805 - val_accuracy: 0.9201\n",
      "Epoch 9/80\n",
      "77/77 [==============================] - 4s 56ms/step - loss: 0.1395 - accuracy: 0.9428 - val_loss: 0.1804 - val_accuracy: 0.9233\n",
      "Epoch 10/80\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 0.1340 - accuracy: 0.9432 - val_loss: 0.1842 - val_accuracy: 0.9315\n",
      "Epoch 11/80\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 0.1280 - accuracy: 0.9473 - val_loss: 0.2016 - val_accuracy: 0.9217\n",
      "Epoch 12/80\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 0.1331 - accuracy: 0.9457 - val_loss: 0.1697 - val_accuracy: 0.9331\n",
      "Epoch 13/80\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 0.1210 - accuracy: 0.9539 - val_loss: 0.1713 - val_accuracy: 0.9315\n",
      "Epoch 14/80\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 0.1283 - accuracy: 0.9486 - val_loss: 0.1630 - val_accuracy: 0.9347\n",
      "Epoch 15/80\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.1268 - accuracy: 0.9465 - val_loss: 0.1605 - val_accuracy: 0.9429\n",
      "Epoch 16/80\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.1215 - accuracy: 0.9498 - val_loss: 0.1591 - val_accuracy: 0.9380\n",
      "Epoch 17/80\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 0.1170 - accuracy: 0.9522 - val_loss: 0.1578 - val_accuracy: 0.9380\n",
      "Epoch 18/80\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.1079 - accuracy: 0.9563 - val_loss: 0.2018 - val_accuracy: 0.9119\n",
      "Epoch 19/80\n",
      "77/77 [==============================] - 4s 58ms/step - loss: 0.1094 - accuracy: 0.9514 - val_loss: 0.1731 - val_accuracy: 0.9331\n",
      "Epoch 20/80\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.1036 - accuracy: 0.9579 - val_loss: 0.1549 - val_accuracy: 0.9462\n",
      "Epoch 21/80\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.1020 - accuracy: 0.9588 - val_loss: 0.1731 - val_accuracy: 0.9331\n",
      "Epoch 22/80\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 0.0961 - accuracy: 0.9633 - val_loss: 0.1522 - val_accuracy: 0.9347\n",
      "Epoch 23/80\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 0.0965 - accuracy: 0.9567 - val_loss: 0.1889 - val_accuracy: 0.9233\n",
      "Epoch 24/80\n",
      "77/77 [==============================] - 4s 48ms/step - loss: 0.0965 - accuracy: 0.9596 - val_loss: 0.1484 - val_accuracy: 0.9429\n",
      "Epoch 25/80\n",
      "77/77 [==============================] - 4s 48ms/step - loss: 0.1078 - accuracy: 0.9579 - val_loss: 0.1727 - val_accuracy: 0.9331\n",
      "Epoch 26/80\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 0.0923 - accuracy: 0.9633 - val_loss: 0.1493 - val_accuracy: 0.9413\n",
      "Epoch 27/80\n",
      "77/77 [==============================] - 5s 61ms/step - loss: 0.0865 - accuracy: 0.9645 - val_loss: 0.1556 - val_accuracy: 0.9315\n",
      "Epoch 28/80\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.1030 - accuracy: 0.9555 - val_loss: 0.1987 - val_accuracy: 0.9201\n",
      "Epoch 29/80\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 0.0915 - accuracy: 0.9596 - val_loss: 0.1560 - val_accuracy: 0.9347\n",
      "Epoch 30/80\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 0.0882 - accuracy: 0.9641 - val_loss: 0.1727 - val_accuracy: 0.9266\n",
      "Epoch 31/80\n",
      "77/77 [==============================] - 4s 57ms/step - loss: 0.1052 - accuracy: 0.9579 - val_loss: 0.1880 - val_accuracy: 0.9168\n",
      "Epoch 32/80\n",
      "77/77 [==============================] - 5s 59ms/step - loss: 0.0874 - accuracy: 0.9661 - val_loss: 0.1465 - val_accuracy: 0.9380\n",
      "Epoch 33/80\n",
      "77/77 [==============================] - 5s 60ms/step - loss: 0.0741 - accuracy: 0.9682 - val_loss: 0.1851 - val_accuracy: 0.9347\n",
      "Epoch 34/80\n",
      "77/77 [==============================] - 5s 63ms/step - loss: 0.0753 - accuracy: 0.9677 - val_loss: 0.1806 - val_accuracy: 0.9380\n",
      "Epoch 35/80\n",
      "77/77 [==============================] - 5s 64ms/step - loss: 0.0771 - accuracy: 0.9698 - val_loss: 0.2090 - val_accuracy: 0.9184\n",
      "Epoch 36/80\n",
      "77/77 [==============================] - 5s 65ms/step - loss: 0.0749 - accuracy: 0.9698 - val_loss: 0.1649 - val_accuracy: 0.9168\n",
      "Epoch 37/80\n",
      "77/77 [==============================] - 5s 65ms/step - loss: 0.1025 - accuracy: 0.9592 - val_loss: 0.1477 - val_accuracy: 0.9413\n",
      "Epoch 38/80\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.0784 - accuracy: 0.9710 - val_loss: 0.1679 - val_accuracy: 0.9152\n",
      "Epoch 39/80\n",
      "77/77 [==============================] - 4s 55ms/step - loss: 0.0681 - accuracy: 0.9722 - val_loss: 0.1665 - val_accuracy: 0.9445\n",
      "Epoch 40/80\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 0.0612 - accuracy: 0.9747 - val_loss: 0.2157 - val_accuracy: 0.9380\n",
      "Epoch 41/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0770 - accuracy: 0.9739 - val_loss: 0.1744 - val_accuracy: 0.9315\n",
      "Epoch 42/80\n",
      "77/77 [==============================] - 4s 46ms/step - loss: 0.0599 - accuracy: 0.9726 - val_loss: 0.1835 - val_accuracy: 0.9478\n",
      "Epoch 43/80\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 0.0730 - accuracy: 0.9710 - val_loss: 0.1741 - val_accuracy: 0.9331\n",
      "Epoch 44/80\n",
      "77/77 [==============================] - 4s 54ms/step - loss: 0.0678 - accuracy: 0.9751 - val_loss: 0.2402 - val_accuracy: 0.9233\n",
      "Epoch 45/80\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 0.0703 - accuracy: 0.9710 - val_loss: 0.1782 - val_accuracy: 0.9217\n",
      "Epoch 46/80\n",
      "77/77 [==============================] - 4s 52ms/step - loss: 0.0648 - accuracy: 0.9747 - val_loss: 0.1898 - val_accuracy: 0.9347\n",
      "Epoch 47/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0615 - accuracy: 0.9755 - val_loss: 0.1679 - val_accuracy: 0.9347\n",
      "Epoch 48/80\n",
      "77/77 [==============================] - 4s 48ms/step - loss: 0.0614 - accuracy: 0.9726 - val_loss: 0.1829 - val_accuracy: 0.9347\n",
      "Epoch 49/80\n",
      "77/77 [==============================] - 4s 49ms/step - loss: 0.0696 - accuracy: 0.9686 - val_loss: 0.1728 - val_accuracy: 0.9396\n",
      "Epoch 50/80\n",
      "77/77 [==============================] - 4s 46ms/step - loss: 0.0592 - accuracy: 0.9767 - val_loss: 0.1788 - val_accuracy: 0.9315\n",
      "Epoch 51/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0491 - accuracy: 0.9820 - val_loss: 0.1823 - val_accuracy: 0.9445\n",
      "Epoch 52/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0541 - accuracy: 0.9796 - val_loss: 0.2304 - val_accuracy: 0.9331\n",
      "Epoch 53/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0504 - accuracy: 0.9788 - val_loss: 0.2326 - val_accuracy: 0.9070\n",
      "Epoch 54/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0653 - accuracy: 0.9763 - val_loss: 0.2321 - val_accuracy: 0.9201\n",
      "Epoch 55/80\n",
      "77/77 [==============================] - 4s 48ms/step - loss: 0.0443 - accuracy: 0.9824 - val_loss: 0.1944 - val_accuracy: 0.9364\n",
      "Epoch 56/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.1929 - val_accuracy: 0.9347\n",
      "Epoch 57/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0397 - accuracy: 0.9841 - val_loss: 0.2622 - val_accuracy: 0.9282\n",
      "Epoch 58/80\n",
      "77/77 [==============================] - 4s 46ms/step - loss: 0.0497 - accuracy: 0.9820 - val_loss: 0.2071 - val_accuracy: 0.9429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/80\n",
      "77/77 [==============================] - 4s 46ms/step - loss: 0.0435 - accuracy: 0.9841 - val_loss: 0.2360 - val_accuracy: 0.9266\n",
      "Epoch 60/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0577 - accuracy: 0.9784 - val_loss: 0.2149 - val_accuracy: 0.9413\n",
      "Epoch 61/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0519 - accuracy: 0.9771 - val_loss: 0.2063 - val_accuracy: 0.9396\n",
      "Epoch 62/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0371 - accuracy: 0.9845 - val_loss: 0.1994 - val_accuracy: 0.9413\n",
      "Epoch 63/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0459 - accuracy: 0.9796 - val_loss: 0.2165 - val_accuracy: 0.9380\n",
      "Epoch 64/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0344 - accuracy: 0.9869 - val_loss: 0.2382 - val_accuracy: 0.9331\n",
      "Epoch 65/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0425 - accuracy: 0.9837 - val_loss: 0.1958 - val_accuracy: 0.9413\n",
      "Epoch 66/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0288 - accuracy: 0.9878 - val_loss: 0.2446 - val_accuracy: 0.9347\n",
      "Epoch 67/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0316 - accuracy: 0.9886 - val_loss: 0.2148 - val_accuracy: 0.9299\n",
      "Epoch 68/80\n",
      "77/77 [==============================] - 3s 45ms/step - loss: 0.0429 - accuracy: 0.9820 - val_loss: 0.2465 - val_accuracy: 0.9315\n",
      "Epoch 69/80\n",
      "77/77 [==============================] - 4s 46ms/step - loss: 0.0360 - accuracy: 0.9861 - val_loss: 0.2599 - val_accuracy: 0.9233\n",
      "Epoch 70/80\n",
      "77/77 [==============================] - 4s 46ms/step - loss: 0.0459 - accuracy: 0.9833 - val_loss: 0.2906 - val_accuracy: 0.9347\n",
      "Epoch 71/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0458 - accuracy: 0.9816 - val_loss: 0.3366 - val_accuracy: 0.9299\n",
      "Epoch 72/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0426 - accuracy: 0.9833 - val_loss: 0.2287 - val_accuracy: 0.9380\n",
      "Epoch 73/80\n",
      "77/77 [==============================] - 4s 48ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.2652 - val_accuracy: 0.9380\n",
      "Epoch 74/80\n",
      "77/77 [==============================] - 4s 47ms/step - loss: 0.0243 - accuracy: 0.9902 - val_loss: 0.2691 - val_accuracy: 0.9380\n",
      "Epoch 75/80\n",
      "77/77 [==============================] - 4s 46ms/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.2858 - val_accuracy: 0.9364\n",
      "Epoch 76/80\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.2746 - val_accuracy: 0.9364\n",
      "Epoch 77/80\n",
      "77/77 [==============================] - 4s 48ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.2758 - val_accuracy: 0.9478\n",
      "Epoch 78/80\n",
      "77/77 [==============================] - 4s 48ms/step - loss: 0.0742 - accuracy: 0.9710 - val_loss: 0.3362 - val_accuracy: 0.9119\n",
      "Epoch 79/80\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 0.0317 - accuracy: 0.9898 - val_loss: 0.2402 - val_accuracy: 0.9445\n",
      "Epoch 80/80\n",
      "77/77 [==============================] - 4s 53ms/step - loss: 0.0257 - accuracy: 0.9902 - val_loss: 0.2488 - val_accuracy: 0.9396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d805137160>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f75542c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1099,   18],\n",
       "       [  10,  183]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y_test[:2000]\n",
    "pred = model.predict(test_df[:2000])\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "199466a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289340101522843"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "56a3eb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (32,6,12)\n",
    "a[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257102bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
