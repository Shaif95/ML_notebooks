{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5419b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fca053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn='D:/data/PennA/Penn_Action/*/'\n",
    "tr= glob(trn)\n",
    "\n",
    "len(tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273abbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "test_y = []\n",
    "\n",
    "y = 0\n",
    "for i in tr:\n",
    "    \n",
    "    #print(i)\n",
    "    x = glob(i+'/*/')\n",
    "    \n",
    "    #shuffle(x)\n",
    "    t,tt = train_test_split( x , test_size=0.1, random_state=42)\n",
    "    t, vv = train_test_split( t , test_size=0.1, random_state=42)\n",
    "    \n",
    "    for j in t:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "        \n",
    "        train.append(j)\n",
    "        train_y.append(y)\n",
    "    \n",
    "    for j in vv:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        val.append(j)\n",
    "        val_y.append(y)\n",
    "        \n",
    "    for j in tt:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        test.append(j)\n",
    "        test_y.append(y)\n",
    "        \n",
    "    y = y+1\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tra_y =  np.array(to_categorical(train_y))\n",
    "va_y  =  np.array(to_categorical(val_y))\n",
    "te_y  =  np.array(to_categorical(test_y))\n",
    "\n",
    "(train, tra_y) = shuffle(train, tra_y)\n",
    "(val, va_y) = shuffle(val, va_y)\n",
    "(test, te_y) = shuffle(test, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "798d6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    for i in range(0,5):\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((224, 224))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(224,224,3))\n",
    "        \n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e352d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b004fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , batch_size) :\n",
    "    self.filename = filename\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28523f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(train, tra_y, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(val, va_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bded865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(My_Test_Generator(test, batch_size).__getitem__(1))\n",
    "for i in range(2,len(x)):\n",
    "    x = My_Test_Generator(test, batch_size).__getitem__(i)\n",
    "    arr = np.concatenate((arr,x),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffe4a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5, 224, 224, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eb0f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_48 (TimeDi  (None, 5, 222, 222, 256)  7168     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_49 (TimeDi  (None, 5, 111, 111, 256)  0        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_50 (TimeDi  (None, 5, 109, 109, 128)  295040   \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_51 (TimeDi  (None, 5, 54, 54, 128)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_52 (TimeDi  (None, 5, 52, 52, 64)    73792     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_53 (TimeDi  (None, 5, 26, 26, 64)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_54 (TimeDi  (None, 5, 24, 24, 32)    18464     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_55 (TimeDi  (None, 5, 12, 12, 32)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_56 (TimeDi  (None, 5, 10, 10, 16)    4624      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_57 (TimeDi  (None, 5, 5, 5, 16)      0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_58 (TimeDi  (None, 5, 3, 3, 8)       1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_59 (TimeDi  (None, 5, 72)            0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 50)                24600     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 15)                765       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,613\n",
      "Trainable params: 425,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "num_frames = 5\n",
    "frame_height = 224\n",
    "frame_width = 224\n",
    "num_channels = 3\n",
    "num_classes = 15  # Change this to the number of classes in your dataset\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CNN\n",
    "model.add(TimeDistributed(Conv2D(256, (3, 3), activation='relu'), input_shape=(num_frames, frame_height, frame_width, num_channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(50))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81e2a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67fd3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_1528\\789722107.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_1528\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[80,256,222,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential_4/time_distributed_49/max_pooling2d_21/MaxPool/MaxPoolGrad\n (defined at C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_9946]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/sequential_4/time_distributed_49/max_pooling2d_21/MaxPool/MaxPoolGrad:\nIn[0] sequential_4/time_distributed_49/Reshape (defined at C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\layers\\wrappers.py:260)\t\nIn[1] sequential_4/time_distributed_49/max_pooling2d_21/MaxPool (defined at C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\layers\\pooling.py:357)\t\nIn[2] gradient_tape/sequential_4/time_distributed_49/Reshape:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n>>>     result = runner(coro)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_1528\\789722107.py\", line 2, in <module>\n>>>     model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 2016, in fit_generator\n>>>     return self.fit(\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_training_batch_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmy_validation_batch_generator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py:2016\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2006\u001b[0m \n\u001b[0;32m   2007\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   2009\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[0;32m   2010\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2011\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2012\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2013\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2014\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2015\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2016\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2018\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2030\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[80,256,222,222] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential_4/time_distributed_49/max_pooling2d_21/MaxPool/MaxPoolGrad\n (defined at C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_9946]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/sequential_4/time_distributed_49/max_pooling2d_21/MaxPool/MaxPoolGrad:\nIn[0] sequential_4/time_distributed_49/Reshape (defined at C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\layers\\wrappers.py:260)\t\nIn[1] sequential_4/time_distributed_49/max_pooling2d_21/MaxPool (defined at C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\layers\\pooling.py:357)\t\nIn[2] gradient_tape/sequential_4/time_distributed_49/Reshape:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 728, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n>>>     res = shell.run_cell(\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n>>>     result = runner(coro)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_1528\\789722107.py\", line 2, in <module>\n>>>     model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 2016, in fit_generator\n>>>     return self.fit(\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"C:\\Users\\shaif\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(My_Test_Generator(test, batch_size), verbose=0)\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import Ofrom sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "scoreneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "p = np.argmax(predictions, axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ab8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossAndMetrics = model.evaluate(arr, te_y)\n",
    "lossAndMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69843fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(4, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                (layers.Conv2D(8, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2649eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (10,40,40,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(10, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.3)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "outputs = layers.Dense(units=15, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98506d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\1958852391.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 2.7010 - accuracy: 0.0975 - val_loss: 2.5393 - val_accuracy: 0.1495\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 2.4694 - accuracy: 0.1551 - val_loss: 2.3966 - val_accuracy: 0.1916\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.3188 - accuracy: 0.2116 - val_loss: 2.2126 - val_accuracy: 0.2383\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.1786 - accuracy: 0.2425 - val_loss: 2.0953 - val_accuracy: 0.2850\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.0074 - accuracy: 0.3177 - val_loss: 2.0630 - val_accuracy: 0.3131\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.8937 - accuracy: 0.3609 - val_loss: 2.0963 - val_accuracy: 0.3551\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.7027 - accuracy: 0.4270 - val_loss: 2.1092 - val_accuracy: 0.3598\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.6063 - accuracy: 0.4659 - val_loss: 2.0904 - val_accuracy: 0.3411\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.4988 - accuracy: 0.5075 - val_loss: 2.1328 - val_accuracy: 0.3271\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 1.3796 - accuracy: 0.5384 - val_loss: 2.1468 - val_accuracy: 0.3692\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.2801 - accuracy: 0.5821 - val_loss: 2.1217 - val_accuracy: 0.4159\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.1926 - accuracy: 0.5991 - val_loss: 2.2305 - val_accuracy: 0.3925\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.0973 - accuracy: 0.6343 - val_loss: 2.1840 - val_accuracy: 0.3972\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.9823 - accuracy: 0.6818 - val_loss: 2.2423 - val_accuracy: 0.4206\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.8933 - accuracy: 0.7111 - val_loss: 2.3906 - val_accuracy: 0.4019\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.8420 - accuracy: 0.7233 - val_loss: 2.3831 - val_accuracy: 0.4393\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.7419 - accuracy: 0.7607 - val_loss: 2.4700 - val_accuracy: 0.4299\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.6882 - accuracy: 0.7788 - val_loss: 2.4809 - val_accuracy: 0.4019\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6102 - accuracy: 0.8001 - val_loss: 2.6649 - val_accuracy: 0.3832\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6006 - accuracy: 0.7894 - val_loss: 2.5325 - val_accuracy: 0.4159\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.4936 - accuracy: 0.8406 - val_loss: 2.6374 - val_accuracy: 0.4252\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.4315 - accuracy: 0.8625 - val_loss: 2.8971 - val_accuracy: 0.3832\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3825 - accuracy: 0.8785 - val_loss: 2.9358 - val_accuracy: 0.4159\n",
      "Epoch 24/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3450 - accuracy: 0.8854 - val_loss: 2.9100 - val_accuracy: 0.3972\n",
      "Epoch 25/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3824 - accuracy: 0.8662 - val_loss: 3.0404 - val_accuracy: 0.4065\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.3293 - accuracy: 0.8902 - val_loss: 2.8838 - val_accuracy: 0.4299\n",
      "Epoch 27/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2496 - accuracy: 0.9334 - val_loss: 3.1626 - val_accuracy: 0.4112\n",
      "Epoch 28/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2344 - accuracy: 0.9243 - val_loss: 3.0807 - val_accuracy: 0.4065\n",
      "Epoch 29/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2187 - accuracy: 0.9259 - val_loss: 3.2106 - val_accuracy: 0.4206\n",
      "Epoch 30/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2633 - accuracy: 0.9088 - val_loss: 3.1247 - val_accuracy: 0.4019\n",
      "Epoch 31/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.2184 - accuracy: 0.9307 - val_loss: 3.2864 - val_accuracy: 0.3925\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.1306 - accuracy: 0.9664 - val_loss: 3.2190 - val_accuracy: 0.4206\n",
      "Epoch 33/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0923 - accuracy: 0.9765 - val_loss: 3.4107 - val_accuracy: 0.4346\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0822 - accuracy: 0.9776 - val_loss: 3.2697 - val_accuracy: 0.4626\n",
      "Epoch 35/50\n",
      "59/59 [==============================] - 78s 1s/step - loss: 0.1045 - accuracy: 0.9712 - val_loss: 3.4077 - val_accuracy: 0.4393\n",
      "Epoch 36/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.1467 - accuracy: 0.9520 - val_loss: 3.5177 - val_accuracy: 0.4112\n",
      "Epoch 37/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.2258 - accuracy: 0.9291 - val_loss: 3.4396 - val_accuracy: 0.4019\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.2296 - accuracy: 0.9200 - val_loss: 3.5429 - val_accuracy: 0.4206\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.1258 - accuracy: 0.9627 - val_loss: 3.5298 - val_accuracy: 0.4393\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0759 - accuracy: 0.9813 - val_loss: 3.4607 - val_accuracy: 0.4299\n",
      "Epoch 41/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0457 - accuracy: 0.9893 - val_loss: 3.5703 - val_accuracy: 0.4393\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0411 - accuracy: 0.9909 - val_loss: 3.6765 - val_accuracy: 0.4159\n",
      "Epoch 43/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0441 - accuracy: 0.9915 - val_loss: 3.7290 - val_accuracy: 0.4159\n",
      "Epoch 44/50\n",
      "59/59 [==============================] - 79s 1s/step - loss: 0.0341 - accuracy: 0.9941 - val_loss: 3.8098 - val_accuracy: 0.4252\n",
      "Epoch 45/50\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 3.9272 - val_accuracy: 0.4299\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0561 - accuracy: 0.9808 - val_loss: 3.9670 - val_accuracy: 0.4393\n",
      "Epoch 47/50\n",
      "59/59 [==============================] - 83s 1s/step - loss: 0.1017 - accuracy: 0.9675 - val_loss: 4.0243 - val_accuracy: 0.3972\n",
      "Epoch 48/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.1166 - accuracy: 0.9606 - val_loss: 3.9243 - val_accuracy: 0.3785\n",
      "Epoch 49/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.3064 - accuracy: 0.9025 - val_loss: 3.8354 - val_accuracy: 0.4019\n",
      "Epoch 50/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.2561 - accuracy: 0.9110 - val_loss: 3.6883 - val_accuracy: 0.4065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c24dfb9e50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7de704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a501e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831105e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
