{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5419b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fca053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn='D:/data/PennA/Penn_Action/*/'\n",
    "tr= glob(trn)\n",
    "\n",
    "len(tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273abbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "test_y = []\n",
    "\n",
    "y = 0\n",
    "for i in tr:\n",
    "    \n",
    "    #print(i)\n",
    "    x = glob(i+'/*/')\n",
    "    \n",
    "    #shuffle(x)\n",
    "    t,tt = train_test_split( x , test_size=0.1, random_state=42)\n",
    "    t, vv = train_test_split( t , test_size=0.1, random_state=42)\n",
    "    \n",
    "    for j in t:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "        \n",
    "        train.append(j)\n",
    "        train_y.append(y)\n",
    "    \n",
    "    for j in vv:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        val.append(j)\n",
    "        val_y.append(y)\n",
    "        \n",
    "    for j in tt:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        test.append(j)\n",
    "        test_y.append(y)\n",
    "        \n",
    "    y = y+1\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tra_y =  np.array(to_categorical(train_y))\n",
    "va_y  =  np.array(to_categorical(val_y))\n",
    "te_y  =  np.array(to_categorical(test_y))\n",
    "\n",
    "(train, tra_y) = shuffle(train, tra_y)\n",
    "(val, va_y) = shuffle(val, va_y)\n",
    "(test, te_y) = shuffle(test, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798d6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    for i in range(0,10):\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((224, 224))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(224,224,3))\n",
    "        \n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e352d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b004fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , batch_size) :\n",
    "    self.filename = filename\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28523f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(train, tra_y, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(val, va_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bded865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(My_Test_Generator(test, batch_size).__getitem__(1))\n",
    "for i in range(2,len(x)):\n",
    "    x = My_Test_Generator(test, batch_size).__getitem__(i)\n",
    "    arr = np.concatenate((arr,x),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe4a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eb0f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 10, 222, 222, 256  7168     \n",
      " ibuted)                     )                                   \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 10, 111, 111, 256  0        \n",
      " tributed)                   )                                   \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 10, 109, 109, 128  295040   \n",
      " tributed)                   )                                   \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 10, 54, 54, 128)  0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 10, 52, 52, 64)   73792     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 10, 26, 26, 64)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 10, 24, 24, 32)   18464     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 10, 12, 12, 32)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 10, 10, 10, 32)   9248      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 10, 5, 5, 32)     0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 10, 3, 3, 32)     9248      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 10, 1, 1, 32)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 10, 32)           0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               53200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                1515      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 467,675\n",
      "Trainable params: 467,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "num_frames = 10\n",
    "frame_height = 224\n",
    "frame_width = 224\n",
    "num_channels = 3\n",
    "num_classes = 15  # Change this to the number of classes in your dataset\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CNN\n",
    "model.add(TimeDistributed(Conv2D(256, (3, 3), activation='relu'), input_shape=(num_frames, frame_height, frame_width, num_channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(100))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e2a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67fd3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\1958852391.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 82s 1s/step - loss: 2.6643 - accuracy: 0.0906 - val_loss: 2.6299 - val_accuracy: 0.1075\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 90s 2s/step - loss: 2.5200 - accuracy: 0.1514 - val_loss: 2.3912 - val_accuracy: 0.1869\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 2.3497 - accuracy: 0.2074 - val_loss: 2.2624 - val_accuracy: 0.2617\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 2.2227 - accuracy: 0.2484 - val_loss: 2.1766 - val_accuracy: 0.2617\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 2.1637 - accuracy: 0.2809 - val_loss: 2.1615 - val_accuracy: 0.2570\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 2.0295 - accuracy: 0.3209 - val_loss: 2.1996 - val_accuracy: 0.2430\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 79s 1s/step - loss: 1.9381 - accuracy: 0.3689 - val_loss: 2.0051 - val_accuracy: 0.3084\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 1.8405 - accuracy: 0.3966 - val_loss: 1.9359 - val_accuracy: 0.3458\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 1.7437 - accuracy: 0.4296 - val_loss: 1.9239 - val_accuracy: 0.3131\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 1.6728 - accuracy: 0.4558 - val_loss: 1.9235 - val_accuracy: 0.3318\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 86s 1s/step - loss: 1.5857 - accuracy: 0.4877 - val_loss: 1.8796 - val_accuracy: 0.3551\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.5118 - accuracy: 0.4984 - val_loss: 1.8620 - val_accuracy: 0.3598\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.4172 - accuracy: 0.5362 - val_loss: 1.7924 - val_accuracy: 0.4159\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.3434 - accuracy: 0.5581 - val_loss: 1.8708 - val_accuracy: 0.3505\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.2837 - accuracy: 0.5826 - val_loss: 1.8905 - val_accuracy: 0.3785\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.2204 - accuracy: 0.5997 - val_loss: 1.8231 - val_accuracy: 0.4019\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.1438 - accuracy: 0.6237 - val_loss: 1.8098 - val_accuracy: 0.3972\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 1.0852 - accuracy: 0.6487 - val_loss: 1.8585 - val_accuracy: 0.4252\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 79s 1s/step - loss: 1.0825 - accuracy: 0.6466 - val_loss: 1.9605 - val_accuracy: 0.3925\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.9875 - accuracy: 0.6882 - val_loss: 1.9382 - val_accuracy: 0.4206\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 78s 1s/step - loss: 0.9533 - accuracy: 0.6956 - val_loss: 1.9044 - val_accuracy: 0.3972\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.9128 - accuracy: 0.7159 - val_loss: 1.9731 - val_accuracy: 0.4065\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.8302 - accuracy: 0.7452 - val_loss: 1.9895 - val_accuracy: 0.3879\n",
      "Epoch 24/50\n",
      "59/59 [==============================] - 79s 1s/step - loss: 0.7989 - accuracy: 0.7569 - val_loss: 2.0366 - val_accuracy: 0.4299\n",
      "Epoch 25/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.7406 - accuracy: 0.7756 - val_loss: 2.0209 - val_accuracy: 0.3972\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.7224 - accuracy: 0.7772 - val_loss: 2.0770 - val_accuracy: 0.4065\n",
      "Epoch 27/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6649 - accuracy: 0.8097 - val_loss: 2.1267 - val_accuracy: 0.4159\n",
      "Epoch 28/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.6544 - accuracy: 0.8049 - val_loss: 2.1355 - val_accuracy: 0.4019\n",
      "Epoch 29/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.6787 - accuracy: 0.7820 - val_loss: 1.9736 - val_accuracy: 0.4299\n",
      "Epoch 30/50\n",
      "59/59 [==============================] - 82s 1s/step - loss: 0.6499 - accuracy: 0.8038 - val_loss: 2.1432 - val_accuracy: 0.3785\n",
      "Epoch 31/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.6112 - accuracy: 0.8156 - val_loss: 2.2140 - val_accuracy: 0.3879\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.6250 - accuracy: 0.8092 - val_loss: 2.1891 - val_accuracy: 0.4206\n",
      "Epoch 33/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.5252 - accuracy: 0.8454 - val_loss: 2.1850 - val_accuracy: 0.3972\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - 78s 1s/step - loss: 0.4914 - accuracy: 0.8619 - val_loss: 2.1438 - val_accuracy: 0.4159\n",
      "Epoch 35/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.4591 - accuracy: 0.8731 - val_loss: 2.2209 - val_accuracy: 0.4159\n",
      "Epoch 36/50\n",
      "59/59 [==============================] - 78s 1s/step - loss: 0.4205 - accuracy: 0.8934 - val_loss: 2.2467 - val_accuracy: 0.4252\n",
      "Epoch 37/50\n",
      "59/59 [==============================] - 72s 1s/step - loss: 0.3991 - accuracy: 0.8977 - val_loss: 2.3415 - val_accuracy: 0.4019\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.3683 - accuracy: 0.9115 - val_loss: 2.3055 - val_accuracy: 0.4206\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.3429 - accuracy: 0.9184 - val_loss: 2.4092 - val_accuracy: 0.4393\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.4027 - accuracy: 0.8923 - val_loss: 2.3812 - val_accuracy: 0.4206\n",
      "Epoch 41/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.4019 - accuracy: 0.8881 - val_loss: 2.4521 - val_accuracy: 0.4206\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3741 - accuracy: 0.9003 - val_loss: 2.3343 - val_accuracy: 0.4346\n",
      "Epoch 43/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3049 - accuracy: 0.9227 - val_loss: 2.3805 - val_accuracy: 0.4346\n",
      "Epoch 44/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.2602 - accuracy: 0.9456 - val_loss: 2.3903 - val_accuracy: 0.4579\n",
      "Epoch 45/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2336 - accuracy: 0.9494 - val_loss: 2.3907 - val_accuracy: 0.4579\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.2349 - accuracy: 0.9478 - val_loss: 2.4386 - val_accuracy: 0.4299\n",
      "Epoch 47/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2895 - accuracy: 0.9318 - val_loss: 2.4676 - val_accuracy: 0.4439\n",
      "Epoch 48/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.3110 - accuracy: 0.9200 - val_loss: 2.5248 - val_accuracy: 0.4439\n",
      "Epoch 49/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.2573 - accuracy: 0.9424 - val_loss: 2.5118 - val_accuracy: 0.4252\n",
      "Epoch 50/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.2249 - accuracy: 0.9552 - val_loss: 2.5769 - val_accuracy: 0.4346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1e0c1a820>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(My_Test_Generator(test, batch_size), verbose=0)\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import Ofrom sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "scoreneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "p = np.argmax(predictions, axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ab8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossAndMetrics = model.evaluate(arr, te_y)\n",
    "lossAndMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69843fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(4, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                (layers.Conv2D(8, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2649eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (10,40,40,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(10, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.3)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "outputs = layers.Dense(units=15, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98506d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\1958852391.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 2.7010 - accuracy: 0.0975 - val_loss: 2.5393 - val_accuracy: 0.1495\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 2.4694 - accuracy: 0.1551 - val_loss: 2.3966 - val_accuracy: 0.1916\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.3188 - accuracy: 0.2116 - val_loss: 2.2126 - val_accuracy: 0.2383\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.1786 - accuracy: 0.2425 - val_loss: 2.0953 - val_accuracy: 0.2850\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.0074 - accuracy: 0.3177 - val_loss: 2.0630 - val_accuracy: 0.3131\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.8937 - accuracy: 0.3609 - val_loss: 2.0963 - val_accuracy: 0.3551\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.7027 - accuracy: 0.4270 - val_loss: 2.1092 - val_accuracy: 0.3598\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.6063 - accuracy: 0.4659 - val_loss: 2.0904 - val_accuracy: 0.3411\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.4988 - accuracy: 0.5075 - val_loss: 2.1328 - val_accuracy: 0.3271\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 1.3796 - accuracy: 0.5384 - val_loss: 2.1468 - val_accuracy: 0.3692\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.2801 - accuracy: 0.5821 - val_loss: 2.1217 - val_accuracy: 0.4159\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.1926 - accuracy: 0.5991 - val_loss: 2.2305 - val_accuracy: 0.3925\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.0973 - accuracy: 0.6343 - val_loss: 2.1840 - val_accuracy: 0.3972\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.9823 - accuracy: 0.6818 - val_loss: 2.2423 - val_accuracy: 0.4206\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.8933 - accuracy: 0.7111 - val_loss: 2.3906 - val_accuracy: 0.4019\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.8420 - accuracy: 0.7233 - val_loss: 2.3831 - val_accuracy: 0.4393\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.7419 - accuracy: 0.7607 - val_loss: 2.4700 - val_accuracy: 0.4299\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.6882 - accuracy: 0.7788 - val_loss: 2.4809 - val_accuracy: 0.4019\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6102 - accuracy: 0.8001 - val_loss: 2.6649 - val_accuracy: 0.3832\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6006 - accuracy: 0.7894 - val_loss: 2.5325 - val_accuracy: 0.4159\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.4936 - accuracy: 0.8406 - val_loss: 2.6374 - val_accuracy: 0.4252\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.4315 - accuracy: 0.8625 - val_loss: 2.8971 - val_accuracy: 0.3832\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3825 - accuracy: 0.8785 - val_loss: 2.9358 - val_accuracy: 0.4159\n",
      "Epoch 24/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3450 - accuracy: 0.8854 - val_loss: 2.9100 - val_accuracy: 0.3972\n",
      "Epoch 25/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3824 - accuracy: 0.8662 - val_loss: 3.0404 - val_accuracy: 0.4065\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.3293 - accuracy: 0.8902 - val_loss: 2.8838 - val_accuracy: 0.4299\n",
      "Epoch 27/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2496 - accuracy: 0.9334 - val_loss: 3.1626 - val_accuracy: 0.4112\n",
      "Epoch 28/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2344 - accuracy: 0.9243 - val_loss: 3.0807 - val_accuracy: 0.4065\n",
      "Epoch 29/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2187 - accuracy: 0.9259 - val_loss: 3.2106 - val_accuracy: 0.4206\n",
      "Epoch 30/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2633 - accuracy: 0.9088 - val_loss: 3.1247 - val_accuracy: 0.4019\n",
      "Epoch 31/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.2184 - accuracy: 0.9307 - val_loss: 3.2864 - val_accuracy: 0.3925\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.1306 - accuracy: 0.9664 - val_loss: 3.2190 - val_accuracy: 0.4206\n",
      "Epoch 33/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0923 - accuracy: 0.9765 - val_loss: 3.4107 - val_accuracy: 0.4346\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0822 - accuracy: 0.9776 - val_loss: 3.2697 - val_accuracy: 0.4626\n",
      "Epoch 35/50\n",
      "59/59 [==============================] - 78s 1s/step - loss: 0.1045 - accuracy: 0.9712 - val_loss: 3.4077 - val_accuracy: 0.4393\n",
      "Epoch 36/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.1467 - accuracy: 0.9520 - val_loss: 3.5177 - val_accuracy: 0.4112\n",
      "Epoch 37/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.2258 - accuracy: 0.9291 - val_loss: 3.4396 - val_accuracy: 0.4019\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.2296 - accuracy: 0.9200 - val_loss: 3.5429 - val_accuracy: 0.4206\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.1258 - accuracy: 0.9627 - val_loss: 3.5298 - val_accuracy: 0.4393\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0759 - accuracy: 0.9813 - val_loss: 3.4607 - val_accuracy: 0.4299\n",
      "Epoch 41/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0457 - accuracy: 0.9893 - val_loss: 3.5703 - val_accuracy: 0.4393\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0411 - accuracy: 0.9909 - val_loss: 3.6765 - val_accuracy: 0.4159\n",
      "Epoch 43/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0441 - accuracy: 0.9915 - val_loss: 3.7290 - val_accuracy: 0.4159\n",
      "Epoch 44/50\n",
      "59/59 [==============================] - 79s 1s/step - loss: 0.0341 - accuracy: 0.9941 - val_loss: 3.8098 - val_accuracy: 0.4252\n",
      "Epoch 45/50\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 3.9272 - val_accuracy: 0.4299\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0561 - accuracy: 0.9808 - val_loss: 3.9670 - val_accuracy: 0.4393\n",
      "Epoch 47/50\n",
      "59/59 [==============================] - 83s 1s/step - loss: 0.1017 - accuracy: 0.9675 - val_loss: 4.0243 - val_accuracy: 0.3972\n",
      "Epoch 48/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.1166 - accuracy: 0.9606 - val_loss: 3.9243 - val_accuracy: 0.3785\n",
      "Epoch 49/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.3064 - accuracy: 0.9025 - val_loss: 3.8354 - val_accuracy: 0.4019\n",
      "Epoch 50/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.2561 - accuracy: 0.9110 - val_loss: 3.6883 - val_accuracy: 0.4065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c24dfb9e50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7de704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a501e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831105e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
