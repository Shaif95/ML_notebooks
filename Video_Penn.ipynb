{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5419b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fca053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn='D:/data/PennA/Penn_Action/*/'\n",
    "tr= glob(trn)\n",
    "\n",
    "len(tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273abbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "test_y = []\n",
    "\n",
    "y = 0\n",
    "for i in tr:\n",
    "    \n",
    "    #print(i)\n",
    "    x = glob(i+'/*/')\n",
    "    \n",
    "    #shuffle(x)\n",
    "    t,tt = train_test_split( x , test_size=0.1, random_state=42)\n",
    "    t, vv = train_test_split( t , test_size=0.1, random_state=42)\n",
    "    \n",
    "    for j in t:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "        \n",
    "        train.append(j)\n",
    "        train_y.append(y)\n",
    "    \n",
    "    for j in vv:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        val.append(j)\n",
    "        val_y.append(y)\n",
    "        \n",
    "    for j in tt:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        test.append(j)\n",
    "        test_y.append(y)\n",
    "        \n",
    "    y = y+1\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tra_y =  np.array(to_categorical(train_y))\n",
    "va_y  =  np.array(to_categorical(val_y))\n",
    "te_y  =  np.array(to_categorical(test_y))\n",
    "\n",
    "(train, tra_y) = shuffle(train, tra_y)\n",
    "(val, va_y) = shuffle(val, va_y)\n",
    "(test, te_y) = shuffle(test, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "798d6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    for i in range(0,5):\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((224, 224))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(224,224,3))\n",
    "        \n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e352d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b004fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , batch_size) :\n",
    "    self.filename = filename\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28523f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(train, tra_y, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(val, va_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bded865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(My_Test_Generator(test, batch_size).__getitem__(1))\n",
    "for i in range(2,len(x)):\n",
    "    x = My_Test_Generator(test, batch_size).__getitem__(i)\n",
    "    arr = np.concatenate((arr,x),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffe4a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5, 224, 224, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3eb0f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_84 (TimeDi  (None, 5, 222, 222, 128)  3584     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_85 (TimeDi  (None, 5, 111, 111, 128)  0        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_86 (TimeDi  (None, 5, 109, 109, 128)  147584   \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_87 (TimeDi  (None, 5, 54, 54, 128)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_88 (TimeDi  (None, 5, 52, 52, 64)    73792     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_89 (TimeDi  (None, 5, 26, 26, 64)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_90 (TimeDi  (None, 5, 24, 24, 32)    18464     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_91 (TimeDi  (None, 5, 12, 12, 32)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_92 (TimeDi  (None, 5, 10, 10, 16)    4624      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_93 (TimeDi  (None, 5, 5, 5, 16)      0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_94 (TimeDi  (None, 5, 3, 3, 8)       1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_95 (TimeDi  (None, 5, 72)            0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 50)                24600     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 15)                765       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 274,573\n",
      "Trainable params: 274,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "num_frames = 5\n",
    "frame_height = 224\n",
    "frame_width = 224\n",
    "num_channels = 3\n",
    "num_classes = 15  # Change this to the number of classes in your dataset\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CNN\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu'), input_shape=(num_frames, frame_height, frame_width, num_channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(50))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81e2a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_1528\\789722107.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_1528\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 83s 665ms/step - loss: 2.6860 - accuracy: 0.0768 - val_loss: 2.6619 - val_accuracy: 0.0986\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 37s 314ms/step - loss: 2.6365 - accuracy: 0.1115 - val_loss: 2.4510 - val_accuracy: 0.1737\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 38s 321ms/step - loss: 2.5004 - accuracy: 0.1724 - val_loss: 2.4328 - val_accuracy: 0.1643\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 38s 320ms/step - loss: 2.3572 - accuracy: 0.2263 - val_loss: 2.2658 - val_accuracy: 0.2347\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 40s 336ms/step - loss: 2.2476 - accuracy: 0.2561 - val_loss: 2.3179 - val_accuracy: 0.2113\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 2.1883 - accuracy: 0.2716 - val_loss: 2.2176 - val_accuracy: 0.2488\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 44s 371ms/step - loss: 2.0921 - accuracy: 0.3058 - val_loss: 2.2175 - val_accuracy: 0.2207\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 43s 358ms/step - loss: 1.9949 - accuracy: 0.3410 - val_loss: 2.2009 - val_accuracy: 0.2347\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 54s 453ms/step - loss: 1.9110 - accuracy: 0.3709 - val_loss: 2.2003 - val_accuracy: 0.2535\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 44s 370ms/step - loss: 1.8491 - accuracy: 0.3837 - val_loss: 2.2253 - val_accuracy: 0.2582\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 39s 328ms/step - loss: 1.7823 - accuracy: 0.4216 - val_loss: 2.2152 - val_accuracy: 0.2394\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 39s 325ms/step - loss: 1.6936 - accuracy: 0.4434 - val_loss: 2.2740 - val_accuracy: 0.2488\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 45s 379ms/step - loss: 1.6477 - accuracy: 0.4546 - val_loss: 2.2063 - val_accuracy: 0.3005\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 47s 392ms/step - loss: 1.6166 - accuracy: 0.4685 - val_loss: 2.2175 - val_accuracy: 0.2911\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 46s 385ms/step - loss: 1.5171 - accuracy: 0.5021 - val_loss: 2.2712 - val_accuracy: 0.2347\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 52s 440ms/step - loss: 1.4771 - accuracy: 0.5197 - val_loss: 2.3103 - val_accuracy: 0.3005\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 63s 517ms/step - loss: 1.4253 - accuracy: 0.5480 - val_loss: 2.3221 - val_accuracy: 0.2864\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 72s 611ms/step - loss: 1.3610 - accuracy: 0.5694 - val_loss: 2.2971 - val_accuracy: 0.2770\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 65s 547ms/step - loss: 1.2838 - accuracy: 0.5907 - val_loss: 2.3279 - val_accuracy: 0.2817\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 59s 501ms/step - loss: 1.2785 - accuracy: 0.5939 - val_loss: 2.3012 - val_accuracy: 0.2676\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 61s 520ms/step - loss: 1.2189 - accuracy: 0.6142 - val_loss: 2.3246 - val_accuracy: 0.2770\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 72s 599ms/step - loss: 1.2188 - accuracy: 0.6062 - val_loss: 2.3423 - val_accuracy: 0.2958\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 74s 615ms/step - loss: 1.1584 - accuracy: 0.6329 - val_loss: 2.3296 - val_accuracy: 0.3192\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 73s 608ms/step - loss: 1.0738 - accuracy: 0.6740 - val_loss: 2.4100 - val_accuracy: 0.2535\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 71s 589ms/step - loss: 1.0365 - accuracy: 0.6729 - val_loss: 2.4034 - val_accuracy: 0.3239\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 77s 637ms/step - loss: 1.0108 - accuracy: 0.6942 - val_loss: 2.4978 - val_accuracy: 0.3286\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 63s 515ms/step - loss: 1.0125 - accuracy: 0.6841 - val_loss: 2.3820 - val_accuracy: 0.3005\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 68s 563ms/step - loss: 0.9663 - accuracy: 0.7081 - val_loss: 2.4028 - val_accuracy: 0.3380\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 73s 606ms/step - loss: 0.9432 - accuracy: 0.7129 - val_loss: 2.3926 - val_accuracy: 0.3568\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 73s 603ms/step - loss: 0.8206 - accuracy: 0.7684 - val_loss: 2.4268 - val_accuracy: 0.3005\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 64s 534ms/step - loss: 0.8246 - accuracy: 0.7556 - val_loss: 2.4135 - val_accuracy: 0.3099\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 72s 598ms/step - loss: 0.7360 - accuracy: 0.7988 - val_loss: 2.5383 - val_accuracy: 0.2864\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 69s 569ms/step - loss: 0.7073 - accuracy: 0.8058 - val_loss: 2.5070 - val_accuracy: 0.2911\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 404s 3s/step - loss: 0.7173 - accuracy: 0.7978 - val_loss: 2.5549 - val_accuracy: 0.3146\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 508s 4s/step - loss: 0.6510 - accuracy: 0.8340 - val_loss: 2.5882 - val_accuracy: 0.3005\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 490s 4s/step - loss: 0.6220 - accuracy: 0.8362 - val_loss: 2.5206 - val_accuracy: 0.3192\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 436s 4s/step - loss: 0.6489 - accuracy: 0.8196 - val_loss: 2.5211 - val_accuracy: 0.3052\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 429s 4s/step - loss: 0.6232 - accuracy: 0.8346 - val_loss: 2.6162 - val_accuracy: 0.3427\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 110s 837ms/step - loss: 0.5858 - accuracy: 0.8458 - val_loss: 2.6089 - val_accuracy: 0.3005\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 54s 456ms/step - loss: 0.5964 - accuracy: 0.8383 - val_loss: 2.6668 - val_accuracy: 0.3239\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 63s 517ms/step - loss: 0.5052 - accuracy: 0.8735 - val_loss: 2.7517 - val_accuracy: 0.2958\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 75s 625ms/step - loss: 0.4927 - accuracy: 0.8767 - val_loss: 2.7077 - val_accuracy: 0.3192\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 68s 563ms/step - loss: 0.5412 - accuracy: 0.8506 - val_loss: 2.6422 - val_accuracy: 0.3052\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 88s 734ms/step - loss: 0.4696 - accuracy: 0.8885 - val_loss: 2.8309 - val_accuracy: 0.3052\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 347s 3s/step - loss: 0.4346 - accuracy: 0.9013 - val_loss: 2.7426 - val_accuracy: 0.2911\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 64s 542ms/step - loss: 0.4365 - accuracy: 0.9002 - val_loss: 2.7423 - val_accuracy: 0.3239\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 153s 1s/step - loss: 0.4088 - accuracy: 0.9072 - val_loss: 2.8407 - val_accuracy: 0.2958\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 69s 579ms/step - loss: 0.3947 - accuracy: 0.9168 - val_loss: 2.8775 - val_accuracy: 0.2958\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 52s 435ms/step - loss: 0.3394 - accuracy: 0.9360 - val_loss: 2.8603 - val_accuracy: 0.3286\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 59s 487ms/step - loss: 0.3868 - accuracy: 0.9055 - val_loss: 2.8991 - val_accuracy: 0.2817\n",
      "Epoch 51/100\n",
      " 80/118 [===================>..........] - ETA: 20s - loss: 0.3825 - accuracy: 0.9155"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(My_Test_Generator(test, batch_size), verbose=0)\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import Ofrom sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "scoreneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "p = np.argmax(predictions, axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ab8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossAndMetrics = model.evaluate(arr, te_y)\n",
    "lossAndMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69843fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(4, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                (layers.Conv2D(8, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2649eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (10,40,40,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(10, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.3)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "outputs = layers.Dense(units=15, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98506d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\1958852391.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 2.7010 - accuracy: 0.0975 - val_loss: 2.5393 - val_accuracy: 0.1495\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 2.4694 - accuracy: 0.1551 - val_loss: 2.3966 - val_accuracy: 0.1916\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.3188 - accuracy: 0.2116 - val_loss: 2.2126 - val_accuracy: 0.2383\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.1786 - accuracy: 0.2425 - val_loss: 2.0953 - val_accuracy: 0.2850\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.0074 - accuracy: 0.3177 - val_loss: 2.0630 - val_accuracy: 0.3131\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.8937 - accuracy: 0.3609 - val_loss: 2.0963 - val_accuracy: 0.3551\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.7027 - accuracy: 0.4270 - val_loss: 2.1092 - val_accuracy: 0.3598\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.6063 - accuracy: 0.4659 - val_loss: 2.0904 - val_accuracy: 0.3411\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.4988 - accuracy: 0.5075 - val_loss: 2.1328 - val_accuracy: 0.3271\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 1.3796 - accuracy: 0.5384 - val_loss: 2.1468 - val_accuracy: 0.3692\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.2801 - accuracy: 0.5821 - val_loss: 2.1217 - val_accuracy: 0.4159\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.1926 - accuracy: 0.5991 - val_loss: 2.2305 - val_accuracy: 0.3925\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.0973 - accuracy: 0.6343 - val_loss: 2.1840 - val_accuracy: 0.3972\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.9823 - accuracy: 0.6818 - val_loss: 2.2423 - val_accuracy: 0.4206\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.8933 - accuracy: 0.7111 - val_loss: 2.3906 - val_accuracy: 0.4019\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.8420 - accuracy: 0.7233 - val_loss: 2.3831 - val_accuracy: 0.4393\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.7419 - accuracy: 0.7607 - val_loss: 2.4700 - val_accuracy: 0.4299\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.6882 - accuracy: 0.7788 - val_loss: 2.4809 - val_accuracy: 0.4019\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6102 - accuracy: 0.8001 - val_loss: 2.6649 - val_accuracy: 0.3832\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6006 - accuracy: 0.7894 - val_loss: 2.5325 - val_accuracy: 0.4159\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.4936 - accuracy: 0.8406 - val_loss: 2.6374 - val_accuracy: 0.4252\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.4315 - accuracy: 0.8625 - val_loss: 2.8971 - val_accuracy: 0.3832\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3825 - accuracy: 0.8785 - val_loss: 2.9358 - val_accuracy: 0.4159\n",
      "Epoch 24/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3450 - accuracy: 0.8854 - val_loss: 2.9100 - val_accuracy: 0.3972\n",
      "Epoch 25/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3824 - accuracy: 0.8662 - val_loss: 3.0404 - val_accuracy: 0.4065\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.3293 - accuracy: 0.8902 - val_loss: 2.8838 - val_accuracy: 0.4299\n",
      "Epoch 27/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2496 - accuracy: 0.9334 - val_loss: 3.1626 - val_accuracy: 0.4112\n",
      "Epoch 28/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2344 - accuracy: 0.9243 - val_loss: 3.0807 - val_accuracy: 0.4065\n",
      "Epoch 29/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2187 - accuracy: 0.9259 - val_loss: 3.2106 - val_accuracy: 0.4206\n",
      "Epoch 30/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2633 - accuracy: 0.9088 - val_loss: 3.1247 - val_accuracy: 0.4019\n",
      "Epoch 31/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.2184 - accuracy: 0.9307 - val_loss: 3.2864 - val_accuracy: 0.3925\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.1306 - accuracy: 0.9664 - val_loss: 3.2190 - val_accuracy: 0.4206\n",
      "Epoch 33/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0923 - accuracy: 0.9765 - val_loss: 3.4107 - val_accuracy: 0.4346\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0822 - accuracy: 0.9776 - val_loss: 3.2697 - val_accuracy: 0.4626\n",
      "Epoch 35/50\n",
      "59/59 [==============================] - 78s 1s/step - loss: 0.1045 - accuracy: 0.9712 - val_loss: 3.4077 - val_accuracy: 0.4393\n",
      "Epoch 36/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.1467 - accuracy: 0.9520 - val_loss: 3.5177 - val_accuracy: 0.4112\n",
      "Epoch 37/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.2258 - accuracy: 0.9291 - val_loss: 3.4396 - val_accuracy: 0.4019\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.2296 - accuracy: 0.9200 - val_loss: 3.5429 - val_accuracy: 0.4206\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.1258 - accuracy: 0.9627 - val_loss: 3.5298 - val_accuracy: 0.4393\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0759 - accuracy: 0.9813 - val_loss: 3.4607 - val_accuracy: 0.4299\n",
      "Epoch 41/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0457 - accuracy: 0.9893 - val_loss: 3.5703 - val_accuracy: 0.4393\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0411 - accuracy: 0.9909 - val_loss: 3.6765 - val_accuracy: 0.4159\n",
      "Epoch 43/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0441 - accuracy: 0.9915 - val_loss: 3.7290 - val_accuracy: 0.4159\n",
      "Epoch 44/50\n",
      "59/59 [==============================] - 79s 1s/step - loss: 0.0341 - accuracy: 0.9941 - val_loss: 3.8098 - val_accuracy: 0.4252\n",
      "Epoch 45/50\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 3.9272 - val_accuracy: 0.4299\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0561 - accuracy: 0.9808 - val_loss: 3.9670 - val_accuracy: 0.4393\n",
      "Epoch 47/50\n",
      "59/59 [==============================] - 83s 1s/step - loss: 0.1017 - accuracy: 0.9675 - val_loss: 4.0243 - val_accuracy: 0.3972\n",
      "Epoch 48/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.1166 - accuracy: 0.9606 - val_loss: 3.9243 - val_accuracy: 0.3785\n",
      "Epoch 49/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.3064 - accuracy: 0.9025 - val_loss: 3.8354 - val_accuracy: 0.4019\n",
      "Epoch 50/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.2561 - accuracy: 0.9110 - val_loss: 3.6883 - val_accuracy: 0.4065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c24dfb9e50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7de704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a501e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831105e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
