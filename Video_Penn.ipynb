{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5419b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fca053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn='D:/data/PennA/Penn_Action/*/'\n",
    "tr= glob(trn)\n",
    "\n",
    "len(tr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "273abbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "train_y = []\n",
    "val_y = []\n",
    "test_y = []\n",
    "\n",
    "y = 0\n",
    "for i in tr:\n",
    "    \n",
    "    #print(i)\n",
    "    x = glob(i+'/*/')\n",
    "    \n",
    "    #shuffle(x)\n",
    "    t,tt = train_test_split( x , test_size=0.1, random_state=42)\n",
    "    t, vv = train_test_split( t , test_size=0.1, random_state=42)\n",
    "    \n",
    "    for j in t:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "        \n",
    "        train.append(j)\n",
    "        train_y.append(y)\n",
    "    \n",
    "    for j in vv:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        val.append(j)\n",
    "        val_y.append(y)\n",
    "        \n",
    "    for j in tt:\n",
    "        \n",
    "        mm = len(glob(j+'/*'))\n",
    "        \n",
    "        if(mm<10):\n",
    "            continue\n",
    "            \n",
    "        test.append(j)\n",
    "        test_y.append(y)\n",
    "        \n",
    "    y = y+1\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tra_y =  np.array(to_categorical(train_y))\n",
    "va_y  =  np.array(to_categorical(val_y))\n",
    "te_y  =  np.array(to_categorical(test_y))\n",
    "\n",
    "(train, tra_y) = shuffle(train, tra_y)\n",
    "(val, va_y) = shuffle(val, va_y)\n",
    "(test, te_y) = shuffle(test, te_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edb552fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639495b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "798d6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_te(k , a) :\n",
    "    x = glob(k+'/*')\n",
    "    imgdata=[]\n",
    "    for i in range(0,15):\n",
    "        \n",
    "        a = Image.open(x[i])\n",
    "        b = a.resize((48, 48))\n",
    "        c = np.array(b)\n",
    "        imgdata.append(c.reshape(48, 48,3))\n",
    "        \n",
    "    idata = np.array(imgdata)\n",
    "    X_train = idata\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    #print(np.shape(X_train))\n",
    "    return X_train\n",
    "\n",
    "def get_cat(k) :\n",
    "    return np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e352d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , labels, batch_size) :\n",
    "    self.filename = filename\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    y_train = get_cat(batch_y)\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x]), np.array( y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b004fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Test_Generator(keras.utils.Sequence) :\n",
    "  \n",
    "  def __init__(self, filename , batch_size) :\n",
    "    self.filename = filename\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.filename[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    i=0\n",
    "    return np.array([get_te(i,self.filename)for i in batch_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28523f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "my_training_batch_generator = My_Custom_Generator(train, tra_y, batch_size)\n",
    "my_validation_batch_generator = My_Custom_Generator(val, va_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bded865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(My_Test_Generator(test, batch_size).__getitem__(1))\n",
    "for i in range(2,len(x)):\n",
    "    x = My_Test_Generator(test, batch_size).__getitem__(i)\n",
    "    arr = np.concatenate((arr,x),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffe4a3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 15, 48, 48, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d616e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3eb0f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_18 (TimeDi  (None, 15, 46, 46, 64)   1792      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_19 (TimeDi  (None, 15, 23, 23, 64)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_20 (TimeDi  (None, 15, 21, 21, 32)   18464     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_21 (TimeDi  (None, 15, 10, 10, 32)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 15, 8, 8, 16)     4624      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_23 (TimeDi  (None, 15, 4, 4, 16)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_24 (TimeDi  (None, 15, 2, 2, 8)      1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_25 (TimeDi  (None, 15, 1, 1, 8)      0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_26 (TimeDi  (None, 15, 8)            0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                11800     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                765       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,605\n",
      "Trainable params: 38,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "\n",
    "num_frames = 15\n",
    "frame_height = 48\n",
    "frame_width = 48\n",
    "num_channels = 3\n",
    "num_classes = 15  # Change this to the number of classes in your dataset\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CNN\n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu'), input_shape=(num_frames, frame_height, frame_width, num_channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM\n",
    "model.add(LSTM(50))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81e2a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "optimizer = keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67fd3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_20536\\789722107.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_20536\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 112s 918ms/step - loss: 2.6735 - accuracy: 0.0977 - val_loss: 2.6469 - val_accuracy: 0.1174\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 77s 650ms/step - loss: 2.5594 - accuracy: 0.1238 - val_loss: 2.3768 - val_accuracy: 0.1596\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 86s 729ms/step - loss: 2.4100 - accuracy: 0.1814 - val_loss: 2.3747 - val_accuracy: 0.1878\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 73s 613ms/step - loss: 2.3223 - accuracy: 0.2113 - val_loss: 2.2202 - val_accuracy: 0.2254\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 76s 640ms/step - loss: 2.2589 - accuracy: 0.2332 - val_loss: 2.1910 - val_accuracy: 0.2535\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 70s 587ms/step - loss: 2.1835 - accuracy: 0.2599 - val_loss: 2.1944 - val_accuracy: 0.2723\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 77s 653ms/step - loss: 2.1291 - accuracy: 0.2775 - val_loss: 2.1786 - val_accuracy: 0.2864\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 81s 682ms/step - loss: 2.0634 - accuracy: 0.3026 - val_loss: 2.0964 - val_accuracy: 0.2770\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 82s 691ms/step - loss: 2.0003 - accuracy: 0.3095 - val_loss: 2.0547 - val_accuracy: 0.3192\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 81s 686ms/step - loss: 1.9570 - accuracy: 0.3404 - val_loss: 2.0150 - val_accuracy: 0.2958\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 81s 682ms/step - loss: 1.9017 - accuracy: 0.3490 - val_loss: 1.9891 - val_accuracy: 0.3146\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 80s 676ms/step - loss: 1.8427 - accuracy: 0.3677 - val_loss: 1.9550 - val_accuracy: 0.3099\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 76s 641ms/step - loss: 1.8018 - accuracy: 0.3858 - val_loss: 1.9816 - val_accuracy: 0.3333\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 77s 653ms/step - loss: 1.7652 - accuracy: 0.3997 - val_loss: 1.9933 - val_accuracy: 0.2864\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 76s 641ms/step - loss: 1.7090 - accuracy: 0.4242 - val_loss: 1.9391 - val_accuracy: 0.3474\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 75s 638ms/step - loss: 1.6777 - accuracy: 0.4221 - val_loss: 1.8902 - val_accuracy: 0.3474\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 78s 658ms/step - loss: 1.6183 - accuracy: 0.4514 - val_loss: 1.9330 - val_accuracy: 0.3192\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 79s 672ms/step - loss: 1.6005 - accuracy: 0.4568 - val_loss: 1.9113 - val_accuracy: 0.3897\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 79s 666ms/step - loss: 1.5033 - accuracy: 0.4941 - val_loss: 1.9561 - val_accuracy: 0.3568\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 79s 663ms/step - loss: 1.5358 - accuracy: 0.4701 - val_loss: 1.9664 - val_accuracy: 0.3333\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 81s 686ms/step - loss: 1.4454 - accuracy: 0.5155 - val_loss: 1.9238 - val_accuracy: 0.3709\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 79s 664ms/step - loss: 1.4379 - accuracy: 0.5181 - val_loss: 1.9870 - val_accuracy: 0.3568\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 73s 620ms/step - loss: 1.4072 - accuracy: 0.5267 - val_loss: 1.8691 - val_accuracy: 0.4178\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 79s 669ms/step - loss: 1.3348 - accuracy: 0.5475 - val_loss: 2.0829 - val_accuracy: 0.3709\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 81s 687ms/step - loss: 1.3220 - accuracy: 0.5550 - val_loss: 1.9537 - val_accuracy: 0.3568\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 79s 666ms/step - loss: 1.2768 - accuracy: 0.5726 - val_loss: 1.8937 - val_accuracy: 0.4178\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 81s 683ms/step - loss: 1.2311 - accuracy: 0.5945 - val_loss: 1.9235 - val_accuracy: 0.4131\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 79s 672ms/step - loss: 1.1811 - accuracy: 0.5971 - val_loss: 1.9066 - val_accuracy: 0.4319\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 81s 688ms/step - loss: 1.1491 - accuracy: 0.6067 - val_loss: 2.0246 - val_accuracy: 0.3944\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 84s 712ms/step - loss: 1.1845 - accuracy: 0.5977 - val_loss: 2.0875 - val_accuracy: 0.3615\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 77s 654ms/step - loss: 1.0942 - accuracy: 0.6163 - val_loss: 2.0863 - val_accuracy: 0.3850\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 81s 682ms/step - loss: 1.0745 - accuracy: 0.6361 - val_loss: 2.0625 - val_accuracy: 0.3944\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 82s 698ms/step - loss: 1.0709 - accuracy: 0.6409 - val_loss: 2.1488 - val_accuracy: 0.3850\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 81s 686ms/step - loss: 1.1026 - accuracy: 0.6206 - val_loss: 2.0866 - val_accuracy: 0.3897\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 77s 655ms/step - loss: 0.9861 - accuracy: 0.6718 - val_loss: 2.1597 - val_accuracy: 0.3803\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 78s 659ms/step - loss: 0.9659 - accuracy: 0.6729 - val_loss: 2.1651 - val_accuracy: 0.3756\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 78s 660ms/step - loss: 0.9532 - accuracy: 0.6841 - val_loss: 2.1554 - val_accuracy: 0.4038\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 76s 641ms/step - loss: 0.9132 - accuracy: 0.6969 - val_loss: 2.1828 - val_accuracy: 0.3991\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 81s 682ms/step - loss: 0.9252 - accuracy: 0.6804 - val_loss: 2.1369 - val_accuracy: 0.4178\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 79s 667ms/step - loss: 0.8558 - accuracy: 0.7092 - val_loss: 2.2219 - val_accuracy: 0.3803\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 77s 655ms/step - loss: 0.8497 - accuracy: 0.7257 - val_loss: 2.3356 - val_accuracy: 0.3944\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 79s 669ms/step - loss: 0.8162 - accuracy: 0.7348 - val_loss: 2.3299 - val_accuracy: 0.3850\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 79s 670ms/step - loss: 0.7976 - accuracy: 0.7236 - val_loss: 2.3687 - val_accuracy: 0.3944\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 79s 668ms/step - loss: 0.7841 - accuracy: 0.7375 - val_loss: 2.3318 - val_accuracy: 0.3991\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 80s 674ms/step - loss: 0.7762 - accuracy: 0.7428 - val_loss: 2.2556 - val_accuracy: 0.4178\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 81s 681ms/step - loss: 0.7384 - accuracy: 0.7508 - val_loss: 2.4396 - val_accuracy: 0.3944\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 80s 680ms/step - loss: 0.7672 - accuracy: 0.7407 - val_loss: 2.4653 - val_accuracy: 0.4038\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 81s 681ms/step - loss: 0.7116 - accuracy: 0.7625 - val_loss: 2.4990 - val_accuracy: 0.3850\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 80s 674ms/step - loss: 0.6968 - accuracy: 0.7695 - val_loss: 2.3864 - val_accuracy: 0.3803\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 78s 658ms/step - loss: 0.6738 - accuracy: 0.7711 - val_loss: 2.5311 - val_accuracy: 0.3850\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 79s 672ms/step - loss: 0.6786 - accuracy: 0.7780 - val_loss: 2.6039 - val_accuracy: 0.3568\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 80s 677ms/step - loss: 0.6170 - accuracy: 0.7930 - val_loss: 2.5046 - val_accuracy: 0.4085\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 80s 675ms/step - loss: 0.6535 - accuracy: 0.7732 - val_loss: 2.6662 - val_accuracy: 0.3756\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 82s 690ms/step - loss: 0.6301 - accuracy: 0.7946 - val_loss: 2.6845 - val_accuracy: 0.3944\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 79s 664ms/step - loss: 0.7011 - accuracy: 0.7636 - val_loss: 2.6294 - val_accuracy: 0.3991\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 78s 661ms/step - loss: 0.5422 - accuracy: 0.8260 - val_loss: 2.7175 - val_accuracy: 0.3850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "118/118 [==============================] - 79s 671ms/step - loss: 0.5392 - accuracy: 0.8202 - val_loss: 2.7637 - val_accuracy: 0.3897\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 81s 687ms/step - loss: 0.5240 - accuracy: 0.8239 - val_loss: 2.8153 - val_accuracy: 0.3944\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 79s 673ms/step - loss: 0.5985 - accuracy: 0.7940 - val_loss: 2.6452 - val_accuracy: 0.3756\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 77s 649ms/step - loss: 0.5464 - accuracy: 0.8175 - val_loss: 2.6878 - val_accuracy: 0.4131\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 79s 670ms/step - loss: 0.5194 - accuracy: 0.8287 - val_loss: 2.8582 - val_accuracy: 0.3897\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 80s 677ms/step - loss: 0.5124 - accuracy: 0.8314 - val_loss: 2.6803 - val_accuracy: 0.4038\n",
      "Epoch 63/100\n",
      " 20/118 [====>.........................] - ETA: 55s - loss: 0.3965 - accuracy: 0.8660"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 100,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "460f9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_1528\\3949629984.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = model.predict_generator(My_Test_Generator(test, batch_size), verbose=0)\n",
      "C:\\Users\\shaif\\AppData\\Local\\Temp\\ipykernel_1528\\1543328956.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      5\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(predictions)\n\u001b[1;32m----> 6\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m scoreneHotEncoder\n\u001b[0;32m      8\u001b[0m onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(My_Test_Generator(test, batch_size), verbose=0)\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "p = np.round(predictions)\n",
    "score = accuracy_score(test_y, p)\n",
    "scoreneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "p = np.argmax(predictions, axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(test_y, p)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f6ab8e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 16\n  y sizes: 239\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lossAndMetrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mte_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m lossAndMetrics\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\keras\\engine\\data_adapter.py:1657\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1653\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1654\u001b[0m       label, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1655\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)))\n\u001b[0;32m   1656\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1657\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 16\n  y sizes: 239\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "lossAndMetrics = model.evaluate(arr, te_y)\n",
    "lossAndMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69843fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(4, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                (layers.Conv2D(8, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2649eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (10,40,40,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(10, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.3)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "outputs = layers.Dense(units=15, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98506d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\1958852391.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)\n",
      "C:\\Users\\chowd\\AppData\\Local\\Temp\\ipykernel_788\\2168406815.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return (np.ceil(len(self.filename) / float(self.batch_size))).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 2.7010 - accuracy: 0.0975 - val_loss: 2.5393 - val_accuracy: 0.1495\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 2.4694 - accuracy: 0.1551 - val_loss: 2.3966 - val_accuracy: 0.1916\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.3188 - accuracy: 0.2116 - val_loss: 2.2126 - val_accuracy: 0.2383\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.1786 - accuracy: 0.2425 - val_loss: 2.0953 - val_accuracy: 0.2850\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 2.0074 - accuracy: 0.3177 - val_loss: 2.0630 - val_accuracy: 0.3131\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.8937 - accuracy: 0.3609 - val_loss: 2.0963 - val_accuracy: 0.3551\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.7027 - accuracy: 0.4270 - val_loss: 2.1092 - val_accuracy: 0.3598\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.6063 - accuracy: 0.4659 - val_loss: 2.0904 - val_accuracy: 0.3411\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 1.4988 - accuracy: 0.5075 - val_loss: 2.1328 - val_accuracy: 0.3271\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 1.3796 - accuracy: 0.5384 - val_loss: 2.1468 - val_accuracy: 0.3692\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.2801 - accuracy: 0.5821 - val_loss: 2.1217 - val_accuracy: 0.4159\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.1926 - accuracy: 0.5991 - val_loss: 2.2305 - val_accuracy: 0.3925\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 1.0973 - accuracy: 0.6343 - val_loss: 2.1840 - val_accuracy: 0.3972\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.9823 - accuracy: 0.6818 - val_loss: 2.2423 - val_accuracy: 0.4206\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.8933 - accuracy: 0.7111 - val_loss: 2.3906 - val_accuracy: 0.4019\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.8420 - accuracy: 0.7233 - val_loss: 2.3831 - val_accuracy: 0.4393\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.7419 - accuracy: 0.7607 - val_loss: 2.4700 - val_accuracy: 0.4299\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.6882 - accuracy: 0.7788 - val_loss: 2.4809 - val_accuracy: 0.4019\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6102 - accuracy: 0.8001 - val_loss: 2.6649 - val_accuracy: 0.3832\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.6006 - accuracy: 0.7894 - val_loss: 2.5325 - val_accuracy: 0.4159\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.4936 - accuracy: 0.8406 - val_loss: 2.6374 - val_accuracy: 0.4252\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.4315 - accuracy: 0.8625 - val_loss: 2.8971 - val_accuracy: 0.3832\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3825 - accuracy: 0.8785 - val_loss: 2.9358 - val_accuracy: 0.4159\n",
      "Epoch 24/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3450 - accuracy: 0.8854 - val_loss: 2.9100 - val_accuracy: 0.3972\n",
      "Epoch 25/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.3824 - accuracy: 0.8662 - val_loss: 3.0404 - val_accuracy: 0.4065\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.3293 - accuracy: 0.8902 - val_loss: 2.8838 - val_accuracy: 0.4299\n",
      "Epoch 27/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2496 - accuracy: 0.9334 - val_loss: 3.1626 - val_accuracy: 0.4112\n",
      "Epoch 28/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2344 - accuracy: 0.9243 - val_loss: 3.0807 - val_accuracy: 0.4065\n",
      "Epoch 29/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2187 - accuracy: 0.9259 - val_loss: 3.2106 - val_accuracy: 0.4206\n",
      "Epoch 30/50\n",
      "59/59 [==============================] - 73s 1s/step - loss: 0.2633 - accuracy: 0.9088 - val_loss: 3.1247 - val_accuracy: 0.4019\n",
      "Epoch 31/50\n",
      "59/59 [==============================] - 74s 1s/step - loss: 0.2184 - accuracy: 0.9307 - val_loss: 3.2864 - val_accuracy: 0.3925\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - 86s 1s/step - loss: 0.1306 - accuracy: 0.9664 - val_loss: 3.2190 - val_accuracy: 0.4206\n",
      "Epoch 33/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0923 - accuracy: 0.9765 - val_loss: 3.4107 - val_accuracy: 0.4346\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0822 - accuracy: 0.9776 - val_loss: 3.2697 - val_accuracy: 0.4626\n",
      "Epoch 35/50\n",
      "59/59 [==============================] - 78s 1s/step - loss: 0.1045 - accuracy: 0.9712 - val_loss: 3.4077 - val_accuracy: 0.4393\n",
      "Epoch 36/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.1467 - accuracy: 0.9520 - val_loss: 3.5177 - val_accuracy: 0.4112\n",
      "Epoch 37/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.2258 - accuracy: 0.9291 - val_loss: 3.4396 - val_accuracy: 0.4019\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - 80s 1s/step - loss: 0.2296 - accuracy: 0.9200 - val_loss: 3.5429 - val_accuracy: 0.4206\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.1258 - accuracy: 0.9627 - val_loss: 3.5298 - val_accuracy: 0.4393\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0759 - accuracy: 0.9813 - val_loss: 3.4607 - val_accuracy: 0.4299\n",
      "Epoch 41/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.0457 - accuracy: 0.9893 - val_loss: 3.5703 - val_accuracy: 0.4393\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - 77s 1s/step - loss: 0.0411 - accuracy: 0.9909 - val_loss: 3.6765 - val_accuracy: 0.4159\n",
      "Epoch 43/50\n",
      "59/59 [==============================] - 76s 1s/step - loss: 0.0441 - accuracy: 0.9915 - val_loss: 3.7290 - val_accuracy: 0.4159\n",
      "Epoch 44/50\n",
      "59/59 [==============================] - 79s 1s/step - loss: 0.0341 - accuracy: 0.9941 - val_loss: 3.8098 - val_accuracy: 0.4252\n",
      "Epoch 45/50\n",
      "59/59 [==============================] - 89s 2s/step - loss: 0.0377 - accuracy: 0.9888 - val_loss: 3.9272 - val_accuracy: 0.4299\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - 85s 1s/step - loss: 0.0561 - accuracy: 0.9808 - val_loss: 3.9670 - val_accuracy: 0.4393\n",
      "Epoch 47/50\n",
      "59/59 [==============================] - 83s 1s/step - loss: 0.1017 - accuracy: 0.9675 - val_loss: 4.0243 - val_accuracy: 0.3972\n",
      "Epoch 48/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.1166 - accuracy: 0.9606 - val_loss: 3.9243 - val_accuracy: 0.3785\n",
      "Epoch 49/50\n",
      "59/59 [==============================] - 75s 1s/step - loss: 0.3064 - accuracy: 0.9025 - val_loss: 3.8354 - val_accuracy: 0.4019\n",
      "Epoch 50/50\n",
      "59/59 [==============================] - 81s 1s/step - loss: 0.2561 - accuracy: 0.9110 - val_loss: 3.6883 - val_accuracy: 0.4065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c24dfb9e50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit_generator(generator=my_training_batch_generator, epochs = 50,validation_data = my_validation_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7de704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a501e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831105e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
