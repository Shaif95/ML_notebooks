{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acba090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ffa13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "\n",
    "trn1='D:/data/invasive-aquatic-species-data/noninvasive/*/'\n",
    "trn2='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Ostracod Image1/*/'\n",
    "trn3='D:/data/invasive-aquatic-species-data/invasive/*/'\n",
    "\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)\n",
    "tr3= glob(trn3)\n",
    "\n",
    "trn11='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers/*/'\n",
    "trn33='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Zebra Pediveliger Image1a/*/'\n",
    "tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "trn111='D:/data/Ostracod/Ostracods Day 2 Image1 To Baylor/Ostracods Day 2 Image1 To Baylor/Sorted Images/Not/*/'\n",
    "\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "trn11='D:/data/Ostracod/Preserved Ostracods 1 To Baylor/Preserved Ostracods 1 To Baylor/Sorted Images/Not/*/'\n",
    "trn33='D:/data/Veligers/Preserved Zebra Ped 1 To Baylor/Preserved Zebra Ped 1 To Baylor/Sorted Images/Pedi-Zebra Veligers/*/'\n",
    "tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "trn111='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/NonVeligers/Images_001/*/'\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "trn11='D:/data/Veligers/Preserved Zebra Ped 1a To Baylor/Preserved Zebra Ped 1a To Baylor/Sorted Images/Not/*/'\n",
    "trn33='D:/data/Veligers/Preserved Zebra Ped 1a To Baylor/Preserved Zebra Ped 1a To Baylor/Sorted Images/Preserved Zebra Ped 1a/*/'\n",
    "tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "trn111='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/NonVeligers/Images_001/*/'\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "trnl1='D:/data/Ostracod/Ostracod Day 2 Image12 Short To Baylor/Ostracod Day 2 Image12 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl2='D:/data/Ostracod/Ostracods Day 2 Image1 To Baylor/Ostracods Day 2 Image1 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl3='D:/data/Ostracod/Ostracods Day 2 Image2 To Baylor/Ostracods Day 2 Image2 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl4='D:/data/Ostracod/Ostracods Day 2 Image3 To Baylor/Ostracods Day 2 Image3 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl5='D:/data/Ostracod/Ostracods Day 2 Image12 To Baylor/Ostracods Day 2 Image12 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl6='D:/data/Ostracod/Preserved Ostracods 1 To Baylor/Preserved Ostracods 1 To Baylor/Sorted Images/Preserve Ostracods/*/'\n",
    "trnl7='D:/data/Ostracod/Preserved Ostracods 1a To Baylor/Preserved Ostracods 1a To Baylor/Sorted Images/Preserved Ostracods 1a/*/'\n",
    "\n",
    "trl1= glob(trnl1)\n",
    "trl2= glob(trnl2)\n",
    "trl3= glob(trnl3)\n",
    "trl4= glob(trnl4)\n",
    "trl5= glob(trnl5)\n",
    "trl6= glob(trnl6)\n",
    "trl7= glob(trnl7)\n",
    "\n",
    "\n",
    "tr2.extend(trl1)\n",
    "tr2.extend(trl2)\n",
    "tr2.extend(trl3)\n",
    "tr2.extend(trl4)\n",
    "tr2.extend(trl5)\n",
    "tr2.extend(trl6)\n",
    "tr2.extend(trl7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf0822e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeab214c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8a504b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3425.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "tr1= shuffle(tr1)\n",
    "tr2= shuffle(tr2)\n",
    "tr3= shuffle(tr3)\n",
    "\n",
    "tran_index_noninv = np.round( len(tr1)* .7  )\n",
    "tran_index_osc = np.round( len(tr2)* .9  )\n",
    "tran_index_inv = np.round( len(tr3)* .9  )\n",
    "tran_index_noninv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ae7f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9c51980",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr3[:(int) (tran_index_inv)]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr1[:(int) (tran_index_noninv)]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[:(int) (tran_index_osc)]:\n",
    "    label.append(2)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr3[:(int) (tran_index_inv)])):\n",
    "    a = glob(tr3[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr1[:(int) (tran_index_noninv)])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])        \n",
    "\n",
    "for j in range(0,len(tr2[:(int) (tran_index_osc)])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k]) \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = tf.image.resize_with_crop_or_pad(tf.keras.preprocessing.image.img_to_array(a), 28, 28)\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(28,28,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),28,28,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "079c6d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4673, 5, 28, 28, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "train_df= []\n",
    "breath = 5\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*5+k)\n",
    "        \n",
    "        deff.append(X_train[index])\n",
    "        \n",
    "    train_df.append(deff)\n",
    "\n",
    "Y_train = to_categorical(label)\n",
    "train_df = np.array(train_df)\n",
    "YY_Train = label\n",
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "104123f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5370"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24d262b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr3[(int) (tran_index_inv) + 1 :]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr1[ (int)(tran_index_noninv) + 1:]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in tr2[ (int)(tran_index_osc) + 1:]:\n",
    "    label.append(2)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in range(0,len(tr3[(int) (tran_index_inv) + 1 :])):\n",
    "    a = glob(tr3[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr1[ (int)(tran_index_noninv) + 1:])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])  \n",
    "        \n",
    "for j in range(0,len(tr2[ (int)(tran_index_osc) + 1:])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])  \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = tf.image.resize_with_crop_or_pad(tf.keras.preprocessing.image.img_to_array(a), 28, 28)\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(28,28,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),28,28,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "661c2759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1603, 5, 28, 28, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "test_df= []\n",
    "breath = 5\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*5 + k)\n",
    "        \n",
    "        deff.append(X_test[index])\n",
    "        \n",
    "    test_df.append(deff)\n",
    "    \n",
    "Y_test = to_categorical(label)\n",
    "test_df = np.array(test_df)\n",
    "YY_Test = label\n",
    "np.shape(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56c507ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 5, 28, 28, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b5cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"organmnist3d\"\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = ( 5, 28, 28, 3 )\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 60\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (4, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 32\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ae32102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88acaa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf0e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c674b1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6123, 2)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31947b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc77872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6, 2352)]    0           []                               \n",
      "                                                                                                  \n",
      " patch_encoder (PatchEncoder)   (None, 6, 32)        75488       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 6, 32)       64          ['patch_encoder[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 6, 32)       25184       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 6, 32)        8320        ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 6, 32)        0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'patch_encoder[0][0]',          \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 6, 32)       64          ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 6, 32)        1056        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 6, 32)        0           ['sequential_1[0][0]',           \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 6, 32)       64          ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 6, 32)       25184       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 6, 32)        8320        ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 6, 32)        0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]',                  \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 6, 32)       64          ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 6, 32)        1056        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 6, 32)        0           ['sequential_2[0][0]',           \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 6, 32)       64          ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 6, 32)       25184       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 6, 32)        8320        ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 6, 32)        0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]',                  \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 6, 32)       64          ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 6, 32)        1056        ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 6, 32)        0           ['sequential_3[0][0]',           \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 6, 32)       64          ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 6, 32)       25184       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 6, 32)        8320        ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 6, 32)        0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]',                  \n",
      "                                                                  'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 6, 32)       64          ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 6, 32)        1056        ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 6, 32)        0           ['sequential_4[0][0]',           \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 6, 32)       64          ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 6, 32)       25184       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 6, 32)        8320        ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 6, 32)        0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]',                  \n",
      "                                                                  'lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 6, 32)       64          ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 6, 32)        1056        ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 6, 32)        0           ['sequential_5[0][0]',           \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 6, 32)       64          ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 6, 32)       25184       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 6, 32)        8320        ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 6, 32)        0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]',                  \n",
      "                                                                  'lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 6, 32)       64          ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 6, 32)        1056        ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 6, 32)        0           ['sequential_6[0][0]',           \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 6, 32)       64          ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 32)          0           ['layer_normalization_12[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 2)            66          ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 283,746\n",
      "Trainable params: 283,746\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (6,2352) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(6, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=2, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c833aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_df = train_df.reshape( train_df.shape[0] , train_df.shape[1],( train_df.shape[2] * train_df.shape[3] * 3)  )\n",
    "#tt_df = test_df.reshape(test_df.shape[0] ,test_df.shape[1],( test_df.shape[2] * test_df.shape[3] * 3)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e83af007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "   Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_train_function_84197]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1388\\2042756921.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtra_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:    Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_train_function_84197]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(tra_df,Y_train,validation_split=0.2,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3abe3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1103,    0],\n",
       "       [   6,  201]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y_test\n",
    "pred = model.predict(tt_df)\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "786c9ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9852941176470589 0.9972801450589301 0.9710144927536232\n"
     ]
    }
   ],
   "source": [
    "f = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "b = 1 - ( (a[1][0]/a[1][1] + a[0][1]/a[0][0])/2  )\n",
    "r =  (  a[1][1]  / (a[1][1] + a[0][1])  )\n",
    "print(f,b,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87100053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6, 2352)]    0           []                               \n",
      "                                                                                                  \n",
      " patch_encoder (PatchEncoder)   (None, 6, 32)        75488       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 6, 32)       64          ['patch_encoder[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 6, 32)       8416        ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 6, 32)        0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'patch_encoder[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 6, 32)       64          ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 6, 32)        1056        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 6, 32)        0           ['sequential_1[0][0]',           \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 6, 32)       64          ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 6, 32)       8416        ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 6, 32)        0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 6, 32)       64          ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 6, 32)        1056        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 6, 32)        0           ['sequential_2[0][0]',           \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 6, 32)       64          ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 32)          0           ['layer_normalization_4[0][0]']  \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            66          ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 94,818\n",
      "Trainable params: 94,818\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tra_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14576\\1200473485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtra_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tra_df' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (6,2352) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(6, 32 )) (inputs)\n",
    "\n",
    "for _ in range(2):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=2, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    #lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=2, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(tra_df,Y_train,validation_split=0.2,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da7ea818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995049504950495 0.999096657633243 0.9901477832512315\n"
     ]
    }
   ],
   "source": [
    "Y_test = Y_test\n",
    "pred = model.predict(tt_df)\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T\n",
    "f = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "b = 1 - ( (a[1][0]/a[1][1] + a[0][1]/a[0][0])/2  )\n",
    "r =  (  a[1][1]  / (a[1][1] + a[0][1])  )\n",
    "print(f,b,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dd475d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 6, 2352)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder_2 (PatchEncoder)  (None, 6, 32)        75488       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 6, 32)        64          patch_encoder_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 6, 32)        50336       layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 6, 32)        0           multi_head_attention[0][0]       \n",
      "                                                                 patch_encoder_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 6, 32)        64          add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 6, 32)        1056        layer_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 32)        0           sequential_13[0][0]              \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 6, 32)        64          add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 6, 32)        50336       layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 32)        0           multi_head_attention_1[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 6, 32)        64          add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_14 (Sequential)      (None, 6, 32)        1056        layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 6, 32)        0           sequential_14[0][0]              \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 6, 32)        64          add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 6, 32)        50336       layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 6, 32)        0           multi_head_attention_2[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, 6, 32)        64          add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_15 (Sequential)      (None, 6, 32)        1056        layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 6, 32)        0           sequential_15[0][0]              \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 6, 32)        64          add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 6, 32)        50336       layer_normalization_16[0][0]     \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 6, 32)        0           multi_head_attention_3[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, 6, 32)        64          add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_16 (Sequential)      (None, 6, 32)        1056        layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 6, 32)        0           sequential_16[0][0]              \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, 6, 32)        64          add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 6, 32)        50336       layer_normalization_18[0][0]     \n",
      "                                                                 layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 6, 32)        0           multi_head_attention_4[0][0]     \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 6, 32)        64          add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_17 (Sequential)      (None, 6, 32)        1056        layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 6, 32)        0           sequential_17[0][0]              \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, 6, 32)        64          add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 6, 32)        50336       layer_normalization_20[0][0]     \n",
      "                                                                 layer_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 6, 32)        0           multi_head_attention_5[0][0]     \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, 6, 32)        64          add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_18 (Sequential)      (None, 6, 32)        1056        layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 6, 32)        0           sequential_18[0][0]              \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_22 (LayerNo (None, 6, 32)        64          add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 6, 32)        50336       layer_normalization_22[0][0]     \n",
      "                                                                 layer_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 6, 32)        0           multi_head_attention_6[0][0]     \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_23 (LayerNo (None, 6, 32)        64          add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_19 (Sequential)      (None, 6, 32)        1056        layer_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 6, 32)        0           sequential_19[0][0]              \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_24 (LayerNo (None, 6, 32)        64          add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 6, 32)        50336       layer_normalization_24[0][0]     \n",
      "                                                                 layer_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 6, 32)        0           multi_head_attention_7[0][0]     \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_25 (LayerNo (None, 6, 32)        64          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_20 (Sequential)      (None, 6, 32)        1056        layer_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 6, 32)        0           sequential_20[0][0]              \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_26 (LayerNo (None, 6, 32)        64          add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, 6, 32)        50336       layer_normalization_26[0][0]     \n",
      "                                                                 layer_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 6, 32)        0           multi_head_attention_8[0][0]     \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_27 (LayerNo (None, 6, 32)        64          add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_21 (Sequential)      (None, 6, 32)        1056        layer_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 6, 32)        0           sequential_21[0][0]              \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_28 (LayerNo (None, 6, 32)        64          add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_9 (MultiHe (None, 6, 32)        50336       layer_normalization_28[0][0]     \n",
      "                                                                 layer_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 6, 32)        0           multi_head_attention_9[0][0]     \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_29 (LayerNo (None, 6, 32)        64          add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_22 (Sequential)      (None, 6, 32)        1056        layer_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 6, 32)        0           sequential_22[0][0]              \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_30 (LayerNo (None, 6, 32)        64          add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_10 (MultiH (None, 6, 32)        50336       layer_normalization_30[0][0]     \n",
      "                                                                 layer_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 6, 32)        0           multi_head_attention_10[0][0]    \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_31 (LayerNo (None, 6, 32)        64          add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_23 (Sequential)      (None, 6, 32)        1056        layer_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 6, 32)        0           sequential_23[0][0]              \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_32 (LayerNo (None, 6, 32)        64          add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_11 (MultiH (None, 6, 32)        50336       layer_normalization_32[0][0]     \n",
      "                                                                 layer_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 6, 32)        0           multi_head_attention_11[0][0]    \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_33 (LayerNo (None, 6, 32)        64          add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_24 (Sequential)      (None, 6, 32)        1056        layer_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 6, 32)        0           sequential_24[0][0]              \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_34 (LayerNo (None, 6, 32)        64          add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 32)           0           layer_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 2)            66          global_average_pooling1d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 693,858\n",
      "Trainable params: 693,858\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 23s 103ms/step - loss: 0.5219 - accuracy: 0.7946 - val_loss: 0.2336 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.3663 - accuracy: 0.8432 - val_loss: 0.4138 - val_accuracy: 0.8206\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.2030 - accuracy: 0.9151 - val_loss: 0.2323 - val_accuracy: 0.8842\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.1755 - accuracy: 0.9294 - val_loss: 0.2131 - val_accuracy: 0.9086\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.1551 - accuracy: 0.9326 - val_loss: 0.1142 - val_accuracy: 0.9494\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.1516 - accuracy: 0.9347 - val_loss: 0.0847 - val_accuracy: 0.9625\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.1491 - accuracy: 0.9379 - val_loss: 0.1124 - val_accuracy: 0.9494\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.1667 - accuracy: 0.9343 - val_loss: 0.1455 - val_accuracy: 0.9347\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 7s 85ms/step - loss: 0.1355 - accuracy: 0.9461 - val_loss: 0.1634 - val_accuracy: 0.9233\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.1162 - accuracy: 0.9559 - val_loss: 0.0763 - val_accuracy: 0.9674\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.1389 - accuracy: 0.9539 - val_loss: 0.0910 - val_accuracy: 0.9608\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.1209 - accuracy: 0.9522 - val_loss: 0.2704 - val_accuracy: 0.8989\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.1106 - accuracy: 0.9575 - val_loss: 0.0810 - val_accuracy: 0.9608\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.1089 - accuracy: 0.9563 - val_loss: 0.1549 - val_accuracy: 0.9299\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.1170 - accuracy: 0.9563 - val_loss: 0.0509 - val_accuracy: 0.9788\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.1228 - accuracy: 0.9514 - val_loss: 0.1363 - val_accuracy: 0.9396\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 7s 87ms/step - loss: 0.1019 - accuracy: 0.9604 - val_loss: 0.0798 - val_accuracy: 0.9608\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.0915 - accuracy: 0.9653 - val_loss: 0.1441 - val_accuracy: 0.9413\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 7s 87ms/step - loss: 0.1009 - accuracy: 0.9608 - val_loss: 0.2379 - val_accuracy: 0.9233\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0921 - accuracy: 0.9661 - val_loss: 0.1586 - val_accuracy: 0.9478\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 7s 87ms/step - loss: 0.0931 - accuracy: 0.9653 - val_loss: 0.2354 - val_accuracy: 0.9038\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 7s 90ms/step - loss: 0.0979 - accuracy: 0.9600 - val_loss: 0.0736 - val_accuracy: 0.9674\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0867 - accuracy: 0.9673 - val_loss: 0.1006 - val_accuracy: 0.9560\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 0.0817 - accuracy: 0.9714 - val_loss: 0.0889 - val_accuracy: 0.9706\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.0728 - accuracy: 0.9718 - val_loss: 0.1131 - val_accuracy: 0.9527\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.0778 - accuracy: 0.9755 - val_loss: 0.1503 - val_accuracy: 0.9315\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0736 - accuracy: 0.9743 - val_loss: 0.3570 - val_accuracy: 0.8940\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0810 - accuracy: 0.9641 - val_loss: 0.3989 - val_accuracy: 0.8499\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 7s 85ms/step - loss: 0.0914 - accuracy: 0.9628 - val_loss: 0.1788 - val_accuracy: 0.9315\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 0.1003 - val_accuracy: 0.9674\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.0675 - accuracy: 0.9722 - val_loss: 0.2169 - val_accuracy: 0.9282\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 7s 89ms/step - loss: 0.0621 - accuracy: 0.9739 - val_loss: 0.1146 - val_accuracy: 0.9511\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.0536 - accuracy: 0.9767 - val_loss: 0.1284 - val_accuracy: 0.9543\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.1891 - val_accuracy: 0.9282\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0566 - accuracy: 0.9763 - val_loss: 0.1903 - val_accuracy: 0.9331\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.0715 - accuracy: 0.9722 - val_loss: 0.3347 - val_accuracy: 0.9462\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0535 - accuracy: 0.9816 - val_loss: 0.1838 - val_accuracy: 0.9462\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 7s 85ms/step - loss: 0.0659 - accuracy: 0.9755 - val_loss: 0.2889 - val_accuracy: 0.8972\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.0868 - accuracy: 0.9661 - val_loss: 0.1128 - val_accuracy: 0.9625\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 6s 80ms/step - loss: 0.0629 - accuracy: 0.9759 - val_loss: 0.2529 - val_accuracy: 0.9413\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.0442 - accuracy: 0.9829 - val_loss: 0.0514 - val_accuracy: 0.9821\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 7s 86ms/step - loss: 0.0566 - accuracy: 0.9755 - val_loss: 0.2314 - val_accuracy: 0.9413\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.2113 - val_accuracy: 0.9315\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.3788 - val_accuracy: 0.8874\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0567 - accuracy: 0.9804 - val_loss: 0.1981 - val_accuracy: 0.9347\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 6s 72ms/step - loss: 0.0533 - accuracy: 0.9792 - val_loss: 0.1110 - val_accuracy: 0.9641\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0373 - accuracy: 0.9861 - val_loss: 0.1416 - val_accuracy: 0.9576\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0775 - accuracy: 0.9710 - val_loss: 0.1295 - val_accuracy: 0.9511\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0339 - accuracy: 0.9853 - val_loss: 0.2037 - val_accuracy: 0.9478\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0259 - accuracy: 0.9890 - val_loss: 0.1323 - val_accuracy: 0.9625\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0250 - accuracy: 0.9894 - val_loss: 0.2138 - val_accuracy: 0.9462\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 0.0739 - val_accuracy: 0.9723\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.0415 - accuracy: 0.9833 - val_loss: 0.1021 - val_accuracy: 0.9608\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0333 - accuracy: 0.9857 - val_loss: 0.1161 - val_accuracy: 0.9560\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0295 - accuracy: 0.9878 - val_loss: 0.1552 - val_accuracy: 0.9560\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.2156 - val_accuracy: 0.9608\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0389 - accuracy: 0.9849 - val_loss: 0.2261 - val_accuracy: 0.9527\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0262 - accuracy: 0.9894 - val_loss: 0.3019 - val_accuracy: 0.9364\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 7s 89ms/step - loss: 0.0304 - accuracy: 0.9853 - val_loss: 0.2947 - val_accuracy: 0.9299\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.3137 - val_accuracy: 0.9396\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0398 - accuracy: 0.9849 - val_loss: 0.1475 - val_accuracy: 0.9576\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.1855 - val_accuracy: 0.9445\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 6s 79ms/step - loss: 0.0304 - accuracy: 0.9869 - val_loss: 0.1199 - val_accuracy: 0.9706\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 6s 75ms/step - loss: 0.0410 - accuracy: 0.9837 - val_loss: 0.2752 - val_accuracy: 0.9445\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.2091 - val_accuracy: 0.9608\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.2158 - val_accuracy: 0.9592\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 6s 74ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.2110 - val_accuracy: 0.9462\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 0.1017 - accuracy: 0.9641 - val_loss: 0.1465 - val_accuracy: 0.9560\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0837 - accuracy: 0.9690 - val_loss: 0.1615 - val_accuracy: 0.9560\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.1601 - val_accuracy: 0.9560\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0287 - accuracy: 0.9902 - val_loss: 0.1442 - val_accuracy: 0.9592\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0739 - accuracy: 0.9718 - val_loss: 0.1142 - val_accuracy: 0.9723\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 6s 73ms/step - loss: 0.0166 - accuracy: 0.9931 - val_loss: 0.1481 - val_accuracy: 0.9657\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0219 - accuracy: 0.9914 - val_loss: 0.1104 - val_accuracy: 0.9739\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 7s 92ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.2892 - val_accuracy: 0.9380\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 7s 87ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.1324 - val_accuracy: 0.9625\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 6s 82ms/step - loss: 0.0399 - accuracy: 0.9857 - val_loss: 0.2416 - val_accuracy: 0.9266\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 7s 86ms/step - loss: 0.0546 - accuracy: 0.9812 - val_loss: 0.1394 - val_accuracy: 0.9674\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 7s 90ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.1475 - val_accuracy: 0.9690\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.1367 - val_accuracy: 0.9739\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 7s 86ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.2944 - val_accuracy: 0.9511\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.4960 - val_accuracy: 0.9184\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 7s 84ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.2138 - val_accuracy: 0.9462\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.1937 - val_accuracy: 0.9592\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.2368 - val_accuracy: 0.9413\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 7s 93ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.1489 - val_accuracy: 0.9641\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0144 - accuracy: 0.9943 - val_loss: 0.1541 - val_accuracy: 0.9674\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 7s 85ms/step - loss: 0.0129 - accuracy: 0.9939 - val_loss: 0.2583 - val_accuracy: 0.9576\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 7s 89ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.1197 - val_accuracy: 0.9739\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 7s 85ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.2260 - val_accuracy: 0.9608\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 6.6339e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9625\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 6s 85ms/step - loss: 2.4115e-04 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9576\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 7s 85ms/step - loss: 2.8148e-04 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9657\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 6s 78ms/step - loss: 2.0978e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9511\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.1025 - val_accuracy: 0.9625\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.2442 - val_accuracy: 0.9576\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 6s 81ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.3115 - val_accuracy: 0.9429\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 6s 76ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9608\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 6s 77ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2760 - val_accuracy: 0.9625\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 7s 90ms/step - loss: 0.0537 - accuracy: 0.9792 - val_loss: 0.1679 - val_accuracy: 0.9511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263c237ab50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "inputs = layers.Input(shape= (6,2352) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(6, 32 )) (inputs)\n",
    "\n",
    "for _ in range(12):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output =layers.MultiHeadAttention (  num_heads=12, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    #lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=2, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(tra_df,Y_train,validation_split=0.2,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c6c53cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824561403508771 0.9863415555924266 0.98989898989899\n"
     ]
    }
   ],
   "source": [
    "Y_test = Y_test\n",
    "pred = model.predict(tt_df)\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T\n",
    "f = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "b = 1 - ( (a[1][0]/a[1][1] + a[0][1]/a[0][0])/2  )\n",
    "r =  (  a[1][1]  / (a[1][1] + a[0][1])  )\n",
    "print(f,b,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325fe64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a6163a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super(PatchEncoder, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(2, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\": self.projection_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26057200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 5, 28, 28,   0           []                               \n",
      "                                3)]                                                               \n",
      "                                                                                                  \n",
      " patch_encoder_4 (PatchEncoder)  (None, 5, 32)       11064       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 5, 32)       64          ['patch_encoder_4[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 5, 32)       25184       ['layer_normalization_52[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_24 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 5, 32)        0           ['multi_head_attention_24[0][0]',\n",
      "                                                                  'patch_encoder_4[0][0]',        \n",
      "                                                                  'lstm_24[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 5, 32)       64          ['add_48[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_29 (Sequential)     (None, 5, 32)        1056        ['layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 5, 32)        0           ['sequential_29[0][0]',          \n",
      "                                                                  'add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 5, 32)       64          ['add_49[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 5, 32)       25184       ['layer_normalization_54[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_25 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 5, 32)        0           ['multi_head_attention_25[0][0]',\n",
      "                                                                  'add_49[0][0]',                 \n",
      "                                                                  'lstm_25[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 5, 32)       64          ['add_50[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_30 (Sequential)     (None, 5, 32)        1056        ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 5, 32)        0           ['sequential_30[0][0]',          \n",
      "                                                                  'add_50[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 5, 32)       64          ['add_51[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 5, 32)       25184       ['layer_normalization_56[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_26 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " add_52 (Add)                   (None, 5, 32)        0           ['multi_head_attention_26[0][0]',\n",
      "                                                                  'add_51[0][0]',                 \n",
      "                                                                  'lstm_26[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 5, 32)       64          ['add_52[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_31 (Sequential)     (None, 5, 32)        1056        ['layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " add_53 (Add)                   (None, 5, 32)        0           ['sequential_31[0][0]',          \n",
      "                                                                  'add_52[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_58 (LayerN  (None, 5, 32)       64          ['add_53[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 5, 32)       25184       ['layer_normalization_58[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_27 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " add_54 (Add)                   (None, 5, 32)        0           ['multi_head_attention_27[0][0]',\n",
      "                                                                  'add_53[0][0]',                 \n",
      "                                                                  'lstm_27[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_59 (LayerN  (None, 5, 32)       64          ['add_54[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_32 (Sequential)     (None, 5, 32)        1056        ['layer_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " add_55 (Add)                   (None, 5, 32)        0           ['sequential_32[0][0]',          \n",
      "                                                                  'add_54[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_60 (LayerN  (None, 5, 32)       64          ['add_55[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 5, 32)       25184       ['layer_normalization_60[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_28 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 5, 32)        0           ['multi_head_attention_28[0][0]',\n",
      "                                                                  'add_55[0][0]',                 \n",
      "                                                                  'lstm_28[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_61 (LayerN  (None, 5, 32)       64          ['add_56[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_33 (Sequential)     (None, 5, 32)        1056        ['layer_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 5, 32)        0           ['sequential_33[0][0]',          \n",
      "                                                                  'add_56[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_62 (LayerN  (None, 5, 32)       64          ['add_57[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 5, 32)       25184       ['layer_normalization_62[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_29 (LSTM)                 (None, 5, 32)        8320        ['layer_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 5, 32)        0           ['multi_head_attention_29[0][0]',\n",
      "                                                                  'add_57[0][0]',                 \n",
      "                                                                  'lstm_29[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_63 (LayerN  (None, 5, 32)       64          ['add_58[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_34 (Sequential)     (None, 5, 32)        1056        ['layer_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 5, 32)        0           ['sequential_34[0][0]',          \n",
      "                                                                  'add_58[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_64 (LayerN  (None, 5, 32)       64          ['add_59[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 32)          0           ['layer_normalization_64[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 3)            99          ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 219,355\n",
      "Trainable params: 219,355\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (5,28,28,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(5, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output= layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=3, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262812d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2676f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "117/117 [==============================] - 33s 123ms/step - loss: 0.5952 - accuracy: 0.7138 - val_loss: 0.8654 - val_accuracy: 0.8225\n",
      "Epoch 2/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.4586 - accuracy: 0.7785 - val_loss: 0.7451 - val_accuracy: 0.8492\n",
      "Epoch 3/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.3951 - accuracy: 0.8274 - val_loss: 0.9775 - val_accuracy: 0.7872\n",
      "Epoch 4/100\n",
      "117/117 [==============================] - 9s 81ms/step - loss: 0.3184 - accuracy: 0.8625 - val_loss: 0.8003 - val_accuracy: 0.8332\n",
      "Epoch 5/100\n",
      "117/117 [==============================] - 10s 84ms/step - loss: 0.2900 - accuracy: 0.8732 - val_loss: 0.9354 - val_accuracy: 0.8332\n",
      "Epoch 6/100\n",
      "117/117 [==============================] - 9s 81ms/step - loss: 0.2510 - accuracy: 0.8965 - val_loss: 0.9874 - val_accuracy: 0.8278\n",
      "Epoch 7/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.2273 - accuracy: 0.9050 - val_loss: 0.9453 - val_accuracy: 0.8460\n",
      "Epoch 8/100\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.2011 - accuracy: 0.9205 - val_loss: 0.9180 - val_accuracy: 0.8749\n",
      "Epoch 9/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.2022 - accuracy: 0.9181 - val_loss: 1.0130 - val_accuracy: 0.8406\n",
      "Epoch 10/100\n",
      "117/117 [==============================] - 9s 78ms/step - loss: 0.1857 - accuracy: 0.9243 - val_loss: 0.9721 - val_accuracy: 0.8674\n",
      "Epoch 11/100\n",
      "117/117 [==============================] - 10s 83ms/step - loss: 0.1720 - accuracy: 0.9307 - val_loss: 1.0103 - val_accuracy: 0.8513\n",
      "Epoch 12/100\n",
      "117/117 [==============================] - 10s 83ms/step - loss: 0.1619 - accuracy: 0.9369 - val_loss: 1.1487 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "117/117 [==============================] - 10s 83ms/step - loss: 0.1477 - accuracy: 0.9398 - val_loss: 1.0687 - val_accuracy: 0.8342\n",
      "Epoch 14/100\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.1356 - accuracy: 0.9454 - val_loss: 1.1032 - val_accuracy: 0.8278\n",
      "Epoch 15/100\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.1238 - accuracy: 0.9529 - val_loss: 1.0096 - val_accuracy: 0.8545\n",
      "Epoch 16/100\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.1239 - accuracy: 0.9494 - val_loss: 1.2055 - val_accuracy: 0.8139\n",
      "Epoch 17/100\n",
      "117/117 [==============================] - 10s 82ms/step - loss: 0.1120 - accuracy: 0.9623 - val_loss: 1.1370 - val_accuracy: 0.8374\n",
      "Epoch 18/100\n",
      "117/117 [==============================] - 9s 81ms/step - loss: 0.1121 - accuracy: 0.9601 - val_loss: 1.1145 - val_accuracy: 0.8460\n",
      "Epoch 19/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0949 - accuracy: 0.9663 - val_loss: 1.0790 - val_accuracy: 0.8620\n",
      "Epoch 20/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0889 - accuracy: 0.9644 - val_loss: 1.0777 - val_accuracy: 0.8578\n",
      "Epoch 21/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.1069 - accuracy: 0.9599 - val_loss: 1.1096 - val_accuracy: 0.8588\n",
      "Epoch 22/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0784 - accuracy: 0.9719 - val_loss: 1.0783 - val_accuracy: 0.8599\n",
      "Epoch 23/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0815 - accuracy: 0.9706 - val_loss: 1.2818 - val_accuracy: 0.8075\n",
      "Epoch 24/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0850 - accuracy: 0.9690 - val_loss: 1.1046 - val_accuracy: 0.8588\n",
      "Epoch 25/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0738 - accuracy: 0.9722 - val_loss: 1.2823 - val_accuracy: 0.8118\n",
      "Epoch 26/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0602 - accuracy: 0.9762 - val_loss: 1.3266 - val_accuracy: 0.8235\n",
      "Epoch 27/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0669 - accuracy: 0.9770 - val_loss: 1.2079 - val_accuracy: 0.8588\n",
      "Epoch 28/100\n",
      "117/117 [==============================] - 9s 78ms/step - loss: 0.0522 - accuracy: 0.9821 - val_loss: 1.2299 - val_accuracy: 0.8567\n",
      "Epoch 29/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.0700 - accuracy: 0.9746 - val_loss: 1.2691 - val_accuracy: 0.8460\n",
      "Epoch 30/100\n",
      "117/117 [==============================] - 9s 81ms/step - loss: 0.0452 - accuracy: 0.9850 - val_loss: 1.1922 - val_accuracy: 0.8524\n",
      "Epoch 31/100\n",
      "117/117 [==============================] - 11s 93ms/step - loss: 0.0592 - accuracy: 0.9807 - val_loss: 1.2398 - val_accuracy: 0.8567\n",
      "Epoch 32/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.0513 - accuracy: 0.9823 - val_loss: 1.1709 - val_accuracy: 0.8610\n",
      "Epoch 33/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0578 - accuracy: 0.9805 - val_loss: 1.1851 - val_accuracy: 0.8524\n",
      "Epoch 34/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0717 - accuracy: 0.9732 - val_loss: 1.2437 - val_accuracy: 0.8513\n",
      "Epoch 35/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0565 - accuracy: 0.9791 - val_loss: 1.4500 - val_accuracy: 0.8053\n",
      "Epoch 36/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0495 - accuracy: 0.9837 - val_loss: 1.4108 - val_accuracy: 0.8267\n",
      "Epoch 37/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0479 - accuracy: 0.9829 - val_loss: 1.4277 - val_accuracy: 0.8225\n",
      "Epoch 38/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 1.2168 - val_accuracy: 0.8599\n",
      "Epoch 39/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 1.3917 - val_accuracy: 0.8160\n",
      "Epoch 40/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0331 - accuracy: 0.9893 - val_loss: 1.3022 - val_accuracy: 0.8631\n",
      "Epoch 41/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 1.3062 - val_accuracy: 0.8545\n",
      "Epoch 42/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0385 - accuracy: 0.9845 - val_loss: 1.4933 - val_accuracy: 0.8139\n",
      "Epoch 43/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 1.2641 - val_accuracy: 0.8578\n",
      "Epoch 44/100\n",
      "117/117 [==============================] - 9s 78ms/step - loss: 0.0449 - accuracy: 0.9839 - val_loss: 1.3181 - val_accuracy: 0.8492\n",
      "Epoch 45/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0304 - accuracy: 0.9909 - val_loss: 1.2585 - val_accuracy: 0.8578\n",
      "Epoch 46/100\n",
      "117/117 [==============================] - 9s 73ms/step - loss: 0.0345 - accuracy: 0.9874 - val_loss: 1.2556 - val_accuracy: 0.8449\n",
      "Epoch 47/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 1.2498 - val_accuracy: 0.8471\n",
      "Epoch 48/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0511 - accuracy: 0.9821 - val_loss: 1.1828 - val_accuracy: 0.8513\n",
      "Epoch 49/100\n",
      "117/117 [==============================] - 8s 72ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 1.4295 - val_accuracy: 0.8460\n",
      "Epoch 50/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 1.5147 - val_accuracy: 0.8332\n",
      "Epoch 51/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 1.4025 - val_accuracy: 0.8417\n",
      "Epoch 52/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 1.3672 - val_accuracy: 0.8535\n",
      "Epoch 53/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 1.4451 - val_accuracy: 0.8471\n",
      "Epoch 54/100\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 1.3766 - val_accuracy: 0.8374\n",
      "Epoch 55/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 1.3669 - val_accuracy: 0.8342\n",
      "Epoch 56/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 1.3646 - val_accuracy: 0.8556\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 9s 77ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 1.4432 - val_accuracy: 0.8406\n",
      "Epoch 58/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 1.4466 - val_accuracy: 0.8524\n",
      "Epoch 59/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 1.3360 - val_accuracy: 0.8535\n",
      "Epoch 60/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0268 - accuracy: 0.9896 - val_loss: 1.4714 - val_accuracy: 0.8406\n",
      "Epoch 61/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 1.5393 - val_accuracy: 0.8332\n",
      "Epoch 62/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0399 - accuracy: 0.9866 - val_loss: 1.5293 - val_accuracy: 0.8374\n",
      "Epoch 63/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 1.4696 - val_accuracy: 0.8374\n",
      "Epoch 64/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0179 - accuracy: 0.9930 - val_loss: 1.4129 - val_accuracy: 0.8588\n",
      "Epoch 65/100\n",
      "117/117 [==============================] - 9s 73ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 1.4979 - val_accuracy: 0.8535\n",
      "Epoch 66/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 1.5334 - val_accuracy: 0.8492\n",
      "Epoch 67/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0336 - accuracy: 0.9898 - val_loss: 1.5359 - val_accuracy: 0.8396\n",
      "Epoch 68/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.5350 - val_accuracy: 0.8524\n",
      "Epoch 69/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.0233 - accuracy: 0.9909 - val_loss: 1.5221 - val_accuracy: 0.8535\n",
      "Epoch 70/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 1.5888 - val_accuracy: 0.8535\n",
      "Epoch 71/100\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0213 - accuracy: 0.9917 - val_loss: 1.6678 - val_accuracy: 0.8353\n",
      "Epoch 72/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0233 - accuracy: 0.9912 - val_loss: 1.6109 - val_accuracy: 0.8578\n",
      "Epoch 73/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 1.5303 - val_accuracy: 0.8513\n",
      "Epoch 74/100\n",
      "117/117 [==============================] - 9s 75ms/step - loss: 0.0395 - accuracy: 0.9856 - val_loss: 1.6377 - val_accuracy: 0.8364\n",
      "Epoch 75/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 1.5448 - val_accuracy: 0.8289\n",
      "Epoch 76/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 1.5648 - val_accuracy: 0.8364\n",
      "Epoch 77/100\n",
      "117/117 [==============================] - 12s 103ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 1.6760 - val_accuracy: 0.8428\n",
      "Epoch 78/100\n",
      "117/117 [==============================] - 10s 82ms/step - loss: 0.0238 - accuracy: 0.9912 - val_loss: 1.7106 - val_accuracy: 0.8481\n",
      "Epoch 79/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 1.7624 - val_accuracy: 0.8439\n",
      "Epoch 80/100\n",
      "117/117 [==============================] - 9s 78ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 1.6852 - val_accuracy: 0.8535\n",
      "Epoch 81/100\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.6375 - val_accuracy: 0.8567\n",
      "Epoch 82/100\n",
      "117/117 [==============================] - 10s 85ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 1.6253 - val_accuracy: 0.8503\n",
      "Epoch 83/100\n",
      "117/117 [==============================] - 13s 112ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 1.8450 - val_accuracy: 0.8235\n",
      "Epoch 84/100\n",
      "117/117 [==============================] - 11s 90ms/step - loss: 0.0209 - accuracy: 0.9922 - val_loss: 1.6456 - val_accuracy: 0.8545\n",
      "Epoch 85/100\n",
      "117/117 [==============================] - 10s 86ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 1.7105 - val_accuracy: 0.8374\n",
      "Epoch 86/100\n",
      "117/117 [==============================] - 10s 90ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 1.6387 - val_accuracy: 0.8599\n",
      "Epoch 87/100\n",
      "117/117 [==============================] - 10s 82ms/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 1.7352 - val_accuracy: 0.8299\n",
      "Epoch 88/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0254 - accuracy: 0.9920 - val_loss: 1.7508 - val_accuracy: 0.8374\n",
      "Epoch 89/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 1.6669 - val_accuracy: 0.8556\n",
      "Epoch 90/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 1.9513 - val_accuracy: 0.8214\n",
      "Epoch 91/100\n",
      "117/117 [==============================] - 9s 76ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 1.8969 - val_accuracy: 0.8310\n",
      "Epoch 92/100\n",
      "117/117 [==============================] - 10s 88ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 1.7919 - val_accuracy: 0.8492\n",
      "Epoch 93/100\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 1.7916 - val_accuracy: 0.8439\n",
      "Epoch 94/100\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 1.7641 - val_accuracy: 0.8556\n",
      "Epoch 95/100\n",
      "117/117 [==============================] - 9s 74ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 1.7760 - val_accuracy: 0.8492\n",
      "Epoch 96/100\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 1.7457 - val_accuracy: 0.8406\n",
      "Epoch 97/100\n",
      "117/117 [==============================] - 9s 77ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 1.7692 - val_accuracy: 0.8503\n",
      "Epoch 98/100\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 1.9955 - val_accuracy: 0.8235\n",
      "Epoch 99/100\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 1.7876 - val_accuracy: 0.8406\n",
      "Epoch 100/100\n",
      "117/117 [==============================] - 9s 78ms/step - loss: 0.0065 - accuracy: 0.9973 - val_loss: 1.8545 - val_accuracy: 0.8471\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "history = model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efa1675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef7bac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.38%\n",
      "F1 score for class 1: 97.32%\n"
     ]
    }
   ],
   "source": [
    "Y_test = Y_test\n",
    "\n",
    "pred = model.predict(test_df)\n",
    "p = np.round(pred)\n",
    "p = np.argmax(p, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, p)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 score for class 1\n",
    "f1_class1 = f1_score(Y_test, p, labels=[1], average='macro')\n",
    "print(\"F1 score for class 1: {:.2f}%\".format(f1_class1 * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b4d89f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define the class names\n",
    "classes = ['Non-Invasive', 'Invasive', 'Ostracod']\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(Y_test, p)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "normalize = False\n",
    "if normalize:\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Print the confusion matrix values\n",
    "fmt = '.2f' if normalize else 'd'\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c36be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('five_frame_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bb2f5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy over time\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfadae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08dc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506427c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3afd50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847db778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a0cf3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split( train_df,YY_Train , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cc7dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
    "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
    "    # Preprocess images\n",
    "    frames = tf.image.convert_image_dtype(\n",
    "        frames[\n",
    "            ..., tf.newaxis\n",
    "        ],  # The new axis is to help for further processing with Conv3D layers\n",
    "        tf.float32,\n",
    "    )\n",
    "    # Parse label\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return frames, label\n",
    "\n",
    "\n",
    "def prepare_dataloader(\n",
    "    videos: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    loader_type: str = \"train\",\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "):\n",
    "    \"\"\"Utility function to prepare the dataloader.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels))\n",
    "\n",
    "    if loader_type == \"train\":\n",
    "        dataset = dataset.shuffle(BATCH_SIZE * 2)\n",
    "\n",
    "    dataloader = (\n",
    "        dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "trainloader = prepare_dataloader(X_train , y_train , \"train\")\n",
    "validloader = prepare_dataloader(X_val, y_val, \"valid\")\n",
    "testloader = prepare_dataloader(test_df,YY_Test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0523831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2f4f081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
    "\n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        encoded_positions = self.position_embedding(self.positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e6b82757",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECTION_DIM = 32\n",
    "def create_vivit_classifier(\n",
    "    tubelet_embedder,\n",
    "    positional_encoder,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    transformer_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embed_dim=PROJECTION_DIM,\n",
    "    layer_norm_eps=LAYER_NORM_EPS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "):\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = tubelet_embedder(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization and MHSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
    "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
    "            ]\n",
    "        )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(units=3, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28803bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 5, 28, 28,   0           []                               \n",
      "                                3)]                                                               \n",
      "                                                                                                  \n",
      " tubelet_embedding_5 (TubeletEm  (None, 9, 32)       24608       ['input_10[0][0]']               \n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " positional_encoder_5 (Position  (None, 9, 32)       288         ['tubelet_embedding_5[0][0]']    \n",
      " alEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_83 (LayerN  (None, 9, 32)       64          ['positional_encoder_5[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_37 (Multi  (None, 9, 32)       3962        ['layer_normalization_83[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " add_74 (Add)                   (None, 9, 32)        0           ['multi_head_attention_37[0][0]',\n",
      "                                                                  'positional_encoder_5[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_84 (LayerN  (None, 9, 32)       64          ['add_74[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_41 (Sequential)     (None, 9, 32)        8352        ['layer_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " add_75 (Add)                   (None, 9, 32)        0           ['sequential_41[0][0]',          \n",
      "                                                                  'add_74[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_85 (LayerN  (None, 9, 32)       64          ['add_75[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_38 (Multi  (None, 9, 32)       3962        ['layer_normalization_85[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " add_76 (Add)                   (None, 9, 32)        0           ['multi_head_attention_38[0][0]',\n",
      "                                                                  'add_75[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_86 (LayerN  (None, 9, 32)       64          ['add_76[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_42 (Sequential)     (None, 9, 32)        8352        ['layer_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " add_77 (Add)                   (None, 9, 32)        0           ['sequential_42[0][0]',          \n",
      "                                                                  'add_76[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_87 (LayerN  (None, 9, 32)       64          ['add_77[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_39 (Multi  (None, 9, 32)       3962        ['layer_normalization_87[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " add_78 (Add)                   (None, 9, 32)        0           ['multi_head_attention_39[0][0]',\n",
      "                                                                  'add_77[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_88 (LayerN  (None, 9, 32)       64          ['add_78[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_43 (Sequential)     (None, 9, 32)        8352        ['layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " add_79 (Add)                   (None, 9, 32)        0           ['sequential_43[0][0]',          \n",
      "                                                                  'add_78[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_89 (LayerN  (None, 9, 32)       64          ['add_79[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_40 (Multi  (None, 9, 32)       3962        ['layer_normalization_89[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " add_80 (Add)                   (None, 9, 32)        0           ['multi_head_attention_40[0][0]',\n",
      "                                                                  'add_79[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_90 (LayerN  (None, 9, 32)       64          ['add_80[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_44 (Sequential)     (None, 9, 32)        8352        ['layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " add_81 (Add)                   (None, 9, 32)        0           ['sequential_44[0][0]',          \n",
      "                                                                  'add_80[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_91 (LayerN  (None, 9, 32)       64          ['add_81[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_41 (Multi  (None, 9, 32)       3962        ['layer_normalization_91[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " add_82 (Add)                   (None, 9, 32)        0           ['multi_head_attention_41[0][0]',\n",
      "                                                                  'add_81[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_92 (LayerN  (None, 9, 32)       64          ['add_82[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_45 (Sequential)     (None, 9, 32)        8352        ['layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " add_83 (Add)                   (None, 9, 32)        0           ['sequential_45[0][0]',          \n",
      "                                                                  'add_82[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_93 (LayerN  (None, 9, 32)       64          ['add_83[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 32)          0           ['layer_normalization_93[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 3)            99          ['global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 87,269\n",
      "Trainable params: 87,269\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (4, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "NUM_HEADS = 6\n",
    "NUM_LAYERS = 6\n",
    "# TRAINING\n",
    "EPOCHS = 50\n",
    "PROJECTION_DIM = 32\n",
    "\n",
    "md = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
    "    )\n",
    "\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf326e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60360ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6aa5b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - 13s 56ms/step - loss: 0.5367 - accuracy: 0.7845 - top-5-accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.7879 - val_top-5-accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.4612 - accuracy: 0.8008 - top-5-accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.7960 - val_top-5-accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.4161 - accuracy: 0.8075 - top-5-accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.8193 - val_top-5-accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.3934 - accuracy: 0.8198 - top-5-accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.8252 - val_top-5-accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.3567 - accuracy: 0.8358 - top-5-accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.8368 - val_top-5-accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.3419 - accuracy: 0.8408 - top-5-accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.8357 - val_top-5-accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.3279 - accuracy: 0.8577 - top-5-accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.8427 - val_top-5-accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.3061 - accuracy: 0.8629 - top-5-accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.8520 - val_top-5-accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - 6s 51ms/step - loss: 0.2979 - accuracy: 0.8693 - top-5-accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.8438 - val_top-5-accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.2899 - accuracy: 0.8702 - top-5-accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.8566 - val_top-5-accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.2585 - accuracy: 0.8906 - top-5-accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.8753 - val_top-5-accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.2465 - accuracy: 0.8988 - top-5-accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.8683 - val_top-5-accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.2473 - accuracy: 0.9008 - top-5-accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.8741 - val_top-5-accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.2304 - accuracy: 0.9105 - top-5-accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8741 - val_top-5-accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.2154 - accuracy: 0.9157 - top-5-accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.8858 - val_top-5-accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.2148 - accuracy: 0.9157 - top-5-accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.8718 - val_top-5-accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1929 - accuracy: 0.9265 - top-5-accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.8800 - val_top-5-accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.1953 - accuracy: 0.9227 - top-5-accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.8660 - val_top-5-accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.1912 - accuracy: 0.9248 - top-5-accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.8939 - val_top-5-accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.1829 - accuracy: 0.9323 - top-5-accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8951 - val_top-5-accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1881 - accuracy: 0.9274 - top-5-accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.8765 - val_top-5-accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - 6s 55ms/step - loss: 0.1671 - accuracy: 0.9390 - top-5-accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9114 - val_top-5-accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - 6s 56ms/step - loss: 0.1626 - accuracy: 0.9370 - top-5-accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.8928 - val_top-5-accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.1622 - accuracy: 0.9390 - top-5-accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9044 - val_top-5-accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1660 - accuracy: 0.9373 - top-5-accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9126 - val_top-5-accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1470 - accuracy: 0.9443 - top-5-accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.8974 - val_top-5-accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1383 - accuracy: 0.9481 - top-5-accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9021 - val_top-5-accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1323 - accuracy: 0.9554 - top-5-accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.8951 - val_top-5-accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.1452 - accuracy: 0.9469 - top-5-accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9068 - val_top-5-accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1367 - accuracy: 0.9504 - top-5-accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9138 - val_top-5-accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.1487 - accuracy: 0.9408 - top-5-accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9079 - val_top-5-accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.1374 - accuracy: 0.9475 - top-5-accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9068 - val_top-5-accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.1308 - accuracy: 0.9498 - top-5-accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9044 - val_top-5-accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.1192 - accuracy: 0.9577 - top-5-accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9056 - val_top-5-accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1135 - accuracy: 0.9571 - top-5-accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.9009 - val_top-5-accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - 5s 50ms/step - loss: 0.1029 - accuracy: 0.9656 - top-5-accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9009 - val_top-5-accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - 5s 50ms/step - loss: 0.1214 - accuracy: 0.9539 - top-5-accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9161 - val_top-5-accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - 6s 54ms/step - loss: 0.1070 - accuracy: 0.9606 - top-5-accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9184 - val_top-5-accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.0953 - accuracy: 0.9662 - top-5-accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149 - val_top-5-accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.0940 - accuracy: 0.9697 - top-5-accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9184 - val_top-5-accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1003 - accuracy: 0.9653 - top-5-accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9126 - val_top-5-accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.0985 - accuracy: 0.9624 - top-5-accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9079 - val_top-5-accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1086 - accuracy: 0.9574 - top-5-accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9172 - val_top-5-accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.0974 - accuracy: 0.9630 - top-5-accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9009 - val_top-5-accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - 5s 47ms/step - loss: 0.1008 - accuracy: 0.9635 - top-5-accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9091 - val_top-5-accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - 5s 49ms/step - loss: 0.0902 - accuracy: 0.9656 - top-5-accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9091 - val_top-5-accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.0947 - accuracy: 0.9659 - top-5-accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9103 - val_top-5-accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.1037 - accuracy: 0.9589 - top-5-accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9091 - val_top-5-accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.0746 - accuracy: 0.9764 - top-5-accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9161 - val_top-5-accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - 5s 48ms/step - loss: 0.0782 - accuracy: 0.9717 - top-5-accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9033 - val_top-5-accuracy: 1.0000\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 0.1427 - accuracy: 0.9504 - top-5-accuracy: 1.0000\n",
      "Test accuracy: 95.04%\n",
      "Test top 5 accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "PROJECTION_DIM = 32\n",
    "def run_experiment():\n",
    "    # Initialize model\n",
    "    model = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
    "    )\n",
    "\n",
    "    # Compile the model with the optimizer, loss function\n",
    "    # and the metrics.\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Train the model.\n",
    "    _ = model.fit(trainloader, epochs=EPOCHS, validation_data=validloader)\n",
    "\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c6df61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.04%\n",
      "Balanced accuracy: 87.63%\n",
      "F1 score for class 1: 89.44%\n"
     ]
    }
   ],
   "source": [
    "#Y_test = np.argmax(YY_test, axis=1)\n",
    "Y_test = Y_test\n",
    "\n",
    "pred = model.predict(test_df)\n",
    "p = np.round(pred)\n",
    "p = np.argmax(p, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, p)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 score for class 1\n",
    "f1_class1 = f1_score(Y_test, p, labels=[1], average='macro')\n",
    "print(\"F1 score for class 1: {:.2f}%\".format(f1_class1 * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2f7d70cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a3620fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9398567119155354"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d38f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f75542c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "199466a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train_df[19]\n",
    "y = train_df[3]\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "im1 = np.arange(100).reshape((10, 10))\n",
    "im2 = im1.T\n",
    "im3 = np.flipud(im1)\n",
    "im4 = np.fliplr(im2)\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, [x[0], x[1], x[2], x[3],y[0], y[1], y[2], y[3]]):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3eb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257102bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "027188ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, ZeroPadding3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ea8a42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 6, 28, 28, 64)     5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 6, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 6, 14, 14, 128)    221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 3, 7, 7, 256)      884992    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 1, 3, 3, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 1, 3, 3, 512)      3539456   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 9,372,674\n",
      "Trainable params: 9,372,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(64, (3, 3, 3), activation=\"relu\",name=\"conv1\",   input_shape=(6,28,28,3), strides=(1, 1, 1), padding=\"same\"))  \n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\"))\n",
    "model.add(Conv3D(128, (3, 3, 3), activation=\"relu\",name=\"conv2\", strides=(1, 1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\"))\n",
    "model.add(Conv3D(256, (3, 3, 3), activation=\"relu\",name=\"conv3a\", strides=(1, 1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\"))\n",
    "model.add(Conv3D(512, (3, 3, 3), activation=\"relu\",name=\"conv4a\", strides=(1, 1, 1), padding=\"same\"))   \n",
    "\n",
    "model.add(Flatten())\n",
    "                     \n",
    "    # FC layers group\n",
    "model.add(Dense(1024, activation='relu', name='fc6'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(2, activation='softmax', name='fc8'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62d1b41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 357s 5s/step - loss: 0.3074 - accuracy: 0.8591 - val_loss: 0.1795 - val_accuracy: 0.9184\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 356s 5s/step - loss: 0.2036 - accuracy: 0.9224 - val_loss: 0.0635 - val_accuracy: 0.9723\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 338s 4s/step - loss: 0.1969 - accuracy: 0.9216 - val_loss: 0.0981 - val_accuracy: 0.9625\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 360s 5s/step - loss: 0.1657 - accuracy: 0.9306 - val_loss: 0.0700 - val_accuracy: 0.9674\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 358s 5s/step - loss: 0.1690 - accuracy: 0.9310 - val_loss: 0.0765 - val_accuracy: 0.9723\n",
      "Epoch 6/100\n",
      "65/77 [========================>.....] - ETA: 56s - loss: 0.1179 - accuracy: 0.9495 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19660/1501325532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac55aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test\n",
    "pred = model.predict(test_df)\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5845ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "b = 1 - ( (a[1][0]/a[1][1] + a[0][1]/a[0][0])/2  )\n",
    "r = 1 - (  a[1][1]  / (a[1][1] + a[0][1])  )\n",
    "print(f,b,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3fe9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c73fd8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_29 (TimeDis (None, 6, 26, 26, 2)      56        \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 6, 13, 13, 2)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 6, 11, 11, 4)      76        \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 6, 5, 5, 4)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 6, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 3488      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 3,638\n",
      "Trainable params: 3,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 9s 63ms/step - loss: 0.5996 - accuracy: 0.7999 - val_loss: 0.1954 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 4s 50ms/step - loss: 0.3871 - accuracy: 0.8109 - val_loss: 0.0698 - val_accuracy: 0.9951\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 5s 65ms/step - loss: 0.2653 - accuracy: 0.8775 - val_loss: 0.1443 - val_accuracy: 0.9119\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.2197 - accuracy: 0.9036 - val_loss: 0.1015 - val_accuracy: 0.9396\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.2255 - accuracy: 0.9036 - val_loss: 0.0931 - val_accuracy: 0.9494\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.1977 - accuracy: 0.9216 - val_loss: 0.1024 - val_accuracy: 0.9413\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.1912 - accuracy: 0.9192 - val_loss: 0.1007 - val_accuracy: 0.9413\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.1736 - accuracy: 0.9249 - val_loss: 0.0728 - val_accuracy: 0.9625\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.1723 - accuracy: 0.9285 - val_loss: 0.0595 - val_accuracy: 0.9723\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.1685 - accuracy: 0.9281 - val_loss: 0.0819 - val_accuracy: 0.9560\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.1617 - accuracy: 0.9334 - val_loss: 0.0673 - val_accuracy: 0.9690\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.1567 - accuracy: 0.9367 - val_loss: 0.0865 - val_accuracy: 0.9560\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.1526 - accuracy: 0.9330 - val_loss: 0.1450 - val_accuracy: 0.9217\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1517 - accuracy: 0.9355 - val_loss: 0.0741 - val_accuracy: 0.9608\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1458 - accuracy: 0.9371 - val_loss: 0.0587 - val_accuracy: 0.9723\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1495 - accuracy: 0.9388 - val_loss: 0.1112 - val_accuracy: 0.9462\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1493 - accuracy: 0.9351 - val_loss: 0.0823 - val_accuracy: 0.9608\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1511 - accuracy: 0.9404 - val_loss: 0.0887 - val_accuracy: 0.9592\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1392 - accuracy: 0.9432 - val_loss: 0.0730 - val_accuracy: 0.9608\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1403 - accuracy: 0.9424 - val_loss: 0.0548 - val_accuracy: 0.9706\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1383 - accuracy: 0.9416 - val_loss: 0.0401 - val_accuracy: 0.9821\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1377 - accuracy: 0.9383 - val_loss: 0.0796 - val_accuracy: 0.9625\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1334 - accuracy: 0.9449 - val_loss: 0.0729 - val_accuracy: 0.9625\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1263 - accuracy: 0.9514 - val_loss: 0.0650 - val_accuracy: 0.9657\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1363 - accuracy: 0.9424 - val_loss: 0.0694 - val_accuracy: 0.9674\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1304 - accuracy: 0.9453 - val_loss: 0.0843 - val_accuracy: 0.9625\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1290 - accuracy: 0.9449 - val_loss: 0.0952 - val_accuracy: 0.9625\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1299 - accuracy: 0.9465 - val_loss: 0.0770 - val_accuracy: 0.9657\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1281 - accuracy: 0.9477 - val_loss: 0.0804 - val_accuracy: 0.9674\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1228 - accuracy: 0.9547 - val_loss: 0.0688 - val_accuracy: 0.9690\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1204 - accuracy: 0.9526 - val_loss: 0.0862 - val_accuracy: 0.9641\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1332 - accuracy: 0.9449 - val_loss: 0.0644 - val_accuracy: 0.9690\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1205 - accuracy: 0.9457 - val_loss: 0.0761 - val_accuracy: 0.9674\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1197 - accuracy: 0.9473 - val_loss: 0.0930 - val_accuracy: 0.9641\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1345 - accuracy: 0.9388 - val_loss: 0.0513 - val_accuracy: 0.9772\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1221 - accuracy: 0.9469 - val_loss: 0.0652 - val_accuracy: 0.9690\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1235 - accuracy: 0.9473 - val_loss: 0.0506 - val_accuracy: 0.9755\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1137 - accuracy: 0.9518 - val_loss: 0.0591 - val_accuracy: 0.9706\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1185 - accuracy: 0.9494 - val_loss: 0.1011 - val_accuracy: 0.9625\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1152 - accuracy: 0.9526 - val_loss: 0.0479 - val_accuracy: 0.9772\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1166 - accuracy: 0.9522 - val_loss: 0.0808 - val_accuracy: 0.9674\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1106 - accuracy: 0.9530 - val_loss: 0.0765 - val_accuracy: 0.9657\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1124 - accuracy: 0.9555 - val_loss: 0.0914 - val_accuracy: 0.9641\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1097 - accuracy: 0.9526 - val_loss: 0.1018 - val_accuracy: 0.9625\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1180 - accuracy: 0.9477 - val_loss: 0.0502 - val_accuracy: 0.9755\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1083 - accuracy: 0.9514 - val_loss: 0.0792 - val_accuracy: 0.9657\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1104 - accuracy: 0.9522 - val_loss: 0.0804 - val_accuracy: 0.9657\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1078 - accuracy: 0.9530 - val_loss: 0.0793 - val_accuracy: 0.9674\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1058 - accuracy: 0.9543 - val_loss: 0.0647 - val_accuracy: 0.9706\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1088 - accuracy: 0.9506 - val_loss: 0.0543 - val_accuracy: 0.9723\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1102 - accuracy: 0.9526 - val_loss: 0.0945 - val_accuracy: 0.9641\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1052 - accuracy: 0.9604 - val_loss: 0.0945 - val_accuracy: 0.9641\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1075 - accuracy: 0.9530 - val_loss: 0.0544 - val_accuracy: 0.9723\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1023 - accuracy: 0.9588 - val_loss: 0.0930 - val_accuracy: 0.9657\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1092 - accuracy: 0.9584 - val_loss: 0.1430 - val_accuracy: 0.9429\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1212 - accuracy: 0.9469 - val_loss: 0.0491 - val_accuracy: 0.9788\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0981 - accuracy: 0.9559 - val_loss: 0.0854 - val_accuracy: 0.9657\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1032 - accuracy: 0.9518 - val_loss: 0.1032 - val_accuracy: 0.9576\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1055 - accuracy: 0.9547 - val_loss: 0.1238 - val_accuracy: 0.9560\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1008 - accuracy: 0.9596 - val_loss: 0.0652 - val_accuracy: 0.9706\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1004 - accuracy: 0.9575 - val_loss: 0.0691 - val_accuracy: 0.9674\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.1131 - accuracy: 0.9539 - val_loss: 0.0863 - val_accuracy: 0.9657\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0976 - accuracy: 0.9608 - val_loss: 0.1033 - val_accuracy: 0.9641\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0956 - accuracy: 0.9600 - val_loss: 0.1076 - val_accuracy: 0.9641\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0962 - accuracy: 0.9592 - val_loss: 0.0723 - val_accuracy: 0.9674\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.0956 - accuracy: 0.9559 - val_loss: 0.1495 - val_accuracy: 0.9494\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1030 - accuracy: 0.9551 - val_loss: 0.1109 - val_accuracy: 0.9641\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 2s 31ms/step - loss: 0.0991 - accuracy: 0.9559 - val_loss: 0.1028 - val_accuracy: 0.9625\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1012 - accuracy: 0.9588 - val_loss: 0.0904 - val_accuracy: 0.9657\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1014 - accuracy: 0.9551 - val_loss: 0.1130 - val_accuracy: 0.9576\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1081 - accuracy: 0.9539 - val_loss: 0.1036 - val_accuracy: 0.9641\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0987 - accuracy: 0.9579 - val_loss: 0.0856 - val_accuracy: 0.9641\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.1006 - accuracy: 0.9600 - val_loss: 0.1028 - val_accuracy: 0.9576\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0906 - accuracy: 0.9616 - val_loss: 0.0891 - val_accuracy: 0.9641\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0969 - accuracy: 0.9547 - val_loss: 0.0551 - val_accuracy: 0.9804\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0920 - accuracy: 0.9592 - val_loss: 0.1260 - val_accuracy: 0.9543\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0985 - accuracy: 0.9563 - val_loss: 0.0661 - val_accuracy: 0.9690\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0886 - accuracy: 0.9608 - val_loss: 0.0898 - val_accuracy: 0.9674\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0961 - accuracy: 0.9592 - val_loss: 0.1046 - val_accuracy: 0.9625\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0889 - accuracy: 0.9612 - val_loss: 0.1196 - val_accuracy: 0.9641\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0872 - accuracy: 0.9624 - val_loss: 0.0987 - val_accuracy: 0.9608\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0914 - accuracy: 0.9608 - val_loss: 0.0799 - val_accuracy: 0.9674\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0948 - accuracy: 0.9596 - val_loss: 0.1392 - val_accuracy: 0.9429\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0855 - accuracy: 0.9637 - val_loss: 0.0783 - val_accuracy: 0.9674\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 2s 32ms/step - loss: 0.0971 - accuracy: 0.9575 - val_loss: 0.1097 - val_accuracy: 0.9592\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0962 - accuracy: 0.9563 - val_loss: 0.0723 - val_accuracy: 0.9690\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0826 - accuracy: 0.9641 - val_loss: 0.0919 - val_accuracy: 0.9674\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0796 - accuracy: 0.9645 - val_loss: 0.0800 - val_accuracy: 0.9690\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0905 - accuracy: 0.9616 - val_loss: 0.0891 - val_accuracy: 0.9674\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0873 - accuracy: 0.9608 - val_loss: 0.1020 - val_accuracy: 0.9625\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0776 - accuracy: 0.9690 - val_loss: 0.0982 - val_accuracy: 0.9690\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0839 - accuracy: 0.9641 - val_loss: 0.0813 - val_accuracy: 0.9674\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0857 - accuracy: 0.9633 - val_loss: 0.1204 - val_accuracy: 0.9608\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0855 - accuracy: 0.9665 - val_loss: 0.0947 - val_accuracy: 0.9657\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0865 - accuracy: 0.9641 - val_loss: 0.1054 - val_accuracy: 0.9657\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 2s 31ms/step - loss: 0.0940 - accuracy: 0.9612 - val_loss: 0.0821 - val_accuracy: 0.9690\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0846 - accuracy: 0.9641 - val_loss: 0.1317 - val_accuracy: 0.9527\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0773 - accuracy: 0.9682 - val_loss: 0.1421 - val_accuracy: 0.9576\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0958 - accuracy: 0.9584 - val_loss: 0.1490 - val_accuracy: 0.9445\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0880 - accuracy: 0.9653 - val_loss: 0.0884 - val_accuracy: 0.9674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263d82cdd30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "model= models.Sequential()\n",
    "model.add(TimeDistributed(Conv2D(2, (3, 3), strides=(1,1),activation='relu'),input_shape=(6, 28, 28, 3)))\n",
    "model.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "model.add(TimeDistributed(Conv2D(4, (3, 3), strides=(1,1),activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(8,return_sequences=False,dropout=0.2)) # used 32 units\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f23f6883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9253731343283582 0.9528218434864658 0.9253731343283582\n"
     ]
    }
   ],
   "source": [
    "Y_test = Y_test\n",
    "pred = model.predict(test_df)\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T\n",
    "f = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "b = 1 - ( (a[1][0]/a[1][1] + a[0][1]/a[0][0])/2  )\n",
    "r =  (  a[1][1]  / (a[1][1] + a[0][1])  )\n",
    "print(f,b,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c412a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5b058ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e43530db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2643d22cdf0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99db6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "742d452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 6, 28, 28, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder_5 (PatchEncoder)  (None, 6, 32)        11096       input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_85 (LayerNo (None, 6, 32)        64          patch_encoder_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_36 (MultiH (None, 6, 32)        8416        layer_normalization_85[0][0]     \n",
      "                                                                 layer_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                  (None, 6, 32)        8320        layer_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 6, 32)        0           multi_head_attention_36[0][0]    \n",
      "                                                                 patch_encoder_5[0][0]            \n",
      "                                                                 lstm_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_86 (LayerNo (None, 6, 32)        64          add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_52 (Sequential)      (None, 6, 32)        1056        layer_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 6, 32)        0           sequential_52[0][0]              \n",
      "                                                                 add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_87 (LayerNo (None, 6, 32)        64          add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_37 (MultiH (None, 6, 32)        8416        layer_normalization_87[0][0]     \n",
      "                                                                 layer_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                  (None, 6, 32)        8320        layer_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 6, 32)        0           multi_head_attention_37[0][0]    \n",
      "                                                                 add_81[0][0]                     \n",
      "                                                                 lstm_33[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_88 (LayerNo (None, 6, 32)        64          add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_53 (Sequential)      (None, 6, 32)        1056        layer_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 6, 32)        0           sequential_53[0][0]              \n",
      "                                                                 add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_89 (LayerNo (None, 6, 32)        64          add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 32)           0           layer_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 2)            66          global_average_pooling1d_5[0][0] \n",
      "==================================================================================================\n",
      "Total params: 47,066\n",
      "Trainable params: 47,066\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "77/77 [==============================] - 45s 182ms/step - loss: 0.3119 - accuracy: 0.8730 - val_loss: 0.1708 - val_accuracy: 0.9331\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 9s 119ms/step - loss: 0.1945 - accuracy: 0.9253 - val_loss: 0.1656 - val_accuracy: 0.9396\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.1590 - accuracy: 0.9379 - val_loss: 0.1555 - val_accuracy: 0.9380\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 10s 137ms/step - loss: 0.1506 - accuracy: 0.9420 - val_loss: 0.2573 - val_accuracy: 0.9119\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 0.1288 - accuracy: 0.9535 - val_loss: 0.2039 - val_accuracy: 0.9331\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 0.1138 - accuracy: 0.9588 - val_loss: 0.1660 - val_accuracy: 0.9347\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 0.1093 - accuracy: 0.9624 - val_loss: 0.1294 - val_accuracy: 0.9511\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 0.0845 - accuracy: 0.9694 - val_loss: 0.2172 - val_accuracy: 0.9413\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 0.0719 - accuracy: 0.9767 - val_loss: 0.1852 - val_accuracy: 0.9250\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 9s 117ms/step - loss: 0.0763 - accuracy: 0.9690 - val_loss: 0.2777 - val_accuracy: 0.9054\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 9s 118ms/step - loss: 0.0587 - accuracy: 0.9775 - val_loss: 0.3214 - val_accuracy: 0.8923\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 9s 117ms/step - loss: 0.0529 - accuracy: 0.9820 - val_loss: 0.1472 - val_accuracy: 0.9380\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 0.0520 - accuracy: 0.9816 - val_loss: 0.1741 - val_accuracy: 0.9478\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 11s 140ms/step - loss: 0.0469 - accuracy: 0.9829 - val_loss: 0.4499 - val_accuracy: 0.8825\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 11s 140ms/step - loss: 0.0551 - accuracy: 0.9792 - val_loss: 0.2270 - val_accuracy: 0.9380\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 13s 164ms/step - loss: 0.0378 - accuracy: 0.9869 - val_loss: 0.2365 - val_accuracy: 0.9331\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 11s 141ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.3281 - val_accuracy: 0.9070\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 13s 166ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 0.5056 - val_accuracy: 0.8793\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 12s 151ms/step - loss: 0.0563 - accuracy: 0.9804 - val_loss: 0.2307 - val_accuracy: 0.9299\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.2689 - val_accuracy: 0.9250\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 11s 142ms/step - loss: 0.0313 - accuracy: 0.9886 - val_loss: 0.0974 - val_accuracy: 0.9674\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.1747 - val_accuracy: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.1142 - val_accuracy: 0.9625\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 0.0167 - accuracy: 0.9931 - val_loss: 0.4680 - val_accuracy: 0.9021\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 0.0479 - accuracy: 0.9816 - val_loss: 0.1475 - val_accuracy: 0.9608\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 0.0168 - accuracy: 0.9931 - val_loss: 0.2110 - val_accuracy: 0.9511\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 10s 131ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.3497 - val_accuracy: 0.9282\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.3747 - val_accuracy: 0.9233\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.3154 - val_accuracy: 0.9380\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.2614 - val_accuracy: 0.9396\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.3280 - val_accuracy: 0.9331\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.3375 - val_accuracy: 0.9347\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 11s 140ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.4055 - val_accuracy: 0.9299\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 0.0205 - accuracy: 0.9955 - val_loss: 0.1498 - val_accuracy: 0.9576\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0625 - accuracy: 0.9788 - val_loss: 0.3064 - val_accuracy: 0.9266\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 9s 124ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.2326 - val_accuracy: 0.9494\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.3434 - val_accuracy: 0.9364\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.3835 - val_accuracy: 0.9299\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 0.0364 - accuracy: 0.9857 - val_loss: 0.4883 - val_accuracy: 0.8793\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 10s 132ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.2401 - val_accuracy: 0.9445\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9396\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9396\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 10s 136ms/step - loss: 8.8423e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9380\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.3936 - val_accuracy: 0.9299\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9478\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.1240 - accuracy: 0.9608 - val_loss: 0.1293 - val_accuracy: 0.9592\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0338 - accuracy: 0.9894 - val_loss: 0.2322 - val_accuracy: 0.9429\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 9s 118ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.1845 - val_accuracy: 0.9641\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0163 - accuracy: 0.9935 - val_loss: 0.2686 - val_accuracy: 0.9445\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.2194 - val_accuracy: 0.9543\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9396\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 6.6788e-04 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9429\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.2790 - val_accuracy: 0.9494\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2257 - val_accuracy: 0.9576\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 0.0542 - accuracy: 0.9812 - val_loss: 0.1926 - val_accuracy: 0.9543\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0236 - accuracy: 0.9890 - val_loss: 0.2859 - val_accuracy: 0.9413\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 10s 131ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.2832 - val_accuracy: 0.9494\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 11s 148ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.3047 - val_accuracy: 0.9413\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9511\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 6.1541e-04 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9527\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 10s 136ms/step - loss: 6.8710e-04 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9478\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 10s 134ms/step - loss: 4.9433e-04 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9462\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 2.6167e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9445\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 2.9263e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9478\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 1.7604e-04 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9462\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 2.8471e-04 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9478\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 9s 118ms/step - loss: 1.3727e-04 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9445\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.4250 - val_accuracy: 0.9331\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 6.2091e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9494\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 0.0477 - accuracy: 0.9873 - val_loss: 0.2780 - val_accuracy: 0.9527\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 10s 134ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.2241 - val_accuracy: 0.9478\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.3305 - val_accuracy: 0.9364\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.3235 - val_accuracy: 0.9478\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9478\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 9.5974e-04 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9380\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 10s 133ms/step - loss: 2.8283e-04 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9494\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 2.5996e-04 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9445\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 1.1576e-04 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9429\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 1.1305e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9445\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 9.8853e-05 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9462\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 1.3591e-04 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9511\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 1.6559e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9543\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0719 - accuracy: 0.9743 - val_loss: 0.2865 - val_accuracy: 0.9315\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0272 - accuracy: 0.9886 - val_loss: 0.5347 - val_accuracy: 0.8842\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 0.2224 - val_accuracy: 0.9462\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.2061 - val_accuracy: 0.9527\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2713 - val_accuracy: 0.9478\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 9.6324e-04 - accuracy: 0.9996 - val_loss: 0.3461 - val_accuracy: 0.9429\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 10s 134ms/step - loss: 4.2564e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9445\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 5.9142e-04 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9462\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 3.6335e-04 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9462\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 9s 124ms/step - loss: 1.9334e-04 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9478\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 1.6028e-04 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.9429\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 1.2040e-04 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9462\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 1.7867e-04 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9494\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 1.2447e-04 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9478\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 7.7745e-05 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9445\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 9.9591e-05 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9445\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 8.3640e-05 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9445\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 7.6141e-05 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2643d486f40>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "inputs = layers.Input(shape= (6,28,28,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(6, 32 )) (inputs)\n",
    "\n",
    "for _ in range(2):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=2, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=2, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2545595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x2643d2d6f10>,\n",
       " <__main__.PatchEncoder at 0x2643d2d67f0>,\n",
       " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x2643d2d6a60>,\n",
       " <keras.layers.multi_head_attention.MultiHeadAttention at 0x2644020d220>,\n",
       " <keras.layers.recurrent_v2.LSTM at 0x2640c307fd0>,\n",
       " <keras.layers.merge.Add at 0x2643d33f850>,\n",
       " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x2640b258eb0>,\n",
       " <keras.engine.sequential.Sequential at 0x2643d28c8b0>,\n",
       " <keras.layers.merge.Add at 0x2644020e730>,\n",
       " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x2643d27bd00>,\n",
       " <keras.layers.multi_head_attention.MultiHeadAttention at 0x2643d3004f0>,\n",
       " <keras.layers.recurrent_v2.LSTM at 0x2643d28c820>,\n",
       " <keras.layers.merge.Add at 0x2643d3b9970>,\n",
       " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x2643d362dc0>,\n",
       " <keras.engine.sequential.Sequential at 0x2643d40a670>,\n",
       " <keras.layers.merge.Add at 0x2643d27b730>,\n",
       " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x2643d3002e0>,\n",
       " <keras.layers.pooling.GlobalAveragePooling1D at 0x2643d3d6a30>,\n",
       " <keras.layers.core.Dense at 0x2643d42e9d0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5724c4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 169 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000264554A5310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "attn = Model(inputs=model.input, outputs = model.layers[10].output)\n",
    "\n",
    "pred = attn.predict(test_df[:2], steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41a95b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.4132207 , -1.2195096 ,  0.8252611 ,  0.2068735 ,\n",
       "         -1.9345852 , -0.3024784 ,  0.68288636,  0.24726246,\n",
       "          1.4878579 , -0.38394576,  1.9602623 , -1.2115494 ,\n",
       "          0.7494351 , -1.2607741 ,  1.5064203 ,  0.4506906 ,\n",
       "         -0.10477968,  0.67580473,  0.11815078,  0.5772801 ,\n",
       "         -0.5792286 , -2.167793  ,  0.25299546,  0.17493363,\n",
       "         -1.3997712 ,  0.21966185, -0.42484006,  0.366758  ,\n",
       "         -0.8750425 , -0.6389731 , -1.5038117 ,  0.5427528 ],\n",
       "        [-0.49964952, -1.3981657 ,  0.9291378 ,  0.33286896,\n",
       "         -2.1367726 , -0.33195415,  0.7276804 ,  0.17592141,\n",
       "          1.6696632 , -0.3734444 ,  2.1794388 , -1.3467876 ,\n",
       "          0.8988415 , -1.5041916 ,  1.6590377 ,  0.6519078 ,\n",
       "         -0.22443868,  0.88728726,  0.08924537,  0.5581587 ,\n",
       "         -0.6181777 , -2.513119  ,  0.44085464,  0.16715612,\n",
       "         -1.6275524 ,  0.24514648, -0.36834878,  0.35315546,\n",
       "         -1.0476707 , -0.6746873 , -1.7237133 ,  0.67369545],\n",
       "        [-0.5054516 , -1.4051408 ,  0.931937  ,  0.33905593,\n",
       "         -2.1503923 , -0.32643858,  0.72040987,  0.16062592,\n",
       "          1.6761467 , -0.37332964,  2.192372  , -1.3548307 ,\n",
       "          0.91177434, -1.5271318 ,  1.674906  ,  0.67372906,\n",
       "         -0.23302507,  0.90983194,  0.08345299,  0.550993  ,\n",
       "         -0.6208706 , -2.5409727 ,  0.45941108,  0.17093034,\n",
       "         -1.6397773 ,  0.24939248, -0.35014296,  0.3488802 ,\n",
       "         -1.0668329 , -0.6731022 , -1.7361139 ,  0.685371  ],\n",
       "        [-0.45331264, -1.306415  ,  0.8866546 ,  0.25975394,\n",
       "         -2.0246832 , -0.34005788,  0.7407966 ,  0.26629165,\n",
       "          1.5913628 , -0.38598648,  2.0556822 , -1.2800528 ,\n",
       "          0.79983205, -1.3376297 ,  1.550189  ,  0.49013677,\n",
       "         -0.15583493,  0.7203113 ,  0.11949462,  0.58744025,\n",
       "         -0.58959144, -2.295015  ,  0.2989272 ,  0.1614392 ,\n",
       "         -1.4926645 ,  0.22279164, -0.45505288,  0.36787757,\n",
       "         -0.9085372 , -0.6712196 , -1.6083722 ,  0.58423537],\n",
       "        [-0.46676803, -1.3375354 ,  0.89921296,  0.2818547 ,\n",
       "         -2.0564473 , -0.3375323 ,  0.72806275,  0.22456515,\n",
       "          1.6079518 , -0.3822405 ,  2.0922425 , -1.2935742 ,\n",
       "          0.83231705, -1.3891375 ,  1.5930897 ,  0.543874  ,\n",
       "         -0.16311598,  0.7822279 ,  0.11047427,  0.5792245 ,\n",
       "         -0.6069935 , -2.3648562 ,  0.34867156,  0.16283749,\n",
       "         -1.5390068 ,  0.23143686, -0.41973758,  0.36701533,\n",
       "         -0.9627736 , -0.66932124, -1.6384935 ,  0.61658263],\n",
       "        [-0.47220904, -1.3485214 ,  0.9062314 ,  0.28910938,\n",
       "         -2.0689666 , -0.34121707,  0.73520386,  0.22686623,\n",
       "          1.6213392 , -0.38222903,  2.104739  , -1.3030748 ,\n",
       "          0.8397041 , -1.4010637 ,  1.5984538 ,  0.551494  ,\n",
       "         -0.17236249,  0.7889492 ,  0.10953354,  0.57948005,\n",
       "         -0.60737693, -2.3821776 ,  0.35537735,  0.16158032,\n",
       "         -1.5513701 ,  0.2319126 , -0.42227972,  0.36642838,\n",
       "         -0.967269  , -0.67334425, -1.6527948 ,  0.6217404 ]],\n",
       "\n",
       "       [[-0.42649883, -1.07714   ,  1.1484387 ,  0.08490907,\n",
       "         -1.6851516 , -0.46723652,  0.5061661 , -0.5605585 ,\n",
       "          1.0461252 , -0.49998504,  1.0360165 , -0.6946146 ,\n",
       "          0.97356695, -1.060988  ,  1.7463284 ,  0.32441568,\n",
       "          0.33397505,  1.1660689 ,  0.3562874 ,  0.45945892,\n",
       "         -0.47635746, -1.5587056 ,  0.7094144 , -0.17435731,\n",
       "         -1.5678124 ,  0.21163751,  0.17598131,  0.34968036,\n",
       "         -1.2812881 , -0.66485435, -1.0910249 ,  0.6593576 ],\n",
       "        [-0.42786318, -1.0868777 ,  1.1333342 ,  0.09772161,\n",
       "         -1.6886925 , -0.47518152,  0.5093493 , -0.56699693,\n",
       "          1.0518668 , -0.47610977,  1.0434015 , -0.7050921 ,\n",
       "          0.9808329 , -1.0820138 ,  1.7231802 ,  0.33740744,\n",
       "          0.35213426,  1.1791012 ,  0.36592385,  0.45341754,\n",
       "         -0.47471106, -1.5531352 ,  0.7377216 , -0.1596379 ,\n",
       "         -1.5623512 ,  0.20603526,  0.16128173,  0.33179644,\n",
       "         -1.2726437 , -0.669748  , -1.0993601 ,  0.6809811 ],\n",
       "        [-0.46682185, -1.154356  ,  1.1586797 ,  0.13679314,\n",
       "         -1.6567787 , -0.49478176,  0.52970284, -0.6290013 ,\n",
       "          1.0179622 , -0.5025515 ,  0.99508554, -0.7152843 ,\n",
       "          0.97520405, -1.1048411 ,  1.7275623 ,  0.32937735,\n",
       "          0.36986497,  1.1806638 ,  0.43615305,  0.43307212,\n",
       "         -0.48267272, -1.4823427 ,  0.75971186, -0.19307967,\n",
       "         -1.5393314 ,  0.22102971,  0.18088883,  0.34285673,\n",
       "         -1.2822428 , -0.71883744, -1.0900193 ,  0.6960212 ],\n",
       "        [-0.4363001 , -1.0829927 ,  1.1493462 ,  0.0923662 ,\n",
       "         -1.6651357 , -0.48290762,  0.5026756 , -0.5942865 ,\n",
       "          1.0257357 , -0.49765265,  0.9899746 , -0.69200104,\n",
       "          0.9832234 , -1.0667776 ,  1.7409017 ,  0.3290018 ,\n",
       "          0.35922012,  1.1847463 ,  0.38116938,  0.435992  ,\n",
       "         -0.4662827 , -1.517116  ,  0.7349468 , -0.183203  ,\n",
       "         -1.5593985 ,  0.21721348,  0.19318488,  0.33741537,\n",
       "         -1.2820184 , -0.67617387, -1.0793917 ,  0.6741583 ],\n",
       "        [-0.49830765, -1.1531427 ,  1.2187309 ,  0.10719223,\n",
       "         -1.587356  , -0.54115945,  0.49432966, -0.7039962 ,\n",
       "          0.9452714 , -0.57704806,  0.8339936 , -0.6744776 ,\n",
       "          0.9837212 , -1.0368228 ,  1.7723382 ,  0.28157845,\n",
       "          0.40617546,  1.2058271 ,  0.47497472,  0.3932675 ,\n",
       "         -0.44723678, -1.3788327 ,  0.7450216 , -0.2586214 ,\n",
       "         -1.5238549 ,  0.25344393,  0.27242252,  0.34878147,\n",
       "         -1.2884816 , -0.73330414, -1.0293506 ,  0.6805313 ],\n",
       "        [-0.4841547 , -1.1146897 ,  1.2149087 ,  0.08220633,\n",
       "         -1.5884408 , -0.53472805,  0.4779762 , -0.6898922 ,\n",
       "          0.942987  , -0.5763631 ,  0.8229502 , -0.6605422 ,\n",
       "          0.9893767 , -1.0167508 ,  1.7826542 ,  0.28118014,\n",
       "          0.4056453 ,  1.2089812 ,  0.44735393,  0.39052385,\n",
       "         -0.43789554, -1.3930148 ,  0.73019046, -0.25510353,\n",
       "         -1.5354162 ,  0.25418186,  0.28484488,  0.3454959 ,\n",
       "         -1.2892004 , -0.71183616, -1.0225661 ,  0.6692119 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0c239b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15860/4260804453.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mattention_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "attention_layer = model.layers[:3]\n",
    "y = attention_layer.predict(test_df, test_df, return_attention_scores=True)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e844434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51cf7614",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected input 0 to have rank 3 but got: 2 [Op:Einsum]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15860/4266437127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mattention_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_attention_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# take one sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridspec_kw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth_ratios\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\multi_head_attention.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, query, value, key, attention_mask, return_attention_scores, training)\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;31m#   H = `size_per_head`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;31m# `query` = [B, T, N ,H]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[1;31m# `key` = [B, S, N, H]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\einsum_dense.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m       \u001b[0mret\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7184\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7186\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected input 0 to have rank 3 but got: 2 [Op:Einsum]"
     ]
    }
   ],
   "source": [
    "attention_layer = model.layers[10]\n",
    "_, attention_scores = attention_layer(Y_test[:1], test_df[:1], return_attention_scores=True) # take one sample\n",
    "fig, axs = plt.subplots(ncols=3, gridspec_kw=dict(width_ratios=[5,5,0.2]))\n",
    "sb.heatmap(attention_scores[0, 0, :, :], annot=True, cbar=False, ax=axs[0])\n",
    "sb.heatmap(attention_scores[0, 1, :, :], annot=True, yticklabels=False, cbar=False, ax=axs[1])\n",
    "fig.colorbar(axs[1].collections[0], cax=axs[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5f3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b30013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf04e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7ac18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "196759ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMultiHeadAttention(MultiHeadAttention):\n",
    "    def _compute_attention(self, query, key, value, attention_mask=None, training=None):\n",
    "        q = self.query_dense(query)\n",
    "        k = self.key_dense(key)\n",
    "        v = self.value_dense(value)\n",
    "\n",
    "        q = self.separate_heads(q, from_shape=query.shape)\n",
    "        k = self.separate_heads(k, from_shape=key.shape)\n",
    "        v = self.separate_heads(v, from_shape=value.shape)\n",
    "\n",
    "        attention_output, attention_weights = self._scaled_dot_product_attention(q, k, v, attention_mask, training)\n",
    "        attention_output = self.combine_heads(attention_output)\n",
    "        attention_output = self.out_proj(attention_output)\n",
    "\n",
    "        return attention_output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84a5bfae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"custom_multi_head_attention_3\" (type CustomMultiHeadAttention).\n\n'CustomMultiHeadAttention' object has no attribute 'query_dense'\n\nCall arguments received:\n   query=tf.Tensor(shape=(None, 5, 32), dtype=float32)\n   value=tf.Tensor(shape=(None, 5, 32), dtype=float32)\n   key=None\n   attention_mask=None\n   return_attention_scores=False\n   training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12180\\3893264276.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_patches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mattention_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomMultiHeadAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mlstm_output\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12180\\709392748.py\u001b[0m in \u001b[0;36m_compute_attention\u001b[1;34m(self, query, key, value, attention_mask, training)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mCustomMultiHeadAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMultiHeadAttention\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_compute_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling layer \"custom_multi_head_attention_3\" (type CustomMultiHeadAttention).\n\n'CustomMultiHeadAttention' object has no attribute 'query_dense'\n\nCall arguments received:\n   query=tf.Tensor(shape=(None, 5, 32), dtype=float32)\n   value=tf.Tensor(shape=(None, 5, 32), dtype=float32)\n   key=None\n   attention_mask=None\n   return_attention_scores=False\n   training=None"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (5,28,28,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(5, 32 )) (inputs)\n",
    "\n",
    "attention_outputs = []\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output, attention_weights = CustomMultiHeadAttention(num_heads=6, key_dim=32)(x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "    \n",
    "    attention_outputs.append(attention_weights)\n",
    "\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=3, activation=\"softmax\") ( representation)\n",
    "\n",
    "model =  keras.Model(inputs=inputs, outputs=[outputs, attention_outputs])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "history = model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250da400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
