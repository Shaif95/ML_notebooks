{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300d0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ab6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this according to your directory structure \n",
    "\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "\n",
    "trn1='D:/data/invasive-aquatic-species-data/noninvasive/*/'\n",
    "trn2='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Ostracod Image1/*/'\n",
    "trn3='D:/data/invasive-aquatic-species-data/invasive/*/'\n",
    "\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)\n",
    "tr3= glob(trn3)\n",
    "\n",
    "trn11='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Not Veligers/*/'\n",
    "trn33='D:/data/Veligers/To Baylor 2023-01-30/To Baylor 2023-01-30/Zebra Pediveliger Image1a/*/'\n",
    "tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "trn111='D:/data/Ostracod/Ostracods Day 2 Image1 To Baylor/Ostracods Day 2 Image1 To Baylor/Sorted Images/Not/*/'\n",
    "\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "trn11='D:/data/Ostracod/Preserved Ostracods 1 To Baylor/Preserved Ostracods 1 To Baylor/Sorted Images/Not/*/'\n",
    "trn33='D:/data/Veligers/Preserved Zebra Ped 1 To Baylor/Preserved Zebra Ped 1 To Baylor/Sorted Images/Pedi-Zebra Veligers/*/'\n",
    "tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "trn111='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/NonVeligers/Images_001/*/'\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "trn11='D:/data/Veligers/Preserved Zebra Ped 1a To Baylor/Preserved Zebra Ped 1a To Baylor/Sorted Images/Not/*/'\n",
    "trn33='D:/data/Veligers/Preserved Zebra Ped 1a To Baylor/Preserved Zebra Ped 1a To Baylor/Sorted Images/Preserved Zebra Ped 1a/*/'\n",
    "tr11= glob(trn11)\n",
    "tr33= glob(trn33)\n",
    "tr1.extend(tr11)\n",
    "tr3.extend(tr33)\n",
    "\n",
    "\n",
    "trn111='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/NonVeligers/Images_001/*/'\n",
    "trn333='D:/data/Veligers/Baylor 2022-03-21/Baylor 2022-03-21/Davis Dam 2019-07-24/Manually Reviewed/Veligers/Images_001/*/'\n",
    "tr111= glob(trn111)\n",
    "tr333= glob(trn333)\n",
    "tr1.extend(tr111)\n",
    "tr3.extend(tr333)\n",
    "\n",
    "trnl1='D:/data/Ostracod/Ostracod Day 2 Image12 Short To Baylor/Ostracod Day 2 Image12 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl2='D:/data/Ostracod/Ostracods Day 2 Image1 To Baylor/Ostracods Day 2 Image1 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl3='D:/data/Ostracod/Ostracods Day 2 Image2 To Baylor/Ostracods Day 2 Image2 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl4='D:/data/Ostracod/Ostracods Day 2 Image3 To Baylor/Ostracods Day 2 Image3 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl5='D:/data/Ostracod/Ostracods Day 2 Image12 To Baylor/Ostracods Day 2 Image12 To Baylor/Sorted Images/Ostracods/*/'\n",
    "trnl6='D:/data/Ostracod/Preserved Ostracods 1 To Baylor/Preserved Ostracods 1 To Baylor/Sorted Images/Preserve Ostracods/*/'\n",
    "trnl7='D:/data/Ostracod/Preserved Ostracods 1a To Baylor/Preserved Ostracods 1a To Baylor/Sorted Images/Preserved Ostracods 1a/*/'\n",
    "\n",
    "trl1= glob(trnl1)\n",
    "trl2= glob(trnl2)\n",
    "trl3= glob(trnl3)\n",
    "trl4= glob(trnl4)\n",
    "trl5= glob(trnl5)\n",
    "trl6= glob(trnl6)\n",
    "trl7= glob(trnl7)\n",
    "\n",
    "\n",
    "tr2.extend(trl1)\n",
    "tr2.extend(trl2)\n",
    "tr2.extend(trl3)\n",
    "tr2.extend(trl4)\n",
    "tr2.extend(trl5)\n",
    "tr2.extend(trl6)\n",
    "tr2.extend(trl7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b20c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07258443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4404.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "tr1= shuffle(tr1)\n",
    "tr2= shuffle(tr2)\n",
    "tr3= shuffle(tr3)\n",
    "\n",
    "tran_index_noninv = np.round( len(tr1)* .9  )   #Make all of these .6\n",
    "tran_index_osc = np.round( len(tr2)* .9 )\n",
    "tran_index_inv = np.round( len(tr3)* .9  )\n",
    "tran_index_noninv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d405204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Objects for Non-Invasive, Invasive and Ostracod : 4893 1282 104\n"
     ]
    }
   ],
   "source": [
    "print ( \"Number of Objects for Non-Invasive, Invasive and Ostracod :\" , len(tr1), len(tr3), len(tr2)) #Mention these and the total in paper. \n",
    "#You should have enough data to get near 10,000 total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d4f1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e36c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr3[:(int) (tran_index_inv)]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr1[:(int) (tran_index_noninv)]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[:(int) (tran_index_osc)]:\n",
    "    label.append(2)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr3[:(int) (tran_index_inv)])):\n",
    "    a = glob(tr3[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr1[:(int) (tran_index_noninv)])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])        \n",
    "\n",
    "for j in range(0,len(tr2[:(int) (tran_index_osc)])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k]) \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = tf.image.resize_with_crop_or_pad(tf.keras.preprocessing.image.img_to_array(a), 28, 28)\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(28,28,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),28,28,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04dc0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1884, 5, 28, 28, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "train_df= []\n",
    "breath = 5\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*5+k)\n",
    "        \n",
    "        deff.append(X_train[index])\n",
    "        \n",
    "    train_df.append(deff)\n",
    "\n",
    "Y_train = to_categorical(label)\n",
    "train_df = np.array(train_df)\n",
    "YY_Train = label\n",
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ec4677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9420"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_df) #Amount of training data. Mention this in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr3[(int) (tran_index_inv) + 1 :]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr1[ (int)(tran_index_noninv) + 1:]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in tr2[ (int)(tran_index_osc) + 1:]:\n",
    "    label.append(2)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in range(0,len(tr3[(int) (tran_index_inv) + 1 :])):\n",
    "    a = glob(tr3[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr1[ (int)(tran_index_noninv) + 1:])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])  \n",
    "        \n",
    "for j in range(0,len(tr2[ (int)(tran_index_osc) + 1:])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,5):\n",
    "        data.append(a[k])  \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = tf.image.resize_with_crop_or_pad(tf.keras.preprocessing.image.img_to_array(a), 28, 28)\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(28,28,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),28,28,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a9778",
   "metadata": {},
   "outputs": [],
   "source": [
    "end= 0\n",
    "test_df= []\n",
    "breath = 5\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*5 + k)\n",
    "        \n",
    "        deff.append(X_test[index])\n",
    "        \n",
    "    test_df.append(deff)\n",
    "    \n",
    "Y_test = to_categorical(label)\n",
    "test_df = np.array(test_df)\n",
    "YY_Test = label\n",
    "np.shape(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bf302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"organmnist3d\"\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = ( 5, 28, 28, 3 )\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 60\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (4, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 32\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18439a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df661dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis is the Linear Att-LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "add938fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection =keras.Sequential(\n",
    "            [   TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e71f3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 5, 28, 28,   0           []                               \n",
      "                                3)]                                                               \n",
      "                                                                                                  \n",
      " patch_encoder_2 (PatchEncoder)  (None, 5, 32)       75456       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 5, 32)       64          ['patch_encoder_2[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 5, 32)       25184       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 5, 32)        8320        ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 5, 32)        0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'patch_encoder_2[0][0]',        \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 5, 32)       64          ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 5, 32)        1056        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 5, 32)        0           ['sequential_3[0][0]',           \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 5, 32)       64          ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 5, 32)       25184       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 5, 32)        8320        ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 5, 32)        0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]',                  \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 5, 32)       64          ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)      (None, 5, 32)        1056        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 5, 32)        0           ['sequential_4[0][0]',           \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 5, 32)       64          ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 5, 32)       25184       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 5, 32)        8320        ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 5, 32)        0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]',                  \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 5, 32)       64          ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)      (None, 5, 32)        1056        ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 5, 32)        0           ['sequential_5[0][0]',           \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 5, 32)       64          ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 5, 32)       25184       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 5, 32)        8320        ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 5, 32)        0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]',                  \n",
      "                                                                  'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 5, 32)       64          ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)      (None, 5, 32)        1056        ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 5, 32)        0           ['sequential_6[0][0]',           \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 5, 32)       64          ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 5, 32)       25184       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 5, 32)        8320        ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 5, 32)        0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]',                  \n",
      "                                                                  'lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 5, 32)       64          ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 5, 32)        1056        ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 5, 32)        0           ['sequential_7[0][0]',           \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 5, 32)       64          ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 5, 32)       25184       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 5, 32)        8320        ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 5, 32)        0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]',                  \n",
      "                                                                  'lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 5, 32)       64          ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 5, 32)        1056        ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 5, 32)        0           ['sequential_8[0][0]',           \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 5, 32)       64          ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 32)          0           ['layer_normalization_12[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 3)            99          ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 283,747\n",
      "Trainable params: 283,747\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (5,28,28,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(5, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output= layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(units=3, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use 50-100 epochs of training and mention that and the val_split in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d4d36cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "48/48 [==============================] - 20s 128ms/step - loss: 0.6154 - accuracy: 0.7113 - val_loss: 0.6152 - val_accuracy: 0.9125\n",
      "Epoch 2/2\n",
      "48/48 [==============================] - 4s 82ms/step - loss: 0.5293 - accuracy: 0.7678 - val_loss: 0.6125 - val_accuracy: 0.8966\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "history = model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80336b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test\n",
    "\n",
    "pred = model.predict(test_df)\n",
    "p = np.round(pred)\n",
    "p = np.argmax(p, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, p)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate F1 score for class 1\n",
    "f1_class1 = f1_score(Y_test, p, labels=[1], average='macro')\n",
    "print(\"F1 score for class 1: {:.2f}%\".format(f1_class1 * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc43c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be748a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b4ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
