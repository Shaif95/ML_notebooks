{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3241afb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chowd\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import Input\n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CROP_TO = 32\n",
    "SEED = 26\n",
    "\n",
    "PROJECT_DIM = 128\n",
    "LATENT_DIM = 512\n",
    "WEIGHT_DECAY = 0.0005\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "hidden_units = 512\n",
    "projection_units = 256\n",
    "num_epochs = 2\n",
    "dropout_rate = 0.5\n",
    "\n",
    "temperature = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69548e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def preprocess_data(sample):\n",
    "    image = tf.image.resize(sample[\"image\"], (32, 32))\n",
    "    image = preprocess_input(image)\n",
    "    label = tf.one_hot(sample[\"label\"], depth=102)\n",
    "    return image, label\n",
    "\n",
    "# Load the Caltech 101 dataset\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"caltech101\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=False,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "# Use 30% of the training data\n",
    "train_percentage = 1\n",
    "train_size = int(train_percentage * ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.take(train_size)\n",
    "\n",
    "# Preprocess the data\n",
    "ds_train = ds_train.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch and prefetch the data\n",
    "ds_train = ds_train.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71810293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "96/96 [==============================] - 182s 1s/step - loss: 5.4107 - accuracy: 0.0543 - val_loss: 4.4495 - val_accuracy: 0.1270\n",
      "Epoch 2/150\n",
      "96/96 [==============================] - 119s 1s/step - loss: 2.5498 - accuracy: 0.4142 - val_loss: 3.4373 - val_accuracy: 0.2891\n",
      "Epoch 3/150\n",
      "96/96 [==============================] - 120s 1s/step - loss: 0.8851 - accuracy: 0.8460 - val_loss: 3.1563 - val_accuracy: 0.3459\n",
      "Epoch 4/150\n",
      "96/96 [==============================] - 120s 1s/step - loss: 0.1901 - accuracy: 0.9859 - val_loss: 3.0081 - val_accuracy: 0.3836\n",
      "Epoch 5/150\n",
      "96/96 [==============================] - 126s 1s/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 3.0213 - val_accuracy: 0.3865\n",
      "Epoch 6/150\n",
      "96/96 [==============================] - 126s 1s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 3.0274 - val_accuracy: 0.3921\n",
      "Epoch 7/150\n",
      "96/96 [==============================] - 125s 1s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.0331 - val_accuracy: 0.3919\n",
      "Epoch 8/150\n",
      "96/96 [==============================] - 114s 1s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.0341 - val_accuracy: 0.3934\n",
      "Epoch 9/150\n",
      "96/96 [==============================] - 131s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.0325 - val_accuracy: 0.3952\n",
      "Epoch 10/150\n",
      "96/96 [==============================] - 122s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.0301 - val_accuracy: 0.3967\n",
      "Epoch 11/150\n",
      "96/96 [==============================] - 129s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.0272 - val_accuracy: 0.3990\n",
      "Epoch 12/150\n",
      "96/96 [==============================] - 133s 1s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.0246 - val_accuracy: 0.4000\n",
      "Epoch 13/150\n",
      "96/96 [==============================] - 155s 2s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0220 - val_accuracy: 0.4012\n",
      "Epoch 14/150\n",
      "96/96 [==============================] - 126s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0197 - val_accuracy: 0.4021\n",
      "Epoch 15/150\n",
      "96/96 [==============================] - 116s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0175 - val_accuracy: 0.4033\n",
      "Epoch 16/150\n",
      "96/96 [==============================] - 100s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0155 - val_accuracy: 0.4043\n",
      "Epoch 17/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0136 - val_accuracy: 0.4053\n",
      "Epoch 18/150\n",
      "96/96 [==============================] - 110s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.0119 - val_accuracy: 0.4056\n",
      "Epoch 19/150\n",
      "96/96 [==============================] - 111s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0102 - val_accuracy: 0.4067\n",
      "Epoch 20/150\n",
      "96/96 [==============================] - 105s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0086 - val_accuracy: 0.4069\n",
      "Epoch 21/150\n",
      "96/96 [==============================] - 109s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0072 - val_accuracy: 0.4071\n",
      "Epoch 22/150\n",
      "96/96 [==============================] - 108s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0058 - val_accuracy: 0.4081\n",
      "Epoch 23/150\n",
      "96/96 [==============================] - 118s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0045 - val_accuracy: 0.4090\n",
      "Epoch 24/150\n",
      "96/96 [==============================] - 158s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0033 - val_accuracy: 0.4095\n",
      "Epoch 25/150\n",
      "96/96 [==============================] - 126s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0023 - val_accuracy: 0.4097\n",
      "Epoch 26/150\n",
      "96/96 [==============================] - 102s 1s/step - loss: 9.4005e-04 - accuracy: 1.0000 - val_loss: 3.0011 - val_accuracy: 0.4100\n",
      "Epoch 27/150\n",
      "96/96 [==============================] - 107s 1s/step - loss: 8.7943e-04 - accuracy: 1.0000 - val_loss: 3.0001 - val_accuracy: 0.4104\n",
      "Epoch 28/150\n",
      "96/96 [==============================] - 110s 1s/step - loss: 8.2390e-04 - accuracy: 1.0000 - val_loss: 2.9991 - val_accuracy: 0.4104\n",
      "Epoch 29/150\n",
      "96/96 [==============================] - 111s 1s/step - loss: 7.7296e-04 - accuracy: 1.0000 - val_loss: 2.9982 - val_accuracy: 0.4108\n",
      "Epoch 30/150\n",
      "96/96 [==============================] - 115s 1s/step - loss: 7.2605e-04 - accuracy: 1.0000 - val_loss: 2.9973 - val_accuracy: 0.4112\n",
      "Epoch 31/150\n",
      "96/96 [==============================] - 117s 1s/step - loss: 6.8273e-04 - accuracy: 1.0000 - val_loss: 2.9965 - val_accuracy: 0.4113\n",
      "Epoch 32/150\n",
      "96/96 [==============================] - 122s 1s/step - loss: 6.4266e-04 - accuracy: 1.0000 - val_loss: 2.9957 - val_accuracy: 0.4123\n",
      "Epoch 33/150\n",
      "96/96 [==============================] - 131s 1s/step - loss: 6.0554e-04 - accuracy: 1.0000 - val_loss: 2.9950 - val_accuracy: 0.4128\n",
      "Epoch 34/150\n",
      "96/96 [==============================] - 116s 1s/step - loss: 5.7104e-04 - accuracy: 1.0000 - val_loss: 2.9943 - val_accuracy: 0.4133\n",
      "Epoch 35/150\n",
      "96/96 [==============================] - 126s 1s/step - loss: 5.3895e-04 - accuracy: 1.0000 - val_loss: 2.9936 - val_accuracy: 0.4131\n",
      "Epoch 36/150\n",
      "96/96 [==============================] - 137s 1s/step - loss: 5.0905e-04 - accuracy: 1.0000 - val_loss: 2.9930 - val_accuracy: 0.4140\n",
      "Epoch 37/150\n",
      "96/96 [==============================] - 127s 1s/step - loss: 4.8111e-04 - accuracy: 1.0000 - val_loss: 2.9923 - val_accuracy: 0.4140\n",
      "Epoch 38/150\n",
      "96/96 [==============================] - 124s 1s/step - loss: 4.5505e-04 - accuracy: 1.0000 - val_loss: 2.9918 - val_accuracy: 0.4145\n",
      "Epoch 39/150\n",
      "96/96 [==============================] - 126s 1s/step - loss: 4.3065e-04 - accuracy: 1.0000 - val_loss: 2.9911 - val_accuracy: 0.4146\n",
      "Epoch 40/150\n",
      "96/96 [==============================] - 131s 1s/step - loss: 4.0780e-04 - accuracy: 1.0000 - val_loss: 2.9906 - val_accuracy: 0.4154\n",
      "Epoch 41/150\n",
      "96/96 [==============================] - 139s 1s/step - loss: 3.8636e-04 - accuracy: 1.0000 - val_loss: 2.9900 - val_accuracy: 0.4158\n",
      "Epoch 42/150\n",
      "96/96 [==============================] - 137s 1s/step - loss: 3.6625e-04 - accuracy: 1.0000 - val_loss: 2.9895 - val_accuracy: 0.4168\n",
      "Epoch 43/150\n",
      "96/96 [==============================] - 133s 1s/step - loss: 3.4733e-04 - accuracy: 1.0000 - val_loss: 2.9890 - val_accuracy: 0.4171\n",
      "Epoch 44/150\n",
      "96/96 [==============================] - 141s 1s/step - loss: 3.2953e-04 - accuracy: 1.0000 - val_loss: 2.9886 - val_accuracy: 0.4177\n",
      "Epoch 45/150\n",
      "96/96 [==============================] - 142s 1s/step - loss: 3.1278e-04 - accuracy: 1.0000 - val_loss: 2.9882 - val_accuracy: 0.4181\n",
      "Epoch 46/150\n",
      "96/96 [==============================] - 112s 1s/step - loss: 2.9698e-04 - accuracy: 1.0000 - val_loss: 2.9877 - val_accuracy: 0.4186\n",
      "Epoch 47/150\n",
      "96/96 [==============================] - 117s 1s/step - loss: 2.8210e-04 - accuracy: 1.0000 - val_loss: 2.9875 - val_accuracy: 0.4189\n",
      "Epoch 48/150\n",
      "96/96 [==============================] - 115s 1s/step - loss: 2.6804e-04 - accuracy: 1.0000 - val_loss: 2.9872 - val_accuracy: 0.4194\n",
      "Epoch 49/150\n",
      "96/96 [==============================] - 113s 1s/step - loss: 2.5476e-04 - accuracy: 1.0000 - val_loss: 2.9868 - val_accuracy: 0.4196\n",
      "Epoch 50/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 2.4220e-04 - accuracy: 1.0000 - val_loss: 2.9866 - val_accuracy: 0.4196\n",
      "Epoch 51/150\n",
      "96/96 [==============================] - 115s 1s/step - loss: 2.3033e-04 - accuracy: 1.0000 - val_loss: 2.9864 - val_accuracy: 0.4197\n",
      "Epoch 52/150\n",
      "96/96 [==============================] - 112s 1s/step - loss: 2.1909e-04 - accuracy: 1.0000 - val_loss: 2.9862 - val_accuracy: 0.4204\n",
      "Epoch 53/150\n",
      "96/96 [==============================] - 115s 1s/step - loss: 2.0845e-04 - accuracy: 1.0000 - val_loss: 2.9860 - val_accuracy: 0.4204\n",
      "Epoch 54/150\n",
      "96/96 [==============================] - 105s 1s/step - loss: 1.9837e-04 - accuracy: 1.0000 - val_loss: 2.9858 - val_accuracy: 0.4209\n",
      "Epoch 55/150\n",
      "96/96 [==============================] - 97s 1s/step - loss: 1.8882e-04 - accuracy: 1.0000 - val_loss: 2.9857 - val_accuracy: 0.4215\n",
      "Epoch 56/150\n",
      "96/96 [==============================] - 110s 1s/step - loss: 1.7977e-04 - accuracy: 1.0000 - val_loss: 2.9855 - val_accuracy: 0.4224\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 113s 1s/step - loss: 1.7119e-04 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.4225\n",
      "Epoch 58/150\n",
      "96/96 [==============================] - 114s 1s/step - loss: 1.6305e-04 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.4227\n",
      "Epoch 59/150\n",
      "96/96 [==============================] - 111s 1s/step - loss: 1.5532e-04 - accuracy: 1.0000 - val_loss: 2.9852 - val_accuracy: 0.4228\n",
      "Epoch 60/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 1.4798e-04 - accuracy: 1.0000 - val_loss: 2.9853 - val_accuracy: 0.4232\n",
      "Epoch 61/150\n",
      "96/96 [==============================] - 121s 1s/step - loss: 1.4100e-04 - accuracy: 1.0000 - val_loss: 2.9852 - val_accuracy: 0.4235\n",
      "Epoch 62/150\n",
      "96/96 [==============================] - 107s 1s/step - loss: 1.3438e-04 - accuracy: 1.0000 - val_loss: 2.9853 - val_accuracy: 0.4237\n",
      "Epoch 63/150\n",
      "96/96 [==============================] - 110s 1s/step - loss: 1.2807e-04 - accuracy: 1.0000 - val_loss: 2.9852 - val_accuracy: 0.4240\n",
      "Epoch 64/150\n",
      "96/96 [==============================] - 115s 1s/step - loss: 1.2209e-04 - accuracy: 1.0000 - val_loss: 2.9853 - val_accuracy: 0.4243\n",
      "Epoch 65/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 1.1639e-04 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.4247\n",
      "Epoch 66/150\n",
      "96/96 [==============================] - 113s 1s/step - loss: 1.1097e-04 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.4247\n",
      "Epoch 67/150\n",
      "96/96 [==============================] - 106s 1s/step - loss: 1.0582e-04 - accuracy: 1.0000 - val_loss: 2.9855 - val_accuracy: 0.4248\n",
      "Epoch 68/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 1.0090e-04 - accuracy: 1.0000 - val_loss: 2.9856 - val_accuracy: 0.4251\n",
      "Epoch 69/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 9.6230e-05 - accuracy: 1.0000 - val_loss: 2.9857 - val_accuracy: 0.4255\n",
      "Epoch 70/150\n",
      "96/96 [==============================] - 99s 1s/step - loss: 9.1779e-05 - accuracy: 1.0000 - val_loss: 2.9858 - val_accuracy: 0.4261\n",
      "Epoch 71/150\n",
      "96/96 [==============================] - 105s 1s/step - loss: 8.7543e-05 - accuracy: 1.0000 - val_loss: 2.9859 - val_accuracy: 0.4261\n",
      "Epoch 72/150\n",
      "96/96 [==============================] - 104s 1s/step - loss: 8.3499e-05 - accuracy: 1.0000 - val_loss: 2.9862 - val_accuracy: 0.4266\n",
      "Epoch 73/150\n",
      "96/96 [==============================] - 109s 1s/step - loss: 7.9649e-05 - accuracy: 1.0000 - val_loss: 2.9864 - val_accuracy: 0.4270\n",
      "Epoch 74/150\n",
      "96/96 [==============================] - 112s 1s/step - loss: 7.5984e-05 - accuracy: 1.0000 - val_loss: 2.9865 - val_accuracy: 0.4273\n",
      "Epoch 75/150\n",
      "96/96 [==============================] - 97s 1s/step - loss: 7.2489e-05 - accuracy: 1.0000 - val_loss: 2.9867 - val_accuracy: 0.4273\n",
      "Epoch 76/150\n",
      "96/96 [==============================] - 112s 1s/step - loss: 6.9156e-05 - accuracy: 1.0000 - val_loss: 2.9870 - val_accuracy: 0.4276\n",
      "Epoch 77/150\n",
      "96/96 [==============================] - 109s 1s/step - loss: 6.5983e-05 - accuracy: 1.0000 - val_loss: 2.9872 - val_accuracy: 0.4278\n",
      "Epoch 78/150\n",
      "96/96 [==============================] - 114s 1s/step - loss: 6.2950e-05 - accuracy: 1.0000 - val_loss: 2.9874 - val_accuracy: 0.4281\n",
      "Epoch 79/150\n",
      "96/96 [==============================] - 110s 1s/step - loss: 6.0064e-05 - accuracy: 1.0000 - val_loss: 2.9877 - val_accuracy: 0.4284\n",
      "Epoch 80/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 5.7305e-05 - accuracy: 1.0000 - val_loss: 2.9881 - val_accuracy: 0.4291\n",
      "Epoch 81/150\n",
      "96/96 [==============================] - 97s 1s/step - loss: 5.4681e-05 - accuracy: 1.0000 - val_loss: 2.9882 - val_accuracy: 0.4289\n",
      "Epoch 82/150\n",
      "96/96 [==============================] - 107s 1s/step - loss: 5.2178e-05 - accuracy: 1.0000 - val_loss: 2.9887 - val_accuracy: 0.4291\n",
      "Epoch 83/150\n",
      "96/96 [==============================] - 105s 1s/step - loss: 4.9788e-05 - accuracy: 1.0000 - val_loss: 2.9889 - val_accuracy: 0.4293\n",
      "Epoch 84/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 4.7510e-05 - accuracy: 1.0000 - val_loss: 2.9893 - val_accuracy: 0.4291\n",
      "Epoch 85/150\n",
      "96/96 [==============================] - 113s 1s/step - loss: 4.5336e-05 - accuracy: 1.0000 - val_loss: 2.9896 - val_accuracy: 0.4296\n",
      "Epoch 86/150\n",
      "96/96 [==============================] - 109s 1s/step - loss: 4.3266e-05 - accuracy: 1.0000 - val_loss: 2.9901 - val_accuracy: 0.4299\n",
      "Epoch 87/150\n",
      "96/96 [==============================] - 109s 1s/step - loss: 4.1289e-05 - accuracy: 1.0000 - val_loss: 2.9904 - val_accuracy: 0.4306\n",
      "Epoch 88/150\n",
      "96/96 [==============================] - 109s 1s/step - loss: 3.9403e-05 - accuracy: 1.0000 - val_loss: 2.9909 - val_accuracy: 0.4302\n",
      "Epoch 89/150\n",
      "96/96 [==============================] - 110s 1s/step - loss: 3.7600e-05 - accuracy: 1.0000 - val_loss: 2.9913 - val_accuracy: 0.4304\n",
      "Epoch 90/150\n",
      "96/96 [==============================] - 100s 1s/step - loss: 3.5885e-05 - accuracy: 1.0000 - val_loss: 2.9917 - val_accuracy: 0.4304\n",
      "Epoch 91/150\n",
      "96/96 [==============================] - 112s 1s/step - loss: 3.4245e-05 - accuracy: 1.0000 - val_loss: 2.9922 - val_accuracy: 0.4307\n",
      "Epoch 92/150\n",
      "96/96 [==============================] - 98s 1s/step - loss: 3.2682e-05 - accuracy: 1.0000 - val_loss: 2.9927 - val_accuracy: 0.4307\n",
      "Epoch 93/150\n",
      "96/96 [==============================] - 100s 1s/step - loss: 3.1191e-05 - accuracy: 1.0000 - val_loss: 2.9932 - val_accuracy: 0.4312\n",
      "Epoch 94/150\n",
      "96/96 [==============================] - 102s 1s/step - loss: 2.9764e-05 - accuracy: 1.0000 - val_loss: 2.9938 - val_accuracy: 0.4314\n",
      "Epoch 95/150\n",
      "96/96 [==============================] - 96s 1s/step - loss: 2.8406e-05 - accuracy: 1.0000 - val_loss: 2.9943 - val_accuracy: 0.4316\n",
      "Epoch 96/150\n",
      "96/96 [==============================] - 117s 1s/step - loss: 2.7109e-05 - accuracy: 1.0000 - val_loss: 2.9948 - val_accuracy: 0.4320\n",
      "Epoch 97/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 2.5874e-05 - accuracy: 1.0000 - val_loss: 2.9953 - val_accuracy: 0.4327\n",
      "Epoch 98/150\n",
      "96/96 [==============================] - 104s 1s/step - loss: 2.4691e-05 - accuracy: 1.0000 - val_loss: 2.9959 - val_accuracy: 0.4332\n",
      "Epoch 99/150\n",
      "96/96 [==============================] - 95s 995ms/step - loss: 2.3564e-05 - accuracy: 1.0000 - val_loss: 2.9965 - val_accuracy: 0.4334\n",
      "Epoch 100/150\n",
      "96/96 [==============================] - 99s 1s/step - loss: 2.2490e-05 - accuracy: 1.0000 - val_loss: 2.9970 - val_accuracy: 0.4335\n",
      "Epoch 101/150\n",
      "96/96 [==============================] - 104s 1s/step - loss: 2.1460e-05 - accuracy: 1.0000 - val_loss: 2.9977 - val_accuracy: 0.4335\n",
      "Epoch 102/150\n",
      "96/96 [==============================] - 105s 1s/step - loss: 2.0482e-05 - accuracy: 1.0000 - val_loss: 2.9982 - val_accuracy: 0.4342\n",
      "Epoch 103/150\n",
      "96/96 [==============================] - 107s 1s/step - loss: 1.9544e-05 - accuracy: 1.0000 - val_loss: 2.9990 - val_accuracy: 0.4343\n",
      "Epoch 104/150\n",
      "96/96 [==============================] - 114s 1s/step - loss: 1.8651e-05 - accuracy: 1.0000 - val_loss: 2.9996 - val_accuracy: 0.4342\n",
      "Epoch 105/150\n",
      "96/96 [==============================] - 109s 1s/step - loss: 1.7796e-05 - accuracy: 1.0000 - val_loss: 3.0004 - val_accuracy: 0.4340\n",
      "Epoch 106/150\n",
      "96/96 [==============================] - 107s 1s/step - loss: 1.6984e-05 - accuracy: 1.0000 - val_loss: 3.0010 - val_accuracy: 0.4343\n",
      "Epoch 107/150\n",
      "96/96 [==============================] - 110s 1s/step - loss: 1.6208e-05 - accuracy: 1.0000 - val_loss: 3.0018 - val_accuracy: 0.4345\n",
      "Epoch 108/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 1.5462e-05 - accuracy: 1.0000 - val_loss: 3.0025 - val_accuracy: 0.4345\n",
      "Epoch 109/150\n",
      "96/96 [==============================] - 116s 1s/step - loss: 1.4757e-05 - accuracy: 1.0000 - val_loss: 3.0032 - val_accuracy: 0.4348\n",
      "Epoch 110/150\n",
      "96/96 [==============================] - 104s 1s/step - loss: 1.4081e-05 - accuracy: 1.0000 - val_loss: 3.0039 - val_accuracy: 0.4352\n",
      "Epoch 111/150\n",
      "96/96 [==============================] - 105s 1s/step - loss: 1.3440e-05 - accuracy: 1.0000 - val_loss: 3.0049 - val_accuracy: 0.4355\n",
      "Epoch 112/150\n",
      "96/96 [==============================] - 108s 1s/step - loss: 1.2821e-05 - accuracy: 1.0000 - val_loss: 3.0057 - val_accuracy: 0.4357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150\n",
      "96/96 [==============================] - 106s 1s/step - loss: 1.2235e-05 - accuracy: 1.0000 - val_loss: 3.0064 - val_accuracy: 0.4360\n",
      "Epoch 114/150\n",
      "96/96 [==============================] - 102s 1s/step - loss: 1.1677e-05 - accuracy: 1.0000 - val_loss: 3.0073 - val_accuracy: 0.4358\n",
      "Epoch 115/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 1.1143e-05 - accuracy: 1.0000 - val_loss: 3.0082 - val_accuracy: 0.4365\n",
      "Epoch 116/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 1.0629e-05 - accuracy: 1.0000 - val_loss: 3.0090 - val_accuracy: 0.4366\n",
      "Epoch 117/150\n",
      "96/96 [==============================] - 118s 1s/step - loss: 1.0142e-05 - accuracy: 1.0000 - val_loss: 3.0099 - val_accuracy: 0.4368\n",
      "Epoch 118/150\n",
      "96/96 [==============================] - 108s 1s/step - loss: 9.6783e-06 - accuracy: 1.0000 - val_loss: 3.0109 - val_accuracy: 0.4368\n",
      "Epoch 119/150\n",
      "96/96 [==============================] - 96s 1s/step - loss: 9.2345e-06 - accuracy: 1.0000 - val_loss: 3.0118 - val_accuracy: 0.4371\n",
      "Epoch 120/150\n",
      "96/96 [==============================] - 105s 1s/step - loss: 8.8085e-06 - accuracy: 1.0000 - val_loss: 3.0128 - val_accuracy: 0.4376\n",
      "Epoch 121/150\n",
      "96/96 [==============================] - 99s 1s/step - loss: 8.4058e-06 - accuracy: 1.0000 - val_loss: 3.0137 - val_accuracy: 0.4378\n",
      "Epoch 122/150\n",
      "96/96 [==============================] - 102s 1s/step - loss: 8.0194e-06 - accuracy: 1.0000 - val_loss: 3.0147 - val_accuracy: 0.4381\n",
      "Epoch 123/150\n",
      "96/96 [==============================] - 116s 1s/step - loss: 7.6499e-06 - accuracy: 1.0000 - val_loss: 3.0156 - val_accuracy: 0.4383\n",
      "Epoch 124/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 7.3003e-06 - accuracy: 1.0000 - val_loss: 3.0166 - val_accuracy: 0.4386\n",
      "Epoch 125/150\n",
      "96/96 [==============================] - 107s 1s/step - loss: 6.9633e-06 - accuracy: 1.0000 - val_loss: 3.0175 - val_accuracy: 0.4389\n",
      "Epoch 126/150\n",
      "96/96 [==============================] - 99s 1s/step - loss: 6.6420e-06 - accuracy: 1.0000 - val_loss: 3.0186 - val_accuracy: 0.4388\n",
      "Epoch 127/150\n",
      "96/96 [==============================] - 106s 1s/step - loss: 6.3357e-06 - accuracy: 1.0000 - val_loss: 3.0195 - val_accuracy: 0.4391\n",
      "Epoch 128/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 6.0438e-06 - accuracy: 1.0000 - val_loss: 3.0206 - val_accuracy: 0.4391\n",
      "Epoch 129/150\n",
      "96/96 [==============================] - 104s 1s/step - loss: 5.7651e-06 - accuracy: 1.0000 - val_loss: 3.0216 - val_accuracy: 0.4393\n",
      "Epoch 130/150\n",
      "96/96 [==============================] - 106s 1s/step - loss: 5.5017e-06 - accuracy: 1.0000 - val_loss: 3.0227 - val_accuracy: 0.4394\n",
      "Epoch 131/150\n",
      "96/96 [==============================] - 99s 1s/step - loss: 5.2466e-06 - accuracy: 1.0000 - val_loss: 3.0237 - val_accuracy: 0.4396\n",
      "Epoch 132/150\n",
      "96/96 [==============================] - 114s 1s/step - loss: 5.0055e-06 - accuracy: 1.0000 - val_loss: 3.0250 - val_accuracy: 0.4396\n",
      "Epoch 133/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 4.7750e-06 - accuracy: 1.0000 - val_loss: 3.0259 - val_accuracy: 0.4404\n",
      "Epoch 134/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 4.5555e-06 - accuracy: 1.0000 - val_loss: 3.0272 - val_accuracy: 0.4403\n",
      "Epoch 135/150\n",
      "96/96 [==============================] - 103s 1s/step - loss: 4.3436e-06 - accuracy: 1.0000 - val_loss: 3.0282 - val_accuracy: 0.4406\n",
      "Epoch 136/150\n",
      "96/96 [==============================] - 105s 1s/step - loss: 4.1434e-06 - accuracy: 1.0000 - val_loss: 3.0294 - val_accuracy: 0.4408\n",
      "Epoch 137/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 3.9530e-06 - accuracy: 1.0000 - val_loss: 3.0306 - val_accuracy: 0.4409\n",
      "Epoch 138/150\n",
      "96/96 [==============================] - 104s 1s/step - loss: 3.7695e-06 - accuracy: 1.0000 - val_loss: 3.0316 - val_accuracy: 0.4412\n",
      "Epoch 139/150\n",
      "96/96 [==============================] - 104s 1s/step - loss: 3.5970e-06 - accuracy: 1.0000 - val_loss: 3.0328 - val_accuracy: 0.4412\n",
      "Epoch 140/150\n",
      "96/96 [==============================] - 121s 1s/step - loss: 3.4319e-06 - accuracy: 1.0000 - val_loss: 3.0342 - val_accuracy: 0.4416\n",
      "Epoch 141/150\n",
      "96/96 [==============================] - 100s 1s/step - loss: 3.2720e-06 - accuracy: 1.0000 - val_loss: 3.0353 - val_accuracy: 0.4416\n",
      "Epoch 142/150\n",
      "96/96 [==============================] - 109s 1s/step - loss: 3.1168e-06 - accuracy: 1.0000 - val_loss: 3.0366 - val_accuracy: 0.4416\n",
      "Epoch 143/150\n",
      "96/96 [==============================] - 106s 1s/step - loss: 2.9739e-06 - accuracy: 1.0000 - val_loss: 3.0379 - val_accuracy: 0.4419\n",
      "Epoch 144/150\n",
      "96/96 [==============================] - 98s 1s/step - loss: 2.8372e-06 - accuracy: 1.0000 - val_loss: 3.0391 - val_accuracy: 0.4419\n",
      "Epoch 145/150\n",
      "96/96 [==============================] - 108s 1s/step - loss: 2.7058e-06 - accuracy: 1.0000 - val_loss: 3.0405 - val_accuracy: 0.4424\n",
      "Epoch 146/150\n",
      "96/96 [==============================] - 101s 1s/step - loss: 2.5799e-06 - accuracy: 1.0000 - val_loss: 3.0416 - val_accuracy: 0.4426\n",
      "Epoch 147/150\n",
      "96/96 [==============================] - 108s 1s/step - loss: 2.4606e-06 - accuracy: 1.0000 - val_loss: 3.0430 - val_accuracy: 0.4434\n",
      "Epoch 148/150\n",
      "96/96 [==============================] - 108s 1s/step - loss: 2.3482e-06 - accuracy: 1.0000 - val_loss: 3.0443 - val_accuracy: 0.4435\n",
      "Epoch 149/150\n",
      "96/96 [==============================] - 111s 1s/step - loss: 2.2403e-06 - accuracy: 1.0000 - val_loss: 3.0455 - val_accuracy: 0.4439\n",
      "Epoch 150/150\n",
      "96/96 [==============================] - 97s 1s/step - loss: 2.1336e-06 - accuracy: 1.0000 - val_loss: 3.0469 - val_accuracy: 0.4440\n",
      "191/191 [==============================] - 38s 198ms/step - loss: 3.0469 - accuracy: 0.4440\n",
      "Test accuracy: 44.40%\n"
     ]
    }
   ],
   "source": [
    "# Load the ResNet50 model with ImageNet weights\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Add custom layers for the Caltech 101 dataset\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(102, activation=\"softmax\")(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(ds_train, epochs=150, validation_data=ds_test)\n",
    "loss, accuracy = model.evaluate(ds_test)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51ad78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab693f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e2f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
