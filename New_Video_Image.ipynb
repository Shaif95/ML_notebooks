{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0f0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Invasive category\n",
    "invasive_dirs = [\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\Veligers',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal',\n",
    "    ]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\NonVeligers\\Images_001',\n",
    "    ]\n",
    "\n",
    "# Ostracod category\n",
    "ostracod_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Preserve Ostracods',\n",
    "    ]\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "ostracod_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    \n",
    "for ostracod_dir in ostracod_dirs:\n",
    "    ostracod_subdirs.extend(glob.glob(ostracod_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf57a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n",
    "\n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n",
    "\n",
    "    \n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = ostracod_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y3 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y3.extend(subdirectories)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(28, 28)):\n",
    "    # List to store image files\n",
    "    image_files = []\n",
    "    # List to store labels\n",
    "    labels = []\n",
    "\n",
    "    # Retrieve image files and create labels for each directory in y1\n",
    "    for directory in y1:\n",
    "        # Flag to check if all images in the directory were processed successfully\n",
    "        all_images_processed = True\n",
    "        \n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    try:\n",
    "                        # Read the image using PIL\n",
    "                        image = Image.open(os.path.join(root, file))\n",
    "                        # Resize the image using tf.image.resize_with_crop_or_pad()\n",
    "                        image = tf.image.resize_with_crop_or_pad(\n",
    "                            tf.keras.preprocessing.image.img_to_array(image),\n",
    "                            target_size[0],\n",
    "                            target_size[1]\n",
    "                        )\n",
    "                        # Normalize the image pixels for ML training\n",
    "                        image = image / 255.0\n",
    "                        # Add the preprocessed image to the images list\n",
    "                        image_files.append(image)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing image: {os.path.join(root, file)}. Skipping...\")\n",
    "                        all_images_processed = False\n",
    "                        break\n",
    "            \n",
    "            # If any image in the directory failed to be processed, skip the directory\n",
    "            if not all_images_processed:\n",
    "                break\n",
    "\n",
    "            # Add the label to the labels list (only if all images in the directory were processed successfully)\n",
    "            labels.append(label_num)\n",
    "\n",
    "    # Convert the images and labels lists to numpy arrays\n",
    "    images = np.array(image_files)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "X0,Y0 = preprocess_images(y1, label_num = 0)\n",
    "X1,Y1 = preprocess_images(y2, label_num = 1)\n",
    "X2,Y2 = preprocess_images(y3, label_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f73b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1, X2), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1, Y2), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "# Now the shuffled data is assigned to the same variable names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.95, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56877f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f13ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"organmnist3d\"\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = ( 5, 28, 28, 3 )\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 60\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (4, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 32\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super(PatchEncoder, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(2, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\": self.projection_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded \n",
    "    \n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (5,28,28,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(5, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output= layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=3, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfac8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.zeros(3)\n",
    "\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "total_samples = np.sum(counts)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    class_weights[label] = total_samples / (len(unique_labels) * counts[i])\n",
    "\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4df76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28aad665",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=([get_f1]))\n",
    "class_weights = [1,1,1]\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1, class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87928d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cef385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Invasive category\n",
    "invasive_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Not',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Not Veligers\\O1',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Umbonal',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Zebra D-Hinge',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal'\n",
    "]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image2 To Baylor\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image12 To Baylor_3\\Ostracods Day 2 Image12 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Not'\n",
    "]\n",
    "\n",
    "# Ostracod category\n",
    "ostracod_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Preserve Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Preserved Ostracods 1a',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Ostracod Image1\\Ostracods1',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Ostracods',\n",
    "    ]\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "ostracod_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    \n",
    "for ostracod_dir in ostracod_dirs:\n",
    "    ostracod_subdirs.extend(glob.glob(ostracod_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eabc1ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82d08ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n",
    "\n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n",
    "\n",
    "    \n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = ostracod_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y3 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y3.extend(subdirectories)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(40, 40)):\n",
    "    # List to store image files\n",
    "    image_files = []\n",
    "    # List to store labels\n",
    "    labels = []\n",
    "\n",
    "    # Retrieve image files and create labels for each directory in y1\n",
    "    for directory in y1:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    # Add the file path to the image_files list\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                    # Add the label to the labels list\n",
    "                    \n",
    "\n",
    "    # List to store preprocessed images\n",
    "    images = []\n",
    "\n",
    "    # Preprocess each image\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            # Read the image using PIL\n",
    "            image = Image.open(file)\n",
    "            # Resize the image using tf.image.resize_with_crop_or_pad()\n",
    "            image = tf.image.resize_with_crop_or_pad(\n",
    "                tf.keras.preprocessing.image.img_to_array(image),\n",
    "                target_size[0],\n",
    "                target_size[1]\n",
    "            )\n",
    "            # Normalize the image pixels for ML training\n",
    "            image = image / 255.0\n",
    "            # Add the preprocessed image to the images list\n",
    "            images.append(image)\n",
    "            labels.append(label_num)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "    # Convert the images and labels lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "X0,Y0 = preprocess_images(y1, label_num = 0)\n",
    "X1,Y1 = preprocess_images(y2, label_num = 1)\n",
    "X2,Y2 = preprocess_images(y3, label_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db23670c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1, X2), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1, Y2), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming you have the original train_images and train_labels_categorical\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "# Now the shuffled data is assigned to the same variable names\n",
    "\n",
    "X_train, X_test1, Y_train, Y_test1 = train_test_split(train_images, train_labels_categorical, test_size=0.99, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396a53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b9c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a10bb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.zeros(3)\n",
    "\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "total_samples = np.sum(counts)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    class_weights[label] = total_samples / (len(unique_labels) * counts[i])\n",
    "\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33a28019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b47e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=([get_f1]))\n",
    "class_weights = [1,1,1]\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1, class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebf030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "p = np.argmax(pred, axis=1)\n",
    "res = p\n",
    "        \n",
    "test = []\n",
    "for i in Y_test:\n",
    "    if(i[0]==1):\n",
    "        test.append(0)\n",
    "    elif(i[1]==1):\n",
    "        test.append(1)\n",
    "    else:\n",
    "        test.append(2)\n",
    "        \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(test,np.argmax(Y_test, axis=1))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9ca5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d18ca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c56058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image path\n",
    "from PIL import Image\n",
    "image_path = r\"D:\\VeligerData\\Baylor 2022-03-21_2\\Veligers\\Object_031\\Image_009.png\"\n",
    "# Read the image using PIL\n",
    "image = Image.open(image_path)\n",
    "# Define the target size for resizing\n",
    "target_size = (40, 40)\n",
    "# Resize the image using TensorFlow's resize_with_crop_or_pad function\n",
    "resized_image = tf.image.resize_with_crop_or_pad( tf.keras.preprocessing.image.img_to_array(image), target_size[0],   target_size[1]\n",
    ")\n",
    "# Expand the dimensions to match the model's input shape\n",
    "expanded_image = tf.expand_dims(resized_image, axis=0)\n",
    "# Evaluate the TensorFlow tensor and obtain the NumPy array\n",
    "resized_array = tf.keras.backend.eval(expanded_image)\n",
    "normalized_image = resized_array / 255.0\n",
    "x = model.predict(normalized_image)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3a4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming you have a Keras model named \"model\"\n",
    "model.save(\"single_image_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "323db2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b43a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176ce90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40858074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83318ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c959fa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e72d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3390b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51a9c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851f28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce8676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e28fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685075ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cb231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530aff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d803ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f519a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03133f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd83d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "899ed44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22da3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00c417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2f255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
