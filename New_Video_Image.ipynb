{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0f0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Invasive category\n",
    "invasive_dirs = [\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\Veligers',\n",
    "    r'D:\\VeligerData\\invasive',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Pedi-Zebra Veligers',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1a To Baylor\\Preserved Zebra Ped 1a To Baylor\\Sorted Images\\Preserved Zebra Ped 1a',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Zebra Pediveliger Image1a\\Zebra Pediveligers',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal',\n",
    "    ]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\NonVeligers\\Images_001',\n",
    "    r'D:\\VeligerData\\noninvasive',\n",
    "    ]\n",
    "\n",
    "# Ostracod category\n",
    "ostracod_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Preserve Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Preserved Ostracods 1a',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Ostracod Image1\\Ostracods1',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Ostracods',\n",
    "    ]\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "ostracod_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    \n",
    "for ostracod_dir in ostracod_dirs:\n",
    "    ostracod_subdirs.extend(glob.glob(ostracod_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf57a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228e004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods\\Object_002\\._Image_032.png. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n",
    "\n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n",
    "\n",
    "    \n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = ostracod_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y3 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y3.extend(subdirectories)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(28, 28)):\n",
    "    # List to store images\n",
    "    images = []\n",
    "    # List to store labels\n",
    "    labels = []\n",
    "\n",
    "    # Process each directory in y1\n",
    "    for directory in y1:\n",
    "        # Flag to check if all images in the directory were processed successfully\n",
    "        all_images_processed = True\n",
    "        \n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    try:\n",
    "                        # Read the image using PIL\n",
    "                        image = Image.open(os.path.join(root, file))\n",
    "                        # Resize the image using tf.image.resize_with_crop_or_pad()\n",
    "                        image = tf.image.resize_with_crop_or_pad(\n",
    "                            tf.keras.preprocessing.image.img_to_array(image),\n",
    "                            target_size[0],\n",
    "                            target_size[1]\n",
    "                        )\n",
    "                        # Normalize the image pixels for ML training\n",
    "                        image = image / 255.0\n",
    "                        # Add the preprocessed image to the images list\n",
    "                        images.append(image)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing image: {os.path.join(root, file)}. Skipping...\")\n",
    "                        all_images_processed = False\n",
    "                        break\n",
    "            \n",
    "            # If any image in the directory failed to be processed, skip the directory\n",
    "            if not all_images_processed:\n",
    "                break\n",
    "\n",
    "        # If all images in the directory were processed successfully, add the label\n",
    "        if all_images_processed:\n",
    "            labels.append(label_num)\n",
    "\n",
    "    # Convert the images and labels lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X0,Y0 = preprocess_images(y1, label_num = 0)\n",
    "X1,Y1 = preprocess_images(y2, label_num = 1)\n",
    "X2,Y2 = preprocess_images(y3, label_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f73b10",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [143968, 4684]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Split the data into train and test sets\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[1;32m---> 22\u001b[0m train_images, train_labels_categorical \u001b[38;5;241m=\u001b[39m \u001b[43mshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Now the shuffled data is assigned to the same variable names\u001b[39;00m\n\u001b[0;32m     26\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(train_images, train_labels_categorical, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\utils\\__init__.py:691\u001b[0m, in \u001b[0;36mshuffle\u001b[1;34m(random_state, n_samples, *arrays)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle\u001b[39m(\u001b[38;5;241m*\u001b[39marrays, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    626\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Shuffle arrays or sparse matrices in a consistent way.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03m    This is a convenience alias to ``resample(*arrays, replace=False)`` to do\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;124;03m      array([0, 1])\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\utils\\__init__.py:577\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(replace, n_samples, random_state, stratify, *arrays)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (max_n_samples \u001b[38;5;241m>\u001b[39m n_samples) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m replace):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot sample \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m out of arrays with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m when replace is False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;241m%\u001b[39m (max_n_samples, n_samples)\n\u001b[0;32m    575\u001b[0m     )\n\u001b[1;32m--> 577\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m replace:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [143968, 4684]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1, X2), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1, Y2), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "# Now the shuffled data is assigned to the same variable names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.95, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56877f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f13ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"organmnist3d\"\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = ( 5, 28, 28, 3 )\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 60\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (4, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 32\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "#Patch Encoder with Conv2D ,  LSTM , Pos_Emd\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
    "        super(PatchEncoder, self).__init__(**kwargs)\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection =keras.Sequential(\n",
    "            [\n",
    "                (layers.Conv2D(2, (3, 3), strides=(1,1),activation='relu')),\n",
    "                TimeDistributed(MaxPooling2D(2,2)),\n",
    "                TimeDistributed(Flatten()),\n",
    "                layers.Dense(projection_dim)\n",
    "            ]) \n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\": self.num_patches,\n",
    "            \"projection_dim\": self.projection_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded \n",
    "    \n",
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "\n",
    "inputs = layers.Input(shape= (5,28,28,3) )\n",
    "\n",
    "encoded_patches = (PatchEncoder(5, 32 )) (inputs)\n",
    "\n",
    "for _ in range(6):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output= layers.MultiHeadAttention (  num_heads=6, key_dim=32, dropout=0.1 )  (x1, x1)\n",
    "    \n",
    "    lstm_output =  LSTM(32,return_sequences=True,dropout=0.1)(x1)\n",
    "\n",
    "    x2 = layers.Add()([attention_output, encoded_patches,lstm_output])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(layers.Dense(units=32, activation=tf.nn.gelu) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "#representation = LSTM(100,return_sequences=False,dropout=0.1)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=3, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfac8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.zeros(3)\n",
    "\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "total_samples = np.sum(counts)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    class_weights[label] = total_samples / (len(unique_labels) * counts[i])\n",
    "\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4df76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28aad665",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=([get_f1]))\n",
    "class_weights = [1,1,1]\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1, class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87928d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cef385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Invasive category\n",
    "invasive_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Not',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Not Veligers\\O1',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Umbonal',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Zebra D-Hinge',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal'\n",
    "]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image2 To Baylor\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image12 To Baylor_3\\Ostracods Day 2 Image12 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Not'\n",
    "]\n",
    "\n",
    "# Ostracod category\n",
    "ostracod_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Preserve Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Preserved Ostracods 1a',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Ostracod Image1\\Ostracods1',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Ostracods',\n",
    "    ]\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "ostracod_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    \n",
    "for ostracod_dir in ostracod_dirs:\n",
    "    ostracod_subdirs.extend(glob.glob(ostracod_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eabc1ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82d08ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n",
    "\n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n",
    "\n",
    "    \n",
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = ostracod_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y3 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y3.extend(subdirectories)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(40, 40)):\n",
    "    # List to store image files\n",
    "    image_files = []\n",
    "    # List to store labels\n",
    "    labels = []\n",
    "\n",
    "    # Retrieve image files and create labels for each directory in y1\n",
    "    for directory in y1:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    # Add the file path to the image_files list\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                    # Add the label to the labels list\n",
    "                    \n",
    "\n",
    "    # List to store preprocessed images\n",
    "    images = []\n",
    "\n",
    "    # Preprocess each image\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            # Read the image using PIL\n",
    "            image = Image.open(file)\n",
    "            # Resize the image using tf.image.resize_with_crop_or_pad()\n",
    "            image = tf.image.resize_with_crop_or_pad(\n",
    "                tf.keras.preprocessing.image.img_to_array(image),\n",
    "                target_size[0],\n",
    "                target_size[1]\n",
    "            )\n",
    "            # Normalize the image pixels for ML training\n",
    "            image = image / 255.0\n",
    "            # Add the preprocessed image to the images list\n",
    "            images.append(image)\n",
    "            labels.append(label_num)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "    # Convert the images and labels lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "X0,Y0 = preprocess_images(y1, label_num = 0)\n",
    "X1,Y1 = preprocess_images(y2, label_num = 1)\n",
    "X2,Y2 = preprocess_images(y3, label_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db23670c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1, X2), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1, Y2), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming you have the original train_images and train_labels_categorical\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "# Now the shuffled data is assigned to the same variable names\n",
    "\n",
    "X_train, X_test1, Y_train, Y_test1 = train_test_split(train_images, train_labels_categorical, test_size=0.99, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396a53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b9c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a10bb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.zeros(3)\n",
    "\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "total_samples = np.sum(counts)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    class_weights[label] = total_samples / (len(unique_labels) * counts[i])\n",
    "\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33a28019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b47e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=([get_f1]))\n",
    "class_weights = [1,1,1]\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1, class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebf030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "p = np.argmax(pred, axis=1)\n",
    "res = p\n",
    "        \n",
    "test = []\n",
    "for i in Y_test:\n",
    "    if(i[0]==1):\n",
    "        test.append(0)\n",
    "    elif(i[1]==1):\n",
    "        test.append(1)\n",
    "    else:\n",
    "        test.append(2)\n",
    "        \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(test,np.argmax(Y_test, axis=1))\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9ca5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d18ca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c56058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image path\n",
    "from PIL import Image\n",
    "image_path = r\"D:\\VeligerData\\Baylor 2022-03-21_2\\Veligers\\Object_031\\Image_009.png\"\n",
    "# Read the image using PIL\n",
    "image = Image.open(image_path)\n",
    "# Define the target size for resizing\n",
    "target_size = (40, 40)\n",
    "# Resize the image using TensorFlow's resize_with_crop_or_pad function\n",
    "resized_image = tf.image.resize_with_crop_or_pad( tf.keras.preprocessing.image.img_to_array(image), target_size[0],   target_size[1]\n",
    ")\n",
    "# Expand the dimensions to match the model's input shape\n",
    "expanded_image = tf.expand_dims(resized_image, axis=0)\n",
    "# Evaluate the TensorFlow tensor and obtain the NumPy array\n",
    "resized_array = tf.keras.backend.eval(expanded_image)\n",
    "normalized_image = resized_array / 255.0\n",
    "x = model.predict(normalized_image)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3a4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming you have a Keras model named \"model\"\n",
    "model.save(\"five_frame_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "323db2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b43a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176ce90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40858074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83318ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c959fa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e72d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3390b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51a9c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851f28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce8676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e28fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685075ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cb231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530aff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d803ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f519a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03133f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd83d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "899ed44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22da3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00c417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2f255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
