{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0f0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Invasive category\n",
    "invasive_dirs = [\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\Veligers',\n",
    "    r'D:\\VeligerData\\invasive',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Pedi-Zebra Veligers',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1a To Baylor\\Preserved Zebra Ped 1a To Baylor\\Sorted Images\\Preserved Zebra Ped 1a',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Zebra Pediveliger Image1a\\Zebra Pediveligers',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Umbonal',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Zebra D-Hinge',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Umbonal'\n",
    "]\n",
    "\n",
    "# Non-Invasive category\n",
    "non_invasive_dirs = [\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Baylor 2022-03-21_2\\NonVeligers\\Images_001',\n",
    "    r'D:\\VeligerData\\noninvasive',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Zebra Ped 1 To Baylor\\Preserved Zebra Ped 1 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image2 To Baylor\\Not',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image12 To Baylor_3\\Ostracods Day 2 Image12 To Baylor\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Not Veligers\\O1',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1 Image1\\Baylor Preserved Zebra Umbo 1 Image1\\Sorted Images\\Not',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Baylor Preserved Zebra Umbo 1a Image1\\Baylor Preserved Zebra Umbo 1a Image1\\Sorted Images\\Not'\n",
    "]\n",
    "\n",
    "# Ostracod category\n",
    "ostracod_dirs = [\n",
    "    r'D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1 To Baylor\\Preserved Ostracods 1 To Baylor\\Sorted Images\\Preserve Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracod vs Pedi-Veliger Examples\\Ostracod vs Pedi-Veliger Examples\\Preserved Ostracods 1a To Baylor\\Preserved Ostracods 1a To Baylor\\Sorted Images\\Preserved Ostracods 1a',\n",
    "    r'D:\\VeligerData\\To Baylor 2023-01-30\\To Baylor 2023-01-30\\Ostracod Image1\\Ostracods1',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image1 To Baylor\\Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image3 To Baylor_2\\Ostracods Day 2 Image3 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image12 To Baylor_3\\Ostracods Day 2 Image12 To Baylor\\Sorted Images\\Ostracods',\n",
    "    r'D:\\VeligerData\\Ostracods Day 2 Image2 To Baylor\\Ostracods',\n",
    "    r'D:\\VeligerData\\USGS Labled Zebra\\USGS Labled Zebra\\Preserved Zebra D-Hinge 1 Baylor\\Preserved Zebra D-Hinge 1 Baylor\\Sorted Images\\Ostracod'\n",
    "]\n",
    "\n",
    "# List to store subdirectories\n",
    "invasive_subdirs = []\n",
    "non_invasive_subdirs = []\n",
    "ostracod_subdirs = []\n",
    "\n",
    "# Collect subdirectories in the invasive category\n",
    "for invasive_dir in invasive_dirs:\n",
    "    invasive_subdirs.extend(glob.glob(invasive_dir))\n",
    "\n",
    "# Collect subdirectories in the non-invasive category\n",
    "for non_invasive_dir in non_invasive_dirs:\n",
    "    non_invasive_subdirs.extend(glob.glob(non_invasive_dir))\n",
    "    \n",
    "for ostracod_dir in ostracod_dirs:\n",
    "    ostracod_subdirs.extend(glob.glob(ostracod_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf57a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228e004f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\VeligerData\\\\Ostracod Day 2 Image12 Short To Baylor\\\\Ostracod Day 2 Image12 To Baylor\\\\Sorted Images\\\\Ostracods',\n",
       " 'D:\\\\VeligerData\\\\Ostracod vs Pedi-Veliger Examples\\\\Ostracod vs Pedi-Veliger Examples\\\\Preserved Ostracods 1 To Baylor\\\\Preserved Ostracods 1 To Baylor\\\\Sorted Images\\\\Preserve Ostracods',\n",
       " 'D:\\\\VeligerData\\\\Ostracod vs Pedi-Veliger Examples\\\\Ostracod vs Pedi-Veliger Examples\\\\Preserved Ostracods 1a To Baylor\\\\Preserved Ostracods 1a To Baylor\\\\Sorted Images\\\\Preserved Ostracods 1a',\n",
       " 'D:\\\\VeligerData\\\\To Baylor 2023-01-30\\\\To Baylor 2023-01-30\\\\Ostracod Image1\\\\Ostracods1',\n",
       " 'D:\\\\VeligerData\\\\Ostracods Day 2 Image1 To Baylor\\\\Ostracods',\n",
       " 'D:\\\\VeligerData\\\\Ostracods Day 2 Image3 To Baylor_2\\\\Ostracods Day 2 Image3 To Baylor\\\\Sorted Images\\\\Ostracods',\n",
       " 'D:\\\\VeligerData\\\\Ostracods Day 2 Image12 To Baylor_3\\\\Ostracods Day 2 Image12 To Baylor\\\\Sorted Images\\\\Ostracods',\n",
       " 'D:\\\\VeligerData\\\\Ostracods Day 2 Image2 To Baylor\\\\Ostracods',\n",
       " 'D:\\\\VeligerData\\\\USGS Labled Zebra\\\\USGS Labled Zebra\\\\Preserved Zebra D-Hinge 1 Baylor\\\\Preserved Zebra D-Hinge 1 Baylor\\\\Sorted Images\\\\Ostracod']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ostracod_subdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f73b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f13ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = non_invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y1 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y1.extend(subdirectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28aad665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = invasive_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y2 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y2.extend(subdirectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87928d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# List of directories in x\n",
    "x = ostracod_subdirs\n",
    "\n",
    "# List to store subdirectories\n",
    "y3 = []\n",
    "\n",
    "# Read subdirectories for each directory in x\n",
    "for directory in x:\n",
    "    subdirectories = glob.glob(directory + r'\\*')\n",
    "    y3.extend(subdirectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cef385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eabc1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_images(y1, label_num, target_size=(40, 40)):\n",
    "    # List to store image files\n",
    "    image_files = []\n",
    "    # List to store labels\n",
    "    labels = []\n",
    "\n",
    "    # Retrieve image files and create labels for each directory in y1\n",
    "    for directory in y1:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Check if the file has an image extension\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    # Add the file path to the image_files list\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "                    # Add the label to the labels list\n",
    "                    \n",
    "\n",
    "    # List to store preprocessed images\n",
    "    images = []\n",
    "\n",
    "    # Preprocess each image\n",
    "    for file in image_files:\n",
    "        try:\n",
    "            # Read the image using PIL\n",
    "            image = Image.open(file)\n",
    "            # Resize the image using tf.image.resize_with_crop_or_pad()\n",
    "            image = tf.image.resize_with_crop_or_pad(\n",
    "                tf.keras.preprocessing.image.img_to_array(image),\n",
    "                target_size[0],\n",
    "                target_size[1]\n",
    "            )\n",
    "            # Normalize the image pixels for ML training\n",
    "            image = image / 255.0\n",
    "            # Add the preprocessed image to the images list\n",
    "            images.append(image)\n",
    "            labels.append(label_num)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "    # Convert the images and labels lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82d08ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0,Y0 = preprocess_images(y1[:1000], label_num = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db23670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1,Y1 = preprocess_images(y2[:300], label_num = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef91f19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing image: D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods\\Object_002\\._Image_032.png. Skipping...\n",
      "Error processing image: D:\\VeligerData\\Ostracod Day 2 Image12 Short To Baylor\\Ostracod Day 2 Image12 To Baylor\\Sorted Images\\Ostracods\\Object_002\\._Image_036.png. Skipping...\n"
     ]
    }
   ],
   "source": [
    "X2,Y2 = preprocess_images(y3[:40], label_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f396a53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4865, 40, 40, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b9c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a10bb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Concatenate the image arrays\n",
    "train_images = np.concatenate((X0, X1, X2), axis=0)\n",
    "\n",
    "# Combine the label arrays\n",
    "train_labels = np.concatenate((Y0, Y1, Y2), axis=0)\n",
    "\n",
    "# Convert the labels to categorical\n",
    "train_labels_categorical = to_categorical(train_labels)\n",
    "\n",
    "# Set the dtype of train_images to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33a28019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming you have the original train_images and train_labels_categorical\n",
    "\n",
    "# Shuffle the data\n",
    "train_images, train_labels_categorical = shuffle(train_images, train_labels_categorical)\n",
    "\n",
    "# Now the shuffled data is assigned to the same variable names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_images, train_labels_categorical, test_size=0.95, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b47e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adebf030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42055, 40, 40, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e4030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9b9ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [ 0.44761988  1.45657671 12.59122987]\n"
     ]
    }
   ],
   "source": [
    "class_weights = np.zeros(3)\n",
    "\n",
    "unique_labels, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "total_samples = np.sum(counts)\n",
    "\n",
    "for i, label in enumerate(unique_labels):\n",
    "    class_weights[label] = total_samples / (len(unique_labels) * counts[i])\n",
    "\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d18ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [.45,1.5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c56058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model with custom_objects parameter\n",
    "model = tf.keras.models.load_model('single_image_model.h5', custom_objects={'get_f1': get_f1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3a4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2728b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 38, 38, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 19, 19, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 17, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 16)          4624      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,379\n",
      "Trainable params: 52,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(40, 40, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(16, (3, 3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(10))\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "323db2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718b43a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4911/4911 [==============================] - 49s 7ms/step - loss: 0.1797 - get_f1: 0.9098 - val_loss: 0.1993 - val_get_f1: 0.9307\n",
      "Epoch 2/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.1393 - get_f1: 0.9307 - val_loss: 0.1572 - val_get_f1: 0.9445\n",
      "Epoch 3/300\n",
      "4911/4911 [==============================] - 40s 8ms/step - loss: 0.1269 - get_f1: 0.9366 - val_loss: 0.1441 - val_get_f1: 0.9494\n",
      "Epoch 4/300\n",
      "4911/4911 [==============================] - 37s 7ms/step - loss: 0.1202 - get_f1: 0.9397 - val_loss: 0.1907 - val_get_f1: 0.9335\n",
      "Epoch 5/300\n",
      "4911/4911 [==============================] - 40s 8ms/step - loss: 0.1146 - get_f1: 0.9423 - val_loss: 0.1881 - val_get_f1: 0.9364\n",
      "Epoch 6/300\n",
      "4911/4911 [==============================] - 41s 8ms/step - loss: 0.1097 - get_f1: 0.9449 - val_loss: 0.1865 - val_get_f1: 0.9354\n",
      "Epoch 7/300\n",
      "4911/4911 [==============================] - 37s 8ms/step - loss: 0.1065 - get_f1: 0.9460 - val_loss: 0.1220 - val_get_f1: 0.9543\n",
      "Epoch 8/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.1034 - get_f1: 0.9479 - val_loss: 0.1384 - val_get_f1: 0.9486\n",
      "Epoch 9/300\n",
      "4911/4911 [==============================] - 33s 7ms/step - loss: 0.0994 - get_f1: 0.9496 - val_loss: 0.1500 - val_get_f1: 0.9438\n",
      "Epoch 10/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0976 - get_f1: 0.9504 - val_loss: 0.1520 - val_get_f1: 0.9441\n",
      "Epoch 11/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0956 - get_f1: 0.9512 - val_loss: 0.1653 - val_get_f1: 0.9406\n",
      "Epoch 12/300\n",
      "4911/4911 [==============================] - 37s 8ms/step - loss: 0.0943 - get_f1: 0.9519 - val_loss: 0.1457 - val_get_f1: 0.9485\n",
      "Epoch 13/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0915 - get_f1: 0.9536 - val_loss: 0.1389 - val_get_f1: 0.9510\n",
      "Epoch 14/300\n",
      "4911/4911 [==============================] - 34s 7ms/step - loss: 0.0904 - get_f1: 0.9540 - val_loss: 0.2182 - val_get_f1: 0.9239\n",
      "Epoch 15/300\n",
      "4911/4911 [==============================] - 33s 7ms/step - loss: 0.0889 - get_f1: 0.9549 - val_loss: 0.1257 - val_get_f1: 0.9551\n",
      "Epoch 16/300\n",
      "4911/4911 [==============================] - 36s 7ms/step - loss: 0.0881 - get_f1: 0.9552 - val_loss: 0.1504 - val_get_f1: 0.9435\n",
      "Epoch 17/300\n",
      "4911/4911 [==============================] - 39s 8ms/step - loss: 0.0867 - get_f1: 0.9554 - val_loss: 0.1359 - val_get_f1: 0.9509\n",
      "Epoch 18/300\n",
      "4911/4911 [==============================] - 40s 8ms/step - loss: 0.0855 - get_f1: 0.9564 - val_loss: 0.1286 - val_get_f1: 0.9532\n",
      "Epoch 19/300\n",
      "4911/4911 [==============================] - 34s 7ms/step - loss: 0.0841 - get_f1: 0.9570 - val_loss: 0.1403 - val_get_f1: 0.9504\n",
      "Epoch 20/300\n",
      "4911/4911 [==============================] - 37s 8ms/step - loss: 0.0839 - get_f1: 0.9568 - val_loss: 0.1171 - val_get_f1: 0.9594\n",
      "Epoch 21/300\n",
      "4911/4911 [==============================] - 31s 6ms/step - loss: 0.0829 - get_f1: 0.9573 - val_loss: 0.1215 - val_get_f1: 0.9578\n",
      "Epoch 22/300\n",
      "4911/4911 [==============================] - 31s 6ms/step - loss: 0.0817 - get_f1: 0.9577 - val_loss: 0.1405 - val_get_f1: 0.9505\n",
      "Epoch 23/300\n",
      "4911/4911 [==============================] - 40s 8ms/step - loss: 0.0811 - get_f1: 0.9584 - val_loss: 0.1507 - val_get_f1: 0.9464\n",
      "Epoch 24/300\n",
      "4911/4911 [==============================] - 37s 7ms/step - loss: 0.0808 - get_f1: 0.9585 - val_loss: 0.1329 - val_get_f1: 0.9542\n",
      "Epoch 25/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0793 - get_f1: 0.9589 - val_loss: 0.1123 - val_get_f1: 0.9607\n",
      "Epoch 26/300\n",
      "4911/4911 [==============================] - 44s 9ms/step - loss: 0.0787 - get_f1: 0.9594 - val_loss: 0.1653 - val_get_f1: 0.9416\n",
      "Epoch 27/300\n",
      "4911/4911 [==============================] - 35s 7ms/step - loss: 0.0783 - get_f1: 0.9598 - val_loss: 0.1206 - val_get_f1: 0.9567\n",
      "Epoch 28/300\n",
      "4911/4911 [==============================] - 35s 7ms/step - loss: 0.0778 - get_f1: 0.9603 - val_loss: 0.1748 - val_get_f1: 0.9426\n",
      "Epoch 29/300\n",
      "4911/4911 [==============================] - 33s 7ms/step - loss: 0.0766 - get_f1: 0.9603 - val_loss: 0.1175 - val_get_f1: 0.9597\n",
      "Epoch 30/300\n",
      "4911/4911 [==============================] - 36s 7ms/step - loss: 0.0759 - get_f1: 0.9607 - val_loss: 0.1179 - val_get_f1: 0.9588\n",
      "Epoch 31/300\n",
      "4911/4911 [==============================] - 36s 7ms/step - loss: 0.0750 - get_f1: 0.9612 - val_loss: 0.1194 - val_get_f1: 0.9589\n",
      "Epoch 32/300\n",
      "4911/4911 [==============================] - 37s 7ms/step - loss: 0.0748 - get_f1: 0.9612 - val_loss: 0.1369 - val_get_f1: 0.9526\n",
      "Epoch 33/300\n",
      "4911/4911 [==============================] - 36s 7ms/step - loss: 0.0744 - get_f1: 0.9617 - val_loss: 0.1555 - val_get_f1: 0.9465\n",
      "Epoch 34/300\n",
      "4911/4911 [==============================] - 35s 7ms/step - loss: 0.0743 - get_f1: 0.9612 - val_loss: 0.1147 - val_get_f1: 0.9627\n",
      "Epoch 35/300\n",
      "4911/4911 [==============================] - 39s 8ms/step - loss: 0.0728 - get_f1: 0.9622 - val_loss: 0.1823 - val_get_f1: 0.9373\n",
      "Epoch 36/300\n",
      "4911/4911 [==============================] - 36s 7ms/step - loss: 0.0725 - get_f1: 0.9623 - val_loss: 0.1484 - val_get_f1: 0.9509\n",
      "Epoch 37/300\n",
      "4911/4911 [==============================] - 35s 7ms/step - loss: 0.0725 - get_f1: 0.9622 - val_loss: 0.1265 - val_get_f1: 0.9581\n",
      "Epoch 38/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0719 - get_f1: 0.9628 - val_loss: 0.1200 - val_get_f1: 0.9597\n",
      "Epoch 39/300\n",
      "4911/4911 [==============================] - 36s 7ms/step - loss: 0.0717 - get_f1: 0.9625 - val_loss: 0.1500 - val_get_f1: 0.9460\n",
      "Epoch 40/300\n",
      "4911/4911 [==============================] - 40s 8ms/step - loss: 0.0706 - get_f1: 0.9633 - val_loss: 0.1151 - val_get_f1: 0.9613\n",
      "Epoch 41/300\n",
      "4911/4911 [==============================] - 39s 8ms/step - loss: 0.0704 - get_f1: 0.9630 - val_loss: 0.1217 - val_get_f1: 0.9591\n",
      "Epoch 42/300\n",
      "4911/4911 [==============================] - 40s 8ms/step - loss: 0.0700 - get_f1: 0.9633 - val_loss: 0.1519 - val_get_f1: 0.9489\n",
      "Epoch 43/300\n",
      "4911/4911 [==============================] - 39s 8ms/step - loss: 0.0695 - get_f1: 0.9632 - val_loss: 0.1177 - val_get_f1: 0.9614\n",
      "Epoch 44/300\n",
      "4911/4911 [==============================] - 40s 8ms/step - loss: 0.0690 - get_f1: 0.9643 - val_loss: 0.1263 - val_get_f1: 0.9602\n",
      "Epoch 45/300\n",
      "4911/4911 [==============================] - 41s 8ms/step - loss: 0.0687 - get_f1: 0.9644 - val_loss: 0.1319 - val_get_f1: 0.9563\n",
      "Epoch 46/300\n",
      "4911/4911 [==============================] - 41s 8ms/step - loss: 0.0681 - get_f1: 0.9641 - val_loss: 0.1129 - val_get_f1: 0.9612\n",
      "Epoch 47/300\n",
      "4911/4911 [==============================] - 37s 8ms/step - loss: 0.0677 - get_f1: 0.9648 - val_loss: 0.1343 - val_get_f1: 0.9554\n",
      "Epoch 48/300\n",
      "4911/4911 [==============================] - 33s 7ms/step - loss: 0.0673 - get_f1: 0.9645 - val_loss: 0.1545 - val_get_f1: 0.9496\n",
      "Epoch 49/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0666 - get_f1: 0.9656 - val_loss: 0.1333 - val_get_f1: 0.9540\n",
      "Epoch 50/300\n",
      "4911/4911 [==============================] - 41s 8ms/step - loss: 0.0663 - get_f1: 0.9653 - val_loss: 0.1260 - val_get_f1: 0.9568\n",
      "Epoch 51/300\n",
      "4911/4911 [==============================] - 42s 9ms/step - loss: 0.0662 - get_f1: 0.9657 - val_loss: 0.1180 - val_get_f1: 0.9624\n",
      "Epoch 52/300\n",
      "4911/4911 [==============================] - 39s 8ms/step - loss: 0.0651 - get_f1: 0.9657 - val_loss: 0.1229 - val_get_f1: 0.9621\n",
      "Epoch 53/300\n",
      "4911/4911 [==============================] - 35s 7ms/step - loss: 0.0658 - get_f1: 0.9658 - val_loss: 0.1214 - val_get_f1: 0.9594\n",
      "Epoch 54/300\n",
      "4911/4911 [==============================] - 36s 7ms/step - loss: 0.0646 - get_f1: 0.9665 - val_loss: 0.1316 - val_get_f1: 0.9563\n",
      "Epoch 55/300\n",
      "4911/4911 [==============================] - 46s 9ms/step - loss: 0.0651 - get_f1: 0.9659 - val_loss: 0.1258 - val_get_f1: 0.9571\n",
      "Epoch 56/300\n",
      "4911/4911 [==============================] - 31s 6ms/step - loss: 0.0645 - get_f1: 0.9665 - val_loss: 0.1355 - val_get_f1: 0.9568\n",
      "Epoch 57/300\n",
      "4911/4911 [==============================] - 53s 11ms/step - loss: 0.0638 - get_f1: 0.9667 - val_loss: 0.1202 - val_get_f1: 0.9606\n",
      "Epoch 58/300\n",
      "4911/4911 [==============================] - 47s 9ms/step - loss: 0.0638 - get_f1: 0.9669 - val_loss: 0.1258 - val_get_f1: 0.9604\n",
      "Epoch 59/300\n",
      "4911/4911 [==============================] - 37s 7ms/step - loss: 0.0638 - get_f1: 0.9665 - val_loss: 0.1369 - val_get_f1: 0.9548\n",
      "Epoch 60/300\n",
      "4911/4911 [==============================] - 46s 9ms/step - loss: 0.0637 - get_f1: 0.9662 - val_loss: 0.1234 - val_get_f1: 0.9631\n",
      "Epoch 61/300\n",
      "4911/4911 [==============================] - 49s 10ms/step - loss: 0.0632 - get_f1: 0.9669 - val_loss: 0.1123 - val_get_f1: 0.9623\n",
      "Epoch 62/300\n",
      "4911/4911 [==============================] - 51s 10ms/step - loss: 0.0623 - get_f1: 0.9675 - val_loss: 0.1213 - val_get_f1: 0.9611\n",
      "Epoch 63/300\n",
      "4911/4911 [==============================] - 56s 11ms/step - loss: 0.0623 - get_f1: 0.9678 - val_loss: 0.1415 - val_get_f1: 0.9527\n",
      "Epoch 64/300\n",
      "4911/4911 [==============================] - 39s 8ms/step - loss: 0.0620 - get_f1: 0.9676 - val_loss: 0.1343 - val_get_f1: 0.9540\n",
      "Epoch 65/300\n",
      "4911/4911 [==============================] - 47s 10ms/step - loss: 0.0631 - get_f1: 0.9672 - val_loss: 0.1160 - val_get_f1: 0.9614\n",
      "Epoch 66/300\n",
      "4911/4911 [==============================] - 53s 11ms/step - loss: 0.0618 - get_f1: 0.9677 - val_loss: 0.1614 - val_get_f1: 0.9467\n",
      "Epoch 67/300\n",
      "4911/4911 [==============================] - 56s 11ms/step - loss: 0.0613 - get_f1: 0.9681 - val_loss: 0.1619 - val_get_f1: 0.9463\n",
      "Epoch 68/300\n",
      "4911/4911 [==============================] - 53s 11ms/step - loss: 0.0612 - get_f1: 0.9681 - val_loss: 0.1403 - val_get_f1: 0.9538\n",
      "Epoch 69/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0602 - get_f1: 0.9681 - val_loss: 0.1472 - val_get_f1: 0.9497\n",
      "Epoch 70/300\n",
      "4911/4911 [==============================] - 41s 8ms/step - loss: 0.0596 - get_f1: 0.9689 - val_loss: 0.1304 - val_get_f1: 0.9586\n",
      "Epoch 71/300\n",
      "4911/4911 [==============================] - 50s 10ms/step - loss: 0.0598 - get_f1: 0.9687 - val_loss: 0.1372 - val_get_f1: 0.9560\n",
      "Epoch 72/300\n",
      "4911/4911 [==============================] - 48s 10ms/step - loss: 0.0600 - get_f1: 0.9683 - val_loss: 0.1292 - val_get_f1: 0.9619\n",
      "Epoch 73/300\n",
      "4911/4911 [==============================] - 47s 9ms/step - loss: 0.0599 - get_f1: 0.9683 - val_loss: 0.1698 - val_get_f1: 0.9429\n",
      "Epoch 74/300\n",
      "4911/4911 [==============================] - 35s 7ms/step - loss: 0.0594 - get_f1: 0.9685 - val_loss: 0.1235 - val_get_f1: 0.9608\n",
      "Epoch 75/300\n",
      "4911/4911 [==============================] - 47s 10ms/step - loss: 0.0598 - get_f1: 0.9687 - val_loss: 0.1426 - val_get_f1: 0.9589\n",
      "Epoch 76/300\n",
      "4911/4911 [==============================] - 53s 11ms/step - loss: 0.0592 - get_f1: 0.9693 - val_loss: 0.1477 - val_get_f1: 0.9486\n",
      "Epoch 77/300\n",
      "4911/4911 [==============================] - 51s 10ms/step - loss: 0.0587 - get_f1: 0.9688 - val_loss: 0.1341 - val_get_f1: 0.9578\n",
      "Epoch 78/300\n",
      "4911/4911 [==============================] - 60s 12ms/step - loss: 0.0589 - get_f1: 0.9694 - val_loss: 0.1327 - val_get_f1: 0.9591\n",
      "Epoch 79/300\n",
      "4911/4911 [==============================] - 33s 7ms/step - loss: 0.0587 - get_f1: 0.9689 - val_loss: 0.1262 - val_get_f1: 0.9583\n",
      "Epoch 80/300\n",
      "4911/4911 [==============================] - 41s 8ms/step - loss: 0.0586 - get_f1: 0.9693 - val_loss: 0.1522 - val_get_f1: 0.9551\n",
      "Epoch 81/300\n",
      "4911/4911 [==============================] - 57s 12ms/step - loss: 0.0580 - get_f1: 0.9689 - val_loss: 0.1385 - val_get_f1: 0.9527\n",
      "Epoch 82/300\n",
      "4911/4911 [==============================] - 51s 10ms/step - loss: 0.0581 - get_f1: 0.9699 - val_loss: 0.1623 - val_get_f1: 0.9509\n",
      "Epoch 83/300\n",
      "4911/4911 [==============================] - 61s 12ms/step - loss: 0.0571 - get_f1: 0.9701 - val_loss: 0.1696 - val_get_f1: 0.9445\n",
      "Epoch 84/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0574 - get_f1: 0.9694 - val_loss: 0.1357 - val_get_f1: 0.9540\n",
      "Epoch 85/300\n",
      "4911/4911 [==============================] - 57s 12ms/step - loss: 0.0580 - get_f1: 0.9695 - val_loss: 0.1346 - val_get_f1: 0.9574\n",
      "Epoch 86/300\n",
      "4911/4911 [==============================] - 51s 10ms/step - loss: 0.0557 - get_f1: 0.9706 - val_loss: 0.1264 - val_get_f1: 0.9603\n",
      "Epoch 87/300\n",
      "4911/4911 [==============================] - 58s 12ms/step - loss: 0.0564 - get_f1: 0.9703 - val_loss: 0.1230 - val_get_f1: 0.9612\n",
      "Epoch 88/300\n",
      "4911/4911 [==============================] - 45s 9ms/step - loss: 0.0559 - get_f1: 0.9703 - val_loss: 0.1519 - val_get_f1: 0.9532\n",
      "Epoch 89/300\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0569 - get_f1: 0.9699 - val_loss: 0.1398 - val_get_f1: 0.9528\n",
      "Epoch 90/300\n",
      "4911/4911 [==============================] - 49s 10ms/step - loss: 0.0563 - get_f1: 0.9702 - val_loss: 0.1316 - val_get_f1: 0.9572\n",
      "Epoch 91/300\n",
      "4877/4911 [============================>.] - ETA: 0s - loss: 0.0556 - get_f1: 0.9702"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=([get_f1]))\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "model.fit(X_train, Y_train, epochs=300, batch_size=32, validation_split=0.1, verbose=1, class_weight=class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d176ce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4911/4911 [==============================] - 37s 8ms/step - loss: 0.0501 - get_f1: 0.9736 - val_loss: 0.1214 - val_get_f1: 0.9634\n",
      "Epoch 2/30\n",
      "4911/4911 [==============================] - 39s 8ms/step - loss: 0.0502 - get_f1: 0.9735 - val_loss: 0.1286 - val_get_f1: 0.9610\n",
      "Epoch 3/30\n",
      "4911/4911 [==============================] - 38s 8ms/step - loss: 0.0499 - get_f1: 0.9737 - val_loss: 0.1244 - val_get_f1: 0.9615\n",
      "Epoch 4/30\n",
      "4911/4911 [==============================] - 39s 8ms/step - loss: 0.0492 - get_f1: 0.9737 - val_loss: 0.1187 - val_get_f1: 0.9628\n",
      "Epoch 5/30\n",
      "4911/4911 [==============================] - 36s 7ms/step - loss: 0.0495 - get_f1: 0.9737 - val_loss: 0.1633 - val_get_f1: 0.9513\n",
      "Epoch 6/30\n",
      " 476/4911 [=>............................] - ETA: 27s - loss: 0.0631 - get_f1: 0.9662"
     ]
    }
   ],
   "source": [
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "model.fit(X_train, Y_train, epochs=30, batch_size=32, validation_split=0.1, verbose=1, class_weight=class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40858074",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83318ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c959fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "p = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01e72d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49482,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b3390b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = p\n",
    "        \n",
    "test = []\n",
    "for i in Y_test:\n",
    "    if(i[0]==1):\n",
    "        test.append(0)\n",
    "    elif(i[1]==1):\n",
    "        test.append(1)\n",
    "    else:\n",
    "        test.append(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51a9c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851f28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66ce8676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9476779434946041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(test, res)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e28fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "685075ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Class 1: 0.9743582053742802\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(test)\n",
    "correct_predictions = 0\n",
    "class_1_count = 0\n",
    "num = 0\n",
    "for i in range(total_samples):\n",
    "    if test[i] == num:\n",
    "        class_1_count += 1\n",
    "        if res[i] == test[i]:\n",
    "            correct_predictions += 1\n",
    "\n",
    "class_1_accuracy = correct_predictions / class_1_count\n",
    "print(\"Accuracy for Class 1:\", class_1_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cb231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8530aff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1114547e-02, 9.8887640e-01, 9.0184431e-06]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the image path\n",
    "from PIL import Image\n",
    "image_path = r\"D:\\VeligerData\\Baylor 2022-03-21_2\\Veligers\\Object_031\\Image_009.png\"\n",
    "# Read the image using PIL\n",
    "image = Image.open(image_path)\n",
    "# Define the target size for resizing\n",
    "target_size = (40, 40)\n",
    "# Resize the image using TensorFlow's resize_with_crop_or_pad function\n",
    "resized_image = tf.image.resize_with_crop_or_pad( tf.keras.preprocessing.image.img_to_array(image), target_size[0],   target_size[1]\n",
    ")\n",
    "# Expand the dimensions to match the model's input shape\n",
    "expanded_image = tf.expand_dims(resized_image, axis=0)\n",
    "# Evaluate the TensorFlow tensor and obtain the NumPy array\n",
    "resized_array = tf.keras.backend.eval(expanded_image)\n",
    "normalized_image = resized_array / 255.0\n",
    "x = model.predict(normalized_image)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d803ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "dfa8568f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.2788095e-01, 2.7207914e-01, 3.9928880e-05]], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f1f519a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "11\n",
      "34\n",
      "55\n",
      "58\n",
      "71\n",
      "83\n",
      "162\n",
      "182\n",
      "324\n",
      "359\n",
      "375\n",
      "389\n",
      "410\n",
      "456\n",
      "479\n",
      "507\n",
      "509\n",
      "520\n",
      "602\n",
      "610\n",
      "642\n",
      "644\n",
      "668\n",
      "715\n",
      "734\n",
      "809\n",
      "827\n",
      "838\n",
      "842\n",
      "853\n",
      "882\n",
      "896\n",
      "908\n",
      "944\n",
      "945\n",
      "1058\n",
      "1065\n",
      "1157\n",
      "1166\n",
      "1171\n",
      "1175\n",
      "1186\n",
      "1277\n",
      "1280\n",
      "1352\n",
      "1466\n",
      "1541\n",
      "1556\n",
      "1558\n",
      "1561\n",
      "1581\n",
      "1598\n",
      "1611\n",
      "1682\n",
      "1715\n",
      "1740\n",
      "1789\n",
      "1790\n",
      "1812\n",
      "1851\n",
      "1881\n",
      "1889\n",
      "1940\n",
      "1948\n",
      "1977\n",
      "2068\n",
      "2129\n",
      "2141\n",
      "2182\n",
      "2195\n",
      "2255\n",
      "2264\n",
      "2312\n",
      "2357\n",
      "2394\n",
      "2417\n",
      "2530\n",
      "2539\n",
      "2562\n",
      "2580\n",
      "2601\n",
      "2605\n",
      "2613\n",
      "2659\n",
      "2825\n",
      "2843\n",
      "2904\n",
      "2954\n",
      "3046\n",
      "3063\n",
      "3126\n",
      "3148\n",
      "3152\n",
      "3185\n",
      "3196\n",
      "3197\n",
      "3220\n",
      "3286\n",
      "3292\n",
      "3312\n",
      "3361\n",
      "3382\n",
      "3425\n",
      "3428\n",
      "3446\n",
      "3451\n",
      "3478\n",
      "3482\n",
      "3501\n",
      "3515\n",
      "3566\n",
      "3579\n",
      "3601\n",
      "3710\n",
      "3722\n",
      "3727\n",
      "3753\n",
      "3757\n",
      "3777\n",
      "3788\n",
      "3809\n",
      "3827\n",
      "3881\n",
      "3889\n",
      "3897\n",
      "3927\n",
      "3961\n",
      "3992\n",
      "4038\n",
      "4049\n",
      "4062\n",
      "4218\n",
      "4361\n",
      "4392\n",
      "4404\n",
      "4479\n",
      "4554\n",
      "4570\n",
      "4590\n",
      "4810\n",
      "4887\n",
      "4942\n",
      "4955\n",
      "4987\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(res)\n",
    "correct_predictions = 0\n",
    "class_1_count = 0\n",
    "num = 2\n",
    "for i in range(total_samples):\n",
    "    if test[i] == num:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "03133f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd83d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "899ed44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming you have a Keras model named \"model\"\n",
    "model.save(\"single_image_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22da3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00c417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2f255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
