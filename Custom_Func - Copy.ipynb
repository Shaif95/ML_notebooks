{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acba090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import keras\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM,Flatten, TimeDistributed, Conv2D, Dropout\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa13c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf0822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D,Reshape, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeab214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.callbacks import Callback,ModelCheckpoint\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    tn = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1-y_true) * (y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip((y_true) * (1-y_pred), 0, 1)))\n",
    "    \n",
    "\n",
    "    f1_val = tp / ( tp + ( (1/2) * (fp+fn) ) + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a504b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2775.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "trn1='data/invasive-aquatic-species-data/invasive/*/'\n",
    "trn2='data/invasive-aquatic-species-data/noninvasive/*/'\n",
    "tr1= glob(trn1)\n",
    "tr2= glob(trn2)\n",
    "tr1= shuffle(tr1)\n",
    "tr2= shuffle(tr2)\n",
    "\n",
    "tran_index_inv = np.round( len(tr1)* .75 )\n",
    "tran_index_noninv = np.round( len(tr2)* .75  )\n",
    "tran_index_noninv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c51980",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[:(int) (tran_index_inv)]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[:(int) (tran_index_noninv)]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[:(int) (tran_index_inv)])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr2[:(int) (tran_index_noninv)])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((15, 15))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(15,15,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_train = idata\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train),15,15,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079c6d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3281, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "train_df= []\n",
    "breath = 6\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*6+k)\n",
    "        \n",
    "        deff.append(X_train[index])\n",
    "        \n",
    "    train_df.append(deff)\n",
    "\n",
    "Y_train = to_categorical(label)\n",
    "train_df = np.array(train_df)\n",
    "train_df,Y_train = shuffle(train_df,Y_train)\n",
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d262b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "breath = []\n",
    "total = 0\n",
    "\n",
    "for j in tr1[(int) (tran_index_inv) + 1 :]:\n",
    "    label.append(1)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a))\n",
    "    total = total + len(a)\n",
    "    \n",
    "for j in tr2[ (int)(tran_index_noninv) + 1:]:\n",
    "    label.append(0)\n",
    "    a = glob(j+'/*')\n",
    "    breath.append(len(a)) \n",
    "    total = total + len(a)\n",
    "\n",
    "for j in range(0,len(tr1[(int) (tran_index_inv) + 1 :])):\n",
    "    a = glob(tr1[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])\n",
    "\n",
    "for j in range(0,len(tr2[ (int)(tran_index_noninv) + 1:])):\n",
    "    a = glob(tr2[j]+'/*')\n",
    "    for k in range(0,6):\n",
    "        data.append(a[k])        \n",
    "        \n",
    "\n",
    "imgdata=[]\n",
    "for i in range(len(data)):\n",
    "    a = Image.open(data[i])\n",
    "    b = a.resize((15, 15))\n",
    "    c = np.array(b)\n",
    "    imgdata.append(c.reshape(15,15,3))\n",
    "    \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "idata = np.array(imgdata)\n",
    "X_test = idata\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_test = np.reshape(X_test, (len(X_test),15,15,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661c2759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1091, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end= 0\n",
    "test_df= []\n",
    "breath = 6\n",
    "\n",
    "i = 0\n",
    "for i in range(0, len(label)):\n",
    "    deff = []\n",
    "    for k in range(0, (breath)):\n",
    "        \n",
    "        index = (i*6+k)\n",
    "        \n",
    "        deff.append(X_test[index])\n",
    "        \n",
    "    test_df.append(deff)\n",
    "    \n",
    "Y_test = to_categorical(label)\n",
    "test_df = np.array(test_df)\n",
    "test_df,Y_test = shuffle(test_df,Y_test)\n",
    "np.shape(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c507ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3062, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52b5cc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6561, 6, 15, 15, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "new_train= []\n",
    "rand_df  = []\n",
    "\n",
    "new_y = []\n",
    "\n",
    "rand_y = []\n",
    "\n",
    "for i in range(1,len(train_df)):\n",
    "    \n",
    "    X = train_df[i]\n",
    "    res = np.take(X,np.random.permutation(X.shape[0]),axis=0,out=X)\n",
    "    rand_df.append(res)\n",
    "    rand_y.append(Y_train[i])\n",
    "    \n",
    "new_train = np.concatenate( [ train_df,rand_df ] , axis=0)\n",
    "new_y = np.concatenate( [ Y_train , rand_y ] )\n",
    "from sklearn.utils import shuffle\n",
    "X , Y = shuffle( new_train , new_y ) \n",
    "np.shape(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c674b1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6123, 2)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31947b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc77872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 6, 15, 15, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 6, 675)       0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 6, 256)       173056      time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder_6 (PatchEncoder)  (None, 6, 128)       33664       time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 6, 128)       256         patch_encoder_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 6, 128)       66048       layer_normalization_5[0][0]      \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 6, 128)       0           multi_head_attention_2[0][0]     \n",
      "                                                                 patch_encoder_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 6, 128)       256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 128)          131584      layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 6, 128)       0           sequential_2[0][0]               \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 6, 128)       256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 100)          91600       layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            202         lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 496,922\n",
      "Trainable params: 496,922\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "inputs = layers.Input(shape= (6,15,15,3) )\n",
    "\n",
    "x = (TimeDistributed( Flatten() )) (inputs)\n",
    "y = TimeDistributed(layers.Dense(units=256, activation=\"tanh\")) (x)\n",
    "\n",
    "encoded_patches = (PatchEncoder(6, 128 )) (y)\n",
    "\n",
    "for _ in range(1):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=1, key_dim=128, dropout=0.1 )  (x1, x1)\n",
    "\n",
    "        \n",
    "    x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(LSTM(128,return_sequences=False,dropout=0.2) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = LSTM(100,return_sequences=False,dropout=0.2)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=2, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26057200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 6, 15, 15, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 6, 13, 13, 4) 112         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 6, 6, 6, 4)   0           time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, 6, 144)       0           time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                  (None, 6, 128)       139776      time_distributed_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder_8 (PatchEncoder)  (None, 6, 128)       17280       lstm_29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_49 (LayerNo (None, 6, 128)       256         patch_encoder_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_21 (MultiH (None, 6, 128)       66048       layer_normalization_49[0][0]     \n",
      "                                                                 layer_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 6, 128)       0           multi_head_attention_21[0][0]    \n",
      "                                                                 patch_encoder_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_50 (LayerNo (None, 6, 128)       256         add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sequential_21 (Sequential)      (None, 128)          131584      layer_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 6, 128)       0           sequential_21[0][0]              \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_51 (LayerNo (None, 6, 128)       256         add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  (None, 100)          91600       layer_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 2)            202         lstm_31[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 447,370\n",
      "Trainable params: 447,370\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "inputs = layers.Input(shape= (6,15,15,3) )\n",
    "\n",
    "x =  TimeDistributed( Conv2D(4, (3, 3), strides=(1,1),activation='relu') ) (inputs)\n",
    "\n",
    "y = TimeDistributed(MaxPooling2D(2,2)) (x)\n",
    "\n",
    "w = (TimeDistributed( Flatten() )) (y)\n",
    "\n",
    "z = LSTM(128,return_sequences=True,dropout=0.2) (w)\n",
    "\n",
    "encoded_patches = (PatchEncoder(6, 128 )) (z)\n",
    "\n",
    "for _ in range(1):\n",
    "    \n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "    attention_output = layers.MultiHeadAttention (  num_heads=1, key_dim=128, dropout=0.1 )  (x1, x1)\n",
    "\n",
    "        \n",
    "    x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "    x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "\n",
    "    x3 = keras.Sequential(LSTM(128,return_sequences=False,dropout=0.2) )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "    encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "representation = LSTM(100,return_sequences=False,dropout=0.2)(representation)\n",
    "\n",
    "outputs = layers.Dense(units=2, activation=\"softmax\") ( representation)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262812d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2676f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_df,Y_train,validation_split=0.2,batch_size=32,epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef7bac82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[902,  12],\n",
       "       [ 22, 155]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y_test[:2000]\n",
    "pred = model.predict(test_df[:2000])\n",
    "p = np.round(pred)\n",
    "f1 = get_f1(Y_test, p)\n",
    "f1\n",
    "\n",
    "y_p = []\n",
    "for i in range(len(p)):\n",
    "    if ( p[i][0] == 0 ):\n",
    "        y_p.append(1)\n",
    "    else :\n",
    "        y_p.append(0)\n",
    "y_p = np.array(y_p)\n",
    "y_t = []\n",
    "for i in range(len(Y_test)):\n",
    "    if ( Y_test[i][0] == 0 ):\n",
    "        y_t.append(1)\n",
    "    else :\n",
    "        y_t.append(0)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "a=(confusion_matrix(y_t, y_p , labels=[0,1]))\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b4d89f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9011627906976745"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = a[1][1]/(((a[0][1]+a[1][0])/2)+a[1][1])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36be08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cf3e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cc7dc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 15, 15, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f4f081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 15  # We'll resize input images to this size\n",
    "patch_size = 15  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 128\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6b82757",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(6,15,15,3)) \n",
    "patches = TimeDistributed(Flatten()) (inputs)\n",
    "en = PatchEncoder(6, projection_dim)(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "28803bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 6, 128])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf326e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60360ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6aa5b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_50 (TimeDi  (None, 6, 13, 13, 16)    448       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_51 (TimeDi  (None, 6, 6, 6, 16)      0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_52 (TimeDi  (None, 6, 4, 4, 8)       1160      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_53 (TimeDi  (None, 6, 2, 2, 8)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_54 (TimeDi  (None, 6, 32)            0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " patch_encoder_9 (PatchEncod  (None, 6, 64)            2496      \n",
      " er)                                                             \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100)               66000     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,698\n",
      "Trainable params: 76,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\n",
    "from keras import models\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "model= models.Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), strides=(1,1),activation='relu'),input_shape=(6, 15, 15, 3)))\n",
    "model.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "model.add(TimeDistributed(Conv2D(8, (3, 3), strides=(1,1),activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(2,2)))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(PatchEncoder(6, 64 )) \n",
    "\n",
    "model.add(LSTM(100,return_sequences=False,dropout=0.2)) # used 32 units \n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6df61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75542c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199466a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3eb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257102bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
